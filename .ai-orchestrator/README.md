# AI Orchestrator

Hierarchical LLM orchestration system that optimizes costs by using smart models (Codex/Opus) for planning and cheap models (GLM 4.7) for execution.

## ğŸ¯ Purpose

Stretch your AI coding budget by:
- Using **GPT-5.1-Codex-Max** for strategic planning and decision-making
- Delegating routine work to **GLM 4.7** (10x cheaper)
- Coordinating everything through **Vibe Kanban** via MCP

## ğŸ“‹ Features

- **Task Classification**: Automatically analyzes complexity (1-5 scale)
- **Smart Delegation**: Routes tasks to appropriate models
- **Task Breakdown**: Decomposes complex work into subtasks
- **Vibe Kanban Integration**: Creates and manages tasks via MCP
- **GLM Workers**: Automated workers that claim and execute tasks
- **Quality Control**: Codex reviews all GLM outputs

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
cd .ai-orchestrator
npm install
```

### 2. Configure Vibe Kanban MCP

Make sure Vibe Kanban MCP is configured in your Claude/MCP config:

```json
{
  "mcpServers": {
    "vibe-kanban": {
      "command": "npx",
      "args": ["-y", "vibe-kanban@latest", "--mcp"]
    }
  }
}
```

### 3. Use the Orchestrator

```bash
# Create a new task (analyze and delegate)
npm run orchestrate "Add user authentication to the app"

# Create and auto-start tasks
npm run orchestrate "Implement user profile page" --auto-start

# Check task status
npm run status
```

### 4. Start GLM Workers

```bash
# Start a GLM worker (in a separate terminal)
npm run worker
```

## ğŸ“Š How It Works

### Task Classification

```
Complexity 1-2 â†’ GLM 4.7 (simple, well-defined)
Complexity 3-4 â†’ Codex (medium complexity)
Complexity 5   â†’ Opus Pro (architecture, security)
```

### Example Workflow

```
You: "Add user authentication with login, registration, and password reset"

â†“ Codex analyzes (complexity: 4/5)

â†“ Creates 5 tasks in Vibe Kanban:
  1. Set up database schema (GLM)
  2. Registration endpoint (GLM)
  3. Login endpoint (GLM)
  4. Password reset flow (GLM)
  5. Security review (Codex)

â†“ GLM workers claim tasks 1-4

â†“ Codex reviews outputs

â†“ You approve final results
```

## ğŸ¨ Usage Examples

### Example 1: Simple Task

```bash
npm run orchestrate "Write unit tests for the auth module"
```

**Result:** Creates 1 GLM task for writing tests.

### Example 2: Medium Complexity

```bash
npm run orchestrate "Add user profile page with avatar upload"
```

**Result:** Creates 3-4 tasks mixed between GLM and Codex.

### Example 3: Complex Feature

```bash
npm run orchestrate "Implement real-time chat with WebSocket and online status"
```

**Result:** Creates 5-7 tasks with Codex handling architecture and GLM handling implementation.

## ğŸ“ Project Structure

```
.ai-orchestrator/
â”œâ”€â”€ orchestrator/
â”‚   â”œâ”€â”€ index.ts           # Main orchestrator
â”‚   â”œâ”€â”€ classifier.ts      # Task classification
â”‚   â”œâ”€â”€ task-generator.ts  # Task breakdown
â”‚   â””â”€â”€ mcp-client.ts      # Vibe Kanban wrapper
â”œâ”€â”€ workers/
â”‚   â””â”€â”€ glm-worker.ts      # GLM worker loop
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.ts        # Configuration & prompts
â”œâ”€â”€ types/
â”‚   â””â”€â”€ index.d.ts         # TypeScript definitions
â””â”€â”€ package.json
```

## âš™ï¸ Configuration

### Environment Variables

```bash
# Optional: Set Vibe Kanban project ID
export VIBE_KANBAN_PROJECT_ID="your-project-id"

# Optional: Override model settings
export ORCHESTRATOR_MODEL="gpt-5.1-codex-max"
export WORKER_MODEL="glm-4.7"
```

### Worker Configuration

Edit `config/settings.ts` to customize:

```typescript
export const DEFAULT_WORKER_CONFIG = {
  model: 'glm',
  pollingInterval: 5000,      // Check for tasks every 5 seconds
  maxConcurrentTasks: 1,      // Only work on 1 task at a time
};
```

## ğŸ”§ Development

### Build

```bash
npm run build
```

### Run with TypeScript

```bash
npm run dev
```

## ğŸ“ˆ Cost Savings

### Without Orchestrator
- All tasks: GPT-5.1-Codex-Max ($$$)
- 100 tasks Ã— $0.50 = **$50**

### With Orchestrator
- Planning (10%): Codex = $5
- Execution (70%): GLM = $7
- Review (20%): Codex = $10
- **Total: $22 (56% savings)**

## ğŸš¦ Roadmap

- [ ] Real GLM API integration (currently simulated)
- [ ] Multi-worker parallelization
- [ ] Metrics and cost tracking dashboard
- [ ] Automatic retry on failures
- [ ] Integration with other MCP servers
- [ ] Web UI for task monitoring

## ğŸ¤ Contributing

This is a prototype. Contributions welcome!

## ğŸ“„ License

MIT

## ğŸ™ Acknowledgments

- Built with [Vibe Kanban](https://www.vibekanban.com/)
- Uses Model Context Protocol (MCP)
- Inspired by hierarchical agent systems
