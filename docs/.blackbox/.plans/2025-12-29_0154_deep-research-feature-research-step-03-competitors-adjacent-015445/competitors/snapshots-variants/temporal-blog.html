<!doctype html>
<html lang="en">
  <head>
<meta name="sentry-trace" content="d49338ecf8bba5bf23544c1eca908622-511d4ae8f38515d8-1"/>
<meta name="baggage" content="sentry-environment=production,sentry-release=a6eb27a159237baba60849e5f3a1042346cf77ff,sentry-public_key=cc6a5395b63b8e0fbc289939feb5a883,sentry-trace_id=d49338ecf8bba5bf23544c1eca908622,sentry-transaction=GET%20%2F(site)%2Fblog,sentry-sampled=true,sentry-sample_rand=0.9365930585193984,sentry-sample_rate=1"/>
    <meta charset="utf-8" />
    <meta name="referrer" content="strict-origin" />
    <link rel="icon" href="/favicon.ico" sizes="any" />
    <link rel="icon" href="/favicon.svg" type="image/svg+xml" />

    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
    <link rel="manifest" href="/site.webmanifest" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script>
      window.dataLayer = window.dataLayer || [];

      function gtag(_config, _arg) {
        window.dataLayer.push(arguments);
      }
      window.gtag = gtag;
      gtag('js', new Date());
    </script>
    
		<link href="./_app/immutable/assets/app.STUlqNf5.css" rel="stylesheet">
		<link href="./_app/immutable/assets/6.J9zCA1Ty.css" rel="stylesheet">
		<link href="./_app/immutable/assets/button.Dy9Asrd8.css" rel="stylesheet">
		<link href="./_app/immutable/assets/grid.DPPQ1WPg.css" rel="stylesheet">
		<link href="./_app/immutable/assets/marketo-form.Cb0DaIwE.css" rel="stylesheet">
		<link href="./_app/immutable/assets/input.CGiEVQgT.css" rel="stylesheet">
		<link href="./_app/immutable/assets/textarea.xpX1Xb3c.css" rel="stylesheet">
		<link href="./_app/immutable/assets/combobox.B_Q9AU7w.css" rel="stylesheet">
		<link href="./_app/immutable/assets/text.C3kTaalJ.css" rel="stylesheet">
		<link href="./_app/immutable/assets/rich-text.Cr_g9Ixj.css" rel="stylesheet">
		<link href="./_app/immutable/assets/44.BEyZBevh.css" rel="stylesheet">
		<link href="./_app/immutable/assets/blog-categories.DclEYvnp.css" rel="stylesheet">
		<link href="./_app/immutable/assets/blog-header.q0dihVG6.css" rel="stylesheet">
		<link href="./_app/immutable/assets/blog-list-item.DhmjF6I1.css" rel="stylesheet">
		<link href="./_app/immutable/assets/blog-news.Bt5lTuiX.css" rel="stylesheet">
		<link href="./_app/immutable/assets/promo-block.DI1HrkRh.css" rel="stylesheet">
		<link href="./_app/immutable/assets/testimonial.CJKGIPCP.css" rel="stylesheet">
		<link rel="modulepreload" href="./_app/immutable/entry/start.xLoUKPxz.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/BPzA0-m5.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Be1JIKtj.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/BtTb8AYv.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/qkQZYKtV.js">
		<link rel="modulepreload" href="./_app/immutable/entry/app.CK5js4Bx.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/B24f9B0Q.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/mr0YOyrm.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/DcNLC1P4.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/C5mHMe1F.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/C176ICMI.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/CWwtOSI6.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/BjrqUVVS.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/BkU_-Nox.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/DGqQs2tP.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/zZWBCT7w.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/OUudluyz.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/BBNryIa2.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/QAwk5eMo.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/0.DHT3IwJA.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/BlLcJS7J.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/6.DKnwE7lD.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/DB7ilGOW.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/D0NgJoX8.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/3H6s-xN0.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/8f7yMGqn.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/DRhuC0kj.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Bxrogtur.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/DZuMsmQU.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/CCcb_TdZ.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/3NZtHC0a.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/oyC9_8of.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/w9xMNxK0.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/D5G6LORH.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/rEU276hS.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/C-ED6kW1.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/DifxaVtv.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/rxV93Kph.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Bjq8ebsS.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/DZb3Dula.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/BJYyTwrJ.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/DTFnCF6D.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/k1CWVeB8.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/B772BOTw.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/DC2WtJ9v.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/44.CjKT8WDD.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/B7No-b5B.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/DBcq1Q5c.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/BjrgA4Qi.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Bh8mKtdL.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/BAJDjLU3.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Dlw6b5YF.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/CeJc9e-g.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/DlqYzoSz.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/D9tMKq79.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/CeqNXuG1.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Cb2Vk4Xr.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/yuCyOyWW.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/CmLUH_IQ.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/DHdMuXTR.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/8ijPPAzF.js"><!--[--><link rel="alternate" type="application/rss+xml" href="https://temporal.io/blog/feed.xml"><!--]--><!--[--><meta property="og:image" content="https://temporal.io/images/open-graph/shiny.png"><!--]--><!--[--><!--[--><!--]--> <!--[--><meta name="description" content="Read current articles covering Durable Execution, Temporal Cloud, workflow examination, and open-source news. Stay in the know about Temporal Technologies."><!--]--> <!--[--><link rel="canonical" href="https://temporal.io/blog"><!--]--> <!--[--><meta name="keywords" content="Blog"><!--]--> <!--[!--><!--]--> <!--[!--><!--]--> <!--[!--><!--]--> <!--[!--><!--]--> <!--[!--><!--]--> <!--[!--><!--]--> <!--[!--><!--]--> <meta name="robots" content="index,follow"> <meta name="googlebot" content="index,follow"> <!--[!--><!--]--> <!--[!--><!--]--> <!--[!--><!--]--> <!--[--><!--[--><!--[--><!--[--><meta property="og:url" content="https://temporal.io/blog"><!--]--> <!--[!--><!--]--><!--[--><meta property="og:title" content="Blog"><!--]--> <!--[!--><!--]--><!--[--><meta property="og:description" content="Read current articles covering Durable Execution, Temporal Cloud, workflow examination, and open-source news. Stay in the know about Temporal Technologies."><!--]--> <!--[!--><!--]--><!--[!--><!--]--> <!--[--><!--[--><!--[--><!--[--><meta property="og:image:url" content="https://temporal.io/images/open-graph/shiny.png"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Temporal Open Graph Image"><meta property="og:image:type" content="image/png"><!--]--><!--]--><!--]--><!--]--><!--]--><!--]--><!--]--> <!--[!--><!--]--> <!----><!----><!--]--><!--[--><!--[!--><!--]--><!--]--><title>Blog | Temporal</title>
  </head>
  <!--
    data-sveltekit-preload-data="hover" causes false logouts and redirects from the SSU layout when hovering over the link to SSU in the main nav
  -->
  <body data-sveltekit-preload-data="tap" data-sveltekit-preload-code="hover">
    <div style="display: contents; height: 100%"><!--[--><!--[--><!----><!--[--><!----><div class="overflow-x-clip"><!--[!--><!--]--><!----> <nav class="site-nav site-nav-lg svelte-h6n85t"><a href="/" aria-label="Home"><img src="/images/logos/logo-temporal-with-copy-white-text.svg" alt="Temporal Logo"></a> <span class="xl:hidden"><!----><button role="button" href="" class="button group w-fit ghost center off-white svelte-w4bvtf svelte-w4bvtf"><!--[!--><!--[--><!--[--><svg width="24" height="24" class="transition-colors text-off-white group-hover:text-blue-gray-300" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" role="img" data-contentful-entry-id="" data-contentful-field-id=""><!----><!----><path d="M1 2.5H23V4.9375H1V2.5ZM1 10.625H23V13.0625H1V10.625ZM23 18.75V21.1875H1V18.75H23Z" fill="currentcolor"></path><!----><!----><defs><linearGradient id="mist-68b2bf9c-3ab4-4dfb-8635-0e8ca1050b35"><stop offset="0%" stop-color="#34D399"></stop><stop offset="100%" stop-color="#FF6BFF"></stop></linearGradient><linearGradient id="green-gradient-68b2bf9c-3ab4-4dfb-8635-0e8ca1050b35"><stop offset="0%" stop-color="#C3FF62"></stop><stop offset="100%" stop-color="#1FF1A5"></stop></linearGradient><linearGradient id="pink-gradient-68b2bf9c-3ab4-4dfb-8635-0e8ca1050b35"><stop offset="0%" stop-color="#FF5555"></stop><stop offset="100%" stop-color="#B664FF"></stop></linearGradient><linearGradient id="purple-ultraviolet-gradient-68b2bf9c-3ab4-4dfb-8635-0e8ca1050b35"><stop offset="0%" stop-color="#B664FF"></stop><stop offset="100%" stop-color="#444CE7"></stop></linearGradient></defs></svg><!--]--><!--]--><!--]--> <!----><!----> <!--[!--><!--]--><!----></button><!----><!----></span> <ul class="links links-lg svelte-h6n85t"><!--[--><!--[!--><!--[--><li class="nav-link-group-xl group svelte-e5yg6k">Platform <ul class="sub-nav svelte-e5yg6k"><!--[--><li class="nav-link svelte-e5yg6k"><a href="/product" class="svelte-e5yg6k ">Overview</a></li><li class="nav-link svelte-e5yg6k"><a href="/how-it-works" class="svelte-e5yg6k ">How Temporal Works</a></li><li class="nav-link svelte-e5yg6k"><a href="/cloud" class="svelte-e5yg6k ">Temporal Cloud</a></li><li class="nav-link svelte-e5yg6k"><a href="/security" class="svelte-e5yg6k ">Security</a></li><!--]--></ul></li> <li class="nav-link-group-max-xl svelte-e5yg6k"><button class="sub-nav-trigger svelte-e5yg6k">Platform <!--[--><svg width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" role="img" data-contentful-entry-id="" data-contentful-field-id=""><!----><!----><path d="M13.25 13.25V22H10.75V13.25H2V10.75H10.75V2H13.25V10.75H22V13.25H13.25Z" fill="currentcolor" fill-rule="evenodd" clip-rule="evenodd"></path><!----><!----><defs><linearGradient id="mist-3ecddcf2-899b-4bac-9520-12fd65f6b785"><stop offset="0%" stop-color="#34D399"></stop><stop offset="100%" stop-color="#FF6BFF"></stop></linearGradient><linearGradient id="green-gradient-3ecddcf2-899b-4bac-9520-12fd65f6b785"><stop offset="0%" stop-color="#C3FF62"></stop><stop offset="100%" stop-color="#1FF1A5"></stop></linearGradient><linearGradient id="pink-gradient-3ecddcf2-899b-4bac-9520-12fd65f6b785"><stop offset="0%" stop-color="#FF5555"></stop><stop offset="100%" stop-color="#B664FF"></stop></linearGradient><linearGradient id="purple-ultraviolet-gradient-3ecddcf2-899b-4bac-9520-12fd65f6b785"><stop offset="0%" stop-color="#B664FF"></stop><stop offset="100%" stop-color="#444CE7"></stop></linearGradient></defs></svg><!--]--><!----></button> <!--[!--><!--]--></li><!--]--><!--]--><!--[--><li class="nav-link svelte-e5yg6k"><a href="https://docs.temporal.io/" target="_blank" class="svelte-e5yg6k ">Docs</a></li><!--]--><!--[--><li class="nav-link svelte-e5yg6k"><a href="/pricing" class="svelte-e5yg6k ">Pricing</a></li><!--]--><!--[!--><!--[--><li class="nav-link-group-xl group svelte-e5yg6k">Use Cases <ul class="sub-nav svelte-e5yg6k"><!--[--><li class="nav-link svelte-e5yg6k"><a href="/in-use" class="svelte-e5yg6k ">Customer Stories</a></li><li class="nav-link svelte-e5yg6k"><a href="/solutions/ai" class="svelte-e5yg6k ">AI</a></li><li class="nav-link svelte-e5yg6k"><a href="/solutions/financial-services" class="svelte-e5yg6k ">Financial Services</a></li><li class="nav-link svelte-e5yg6k"><a href="/solutions/platform-engineering" class="svelte-e5yg6k ">Platform Engineering</a></li><!--]--></ul></li> <li class="nav-link-group-max-xl svelte-e5yg6k"><button class="sub-nav-trigger svelte-e5yg6k">Use Cases <!--[--><svg width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" role="img" data-contentful-entry-id="" data-contentful-field-id=""><!----><!----><path d="M13.25 13.25V22H10.75V13.25H2V10.75H10.75V2H13.25V10.75H22V13.25H13.25Z" fill="currentcolor" fill-rule="evenodd" clip-rule="evenodd"></path><!----><!----><defs><linearGradient id="mist-788966c7-6f7f-40eb-8ca8-2ed5a14b8b7b"><stop offset="0%" stop-color="#34D399"></stop><stop offset="100%" stop-color="#FF6BFF"></stop></linearGradient><linearGradient id="green-gradient-788966c7-6f7f-40eb-8ca8-2ed5a14b8b7b"><stop offset="0%" stop-color="#C3FF62"></stop><stop offset="100%" stop-color="#1FF1A5"></stop></linearGradient><linearGradient id="pink-gradient-788966c7-6f7f-40eb-8ca8-2ed5a14b8b7b"><stop offset="0%" stop-color="#FF5555"></stop><stop offset="100%" stop-color="#B664FF"></stop></linearGradient><linearGradient id="purple-ultraviolet-gradient-788966c7-6f7f-40eb-8ca8-2ed5a14b8b7b"><stop offset="0%" stop-color="#B664FF"></stop><stop offset="100%" stop-color="#444CE7"></stop></linearGradient></defs></svg><!--]--><!----></button> <!--[!--><!--]--></li><!--]--><!--]--><!--[!--><!--[--><li class="nav-link-group-xl group svelte-e5yg6k">Resources <ul class="sub-nav svelte-e5yg6k"><!--[--><li class="nav-link svelte-e5yg6k"><a href="/resources" class="svelte-e5yg6k ">Resource Library</a></li><li class="nav-link svelte-e5yg6k"><a href="https://learn.temporal.io" target="_blank" class="svelte-e5yg6k ">Learn Temporal</a></li><li class="nav-link svelte-e5yg6k"><a href="/community" class="svelte-e5yg6k ">Community</a></li><li class="nav-link svelte-e5yg6k"><a href="/code-exchange" class="svelte-e5yg6k ">Code Exchange</a></li><li class="nav-link svelte-e5yg6k"><a href="/blog" class="svelte-e5yg6k active">Blog</a></li><li class="nav-link svelte-e5yg6k"><a href="/startup" class="svelte-e5yg6k ">For Startups</a></li><li class="nav-link svelte-e5yg6k"><a href="/partners" class="svelte-e5yg6k ">Partners</a></li><li class="nav-link svelte-e5yg6k"><a href="/change-log" class="svelte-e5yg6k ">Change Log</a></li><!--]--></ul></li> <li class="nav-link-group-max-xl svelte-e5yg6k"><button class="sub-nav-trigger svelte-e5yg6k">Resources <!--[--><svg width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" role="img" data-contentful-entry-id="" data-contentful-field-id=""><!----><!----><path d="M13.25 13.25V22H10.75V13.25H2V10.75H10.75V2H13.25V10.75H22V13.25H13.25Z" fill="currentcolor" fill-rule="evenodd" clip-rule="evenodd"></path><!----><!----><defs><linearGradient id="mist-721f4397-dd75-463e-bc13-f685c15ad4c0"><stop offset="0%" stop-color="#34D399"></stop><stop offset="100%" stop-color="#FF6BFF"></stop></linearGradient><linearGradient id="green-gradient-721f4397-dd75-463e-bc13-f685c15ad4c0"><stop offset="0%" stop-color="#C3FF62"></stop><stop offset="100%" stop-color="#1FF1A5"></stop></linearGradient><linearGradient id="pink-gradient-721f4397-dd75-463e-bc13-f685c15ad4c0"><stop offset="0%" stop-color="#FF5555"></stop><stop offset="100%" stop-color="#B664FF"></stop></linearGradient><linearGradient id="purple-ultraviolet-gradient-721f4397-dd75-463e-bc13-f685c15ad4c0"><stop offset="0%" stop-color="#B664FF"></stop><stop offset="100%" stop-color="#444CE7"></stop></linearGradient></defs></svg><!--]--><!----></button> <!--[!--><!--]--></li><!--]--><!--]--><!--[--><li class="nav-link svelte-e5yg6k"><a href="https://replay.temporal.io" target="_blank" class="svelte-e5yg6k ">Replay 2026</a></li><!--]--><!--]--> <a class="gh-link svelte-h6n85t" href="https://github.com/temporalio" target="_blank"><!--[--><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" role="img" data-contentful-entry-id="" data-contentful-field-id=""><!----><!----><g clip-path="url(#clip0_1786_8386)"><path d="M8.15156 18.6281C8.15156 18.7219 8.04375 18.7969 7.90781 18.7969C7.75312 18.8109 7.64531 18.7359 7.64531 18.6281C7.64531 18.5344 7.75313 18.4594 7.88906 18.4594C8.02969 18.4453 8.15156 18.5203 8.15156 18.6281ZM6.69375 18.4172C6.66094 18.5109 6.75469 18.6187 6.89531 18.6469C7.01719 18.6937 7.15781 18.6469 7.18594 18.5531C7.21406 18.4594 7.125 18.3516 6.98438 18.3094C6.8625 18.2766 6.72656 18.3234 6.69375 18.4172ZM8.76562 18.3375C8.62969 18.3703 8.53594 18.4594 8.55 18.5672C8.56406 18.6609 8.68594 18.7219 8.82656 18.6891C8.9625 18.6562 9.05625 18.5672 9.04219 18.4734C9.02812 18.3844 8.90156 18.3234 8.76562 18.3375ZM11.85 0.375C5.34844 0.375 0.375 5.31094 0.375 11.8125C0.375 17.0109 3.64688 21.4594 8.32031 23.025C8.92031 23.1328 9.13125 22.7625 9.13125 22.4578C9.13125 22.1672 9.11719 20.5641 9.11719 19.5797C9.11719 19.5797 5.83594 20.2828 5.14688 18.1828C5.14688 18.1828 4.6125 16.8187 3.84375 16.4672C3.84375 16.4672 2.77031 15.7312 3.91875 15.7453C3.91875 15.7453 5.08594 15.8391 5.72812 16.9547C6.75469 18.7641 8.475 18.2437 9.14531 17.9344C9.25313 17.1844 9.55781 16.6641 9.89531 16.3547C7.275 16.0641 4.63125 15.6844 4.63125 11.175C4.63125 9.88594 4.9875 9.23906 5.7375 8.41406C5.61562 8.10938 5.21719 6.85312 5.85938 5.23125C6.83906 4.92656 9.09375 6.49688 9.09375 6.49688C10.0312 6.23438 11.0391 6.09844 12.0375 6.09844C13.0359 6.09844 14.0438 6.23438 14.9813 6.49688C14.9813 6.49688 17.2359 4.92188 18.2156 5.23125C18.8578 6.85781 18.4594 8.10938 18.3375 8.41406C19.0875 9.24375 19.5469 9.89062 19.5469 11.175C19.5469 15.6984 16.7859 16.0594 14.1656 16.3547C14.5969 16.725 14.9625 17.4281 14.9625 18.5297C14.9625 20.1094 14.9484 22.0641 14.9484 22.4484C14.9484 22.7531 15.1641 23.1234 15.7594 23.0156C20.4469 21.4594 23.625 17.0109 23.625 11.8125C23.625 5.31094 18.3516 0.375 11.85 0.375ZM4.93125 16.5422C4.87031 16.5891 4.88438 16.6969 4.96406 16.7859C5.03906 16.8609 5.14687 16.8938 5.20781 16.8328C5.26875 16.7859 5.25469 16.6781 5.175 16.5891C5.1 16.5141 4.99219 16.4812 4.93125 16.5422ZM4.425 16.1625C4.39219 16.2234 4.43906 16.2984 4.53281 16.3453C4.60781 16.3922 4.70156 16.3781 4.73438 16.3125C4.76719 16.2516 4.72031 16.1766 4.62656 16.1297C4.53281 16.1016 4.45781 16.1156 4.425 16.1625ZM5.94375 17.8312C5.86875 17.8922 5.89687 18.0328 6.00469 18.1219C6.1125 18.2297 6.24844 18.2437 6.30937 18.1688C6.37031 18.1078 6.34219 17.9672 6.24844 17.8781C6.14531 17.7703 6.00469 17.7563 5.94375 17.8312ZM5.40938 17.1422C5.33437 17.1891 5.33437 17.3109 5.40938 17.4188C5.48438 17.5266 5.61094 17.5734 5.67188 17.5266C5.74687 17.4656 5.74687 17.3438 5.67188 17.2359C5.60625 17.1281 5.48438 17.0813 5.40938 17.1422Z" fill="currentcolor"></path></g><defs><clipPath id="clip0_1786_8386"><rect width="23.25" height="24" fill="white" transform="translate(0.375)"></rect></clipPath></defs><!----><!----><defs><linearGradient id="mist-8fc3a814-60cb-4de7-92c0-0eb8f5913029"><stop offset="0%" stop-color="#34D399"></stop><stop offset="100%" stop-color="#FF6BFF"></stop></linearGradient><linearGradient id="green-gradient-8fc3a814-60cb-4de7-92c0-0eb8f5913029"><stop offset="0%" stop-color="#C3FF62"></stop><stop offset="100%" stop-color="#1FF1A5"></stop></linearGradient><linearGradient id="pink-gradient-8fc3a814-60cb-4de7-92c0-0eb8f5913029"><stop offset="0%" stop-color="#FF5555"></stop><stop offset="100%" stop-color="#B664FF"></stop></linearGradient><linearGradient id="purple-ultraviolet-gradient-8fc3a814-60cb-4de7-92c0-0eb8f5913029"><stop offset="0%" stop-color="#B664FF"></stop><stop offset="100%" stop-color="#444CE7"></stop></linearGradient></defs></svg><!--]--><!----></a> <div class="flex items-center gap-2"><!--[--><!----><a role="link" href="/get-cloud" class="button group w-fit primary center ultraviolet svelte-w4bvtf svelte-w4bvtf" entityid="79w1QMsJg2MTAVGlu2jdss"><!--[!--><!--[!--><!--]--><!--]--> <!----><!---->Try Free<!----> <!--[!--><!--]--><!----></a><!----><!----><a role="link" target="_blank" href="https://cloud.temporal.io/" class="button group w-fit secondary center ultraviolet svelte-w4bvtf svelte-w4bvtf" entityid="KAPnScSjIJkz74RbczQ2F"><!--[!--><!--[!--><!--]--><!--]--> <!----><!---->Log In<!----> <!--[!--><!--]--><!----></a><!----><!--]--></div></ul></nav> <!--[!--><!--]--><!----> <!--[!--><!----><!----> <!--[--><!----><div class="grid grid-flow-col-dense sm:grid-cols-page sm:gap-x-4 max-sm:grid-cols-1 max-sm:px-5 max-sm:gap-y-4 bg-abstract-stars gap-y-4 sm:gap-y-6 lg:gap-y-0 py-8 lg:py-24 columns temporal-grid svelte-apxkwt " style=""><!----><!----><div class="max-sm:col-span-1 sm:col-span-10 max-sm:col-start-1 sm:col-start-3 col-span-10 col-start-3 lg:col-span-10 lg:col-start-3"><!----><div class="blog-header  none svelte-tv2tdr"><!--[!--><!--]--> <!--[--><h1 class="title svelte-tv2tdr">Blog</h1><!--]--> <!--[!--><!--]--> <!--[--><p class="mt-4 text-lg text-indigo-100">Read current articles covering Durable Execution, Temporal Cloud, workflow examination, and open-source news. Stay in the know about Temporal Technologies.</p><!--]--></div><!----><!----></div><!----><!----> <!----><div class="max-sm:col-span-1 sm:col-span-10 max-sm:col-start-1 sm:col-start-3 col-span-10 col-start-3 pr-0 lg:pr-8 lg:col-span-5 lg:col-start-3"><!----><a href="/blog/temporal-now-supports-swift"><!--[--><!--[!--><!--[--><picture><source type="image/avif" srcset="https://images.ctfassets.net/0uuz8ydxyd9p/6hgCN7R3WNZc6jMk8qCdCA/ff249585d66d7613501fa1046ebe289f/Blog-temporal-swift.png?w=696&amp;h=522&amp;fm=avif&amp;q=60&amp;fit=fill, https://images.ctfassets.net/0uuz8ydxyd9p/6hgCN7R3WNZc6jMk8qCdCA/ff249585d66d7613501fa1046ebe289f/Blog-temporal-swift.png?w=1044&amp;h=783&amp;fm=avif&amp;q=60&amp;fit=fill 1.5x, https://images.ctfassets.net/0uuz8ydxyd9p/6hgCN7R3WNZc6jMk8qCdCA/ff249585d66d7613501fa1046ebe289f/Blog-temporal-swift.png?w=696&amp;h=522&amp;fm=avif&amp;q=60&amp;fit=fill 2x"> <source type="image/webp" srcset="https://images.ctfassets.net/0uuz8ydxyd9p/6hgCN7R3WNZc6jMk8qCdCA/ff249585d66d7613501fa1046ebe289f/Blog-temporal-swift.png?w=696&amp;h=522&amp;fm=webp&amp;q=80&amp;fit=fill, https://images.ctfassets.net/0uuz8ydxyd9p/6hgCN7R3WNZc6jMk8qCdCA/ff249585d66d7613501fa1046ebe289f/Blog-temporal-swift.png?w=1044&amp;h=783&amp;fm=webp&amp;q=80&amp;fit=fill 1.5x, https://images.ctfassets.net/0uuz8ydxyd9p/6hgCN7R3WNZc6jMk8qCdCA/ff249585d66d7613501fa1046ebe289f/Blog-temporal-swift.png?w=696&amp;h=522&amp;fm=webp&amp;q=80&amp;fit=fill 2x"> <img width="696" height="522" src="https://images.ctfassets.net/0uuz8ydxyd9p/6hgCN7R3WNZc6jMk8qCdCA/ff249585d66d7613501fa1046ebe289f/Blog-temporal-swift.png?w=696&amp;h=522&amp;fm=jpg&amp;q=80&amp;fit=fill, https://images.ctfassets.net/0uuz8ydxyd9p/6hgCN7R3WNZc6jMk8qCdCA/ff249585d66d7613501fa1046ebe289f/Blog-temporal-swift.png?w=1044&amp;h=783&amp;fm=jpg&amp;q=80&amp;fit=fill 1.5x, https://images.ctfassets.net/0uuz8ydxyd9p/6hgCN7R3WNZc6jMk8qCdCA/ff249585d66d7613501fa1046ebe289f/Blog-temporal-swift.png?w=696&amp;h=522&amp;fm=jpg&amp;q=80&amp;fit=fill 2x" data-contentful-entry-id="lfaPhZa1NPPslttSljLit" data-contentful-field-id="image"></picture><!--]--><!--]--><!--]--><!----></a><!----><!----></div><!----><!----> <!----><div class="max-sm:col-span-1 sm:col-span-10 max-sm:col-start-1 sm:col-start-3 col-span-10 col-start-3 lg:col-span-5 lg:col-start-8"><!----><div class="flex flex-col gap-4 h-full justify-center"><div class="flex gap-4 uppercase mono items-center"><!----><p data-variant="body" data-size="16" class="text s16 body text-green-300 mono svelte-lrigwr"><!----><!---->FEATURED<!----><!----></p><!----><!----></div> <div class="title"><!----><h2 data-variant="display" data-size="52" class="text s52 display text-off-white svelte-lrigwr"><!----><a href="/blog/temporal-now-supports-swift">Use Swift with Temporal</a><!----><!----></h2><!----><!----></div> <div class="description"><!----><h3 data-variant="body" data-size="20" class="text s20 body text-indigo-100 svelte-lrigwr"><!----><a href="/blog/temporal-now-supports-swift">Announcing the Swift Temporal SDK. Build durable, fault-tolerant Workflows in Swift 6.2 with async/await and structured concurrency.</a><!----><!----></h3><!----><!----></div> <div class="button"><!----><a role="link" href="/blog/temporal-now-supports-swift" class="button group w-fit primary center pink-gradient mt-10 svelte-w4bvtf svelte-w4bvtf"><!--[!--><!--[!--><!--]--><!--]--> <!----><!---->Read post<!----> <!--[--><!--[--><svg width="24" height="24" class="transition-colors group-hover:text-pink-100" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" role="img" data-contentful-entry-id="" data-contentful-field-id=""><!----><!----><path d="M14 18L20 12M20 12L14 6M20 12L4 12" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" fill="currentcolor"></path><!----><!----><defs><linearGradient id="mist-c2f9b3b3-f487-4d3b-8c7f-3122fa2ec42a"><stop offset="0%" stop-color="#34D399"></stop><stop offset="100%" stop-color="#FF6BFF"></stop></linearGradient><linearGradient id="green-gradient-c2f9b3b3-f487-4d3b-8c7f-3122fa2ec42a"><stop offset="0%" stop-color="#C3FF62"></stop><stop offset="100%" stop-color="#1FF1A5"></stop></linearGradient><linearGradient id="pink-gradient-c2f9b3b3-f487-4d3b-8c7f-3122fa2ec42a"><stop offset="0%" stop-color="#FF5555"></stop><stop offset="100%" stop-color="#B664FF"></stop></linearGradient><linearGradient id="purple-ultraviolet-gradient-c2f9b3b3-f487-4d3b-8c7f-3122fa2ec42a"><stop offset="0%" stop-color="#B664FF"></stop><stop offset="100%" stop-color="#444CE7"></stop></linearGradient></defs></svg><!--]--><!--]--><!----></a><!----><!----></div></div><!----><!----></div><!----><!----><!----><!----></div><!----><!--]--> <!----><div class="grid grid-flow-col-dense sm:grid-cols-page sm:gap-x-4 max-sm:grid-cols-1 max-sm:px-5 max-sm:gap-y-4 bg-deep-blue lg:py-16 columns temporal-grid svelte-apxkwt " style=""><!----><!----><div class="max-sm:col-span-1 sm:col-span-10 max-sm:col-start-1 sm:col-start-3 col-span-10 col-start-3 lg:col-span-3 lg:col-start-3 flex flex-col pb-4"><!----><div class="sticky-container svelte-1xoib5v"><!----><div class="blog-categories-container justify-center svelte-1qj1ac2"><!--[--><!----><h3 data-variant="body" data-size="20" class="text s20 body hidden lg:block svelte-lrigwr"><!----><!---->Categories<!----><!----></h3><!----><!--]--> <ul class="category-list svelte-1qj1ac2"><!--[--><li class="category-list-item svelte-1qj1ac2"><a data-sveltekit-preload-data="" class="category svelte-1qj1ac2 " href="/blog">All <!--[-->(314)<!--]--></a></li><li class="category-list-item svelte-1qj1ac2"><a data-sveltekit-preload-data="" class="category svelte-1qj1ac2 " href="/blog/categories/announcements">Announcements <!--[-->(66)<!--]--></a></li><li class="category-list-item svelte-1qj1ac2"><a data-sveltekit-preload-data="" class="category svelte-1qj1ac2 " href="/blog/categories/community">Community <!--[-->(58)<!--]--></a></li><li class="category-list-item svelte-1qj1ac2"><a data-sveltekit-preload-data="" class="category svelte-1qj1ac2 " href="/blog/categories/how-to">How-To <!--[-->(70)<!--]--></a></li><li class="category-list-item svelte-1qj1ac2"><a data-sveltekit-preload-data="" class="category svelte-1qj1ac2 " href="/blog/categories/product-news">Product News <!--[-->(46)<!--]--></a></li><li class="category-list-item svelte-1qj1ac2"><a data-sveltekit-preload-data="" class="category svelte-1qj1ac2 " href="/blog/categories/temporal-concepts">Temporal Concepts <!--[-->(53)<!--]--></a></li><li class="category-list-item svelte-1qj1ac2"><a data-sveltekit-preload-data="" class="category svelte-1qj1ac2 " href="/blog/categories/temporal-voices">Temporal Voices <!--[-->(21)<!--]--></a></li><!--]--></ul> <!--[!--><!--]--></div><!----> <form class="shrink-0 flex items-center placeholder:text-subtle grow max-w-[500px] lg:max-w-[250px] h-10 border-2 border-subtle focus-within:ring-4 focus-within:ring-ultraviolet/75"><input class="w-full px-2 bg-transparent focus:outline-none" id="search" placeholder="Search..." value=""> <!--[!--><!--]--> <button type="submit" class="search-button svelte-1xoib5v"><!--[--><svg width="16" height="16" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" role="img" data-contentful-entry-id="" data-contentful-field-id=""><!----><!----><path d="M18.0706 9.76908C18.0706 6.85714 16.4706 4.13307 13.9294 2.63014C11.3412 1.17417 8.18824 1.17417 5.64706 2.63014C3.05882 4.13307 1.50588 6.85714 1.50588 9.76908C1.50588 12.728 3.05882 15.4521 5.64706 16.955C8.18824 18.411 11.3412 18.411 13.9294 16.955C16.4706 15.4521 18.0706 12.728 18.0706 9.76908ZM16.1412 17.1898C14.4471 18.6928 12.1882 19.5382 9.78824 19.5382C4.37647 19.5382 0 15.1703 0 9.76908C0 4.41487 4.37647 0 9.78824 0C15.1529 0 19.5765 4.41487 19.5765 9.76908C19.5765 12.2114 18.6824 14.4188 17.2235 16.1566L24 22.9198L22.9176 24L16.1412 17.1898Z" fill="currentcolor"></path><!----><!----><defs><linearGradient id="mist-faabdfd0-c661-4474-9e6d-328df98499c7"><stop offset="0%" stop-color="#34D399"></stop><stop offset="100%" stop-color="#FF6BFF"></stop></linearGradient><linearGradient id="green-gradient-faabdfd0-c661-4474-9e6d-328df98499c7"><stop offset="0%" stop-color="#C3FF62"></stop><stop offset="100%" stop-color="#1FF1A5"></stop></linearGradient><linearGradient id="pink-gradient-faabdfd0-c661-4474-9e6d-328df98499c7"><stop offset="0%" stop-color="#FF5555"></stop><stop offset="100%" stop-color="#B664FF"></stop></linearGradient><linearGradient id="purple-ultraviolet-gradient-faabdfd0-c661-4474-9e6d-328df98499c7"><stop offset="0%" stop-color="#B664FF"></stop><stop offset="100%" stop-color="#444CE7"></stop></linearGradient></defs></svg><!--]--><!----></button></form></div><!----><!----></div><!----><!----> <!----><!----><div class="max-sm:col-span-1 sm:col-span-10 max-sm:col-start-1 sm:col-start-3 col-span-10 col-start-3 lg:col-span-7 lg:col-start-6"><!----><!--[--><ul class="flex flex-wrap"><!--[--><li class="blog-list-item svelte-1un72ey" aria-label="Blog List Item tips-for-running-temporal-on-kubernetes"><a href="/blog/tips-for-running-temporal-on-kubernetes" class="svelte-1un72ey"><div class="list-item-content svelte-1un72ey"><div class="list-item-title svelte-1un72ey"><!--[!--><!----><h2 data-variant="heading" data-size="32" class="text s32 heading svelte-lrigwr"><!----><!---->Tips for running Temporal on Kubernetes<!----><!----></h2><!----><!--]--></div> <div class="list-item-body svelte-1un72ey"><!--[!--><!--]--> <!--[!--><!--]--></div> <div class="list-item-meta svelte-1un72ey"><div class="meta-primary svelte-1un72ey"><p class="svelte-1un72ey">Dec 15, 2025</p> <!--[--><p class="svelte-1un72ey">9 min</p><!--]--></div> <div class="meta-secondary svelte-1un72ey"><!--[--><!--[--><span class="list-item-tag svelte-1un72ey">Kubernetes</span><span class="list-item-tag svelte-1un72ey">Python</span><span class="list-item-tag svelte-1un72ey">Go</span><span class="list-item-tag svelte-1un72ey">Scaling</span><span class="list-item-tag svelte-1un72ey">Code Samples</span><!--]--><!--]--></div></div></div> <!--[--><div class="list-item-extra svelte-1un72ey"><p class="svelte-1un72ey">How-To</p></div><!--]--> <span class="arrow svelte-1un72ey"><span class="base svelte-1un72ey"></span> <span class="tip-top svelte-1un72ey"></span> <span class="tip-bottom svelte-1un72ey"></span></span></a></li><li class="blog-list-item svelte-1un72ey" aria-label="Blog List Item city-of-systems-temporal-kafka-nexus"><a href="/blog/city-of-systems-temporal-kafka-nexus" class="svelte-1un72ey"><div class="list-item-content svelte-1un72ey"><div class="list-item-title svelte-1un72ey"><!--[!--><!----><h2 data-variant="heading" data-size="32" class="text s32 heading svelte-lrigwr"><!----><!---->The city of systems: Temporal, Kafka, and Nexus<!----><!----></h2><!----><!--]--></div> <div class="list-item-body svelte-1un72ey"><!--[!--><!--]--> <!--[!--><!--]--></div> <div class="list-item-meta svelte-1un72ey"><div class="meta-primary svelte-1un72ey"><p class="svelte-1un72ey">Dec 10, 2025</p> <!--[--><p class="svelte-1un72ey">5 min</p><!--]--></div> <div class="meta-secondary svelte-1un72ey"><!--[--><!--[--><span class="list-item-tag svelte-1un72ey">Durable Execution</span><!--]--><!--]--></div></div></div> <!--[--><div class="list-item-extra svelte-1un72ey"><p class="svelte-1un72ey">Temporal Voices</p></div><!--]--> <span class="arrow svelte-1un72ey"><span class="base svelte-1un72ey"></span> <span class="tip-top svelte-1un72ey"></span> <span class="tip-bottom svelte-1un72ey"></span></span></a></li><li class="blog-list-item svelte-1un72ey" aria-label="Blog List Item aws-reinvent-2025-recap"><a href="/blog/aws-reinvent-2025-recap" class="svelte-1un72ey"><div class="list-item-content svelte-1un72ey"><div class="list-item-title svelte-1un72ey"><!--[!--><!----><h2 data-variant="heading" data-size="32" class="text s32 heading svelte-lrigwr"><!----><!---->AWS re:Invent 2025: Why the future of the cloud is durable<!----><!----></h2><!----><!--]--></div> <div class="list-item-body svelte-1un72ey"><!--[!--><!--]--> <!--[!--><!--]--></div> <div class="list-item-meta svelte-1un72ey"><div class="meta-primary svelte-1un72ey"><p class="svelte-1un72ey">Dec 04, 2025</p> <!--[--><p class="svelte-1un72ey">3 min</p><!--]--></div> <div class="meta-secondary svelte-1un72ey"><!--[--><!--[--><span class="list-item-tag svelte-1un72ey">Meetups</span><span class="list-item-tag svelte-1un72ey">Industry Events</span><span class="list-item-tag svelte-1un72ey">Durable Execution</span><!--]--><!--]--></div></div></div> <!--[--><div class="list-item-extra svelte-1un72ey"><p class="svelte-1un72ey">Community</p></div><!--]--> <span class="arrow svelte-1un72ey"><span class="base svelte-1un72ey"></span> <span class="tip-top svelte-1un72ey"></span> <span class="tip-bottom svelte-1un72ey"></span></span></a></li><li class="blog-list-item svelte-1un72ey" aria-label="Blog List Item introducing-the-temporal-constellation-program"><a href="/blog/introducing-the-temporal-constellation-program" class="svelte-1un72ey"><div class="list-item-content svelte-1un72ey"><div class="list-item-title svelte-1un72ey"><!--[!--><!----><h2 data-variant="heading" data-size="32" class="text s32 heading svelte-lrigwr"><!----><!---->Introducing the Temporal Constellation Program<!----><!----></h2><!----><!--]--></div> <div class="list-item-body svelte-1un72ey"><!--[!--><!--]--> <!--[!--><!--]--></div> <div class="list-item-meta svelte-1un72ey"><div class="meta-primary svelte-1un72ey"><p class="svelte-1un72ey">Dec 02, 2025</p> <!--[--><p class="svelte-1un72ey">6 min</p><!--]--></div> <div class="meta-secondary svelte-1un72ey"><!--[--><!--[--><span class="list-item-tag svelte-1un72ey">Contributions</span><span class="list-item-tag svelte-1un72ey">Code Samples</span><!--]--><!--]--></div></div></div> <!--[--><div class="list-item-extra svelte-1un72ey"><p class="svelte-1un72ey">Community</p></div><!--]--> <span class="arrow svelte-1un72ey"><span class="base svelte-1un72ey"></span> <span class="tip-top svelte-1un72ey"></span> <span class="tip-bottom svelte-1un72ey"></span></span></a></li><li class="blog-list-item svelte-1un72ey" aria-label="Blog List Item monitoring-temporal-cloud-workflows-with-grafana-cloud"><a href="/blog/monitoring-temporal-cloud-workflows-with-grafana-cloud" class="svelte-1un72ey"><div class="list-item-content svelte-1un72ey"><div class="list-item-title svelte-1un72ey"><!--[!--><!----><h2 data-variant="heading" data-size="32" class="text s32 heading svelte-lrigwr"><!----><!---->Monitoring Temporal Cloud Workflows with Grafana Cloud<!----><!----></h2><!----><!--]--></div> <div class="list-item-body svelte-1un72ey"><!--[!--><!--]--> <!--[!--><!--]--></div> <div class="list-item-meta svelte-1un72ey"><div class="meta-primary svelte-1un72ey"><p class="svelte-1un72ey">Nov 21, 2025</p> <!--[--><p class="svelte-1un72ey">3 min</p><!--]--></div> <div class="meta-secondary svelte-1un72ey"><!--[--><!--[--><span class="list-item-tag svelte-1un72ey">Observability</span><span class="list-item-tag svelte-1un72ey">Cloud</span><!--]--><!--]--></div></div></div> <!--[--><div class="list-item-extra svelte-1un72ey"><p class="svelte-1un72ey">Announcements</p></div><!--]--> <span class="arrow svelte-1un72ey"><span class="base svelte-1un72ey"></span> <span class="tip-top svelte-1un72ey"></span> <span class="tip-bottom svelte-1un72ey"></span></span></a></li><li class="blog-list-item svelte-1un72ey" aria-label="Blog List Item the-journey-to-shippable-ai-systems-patterns-that-work"><a href="/blog/the-journey-to-shippable-ai-systems-patterns-that-work" class="svelte-1un72ey"><div class="list-item-content svelte-1un72ey"><div class="list-item-title svelte-1un72ey"><!--[!--><!----><h2 data-variant="heading" data-size="32" class="text s32 heading svelte-lrigwr"><!----><!---->The journey to shippable AI systems: Patterns that work<!----><!----></h2><!----><!--]--></div> <div class="list-item-body svelte-1un72ey"><!--[!--><!--]--> <!--[!--><!--]--></div> <div class="list-item-meta svelte-1un72ey"><div class="meta-primary svelte-1un72ey"><p class="svelte-1un72ey">Nov 18, 2025</p> <!--[--><p class="svelte-1un72ey">4 min</p><!--]--></div> <div class="meta-secondary svelte-1un72ey"><!--[--><!--[--><span class="list-item-tag svelte-1un72ey">AI/ML</span><!--]--><!--]--></div></div></div> <!--[--><div class="list-item-extra svelte-1un72ey"><p class="svelte-1un72ey">Community</p></div><!--]--> <span class="arrow svelte-1un72ey"><span class="base svelte-1un72ey"></span> <span class="tip-top svelte-1un72ey"></span> <span class="tip-bottom svelte-1un72ey"></span></span></a></li><li class="blog-list-item svelte-1un72ey" aria-label="Blog List Item of-course-you-can-build-dynamic-ai-agents-with-temporal"><a href="/blog/of-course-you-can-build-dynamic-ai-agents-with-temporal" class="svelte-1un72ey"><div class="list-item-content svelte-1un72ey"><div class="list-item-title svelte-1un72ey"><!--[!--><!----><h2 data-variant="heading" data-size="32" class="text s32 heading svelte-lrigwr"><!----><!---->Of course you can build dynamic AI agents with Temporal<!----><!----></h2><!----><!--]--></div> <div class="list-item-body svelte-1un72ey"><!--[!--><!--]--> <!--[!--><!--]--></div> <div class="list-item-meta svelte-1un72ey"><div class="meta-primary svelte-1un72ey"><p class="svelte-1un72ey">Nov 12, 2025</p> <!--[--><p class="svelte-1un72ey">10 min</p><!--]--></div> <div class="meta-secondary svelte-1un72ey"><!--[--><!--[--><span class="list-item-tag svelte-1un72ey">Python</span><span class="list-item-tag svelte-1un72ey">Temporal Primitives</span><span class="list-item-tag svelte-1un72ey">AI/ML</span><span class="list-item-tag svelte-1un72ey">Architecture</span><span class="list-item-tag svelte-1un72ey">Code Samples</span><!--]--><!--]--></div></div></div> <!--[--><div class="list-item-extra svelte-1un72ey"><p class="svelte-1un72ey">Temporal Voices</p></div><!--]--> <span class="arrow svelte-1un72ey"><span class="base svelte-1un72ey"></span> <span class="tip-top svelte-1un72ey"></span> <span class="tip-bottom svelte-1un72ey"></span></span></a></li><li class="blog-list-item svelte-1un72ey" aria-label="Blog List Item temporal-now-supports-swift"><a href="/blog/temporal-now-supports-swift" class="svelte-1un72ey"><div class="list-item-content svelte-1un72ey"><div class="list-item-title svelte-1un72ey"><!--[!--><!----><h2 data-variant="heading" data-size="32" class="text s32 heading svelte-lrigwr"><!----><!---->Use Swift with Temporal<!----><!----></h2><!----><!--]--></div> <div class="list-item-body svelte-1un72ey"><!--[!--><!--]--> <!--[!--><!--]--></div> <div class="list-item-meta svelte-1un72ey"><div class="meta-primary svelte-1un72ey"><p class="svelte-1un72ey">Nov 10, 2025</p> <!--[--><p class="svelte-1un72ey">5 min</p><!--]--></div> <div class="meta-secondary svelte-1un72ey"><!--[--><!--[--><span class="list-item-tag svelte-1un72ey">Durable Execution</span><span class="list-item-tag svelte-1un72ey">Industry Events</span><!--]--><!--]--></div></div></div> <!--[--><div class="list-item-extra svelte-1un72ey"><p class="svelte-1un72ey">Announcements</p></div><!--]--> <span class="arrow svelte-1un72ey"><span class="base svelte-1un72ey"></span> <span class="tip-top svelte-1un72ey"></span> <span class="tip-bottom svelte-1un72ey"></span></span></a></li><li class="blog-list-item svelte-1un72ey" aria-label="Blog List Item how-devs-kept-running-during-the-aws-us-east-1-oct-20-2025"><a href="/blog/how-devs-kept-running-during-the-aws-us-east-1-oct-20-2025" class="svelte-1un72ey"><div class="list-item-content svelte-1un72ey"><div class="list-item-title svelte-1un72ey"><!--[!--><!----><h2 data-variant="heading" data-size="32" class="text s32 heading svelte-lrigwr"><!----><!---->Durable under pressure: How developers kept running during the AWS us-east-1 outage<!----><!----></h2><!----><!--]--></div> <div class="list-item-body svelte-1un72ey"><!--[!--><!--]--> <!--[!--><!--]--></div> <div class="list-item-meta svelte-1un72ey"><div class="meta-primary svelte-1un72ey"><p class="svelte-1un72ey">Nov 07, 2025</p> <!--[--><p class="svelte-1un72ey">7 min</p><!--]--></div> <div class="meta-secondary svelte-1un72ey"><!--[--><!--[--><span class="list-item-tag svelte-1un72ey">Cloud</span><span class="list-item-tag svelte-1un72ey">Durable Execution</span><!--]--><!--]--></div></div></div> <!--[--><div class="list-item-extra svelte-1un72ey"><p class="svelte-1un72ey">Temporal Concepts</p></div><!--]--> <span class="arrow svelte-1un72ey"><span class="base svelte-1un72ey"></span> <span class="tip-top svelte-1un72ey"></span> <span class="tip-bottom svelte-1un72ey"></span></span></a></li><li class="blog-list-item svelte-1un72ey" aria-label="Blog List Item build-durable-ai-agents-pydantic-ai-and-temporal"><a href="/blog/build-durable-ai-agents-pydantic-ai-and-temporal" class="svelte-1un72ey"><div class="list-item-content svelte-1un72ey"><div class="list-item-title svelte-1un72ey"><!--[!--><!----><h2 data-variant="heading" data-size="32" class="text s32 heading svelte-lrigwr"><!----><!---->Build durable AI agents with Pydantic AI and Temporal<!----><!----></h2><!----><!--]--></div> <div class="list-item-body svelte-1un72ey"><!--[!--><!--]--> <!--[!--><!--]--></div> <div class="list-item-meta svelte-1un72ey"><div class="meta-primary svelte-1un72ey"><p class="svelte-1un72ey">Nov 06, 2025</p> <!--[--><p class="svelte-1un72ey">8 min</p><!--]--></div> <div class="meta-secondary svelte-1un72ey"><!--[--><!--[--><span class="list-item-tag svelte-1un72ey">AI/ML</span><span class="list-item-tag svelte-1un72ey">Code Samples</span><span class="list-item-tag svelte-1un72ey">Python</span><!--]--><!--]--></div></div></div> <!--[--><div class="list-item-extra svelte-1un72ey"><p class="svelte-1un72ey">How-To</p></div><!--]--> <span class="arrow svelte-1un72ey"><span class="base svelte-1un72ey"></span> <span class="tip-top svelte-1un72ey"></span> <span class="tip-bottom svelte-1un72ey"></span></span></a></li><li class="blog-list-item svelte-1un72ey" aria-label="Blog List Item durable-digest-october-2025"><a href="/blog/durable-digest-october-2025" class="svelte-1un72ey"><div class="list-item-content svelte-1un72ey"><div class="list-item-title svelte-1un72ey"><!--[!--><!----><h2 data-variant="heading" data-size="32" class="text s32 heading svelte-lrigwr"><!----><!---->Durable Digest: October 2025<!----><!----></h2><!----><!--]--></div> <div class="list-item-body svelte-1un72ey"><!--[!--><!--]--> <!--[!--><!--]--></div> <div class="list-item-meta svelte-1un72ey"><div class="meta-primary svelte-1un72ey"><p class="svelte-1un72ey">Oct 30, 2025</p> <!--[--><p class="svelte-1un72ey">5 min</p><!--]--></div> <div class="meta-secondary svelte-1un72ey"><!--[!--><!--]--></div></div></div> <!--[--><div class="list-item-extra svelte-1un72ey"><p class="svelte-1un72ey">Announcements</p></div><!--]--> <span class="arrow svelte-1un72ey"><span class="base svelte-1un72ey"></span> <span class="tip-top svelte-1un72ey"></span> <span class="tip-bottom svelte-1un72ey"></span></span></a></li><li class="blog-list-item svelte-1un72ey" aria-label="Blog List Item how-to-get-your-boss-to-send-you-to-replay"><a href="/blog/how-to-get-your-boss-to-send-you-to-replay" class="svelte-1un72ey"><div class="list-item-content svelte-1un72ey"><div class="list-item-title svelte-1un72ey"><!--[!--><!----><h2 data-variant="heading" data-size="32" class="text s32 heading svelte-lrigwr"><!----><!---->How to get your boss to send you to Replay<!----><!----></h2><!----><!--]--></div> <div class="list-item-body svelte-1un72ey"><!--[!--><!--]--> <!--[!--><!--]--></div> <div class="list-item-meta svelte-1un72ey"><div class="meta-primary svelte-1un72ey"><p class="svelte-1un72ey">Oct 28, 2025</p> <!--[--><p class="svelte-1un72ey">7 min</p><!--]--></div> <div class="meta-secondary svelte-1un72ey"><!--[--><!--[--><span class="list-item-tag svelte-1un72ey">Replay</span><span class="list-item-tag svelte-1un72ey">Durable Execution</span><span class="list-item-tag svelte-1un72ey">Industry Events</span><!--]--><!--]--></div></div></div> <!--[--><div class="list-item-extra svelte-1un72ey"><p class="svelte-1un72ey">Community</p></div><!--]--> <span class="arrow svelte-1un72ey"><span class="base svelte-1un72ey"></span> <span class="tip-top svelte-1un72ey"></span> <span class="tip-bottom svelte-1un72ey"></span></span></a></li><!--]--> <div class="load-more-container svelte-yrck75"><button class="load-more-button svelte-yrck75">Load More</button></div><!----></ul><!--]--><!----><!----></div><!----><!----><!----><!----></div><!----><!----> <section class="blog-news-block svelte-1gk6e44"><div class="blog-news-text svelte-1gk6e44"><!----><p data-variant="body" data-size="32" class="text s32 body svelte-lrigwr"><!----><!---->Keep up to date with the latest insights, how-tos, and news from Temporal.<!----><!----></p><!----><!----></div> <div class="blog-news-actions svelte-1gk6e44"><div class="blog-news-form"><div><!--[--><!----><div class="newsletter-signup svelte-1m1nool"><form class="pink svelte-1m1nool"><label class="sr-only" for="1001">Email Address</label> <input value="" type="email" data-lpignore="" data-1p-ignore="" placeholder="Email Address" id="1001" required class="svelte-1m1nool"> <!--[!--><!--[--><button class="pink svelte-1m1nool" type="submit"><!--[!--><span class="whitespace-nowrap">Sign up</span><!--]--></button><!--]--><!--]--></form> <!----><!----></div><!----><!--]--> <!--[!--><!--]--> <!--[!--><!--]--></div><!----></div> <div class="blog-news-button"><!----><a role="link" target="_blank" href="https://temporal.io/blog/feed.xml" class="button group w-fit secondary center ultraviolet svelte-w4bvtf svelte-w4bvtf"><!--[!--><!--[--><!--[--><svg width="24" height="24" class="transition-colors text-indigo-300 group-hover:text-off-white" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" role="img" data-contentful-entry-id="" data-contentful-field-id=""><!----><!----><path d="m21.9004 21.625h-2.25c0-10.3125-8.4375-18.75-18.750009-18.75v-2.25c11.578109 0 21.000009 9.4219 21.000009 21zm-6.75 0h-2.25c0-6.6094-5.39063-12-12.000009-12v-2.25c7.828129 0 14.250009 6.4219 14.250009 14.25zm-12.00001-3c0 .4219.32813.75.75.75.375 0 .75-.3281.75-.75 0-.375-.375-.75-.75-.75-.42187 0-.75.375-.75.75zm3.75 0c0 1.0781-.60937 2.0625-1.5 2.625-.9375.5156-2.10937.5156-3 0-.9375-.5625-1.499999-1.5469-1.499999-2.625 0-1.0312.562499-2.0156 1.499999-2.5781.89063-.5157 2.0625-.5157 3 0 .89063.5625 1.5 1.5469 1.5 2.5781z" fill="currentcolor"></path><!----><!----><defs><linearGradient id="mist-2973c950-85b4-49e1-af93-47a8f5df2f82"><stop offset="0%" stop-color="#34D399"></stop><stop offset="100%" stop-color="#FF6BFF"></stop></linearGradient><linearGradient id="green-gradient-2973c950-85b4-49e1-af93-47a8f5df2f82"><stop offset="0%" stop-color="#C3FF62"></stop><stop offset="100%" stop-color="#1FF1A5"></stop></linearGradient><linearGradient id="pink-gradient-2973c950-85b4-49e1-af93-47a8f5df2f82"><stop offset="0%" stop-color="#FF5555"></stop><stop offset="100%" stop-color="#B664FF"></stop></linearGradient><linearGradient id="purple-ultraviolet-gradient-2973c950-85b4-49e1-af93-47a8f5df2f82"><stop offset="0%" stop-color="#B664FF"></stop><stop offset="100%" stop-color="#444CE7"></stop></linearGradient></defs></svg><!--]--><!--]--><!--]--> <!----><span class="whitespace-nowrap">Blog RSS</span><!----> <!--[!--><!--]--><!----></a><!----><!----></div></div></section><!----> <!--[--><!----><div class="grid grid-flow-col-dense sm:grid-cols-page sm:gap-x-4 max-sm:grid-cols-1 max-sm:px-5 max-sm:gap-y-4 bg-customer-hype-rainbow no-padding gap-y-12 max-md:py-24 md:py-48 xl:py-80 columns temporal-grid svelte-apxkwt " style=""><!----><!----><div class="max-sm:col-span-1 sm:col-span-10 max-sm:col-start-1 sm:col-start-3 flex flex-col flex-wrap justify-center items-center text-center gap-8"><!----><!--[!--><!--]--> <!--[--><!----><p data-variant="display" data-size="128" class="text s128 customer-hype-rainbow display text-off-white svelte-lrigwr" data-contentful-entry-id="promo-block" data-contentful-field-id="title"><!----><!---->Build invincible applications<!----><!----></p><!----><!--]--> <!--[--><!----><p data-variant="body" data-size="24" class="text s24 customer-hype-rainbow body text-off-white svelte-lrigwr" data-contentful-entry-id="promo-block" data-contentful-field-id="description"><!----><!---->It sounds like magic, we promise it's not.<!----><!----></p><!----><!--]--> <!--[--><div class="flex max-xl:flex-col xl:flex-row items-center justify-center gap-4 mt-4"><!--[--><!----><a role="link" target="_blank" href="https://docs.temporal.io" class="button group w-fit secondary center ultraviolet svelte-w4bvtf svelte-w4bvtf"><!--[!--><!--[--><!--[--><svg width="24" height="24" class="transition-colors text-indigo-300 group-hover:text-off-white" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" role="img" data-contentful-entry-id="" data-contentful-field-id=""><!----><!----><g clip-path="url(#clip0_1786_8348)"><path d="M1.5 4.125C1.5 1.84688 3.34688 0 5.625 0H21.375H22.5V1.125V17.625V18.75H21.375H21V21.75H21.375H22.5V24H21.375H5.25C3.17812 24 1.5 22.3219 1.5 20.25C1.5 20.1234 1.50469 19.9969 1.51875 19.875H1.5V4.125ZM3.75 20.25C3.75 21.0797 4.42031 21.75 5.25 21.75H18.75V18.75H5.25C4.42031 18.75 3.75 19.4203 3.75 20.25ZM3.75 16.8141C4.20937 16.6125 4.71563 16.5 5.25 16.5H20.25V2.25H5.625C4.58906 2.25 3.75 3.08906 3.75 4.125V16.8141ZM9 5.25L9.75 3.75L10.5 5.25L12 6L10.5 6.75L9.75 8.25L9 6.75L7.5 6L9 5.25ZM13.875 10.125L15 7.5L16.125 10.125L18.75 11.25L16.125 12.375L15 15L13.875 12.375L11.25 11.25L13.875 10.125Z" fill="currentcolor"></path></g><defs><clipPath id="clip0_1786_8348"><rect width="21" height="24" fill="white" transform="translate(1.5)"></rect></clipPath></defs><!----><!----><defs><linearGradient id="mist-39fe1d7f-98fa-42ba-91f7-a068bbde130d"><stop offset="0%" stop-color="#34D399"></stop><stop offset="100%" stop-color="#FF6BFF"></stop></linearGradient><linearGradient id="green-gradient-39fe1d7f-98fa-42ba-91f7-a068bbde130d"><stop offset="0%" stop-color="#C3FF62"></stop><stop offset="100%" stop-color="#1FF1A5"></stop></linearGradient><linearGradient id="pink-gradient-39fe1d7f-98fa-42ba-91f7-a068bbde130d"><stop offset="0%" stop-color="#FF5555"></stop><stop offset="100%" stop-color="#B664FF"></stop></linearGradient><linearGradient id="purple-ultraviolet-gradient-39fe1d7f-98fa-42ba-91f7-a068bbde130d"><stop offset="0%" stop-color="#B664FF"></stop><stop offset="100%" stop-color="#444CE7"></stop></linearGradient></defs></svg><!--]--><!--]--><!--]--> <!----><!---->Documentation<!----> <!--[!--><!--]--><!----></a><!----><!----><a role="link" target="_blank" href="https://github.com/temporalio" class="button group w-fit secondary center ultraviolet svelte-w4bvtf svelte-w4bvtf"><!--[!--><!--[--><!--[--><svg width="24" height="24" class="transition-colors text-indigo-300 group-hover:text-off-white" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" role="img" data-contentful-entry-id="" data-contentful-field-id=""><!----><!----><g clip-path="url(#clip0_2449_10932)"><path d="M3.75 2.25V5.25H6.75V2.25H3.75ZM1.5 0H3.75H6.75H9V2.25V5.25V7.5H6.75H6.375V12C7.31719 11.2922 8.48438 10.875 9.75 10.875H14.25C16.1156 10.875 17.625 9.36562 17.625 7.5H17.25H15V5.25V2.25V0H17.25H20.25H22.5V2.25V5.25V7.5H20.25H19.875C19.875 10.6078 17.3578 13.125 14.25 13.125H9.75C7.88438 13.125 6.375 14.6344 6.375 16.5H6.75H9V18.75V21.75V24H6.75H3.75H1.5V21.75V18.75V16.5H3.75H4.125V7.5H3.75H1.5V5.25V2.25V0ZM6.75 18.75H3.75V21.75H6.75V18.75ZM20.25 2.25H17.25V5.25H20.25V2.25Z" fill="currentcolor"></path></g><defs><clipPath id="clip0_2449_10932"><rect width="24" height="24" fill="white" transform="translate(1.5)"></rect></clipPath></defs><!----><!----><defs><linearGradient id="mist-436ff0e9-eee7-4d8f-806e-e4a5753c1371"><stop offset="0%" stop-color="#34D399"></stop><stop offset="100%" stop-color="#FF6BFF"></stop></linearGradient><linearGradient id="green-gradient-436ff0e9-eee7-4d8f-806e-e4a5753c1371"><stop offset="0%" stop-color="#C3FF62"></stop><stop offset="100%" stop-color="#1FF1A5"></stop></linearGradient><linearGradient id="pink-gradient-436ff0e9-eee7-4d8f-806e-e4a5753c1371"><stop offset="0%" stop-color="#FF5555"></stop><stop offset="100%" stop-color="#B664FF"></stop></linearGradient><linearGradient id="purple-ultraviolet-gradient-436ff0e9-eee7-4d8f-806e-e4a5753c1371"><stop offset="0%" stop-color="#B664FF"></stop><stop offset="100%" stop-color="#444CE7"></stop></linearGradient></defs></svg><!--]--><!--]--><!--]--> <!----><!---->Code Base<!----> <!--[!--><!--]--><!----></a><!----><!----><a role="link" target="_blank" href="https://learn.temporal.io/examples" class="button group w-fit secondary center ultraviolet svelte-w4bvtf svelte-w4bvtf"><!--[!--><!--[--><!--[--><svg width="24" height="24" class="transition-colors text-indigo-300 group-hover:text-off-white" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" role="img" data-contentful-entry-id="" data-contentful-field-id=""><!----><!----><path d="M14.1188 3.0675L13.8451 3.9225L8.44509 20.7225L8.17134 21.5775L9.88509 22.1288L10.1588 21.2738L15.5588 4.47375L15.8326 3.61875L14.1188 3.0675ZM16.4288 8.14126L17.0851 8.75625L21.1838 12.6L17.0851 16.4438L16.4288 17.0588L17.6588 18.3713L18.3151 17.7563L23.1151 13.2563L23.8163 12.6L23.1151 11.9438L18.3151 7.44375L17.6588 6.82875L16.4288 8.14126ZM6.34134 6.82875L5.68509 7.44375L0.885088 11.9438L0.183838 12.6L0.885088 13.2563L5.68509 17.7563L6.34134 18.3713L7.57134 17.0588L6.91509 16.4438L2.81634 12.6L6.91509 8.75625L7.57134 8.14126L6.34134 6.82875Z" fill="currentcolor"></path><!----><!----><defs><linearGradient id="mist-7783247b-db11-4429-be1c-61cd9dd1c62d"><stop offset="0%" stop-color="#34D399"></stop><stop offset="100%" stop-color="#FF6BFF"></stop></linearGradient><linearGradient id="green-gradient-7783247b-db11-4429-be1c-61cd9dd1c62d"><stop offset="0%" stop-color="#C3FF62"></stop><stop offset="100%" stop-color="#1FF1A5"></stop></linearGradient><linearGradient id="pink-gradient-7783247b-db11-4429-be1c-61cd9dd1c62d"><stop offset="0%" stop-color="#FF5555"></stop><stop offset="100%" stop-color="#B664FF"></stop></linearGradient><linearGradient id="purple-ultraviolet-gradient-7783247b-db11-4429-be1c-61cd9dd1c62d"><stop offset="0%" stop-color="#B664FF"></stop><stop offset="100%" stop-color="#444CE7"></stop></linearGradient></defs></svg><!--]--><!--]--><!--]--> <!----><!---->Samples<!----> <!--[!--><!--]--><!----></a><!----><!--]--></div><!--]--><!----><!----></div><!----><!----> <!--[!--><!--]--><!----><!----></div><!----><!--]--><!----><!----><!--]--><!----> <footer class="footer svelte-fyx40k"><div class="footer-content svelte-fyx40k"><!----><div class="grid grid-flow-col-dense sm:grid-cols-page sm:gap-x-4 max-sm:grid-cols-1 max-sm:px-5 max-sm:gap-y-4 bg-none bg-transparent  columns temporal-grid svelte-apxkwt " style=""><!----><!----><div class="max-sm:col-span-1 sm:col-span-8 max-sm:col-start-1 sm:col-start-4 flex lg:flex-row lg:items-center lg:justify-between max-lg:flex-col max-lg:gap-6"><!----><a href="https://status.temporal.io/" class="status-badge none svelte-hg2oi0"><!----><p data-variant="mono" data-size="16" class="text s16 mono svelte-lrigwr"><!----><!---->ALL SYSTEMS OPERATIONAL<!----><!----></p><!----><!----></a><!----> <div class="social-links svelte-khs4et"><a class="social-link svelte-khs4et" target="_blank" href="https://www.youtube.com/temporalio" aria-label="Follow us on YouTube"><!--[--><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" role="img" data-contentful-entry-id="" data-contentful-field-id=""><!----><!----><path d="M 23.498438,5.81639 C 23.222439,4.7078 22.409253,3.8347 21.376599,3.53841 19.504978,3 12.000023,3 12.000023,3 c 0,0 -7.5050005,0 -9.3766687,0.53841 C 1.590775,3.83475 0.7775235,4.7078 0.5015053,5.81639 0,7.82578 0,12.0182 0,12.0182 c 0,0 0,4.1924 0.5015053,6.2018 0.2760182,1.1086 1.0892697,1.9453 2.121849,2.2416 C 4.4950225,21 12.000023,21 12.000023,21 c 0,0 7.504955,0 9.376576,-0.5384 1.032654,-0.2963 1.84584,-1.133 2.121839,-2.2416 C 24,16.2106 24,12.0182 24,12.0182 c 0,0 0,-4.19242 -0.501562,-6.20181 z M 9.545466,15.8246 V 8.2118 l 6.272706,3.8065 z" fill="currentcolor"></path><!----><!----><defs><linearGradient id="mist-4bf7fba5-4d7d-401d-affc-b0c759d2cc18"><stop offset="0%" stop-color="#34D399"></stop><stop offset="100%" stop-color="#FF6BFF"></stop></linearGradient><linearGradient id="green-gradient-4bf7fba5-4d7d-401d-affc-b0c759d2cc18"><stop offset="0%" stop-color="#C3FF62"></stop><stop offset="100%" stop-color="#1FF1A5"></stop></linearGradient><linearGradient id="pink-gradient-4bf7fba5-4d7d-401d-affc-b0c759d2cc18"><stop offset="0%" stop-color="#FF5555"></stop><stop offset="100%" stop-color="#B664FF"></stop></linearGradient><linearGradient id="purple-ultraviolet-gradient-4bf7fba5-4d7d-401d-affc-b0c759d2cc18"><stop offset="0%" stop-color="#B664FF"></stop><stop offset="100%" stop-color="#444CE7"></stop></linearGradient></defs></svg><!--]--><!----></a> <a class="social-link svelte-khs4et" target="_blank" href="https://twitter.com/temporalio" aria-label="Follow us on Twitter"><!--[--><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" role="img" data-contentful-entry-id="" data-contentful-field-id=""><!----><!----><path d="M18.2437 2.25H21.5531L14.325 10.5094L22.8281 21.75H16.1719L10.9547 14.9344L4.99216 21.75H1.6781L9.40779 12.9141L1.25623 2.25H8.08123L12.7922 8.47969L18.2437 2.25ZM17.0812 19.7719H18.914L7.08279 4.125H5.11404L17.0812 19.7719Z" fill="currentcolor"></path><!----><!----><defs><linearGradient id="mist-e35e180d-31c1-4335-b8b2-3d34a797e70a"><stop offset="0%" stop-color="#34D399"></stop><stop offset="100%" stop-color="#FF6BFF"></stop></linearGradient><linearGradient id="green-gradient-e35e180d-31c1-4335-b8b2-3d34a797e70a"><stop offset="0%" stop-color="#C3FF62"></stop><stop offset="100%" stop-color="#1FF1A5"></stop></linearGradient><linearGradient id="pink-gradient-e35e180d-31c1-4335-b8b2-3d34a797e70a"><stop offset="0%" stop-color="#FF5555"></stop><stop offset="100%" stop-color="#B664FF"></stop></linearGradient><linearGradient id="purple-ultraviolet-gradient-e35e180d-31c1-4335-b8b2-3d34a797e70a"><stop offset="0%" stop-color="#B664FF"></stop><stop offset="100%" stop-color="#444CE7"></stop></linearGradient></defs></svg><!--]--><!----></a> <a class="social-link svelte-khs4et" target="_blank" href="https://github.com/temporalio" aria-label="Follow us on GitHub"><!--[--><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" role="img" data-contentful-entry-id="" data-contentful-field-id=""><!----><!----><g clip-path="url(#clip0_1786_8386)"><path d="M8.15156 18.6281C8.15156 18.7219 8.04375 18.7969 7.90781 18.7969C7.75312 18.8109 7.64531 18.7359 7.64531 18.6281C7.64531 18.5344 7.75313 18.4594 7.88906 18.4594C8.02969 18.4453 8.15156 18.5203 8.15156 18.6281ZM6.69375 18.4172C6.66094 18.5109 6.75469 18.6187 6.89531 18.6469C7.01719 18.6937 7.15781 18.6469 7.18594 18.5531C7.21406 18.4594 7.125 18.3516 6.98438 18.3094C6.8625 18.2766 6.72656 18.3234 6.69375 18.4172ZM8.76562 18.3375C8.62969 18.3703 8.53594 18.4594 8.55 18.5672C8.56406 18.6609 8.68594 18.7219 8.82656 18.6891C8.9625 18.6562 9.05625 18.5672 9.04219 18.4734C9.02812 18.3844 8.90156 18.3234 8.76562 18.3375ZM11.85 0.375C5.34844 0.375 0.375 5.31094 0.375 11.8125C0.375 17.0109 3.64688 21.4594 8.32031 23.025C8.92031 23.1328 9.13125 22.7625 9.13125 22.4578C9.13125 22.1672 9.11719 20.5641 9.11719 19.5797C9.11719 19.5797 5.83594 20.2828 5.14688 18.1828C5.14688 18.1828 4.6125 16.8187 3.84375 16.4672C3.84375 16.4672 2.77031 15.7312 3.91875 15.7453C3.91875 15.7453 5.08594 15.8391 5.72812 16.9547C6.75469 18.7641 8.475 18.2437 9.14531 17.9344C9.25313 17.1844 9.55781 16.6641 9.89531 16.3547C7.275 16.0641 4.63125 15.6844 4.63125 11.175C4.63125 9.88594 4.9875 9.23906 5.7375 8.41406C5.61562 8.10938 5.21719 6.85312 5.85938 5.23125C6.83906 4.92656 9.09375 6.49688 9.09375 6.49688C10.0312 6.23438 11.0391 6.09844 12.0375 6.09844C13.0359 6.09844 14.0438 6.23438 14.9813 6.49688C14.9813 6.49688 17.2359 4.92188 18.2156 5.23125C18.8578 6.85781 18.4594 8.10938 18.3375 8.41406C19.0875 9.24375 19.5469 9.89062 19.5469 11.175C19.5469 15.6984 16.7859 16.0594 14.1656 16.3547C14.5969 16.725 14.9625 17.4281 14.9625 18.5297C14.9625 20.1094 14.9484 22.0641 14.9484 22.4484C14.9484 22.7531 15.1641 23.1234 15.7594 23.0156C20.4469 21.4594 23.625 17.0109 23.625 11.8125C23.625 5.31094 18.3516 0.375 11.85 0.375ZM4.93125 16.5422C4.87031 16.5891 4.88438 16.6969 4.96406 16.7859C5.03906 16.8609 5.14687 16.8938 5.20781 16.8328C5.26875 16.7859 5.25469 16.6781 5.175 16.5891C5.1 16.5141 4.99219 16.4812 4.93125 16.5422ZM4.425 16.1625C4.39219 16.2234 4.43906 16.2984 4.53281 16.3453C4.60781 16.3922 4.70156 16.3781 4.73438 16.3125C4.76719 16.2516 4.72031 16.1766 4.62656 16.1297C4.53281 16.1016 4.45781 16.1156 4.425 16.1625ZM5.94375 17.8312C5.86875 17.8922 5.89687 18.0328 6.00469 18.1219C6.1125 18.2297 6.24844 18.2437 6.30937 18.1688C6.37031 18.1078 6.34219 17.9672 6.24844 17.8781C6.14531 17.7703 6.00469 17.7563 5.94375 17.8312ZM5.40938 17.1422C5.33437 17.1891 5.33437 17.3109 5.40938 17.4188C5.48438 17.5266 5.61094 17.5734 5.67188 17.5266C5.74687 17.4656 5.74687 17.3438 5.67188 17.2359C5.60625 17.1281 5.48438 17.0813 5.40938 17.1422Z" fill="currentcolor"></path></g><defs><clipPath id="clip0_1786_8386"><rect width="23.25" height="24" fill="white" transform="translate(0.375)"></rect></clipPath></defs><!----><!----><defs><linearGradient id="mist-553be33a-b59d-481d-882c-01766549b0aa"><stop offset="0%" stop-color="#34D399"></stop><stop offset="100%" stop-color="#FF6BFF"></stop></linearGradient><linearGradient id="green-gradient-553be33a-b59d-481d-882c-01766549b0aa"><stop offset="0%" stop-color="#C3FF62"></stop><stop offset="100%" stop-color="#1FF1A5"></stop></linearGradient><linearGradient id="pink-gradient-553be33a-b59d-481d-882c-01766549b0aa"><stop offset="0%" stop-color="#FF5555"></stop><stop offset="100%" stop-color="#B664FF"></stop></linearGradient><linearGradient id="purple-ultraviolet-gradient-553be33a-b59d-481d-882c-01766549b0aa"><stop offset="0%" stop-color="#B664FF"></stop><stop offset="100%" stop-color="#444CE7"></stop></linearGradient></defs></svg><!--]--><!----></a> <a class="social-link svelte-khs4et" target="_blank" href="https://www.linkedin.com/company/temporal-technologies" aria-label="Follow us on Linkedin"><!--[--><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" role="img" data-contentful-entry-id="" data-contentful-field-id=""><!----><!----><g clip-path="url(#clip0_1786_8402)"><path d="M6.20062 21H1.84688V6.97971H6.20062V21ZM4.02141 5.06721C2.62922 5.06721 1.5 3.91408 1.5 2.52189C1.5 1.85318 1.76565 1.21185 2.2385 0.738991C2.71136 0.266136 3.35269 0.000488281 4.02141 0.000488281C4.69012 0.000488281 5.33145 0.266136 5.80431 0.738991C6.27716 1.21185 6.54281 1.85318 6.54281 2.52189C6.54281 3.91408 5.41313 5.06721 4.02141 5.06721ZM22.4953 21H18.1509V14.175C18.1509 12.5485 18.1181 10.4625 15.8873 10.4625C13.6237 10.4625 13.2769 12.2297 13.2769 14.0578V21H8.92781V6.97971H13.1034V8.89221H13.1644C13.7456 7.79064 15.1655 6.62814 17.2838 6.62814C21.69 6.62814 22.5 9.52971 22.5 13.2985V21H22.4953Z" fill="currentcolor"></path></g><defs><clipPath id="clip0_1786_8402"><rect width="21" height="24" fill="white" transform="translate(1.5)"></rect></clipPath></defs><!----><!----><defs><linearGradient id="mist-c798aed7-6f62-40b0-8b37-e2ff07389dbb"><stop offset="0%" stop-color="#34D399"></stop><stop offset="100%" stop-color="#FF6BFF"></stop></linearGradient><linearGradient id="green-gradient-c798aed7-6f62-40b0-8b37-e2ff07389dbb"><stop offset="0%" stop-color="#C3FF62"></stop><stop offset="100%" stop-color="#1FF1A5"></stop></linearGradient><linearGradient id="pink-gradient-c798aed7-6f62-40b0-8b37-e2ff07389dbb"><stop offset="0%" stop-color="#FF5555"></stop><stop offset="100%" stop-color="#B664FF"></stop></linearGradient><linearGradient id="purple-ultraviolet-gradient-c798aed7-6f62-40b0-8b37-e2ff07389dbb"><stop offset="0%" stop-color="#B664FF"></stop><stop offset="100%" stop-color="#444CE7"></stop></linearGradient></defs></svg><!--]--><!----></a> <a class="social-link svelte-khs4et" target="_blank" href="https://t.mp/slack" aria-label="Join us on Slack"><!--[--><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" role="img" data-contentful-entry-id="" data-contentful-field-id=""><!----><!----><g clip-path="url(#clip0_1786_8418)"><path d="M5.91188 14.7703C5.91188 15.9844 4.92 16.9762 3.70594 16.9762C2.49188 16.9762 1.5 15.9844 1.5 14.7703C1.5 13.5563 2.49188 12.5644 3.70594 12.5644H5.91188V14.7703ZM7.02375 14.7703C7.02375 13.5563 8.01562 12.5644 9.22969 12.5644C10.4437 12.5644 11.4356 13.5563 11.4356 14.7703V20.2941C11.4356 21.5081 10.4437 22.5 9.22969 22.5C8.01562 22.5 7.02375 21.5081 7.02375 20.2941V14.7703ZM9.22969 5.91188C8.01562 5.91188 7.02375 4.92 7.02375 3.70594C7.02375 2.49187 8.01562 1.5 9.22969 1.5C10.4437 1.5 11.4356 2.49187 11.4356 3.70594V5.91188H9.22969ZM9.22969 7.02375C10.4437 7.02375 11.4356 8.01562 11.4356 9.22969C11.4356 10.4437 10.4437 11.4356 9.22969 11.4356H3.70594C2.49188 11.4356 1.5 10.4437 1.5 9.22969C1.5 8.01562 2.49188 7.02375 3.70594 7.02375H9.22969ZM18.0881 9.22969C18.0881 8.01562 19.08 7.02375 20.2941 7.02375C21.5081 7.02375 22.5 8.01562 22.5 9.22969C22.5 10.4437 21.5081 11.4356 20.2941 11.4356H18.0881V9.22969ZM16.9762 9.22969C16.9762 10.4437 15.9844 11.4356 14.7703 11.4356C13.5563 11.4356 12.5644 10.4437 12.5644 9.22969V3.70594C12.5644 2.49187 13.5563 1.5 14.7703 1.5C15.9844 1.5 16.9762 2.49187 16.9762 3.70594V9.22969ZM14.7703 18.0881C15.9844 18.0881 16.9762 19.08 16.9762 20.2941C16.9762 21.5081 15.9844 22.5 14.7703 22.5C13.5563 22.5 12.5644 21.5081 12.5644 20.2941V18.0881H14.7703ZM14.7703 16.9762C13.5563 16.9762 12.5644 15.9844 12.5644 14.7703C12.5644 13.5563 13.5563 12.5644 14.7703 12.5644H20.2941C21.5081 12.5644 22.5 13.5563 22.5 14.7703C22.5 15.9844 21.5081 16.9762 20.2941 16.9762H14.7703Z" fill="currentcolor"></path></g><defs><clipPath id="clip0_1786_8418"><rect width="21" height="24" fill="white" transform="translate(1.5)"></rect></clipPath></defs><!----><!----><defs><linearGradient id="mist-6b8aac42-ef28-4b4a-ab82-b046db031978"><stop offset="0%" stop-color="#34D399"></stop><stop offset="100%" stop-color="#FF6BFF"></stop></linearGradient><linearGradient id="green-gradient-6b8aac42-ef28-4b4a-ab82-b046db031978"><stop offset="0%" stop-color="#C3FF62"></stop><stop offset="100%" stop-color="#1FF1A5"></stop></linearGradient><linearGradient id="pink-gradient-6b8aac42-ef28-4b4a-ab82-b046db031978"><stop offset="0%" stop-color="#FF5555"></stop><stop offset="100%" stop-color="#B664FF"></stop></linearGradient><linearGradient id="purple-ultraviolet-gradient-6b8aac42-ef28-4b4a-ab82-b046db031978"><stop offset="0%" stop-color="#B664FF"></stop><stop offset="100%" stop-color="#444CE7"></stop></linearGradient></defs></svg><!--]--><!----></a></div><!----> <hr class="lg:hidden text-blue-gray-900"><!----><!----></div><!----><!----><!----></div><!----><!----> <!----><div class="grid grid-flow-col-dense sm:grid-cols-page sm:gap-x-4 max-sm:grid-cols-1 max-sm:px-5 max-sm:gap-y-4 bg-none bg-transparent  columns temporal-grid svelte-apxkwt " style=""><!----><!----><div class="max-sm:col-span-1 sm:col-span-8 max-sm:col-start-1 sm:col-start-4 flex flex-wrap justify-between lg:flex-row max-lg:flex-col gap-6"><!----><!--[--><div class="footer-links svelte-qr4y6z"><!----><p data-variant="body" data-size="24" class="text s24 body !font-bold text-gradient-ultraviolet svelte-lrigwr" data-contentful-entry-id="4epztNOZG4zdkSTcNzPL0s" data-contentful-field-id="title"><!----><!---->Discover<!----><!----></p><!----><!----> <!--[--><a href="/product" target="_self" class="footer-link svelte-qr4y6z">Overview</a><a href="/how-it-works" target="_self" class="footer-link svelte-qr4y6z">How Temporal Works</a><a href="/cloud" target="_self" class="footer-link svelte-qr4y6z">Temporal Cloud</a><a href="/pricing" target="_self" class="footer-link svelte-qr4y6z">Pricing</a><a href="/security" target="_self" class="footer-link svelte-qr4y6z">Security</a><a href="https://trust.temporal.io" target="_blank" class="footer-link svelte-qr4y6z">Trust Center</a><a href="/startup" target="_self" class="footer-link svelte-qr4y6z">Startups</a><!--]--> <div class="flex flex-col gap-4 pt-8 max-lg:hidden"><!--[--><!----><a role="link" href="/get-cloud" class="button group w-fit primary center ultraviolet svelte-w4bvtf svelte-w4bvtf" entityid="5rv8zi38jmzvxkw6RTXF10"><!--[!--><!--[!--><!--]--><!--]--> <!----><!---->Get Started for Free<!----> <!--[!--><!--]--><!----></a><!----><!----><a role="link" target="_blank" href="https://cloud.temporal.io/login" class="button group w-fit secondary center ultraviolet svelte-w4bvtf svelte-w4bvtf" entityid="6VuowrEOCRwy7W2AF42x4u"><!--[!--><!--[!--><!--]--><!--]--> <!----><!---->Log In<!----> <!--[!--><!--]--><!----></a><!----><!--]--></div></div><div class="footer-links svelte-qr4y6z"><!----><p data-variant="body" data-size="24" class="text s24 body !font-bold text-gradient-ultraviolet svelte-lrigwr" data-contentful-entry-id="4TSqxuyMrVLtBrzEaGTAfA" data-contentful-field-id="title"><!----><!---->Explore<!----><!----></p><!----><!----> <!--[--><a href="/in-use" target="_self" class="footer-link svelte-qr4y6z">Customer Stories</a><a href="https://learn.temporal.io/tutorials/" target="_blank" class="footer-link svelte-qr4y6z">Project-based tutorials</a><a href="https://learn.temporal.io/examples/" target="_blank" class="footer-link svelte-qr4y6z">Example applications</a><a href="/code-exchange" target="_self" class="footer-link svelte-qr4y6z">Code Exchange</a><a href="/replay/2025" target="_self" class="footer-link svelte-qr4y6z">Replay 2025 Recap</a><a href="https://pages.temporal.io/ask-an-expert" target="_blank" class="footer-link svelte-qr4y6z">Ask an expert</a><a href="/blog" target="_self" class="footer-link svelte-qr4y6z">Blog</a><!--]--> <div class="flex flex-col gap-4 pt-8 max-lg:hidden"><!--[--><!--]--></div></div><div class="footer-links svelte-qr4y6z"><!----><p data-variant="body" data-size="24" class="text s24 body !font-bold text-gradient-ultraviolet svelte-lrigwr" data-contentful-entry-id="7CY4xLfQDevf6lTYNpIQeN" data-contentful-field-id="title"><!----><!---->Developers<!----><!----></p><!----><!----> <!--[--><a href="https://learn.temporal.io/getting_started/" target="_blank" class="footer-link svelte-qr4y6z">Getting Started with Temporal</a><a href="https://docs.temporal.io/dev-guide/" target="_blank" class="footer-link svelte-qr4y6z">Start building your next app</a><a href="https://docs.temporal.io/cloud" target="_blank" class="footer-link svelte-qr4y6z">Temporal Cloud docs</a><a href="https://docs.temporal.io/production-deployment" target="_blank" class="footer-link svelte-qr4y6z">Production deployments</a><a href="https://learn.temporal.io/courses/temporal_101/" target="_blank" class="footer-link svelte-qr4y6z">Temporal 101</a><a href="https://learn.temporal.io/courses/temporal_102/" target="_blank" class="footer-link svelte-qr4y6z">Temporal 102</a><a href="https://learn.temporal.io/courses/intro_to_temporal_cloud/" target="_blank" class="footer-link svelte-qr4y6z">Introduction to Temporal Cloud</a><!--]--> <div class="flex flex-col gap-4 pt-8 max-lg:hidden"><!--[--><!--]--></div></div><!--]--> <div class="flex flex-col gap-12"><!--[--><div class="footer-links svelte-qr4y6z"><!----><p data-variant="body" data-size="24" class="text s24 body !font-bold text-gradient-ultraviolet svelte-lrigwr" data-contentful-entry-id="4NydwQZlTc68NC2MfMnwu2" data-contentful-field-id="title"><!----><!---->Community<!----><!----></p><!----><!----> <!--[--><a href="https://t.mp/slack" target="_blank" class="footer-link svelte-qr4y6z">Join our Slack group</a><a href="/community" target="_self" class="footer-link svelte-qr4y6z">Find a meetup near you</a><a href="https://community.temporal.io/" target="_blank" class="footer-link svelte-qr4y6z">Community forum</a><a href="/events" target="_self" class="footer-link svelte-qr4y6z">Events</a><a href="https://replay.temporal.io/" target="_blank" class="footer-link svelte-qr4y6z">Replay 2026</a><!--]--> <div class="flex flex-col gap-4 pt-8 max-lg:hidden"><!--[--><!--]--></div></div><div class="footer-links svelte-qr4y6z"><!----><p data-variant="body" data-size="24" class="text s24 body !font-bold text-gradient-ultraviolet svelte-lrigwr" data-contentful-entry-id="53AeODgxpn6IHQwIaED2p8" data-contentful-field-id="title"><!----><!---->Company<!----><!----></p><!----><!----> <!--[--><a href="/about" target="_self" class="footer-link svelte-qr4y6z">About</a><a href="/careers" target="_self" class="footer-link svelte-qr4y6z">Careers</a><a href="/news" target="_self" class="footer-link svelte-qr4y6z">News</a><a href="https://pages.temporal.io/contact-us" target="_blank" class="footer-link svelte-qr4y6z">Contact us</a><a href="/partners" target="_self" class="footer-link svelte-qr4y6z">Partners</a><!--]--> <div class="flex flex-col gap-4 pt-8 max-lg:hidden"><!--[--><!--]--></div></div><!--]--></div><!----><!----></div><!----><!----><!----></div><!----><!----> <!----><div class="grid grid-flow-col-dense sm:grid-cols-page sm:gap-x-4 max-sm:grid-cols-1 max-sm:px-5 max-sm:gap-y-4 bg-none bg-transparent  columns temporal-grid svelte-apxkwt " style=""><!----><!----><div class="max-sm:col-span-1 sm:col-span-4 max-sm:col-start-1 sm:col-start-4 flex flex-col gap-4"><!----><!--[--><div><!--[--><!----><div class="newsletter-signup svelte-1m1nool"><form class="dark svelte-1m1nool"><label class="sr-only" for="1001">Email Address</label> <input value="" type="email" data-lpignore="" data-1p-ignore="" placeholder="Email Address" id="1001" required class="svelte-1m1nool"> <!--[!--><!--[!--><button class="dark svelte-1m1nool" type="submit"><!--[--><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" role="img" data-contentful-entry-id="" data-contentful-field-id=""><!----><!----><path d="M0 13.5L2.60625 14.6156L9 17.3578V17.625V20.625V23.25L11.25 24L14.6859 19.7953L18.8531 21.5812L21 22.5L21.3094 20.1844L23.6297 2.78906L24 0L21.5438 1.37812L2.47031 12.1125L0 13.5ZM19.1625 19.2656L12.5812 16.4437L20.8547 6.57187L19.1625 19.2656ZM10.4203 15.5203L5.07656 13.2281L18.8203 5.49375L10.4203 15.5203Z" fill="currentcolor"></path><!----><!----><defs><linearGradient id="mist-ec75cc46-9a17-4e75-a5c7-6b0805e0b0d2"><stop offset="0%" stop-color="#34D399"></stop><stop offset="100%" stop-color="#FF6BFF"></stop></linearGradient><linearGradient id="green-gradient-ec75cc46-9a17-4e75-a5c7-6b0805e0b0d2"><stop offset="0%" stop-color="#C3FF62"></stop><stop offset="100%" stop-color="#1FF1A5"></stop></linearGradient><linearGradient id="pink-gradient-ec75cc46-9a17-4e75-a5c7-6b0805e0b0d2"><stop offset="0%" stop-color="#FF5555"></stop><stop offset="100%" stop-color="#B664FF"></stop></linearGradient><linearGradient id="purple-ultraviolet-gradient-ec75cc46-9a17-4e75-a5c7-6b0805e0b0d2"><stop offset="0%" stop-color="#B664FF"></stop><stop offset="100%" stop-color="#444CE7"></stop></linearGradient></defs></svg><!--]--><!----></button><!--]--><!--]--></form> <!----><!----></div><!----><!--]--> <!--[!--><!--]--> <!--[!--><!--]--></div><!--]--> <div class="legal svelte-129rx56"><p>2025  Temporal Technologies. All Rights Reserved.</p> <a href="/global-privacy-policy" class="svelte-129rx56">Privacy Policy</a> <a href="/candidate-privacy-policy" class="svelte-129rx56">Candidate Privacy Policy</a> <a href="/terms-of-service" class="svelte-129rx56">Terms of Service</a> <a href="/code-of-conduct" class="svelte-129rx56">Code of Conduct</a></div><!----><!----><!----></div><!----><!----><!----></div><!----><!----></div></footer><!----></div> <!--[!--><!--]--><!----><!----><!--]--><!----><!----><!--]--> <!--[!--><!--]--><!--]-->
			
			<script>
				{
					__sveltekit_69vche = {
						base: new URL(".", location).pathname.slice(0, -1)
					};

					const element = document.currentScript.parentElement;

					Promise.all([
						import("./_app/immutable/entry/start.xLoUKPxz.js"),
						import("./_app/immutable/entry/app.CK5js4Bx.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 6, 44],
							data: [null,{"type":"data","data":{globalSettings:{mainMenu:[{title:"Platform",links:[{linkText:"Overview",link:"/product",entityId:"5d7x2oU3GnKl2PwRHfFMuR",contentType:"footerLink"},{linkText:"How Temporal Works",link:"/how-it-works",entityId:"3MXMlddUcrW8nOsJCpEDUx",contentType:"footerLink"},{linkText:"Temporal Cloud",link:"/cloud",entityId:"2JeJYErsmcssv06hMrfwiF",contentType:"footerLink"},{linkText:"Security",link:"/security",entityId:"4meokZHNYwid3e236uZKIJ",contentType:"footerLink"}],callsToAction:[],entityId:"1rq371AgLqwEnh8eclWZ4z",contentType:"footerLinkGroup"},{linkText:"Docs",link:"https://docs.temporal.io/",entityId:"5GIUmSUc4tuKTWmFIx7iJb",contentType:"footerLink"},{linkText:"Pricing",link:"/pricing",entityId:"4mAmb12lsMPKYsVZhppKwL",contentType:"footerLink"},{title:"Use Cases",links:[{linkText:"Customer Stories",link:"/in-use",entityId:"5NHM0cToFOIOfWEKhILN5K",contentType:"footerLink"},{linkText:"AI",link:"/solutions/ai",entityId:"3TlMgadJMFwa4WE2jYMXjZ",contentType:"footerLink"},{linkText:"Financial Services",link:"/solutions/financial-services",entityId:"2aD760BTctiSuChV74SVwl",contentType:"footerLink"},{linkText:"Platform Engineering",link:"/solutions/platform-engineering",entityId:"3H3pNmqq7jm9FQ6UK4100V",contentType:"footerLink"}],callsToAction:[],entityId:"1e95s28bgM2FkcA50IHhyo",contentType:"footerLinkGroup"},{title:"Resources",links:[{linkText:"Resource Library",link:"/resources",entityId:"2jjwhzfbZvR90Zd1ylRlgS",contentType:"footerLink"},{linkText:"Learn Temporal",link:"https://learn.temporal.io",entityId:"6AG3qtWngBbv7iyqhZfUZv",contentType:"footerLink"},{linkText:"Community",link:"/community",entityId:"2ZOhNmQn108V8jKiPBQ1QD",contentType:"footerLink"},{linkText:"Code Exchange",link:"/code-exchange",entityId:"4E03OqVVyu2407sYn3Cmb3",contentType:"footerLink"},{linkText:"Blog",link:"/blog",entityId:"48YgmuEOMCfyNiOG6fKuIi",contentType:"footerLink"},{linkText:"For Startups",link:"/startup",entityId:"207UOY9KD3Fv9Vn1HOpnVq",contentType:"footerLink"},{linkText:"Partners",link:"/partners",entityId:"22Jz9PiLUIpO3te9ZZm2mb",contentType:"footerLink"},{linkText:"Change Log",link:"/change-log",entityId:"6D5newtErYVln01crlUkJ3",contentType:"footerLink"}],callsToAction:[],entityId:"5MBgd98sk9VXlbqC9UhGJS",contentType:"footerLinkGroup"},{linkText:"Replay 2026",link:"https://replay.temporal.io",entityId:"39IihW2pNN1catV0RRjRop",contentType:"footerLink"}],menuCtas:[{text:"Try Free",href:"/get-cloud",variant:"primary",leadingIcon:null,trailingIcon:null,entityId:"79w1QMsJg2MTAVGlu2jdss",large:false,theme:"ultraviolet"},{text:"Log In",href:"https://cloud.temporal.io/",variant:"secondary",leadingIcon:null,trailingIcon:null,entityId:"KAPnScSjIJkz74RbczQ2F",large:false,theme:"ultraviolet"}],footerLinks:[{title:"Discover",links:[{linkText:"Overview",link:"/product",entityId:"5d7x2oU3GnKl2PwRHfFMuR",contentType:"footerLink"},{linkText:"How Temporal Works",link:"/how-it-works",entityId:"5JvBIqkZjDTveG8rBLGk98",contentType:"footerLink"},{linkText:"Temporal Cloud",link:"/cloud",entityId:"7a4w9eJq6SDHLzFBCbPS4",contentType:"footerLink"},{linkText:"Pricing",link:"/pricing",entityId:"4mAmb12lsMPKYsVZhppKwL",contentType:"footerLink"},{linkText:"Security",link:"/security",entityId:"2jeP3NX1QybaIff6VqswXu",contentType:"footerLink"},{linkText:"Trust Center",link:"https://trust.temporal.io",entityId:"6JvstGMvrnsU3k7jr4X44s",contentType:"footerLink"},{linkText:"Startups",link:"/startup",entityId:"4xqwrRciKtVF6u7s1H09QE",contentType:"footerLink"}],callsToAction:[{text:"Get Started for Free",href:"/get-cloud",variant:"primary",leadingIcon:null,trailingIcon:null,entityId:"5rv8zi38jmzvxkw6RTXF10",large:void 0,theme:"ultraviolet"},{text:"Log In",href:"https://cloud.temporal.io/login",variant:"secondary",leadingIcon:null,trailingIcon:null,entityId:"6VuowrEOCRwy7W2AF42x4u",large:void 0,theme:"ultraviolet"}],entityId:"4epztNOZG4zdkSTcNzPL0s",contentType:"footerLinkGroup"},{title:"Explore",links:[{linkText:"Customer Stories",link:"/in-use",entityId:"5NHM0cToFOIOfWEKhILN5K",contentType:"footerLink"},{linkText:"Project-based tutorials",link:"https://learn.temporal.io/tutorials/",entityId:"49m9nbzR6ESqyTPDQes3Bq",contentType:"footerLink"},{linkText:"Example applications",link:"https://learn.temporal.io/examples/",entityId:"4gSShzYEMpRvjMVTm1Z2Zm",contentType:"footerLink"},{linkText:"Code Exchange",link:"/code-exchange",entityId:"4E03OqVVyu2407sYn3Cmb3",contentType:"footerLink"},{linkText:"Replay 2025 Recap",link:"/replay/2025",entityId:"WKxFa7VtBYoFpxbXBmLmE",contentType:"footerLink"},{linkText:"Ask an expert",link:"https://pages.temporal.io/ask-an-expert",entityId:"8EwBCGoohcDZnaSssqVwo",contentType:"footerLink"},{linkText:"Blog",link:"/blog",entityId:"48YgmuEOMCfyNiOG6fKuIi",contentType:"footerLink"}],callsToAction:[],entityId:"4TSqxuyMrVLtBrzEaGTAfA",contentType:"footerLinkGroup"},{title:"Developers",links:[{linkText:"Getting Started with Temporal",link:"https://learn.temporal.io/getting_started/",entityId:"3MakYxt6SSrjcQoHlsMVNd",contentType:"footerLink"},{linkText:"Start building your next app",link:"https://docs.temporal.io/dev-guide/",entityId:"ReUR12o5GJ7TtRT9hqUtb",contentType:"footerLink"},{linkText:"Temporal Cloud docs",link:"https://docs.temporal.io/cloud",entityId:"RzIgM3E3E06xvtI47tS4w",contentType:"footerLink"},{linkText:"Production deployments",link:"https://docs.temporal.io/production-deployment",entityId:"2OeOkTFbu4dsa3o86XzvP2",contentType:"footerLink"},{linkText:"Temporal 101",link:"https://learn.temporal.io/courses/temporal_101/",entityId:"4AhlRbcIYx2cdSgCGmUK8p",contentType:"footerLink"},{linkText:"Temporal 102",link:"https://learn.temporal.io/courses/temporal_102/",entityId:"3XL0r7EBbIw273NdTkW3F2",contentType:"footerLink"},{linkText:"Introduction to Temporal Cloud",link:"https://learn.temporal.io/courses/intro_to_temporal_cloud/",entityId:"3cCsE7bvSqYTOzUMeNk4Ml",contentType:"footerLink"}],callsToAction:[],entityId:"7CY4xLfQDevf6lTYNpIQeN",contentType:"footerLinkGroup"},{title:"Community",links:[{linkText:"Join our Slack group",link:"https://t.mp/slack",entityId:"1xMVykhhiEWRodXOuPnFIW",contentType:"footerLink"},{linkText:"Find a meetup near you",link:"/community",entityId:"2tvkQdG09YTz1isJPXD1U1",contentType:"footerLink"},{linkText:"Community forum",link:"https://community.temporal.io/",entityId:"7oVm0JFGanegsXT4bOOjCJ",contentType:"footerLink"},{linkText:"Events",link:"/events",entityId:"1iTUuLxKMc9djxa9WuGGM2",contentType:"footerLink"},{linkText:"Replay 2026",link:"https://replay.temporal.io/",entityId:"5Cb9K1EWP7AMRmwrG4x7Y3",contentType:"footerLink"}],callsToAction:[],entityId:"4NydwQZlTc68NC2MfMnwu2",contentType:"footerLinkGroup"},{title:"Company",links:[{linkText:"About",link:"/about",entityId:"1elL6e3d8pGbpBqDKKaJ4h",contentType:"footerLink"},{linkText:"Careers",link:"/careers",entityId:"17PUUqXrw2P6vdNHdMKuWp",contentType:"footerLink"},{linkText:"News",link:"/news",entityId:"1jpUgFD5yQTsIGkbEGTTa7",contentType:"footerLink"},{linkText:"Contact us",link:"https://pages.temporal.io/contact-us",entityId:"2BPNJwBWqxI8tta08ppxou",contentType:"footerLink"},{linkText:"Partners",link:"/partners",entityId:"22Jz9PiLUIpO3te9ZZm2mb",contentType:"footerLink"}],callsToAction:[],entityId:"53AeODgxpn6IHQwIaED2p8",contentType:"footerLinkGroup"}],footerForm:{formId:1001,title:void 0,errorMessage:"Please enter a valid email address",successMessage:"      Thank you for signing up for our newsletter!",introContent:"",background:"dark",alignment:"left",contentType:"marketoForm",entityId:"6vvH5NYYvowiSs0UETAzJT",postRollPageUrl:void 0,anchor:void 0},defaultBlogPromoCard:{title:"Get Started with Cloud Promo",eyebrow:"Temporal Cloud",heading:"Ready to see for yourself?",content:"Sign up for Temporal Cloud today and get $1,000 in free credits.",callsToAction:[{text:"Get started",href:"/get-cloud",variant:"primary",leadingIcon:null,trailingIcon:"arrow-right",entityId:"7wKJdxc4JeeNXHCliDfqVV",large:false,theme:"pink"}],entityId:"2SJj3BBBzkr6FefI6ZfRox",contentType:"noise"}},banner:{preLinkText:"Save on Replay 26 with code HOLIDAY60 | Move fast: Workshops almost sold out! | May 57, 2026 | ",link:"https://replay.temporal.io",linkToText:"Get tickets now ",postLinkText:void 0,publishDate:"2025-07-30T06:00-08:00",backgroundColor:void 0,textColor:void 0,linkColor:"#fbbf24",backgroundImage:{title:"replay-24-banner",description:"replay-24-banner",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1PaxfBoaUEi9Orjts4kqo0/1dc7abdfd3dc0b4ab5114220eb18ec57/replay-24-banner.jpg"},contentType:"banner"},githubStats:{stars:17270,forks:1247,watchers:107,issues:946,pulls:6390}},"uses":{}},{"type":"data","data":{featured:{title:"Use Swift with Temporal",content:"Last month in London the Temporal Swift SDK was announced at [ServerSide.swift](https://www.serversideswift.info) during a talk on how to [Write durable and resilient workflows in Swift.](https://www.youtube.com/watch?v=2KW78hoPBWA) I was happy to be invited on stage during the talk to explain Temporal and how it enables Durable Execution for distributed systems. The ServerSide.swift conference, solely run for the love of server-side Swift, was the perfect place to make this announcement.\n\nI started collaborating with the Swift community to create examples for this SDK in the time leading up to the talk. Getting to be one of the first people to write Swift code using this SDK has been a great experience. Im very excited to be able to share all the details about what the Temporal Swift SDK offers and how you can start using it __to build fault-tolerant distributed systems with Swifts modern concurrency features.__\n\nToday the Swift community has published an [announcement](https://www.swift.org/blog/swift-temporal-sdk/) with more details about the Temporal Swift SDK. I wanted to share how this can be adopted by the Temporal community.\n\n## Getting started\nThe Temporal Swift SDK lets you write reliable, long-running Workflows with Swifts native async/await and structured concurrency. This SDK enables you to build applications in Swift __that survive crashes__ and can handle failures, retries, and persistence automatically.\n\n__Docs__: https://swiftpackageindex.com/apple/swift-temporal-sdk/main/documentation/\n__SDK source on GitHub__: https://github.com/apple/swift-temporal-sdk\n\nGet started by adding the SDK to your `Package.swift`:\n\n```swift\ndependencies: [\n    .package(url: \"https://github.com/apple/swift-temporal-sdk.git\", upToNextMinor: \"0.1.0\")\n]\n```\n\nYoull need [Swift 6.2+](https://www.swift.org/install/), and the [Temporal CLI](https://docs.temporal.io/cli) for local development:\n\n## Swift-first design\nThis SDK is designed for Swift developers building distributed systems. Full Swift 6.2 structured concurrency support means that you use `TaskGroup`, async/await, and other concurrency primitives directly in your workflows. Compile-time type safety and macro-based APIs eliminate boilerplate code.\n\nUnder the hood, the Swift SDK wraps the Temporal Core SDK through Swifts C interop, using the same battle-tested state machines that power other Temporal SDKs. The SDK uses gRPC-swift for communication with Temporal Service.\n\nThe SDK provides four core components:\n\n- `@Workflow` and `@ActivityContainer` macros for defining Workflows and Activities\n- `@WorkflowSignal`, `@WorkflowQuery`, and `@WorkflowUpdate` for interacting with running Workflows\n- `TemporalWorker` for executing Workflows and Activities\n- `TemporalClient` for starting and managing Workflows\n\n## Workflows and Activities\nHere's a basic Workflow with a single Activity:\n\n```swift\nimport Temporal\nimport Logging\n\n// Define an Activity\n@ActivityContainer\nstruct GreetingActivities {\n    @Activity\n    func sayHello(input: String) -> String {\n        \"Hello, \\(input)!\"\n    }\n}\n\n// Define a Workflow\n@Workflow\nfinal class GreetingWorkflow {\n    func run(input: String) async throws -> String {\n        try await Workflow.executeActivity(\n            GreetingActivities.Activities.sayHello.self,\n            options: ActivityOptions(startToCloseTimeout: .seconds(30)),\n            input: input\n        )\n    }\n}\n```\nActivities run in the standard Swift environment with no restrictions. Bring along your existing `URLSession` code, file operations, and database calls. By leveraging Temporal, you gain a robust retry and timeout system without writing a mountain of code:\n\n```swift\ntry await Workflow.executeActivity(\n    Activities.fetchData.self,\n    options: ActivityOptions(\n        startToCloseTimeout: .seconds(30),\n        retryPolicy: RetryPolicy(\n            maximumAttempts: 3,\n            initialInterval: .seconds(1),\n            backoffCoefficient: 2.0\n        )\n    ),\n    input: request\n)\n```\n\nThe SDK handles retries and exponential backoff automatically when dealing with network failures, API timeouts, and service disruptions. Your Activity code stays clean.\n\n## Running Workflows\nA Worker connects to the Temporal Servicer, polls for tasks, and executes your Workflows and Activities. Configuring and starting the Worker is straightforward:\n\n```swift\nlet worker = try TemporalWorker(\n    configuration: .init(\n        namespace: \"default\",\n        taskQueue: \"my-queue\"\n    ),\n    target: .ipv4(address: \"127.0.0.1\", port: 7233),\n    transportSecurity: .plaintext,\n    activityContainers: MyActivities(),\n    workflows: [MyWorkflow.self],\n    logger: Logger(label: \"worker\")\n)\n\ntry await worker.run()\n```\n\nClients are able to start Workflows from anywhere in your application (servers, CLI tools, and even iOS apps):\n\n```swift\nlet client = try TemporalClient(\n    target: .ipv4(address: \"127.0.0.1\", port: 7233),\n    transportSecurity: .plaintext,\n    logger: Logger(label: \"client\")\n)\n\nlet result = try await client.executeWorkflow(\n    MyWorkflow.self,\n    options: .init(id: \"business-meaningful-id\", taskQueue: \"my-queue\"),\n    input: \"data\"\n)\n```\n\n## More than just Workflows\nThe SDK includes comprehensive support for Temporal's full feature set:\n\n### Workflow interaction\n- __Signals__  Send data to running Workflows\n- __Queries__  Read Workflow state without modifying it\n- __Updates__  Modify Workflow state, with optional validation, and wait for results\n\n### Advanced patterns\n- __Child Workflows__  Compose Workflows for complex orchestration\n- __Continue-as-New__  Handle long-running Workflows without exceeding history limits\n- __Local Activities__  Execute fast operations without full activity overhead\n- __Search Attributes__  Locate and filter Workflows in the Temporal UI\n\n### Production-ready\n- __Interceptors__  Add cross-cutting concerns like authorization, logging, such as metrics\n- __OpenTelemetry__  Built-in distributed tracing and metrics\n- __Custom Data Converters__  Control serialization and applying client-side encryption to protect your data\n- __Retries & Timeouts__  Declarative failure handling at every level\n\n## Examples to help you get started: Learning by doing\nThe SDK includes examples that show real patterns youll use in production:\n- __[Async Activities](https://github.com/apple/swift-temporal-sdk/tree/main/Examples/AsyncActivities)__  Parallel Activity execution using NYCs Open Data API to process film permits\n- __[Child Workflows](https://github.com/apple/swift-temporal-sdk/tree/main/Examples/ChildWorkflows)__  Parent-child Workflow orchestration with a pizza restaurant order system\n- __[Schedule](https://github.com/apple/swift-temporal-sdk/tree/main/Examples/Schedule)__  Temporal schedules with live NASA APIs monitoring the ISS\n- __[Signals](https://github.com/apple/swift-temporal-sdk/tree/main/Examples/Signals)__  Interact with running Workflows via Signals, Queries, and Updates\n- __[Error Handling](https://github.com/apple/swift-temporal-sdk/tree/main/Examples/ErrorHandling)__  Retry policies, compensation logic, and failure-recovery patterns\n\nEach example runs against real external APIs (NASA, NYC Open Data) or simulates a business process so you see how to handle timeouts, retries, and rate limiting in practice.\n\n## Whats next?\nThis SDK is under active development. The Swift community is iterating quickly based on feedback, adding features, and improving the developer experience.\n\n__Try it out:__\n```shell\ngit clone https://github.com/apple/swift-temporal-sdk.git\ncd swift-temporal-sdk\nswift build\ntemporal server start-dev  # in another terminal\nswift run GreetingExample\n```\n\nBuilding something cool? Share it in the [Community Slack](https://t.mp/slack) (__#community-swift-sdk__) or on the [community forum](https://community.temporal.io/c/show-and-tell/).\n\nHave feedback or hit a snag? [Open an issue](https://github.com/apple/swift-temporal-sdk/issues) on GitHub.\n\nIf youre building distributed systems with Swift (whether thats server-side applications, data pipelines, or business process automation), \u003Ca href=\"mailto:shy@temporal.io\">Id love to hear from you\u003C/a>.",featureImage:{title:"blog-temporal-swift",description:"blog-temporal-swift",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6hgCN7R3WNZc6jMk8qCdCA/ff249585d66d7613501fa1046ebe289f/Blog-temporal-swift.png"},publishDate:"2025-11-10",metaDescription:"Announcing the Swift Temporal SDK. Build durable, fault-tolerant Workflows in Swift 6.2 with async/await and structured concurrency.",metaTitle:"Use Swift with Temporal",socialCard:{title:"Social-swift-1",description:"Social-swift-1",url:"https://images.ctfassets.net/0uuz8ydxyd9p/78MxixAZ7mXNmKRYBSom6G/a5030443fe442f197c65851ce7a48218/Social-swift-1.png"},tags:"Durable Execution,Industry Events",slug:"temporal-now-supports-swift",contentType:"blogPost",entityId:"lfaPhZa1NPPslttSljLit",authors:[{id:"2OEttjgfmRLmQfHqO5YLlQ",name:"Shy Ruparel",slug:"shy-ruparel",jobTitle:"Senior Developer Advocate",photograph:{title:"Shy Ruparel Headshot.",description:"Shy Ruparel Headshot.",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2apitzQRzLDriiJqG3SCbt/77eca358e97163231091dd044cb74034/Headshot.jpg"},biography:"Shy is currently a Senior Developer Advocate at Temporal. Building on a rich career that includes impactful roles at Docker, Superblocks, Contentful, hackNY, and Major League Hacking, Shy has spent a decade dedicated to empowering developer communities. Shy combines technical expertise with a passion for teaching.\n\nBeyond his professional work, Shy spends his time building unconventional IoT projects, reading long science fiction and fantasy novels, hosting dinners for 10-30 friends every other week.",twitterUrl:void 0,linkedInUrl:"https://www.linkedin.com/in/shyruparel/",website:"https://shy.dev/",gitHubUrl:void 0,company:"Temporal",contentType:"person"}],authorsString:"Shy Ruparel",category:"Announcements",relatedPosts:void 0,promoCard:void 0,readingTime:5},posts:[{title:"Tips for running Temporal on Kubernetes",content:"Kubernetes has become the foundation for deploying and operating cloud-native applications at scale. It excels at keeping your application topology healthy by replacing failed pods, managing rollouts, and handling networking and service discovery.\nHowever, Kubernetes stops at the infrastructure boundary. It does not manage what happens inside your applications. It will not handle retries when a call fails, recover in-progress state after a crash, or coordinate multi-step workflows across services.\nWhy Temporal?\nTemporal provides durability as a service. It gives developers a programming model that automatically handles state persistence, retries, and recovery so Workflows continue reliably even when infrastructure is constantly changing. All you need to do is write the happy path and determine the business logic of your code, and Temporal takes care of the rest.\nRunning Temporal on Kubernetes combines operational and logical resilience. Kubernetes keeps workloads alive and healthy, while Temporal ensures that application logic remains consistent and durable. Organizations rely on Temporal to guarantee reliable execution  even when infrastructure is unstable or services fail mid-operation.\nIn this post, we share practical tips for deploying and operating Temporal on Kubernetes to achieve predictable latency, safe upgrades, and efficient scale.\nRun the Temporal Service on Kubernetes with Helm charts\nTemporal provides official Helm charts that make it simple to deploy the Temporal Server components (Frontend, History, Matching, Worker) to Kubernetes. This Helm chart can also be used to install just the Temporal server, configured to connect to dependencies (such as a Cassandra, MySQL, or PostgreSQL database) that you may already have available in your environment.\nOnly the portions of the Helm chart that configure and manage Temporal itself are considered production-ready. The bundled configurations for Cassandra, Elasticsearch, Prometheus, and Grafana are minimal development configurations and should be reconfigured for a production deployment.\nIf you already use Helm for production deployments, you can use our Helm chart with these important modifications:\n\n  \n    Disable bundled dependencies: Turn off all the included add-ons (Cassandra, Prometheus, etc.) that come with the chart.\n  \n  \n    Deploy only Temporal services: Configure the chart to install just the core Temporal components.\n  \n  \n    Use external dependencies: Connect to your existing, externally managed databases and infrastructure instead.\n  \n\nUpgrading is also an important consideration for managing Helm charts, and its crucial to update your database schema before running a Helm upgrade. This prevents schema mismatches that can lead to downtime or failed migrations. We recommend automating this step in your upgrade process for consistency and safety.\nIf youre exposing the Temporal Web UI, its recommended to configure authentication and environment variables early, especially when integrating with SSO or embedding the UI into your own platform. Doing this upfront avoids surprises later when you want to scale access to multiple users.\nDeploy Temporal Workers on Kubernetes\nTemporal Workers are long-running processes that poll for Tasks and execute your Workflow and Activity code. Kubernetes is an ideal platform for running Workers because it handles exactly what Workers need: automatic restarts on failure, horizontal scaling based on workload, and seamless deployments with zero downtime.\nAs your Workflow execution demands grow, Kubernetes lets you scale Worker pods independently from your other services, ensuring your Task Queues never bottleneck your system.\nBasic deployment approach\n1. Containerize your Worker: First, create a Dockerfile for your Worker. Heres an example for Python from the Quick Launch  Deploying your Workers on Amazon EKS guide:\n# Use Python 3.11 slim image as base\nFROM python:3.11-slim\n\n# Set working directory\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update && apt-get install -y \\\n    gcc \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install the Temporal Python SDK dependency\nRUN pip install --no-cache-dir temporalio\n\n# Copy application code\nCOPY . .\n\n# Set Python to run in unbuffered mode\nENV PYTHONUNBUFFERED=1\n\n# Run the worker\nCMD [\"python\", \"worker.py\"]\n\nImportant note: You should dockerize your Worker code (which includes both your Workflow definitions and the Worker process that polls for Tasks) together, not separately. Create one Docker image containing both your Workflow code and Worker.\n2. Deploy to Kubernetes: Create a Kubernetes Deployment manifest with YAML\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n   name: your-app\n   namespace: your-namespace\n   labels:\n      app: your-app\nspec:\n   selector:\n      matchLabels:\n         app: your-app\n   replicas: 1\n   template:\n      metadata:\n         labels:\n            app: your-app\n      spec:\n         serviceAccountName: your-app\n         containers:\n            - name: your-app\n              image: \u003Cyour-ecr-image-name>\n              env:\n                - name: TEMPORAL_ADDRESS\n                  valueFrom:\n                    configMapKeyRef:\n                      name: temporal-worker-config\n                      key: TEMPORAL_ADDRESS\n                - name: TEMPORAL_NAMESPACE\n                  valueFrom:\n                    configMapKeyRef:\n                      name: temporal-worker-config\n                      key: TEMPORAL_NAMESPACE\n                - name: TEMPORAL_TASK_QUEUE\n                  valueFrom:\n                    configMapKeyRef:\n                      name: temporal-worker-config\n                      key: TEMPORAL_TASK_QUEUE\n                - name: TEMPORAL_API_KEY\n                  valueFrom:\n                    secretKeyRef:\n                      name: temporal-secret\n                      key: TEMPORAL_API_KEY\n              resources:\n                limits:\n                  cpu: \"0.5\"\n                  memory: \"512Mi\"\n                requests:\n                  cpu: \"0.2\"\n                  memory: \"256Mi\"\n\n\nYoull then need to apply the deployment.yaml file to the EKS cluster.\n3. Use ConfigMaps for non-sensitive configuration and Secrets for sensitive data like API keys, as shown in the deployment guide.\nWhen you deploy the Temporal Service and Workers in the same Kubernetes Cluster, Workers running inside the Cluster can simply connect to the Frontend service using the Cluster-internal DNS (for example, temporal-frontend.temporal:7233).\nFor Workers outside the Cluster (such as in another VPC, another cloud account, or on-prem), youll need to expose the Frontend via a load balancer or Ingress (for example, using AWS NLB/ALB annotations) so the gRPC port 7233 is reachable externally.\nSome tips\n\n  \n    Use standard Kubernetes patterns: Workers are just regular applications  apply your existing K8s best practices when deploying them.\n  \n  \n    Consider the Worker Controller: For advanced version management, explore the Temporal Worker Controller for zero-disruption deployments. This Kubernetes operator enables you to safely deploy new Worker versions by ensuring old Workflows complete on existing Workers while new Workflows start on updated Workers.\n  \n  \n    Use Worker Versioning: This feature helps you manage different builds or versions, formally called Worker Deployment Versions. This feature enables you to ramp up traffic gradually to a new Worker Deployment Version, verify a new Deployment Version with tests before sending production traffic to it, or initiate an instant rollback when you detect that a new Deployment Version is broken.\n  \n\nAutoscaling Temporal Workers on Kubernetes\nOnce your Workers are deployed to Kubernetes, the next challenge is scaling them. The key insight: traditional CPU and memory metrics often mislead when it comes to Temporal workloads.\nWhy standard metrics fall short\nYou might see perfectly healthy CPU usage while your Task latency climbs. This happens because Workers spend significant time waiting on external operations, such as database queries, API calls, or coordination with the Temporal Server. During these waits, CPU stays low even though Workers are busy and cant accept new tasks. Your autoscaler thinks everythings fine while users experience degraded service.\nMetrics that actually matter\n\n  \n    Task Queue Backlog gives you a direct count via the DescribeTaskQueueEnhanced API. If 100 Tasks are waiting and each Worker handles 10 concurrent Tasks, you need 10 Workers. Simple math, clear signal.\n  \n  \n    Schedule-to-Start latency is your primary signal. This measures the time from when a Task is scheduled until a Worker picks it up. Available as activity_schedule_to_start_latency and workflow_task_schedule_to_start_latency, increasing latency directly indicates Tasks are waiting in Queue  time to scale up.\n  \n  \n    Worker Task slots (temporal_worker_task_slots_available and temporal_worker_task_slots_used) tell you if Workers are at capacity. Calculate utilization as: (used / (used + available)) * 100.\n  \n\nCritical considerations\n\n  Avoid premature scale-down. A backlog of zero doesnt mean Workers are idle; they might be actively processing Tasks. Always check worker_task_slots_used alongside backlog metrics.\n  Ensure graceful shutdown so Workers complete in-flight Tasks before termination. Set appropriate termination grace periods in your Pod specs.\n\nRather than trying to scale manually, its even easier to use KEDA-based autoscaling to automatically scale Temporal Workers based on a Task Queues backlog. This is particularly useful for handling variable workload demands efficiently in a Kubernetes environment. You can see the full demo here and check out the repository to get started.\nPlanning capacity and tuning for production\nScaling a Temporal Cluster isnt a one-size-fits-all process. Every team has different workload patterns, business requirements, and operational constraints. When you first deploy Temporal, youll find it configured with development-level defaults: fine for getting started, but not ready for production traffic.\nThe key is to approach scaling iteratively. We recommend a continuous cycle: gradually increase your load through testing, watch where the system struggles, make targeted adjustments, then repeat.\nAlways load test on dedicated test Clusters before applying changes to production. Each iteration teaches you something new about how your specific workloads behave under pressure. Maybe youll discover you need more CPU headroom, or perhaps youre over-provisioned and can scale down to save costs.\nThe hidden performance killer: CPU throttling\nAs you tune your Cluster, youll likely encounter a subtle but critical issue with request latency. The Temporal Server needs low, consistent latencies to maintain high throughput, and Kubernetes can sometimes act counterintuitively against this. When a container tries to use more CPU than its limit allows within a 0.1-second window, Kubernetes throttles it.\nGOMAXPROCS controls how many OS threads Go uses for concurrent execution. By default, Go detects all CPU cores on the host machine. If your Pod has a 2-core CPU limit but Go sees 64 cores on the node, it will try to use all 64, leading to CPU throttling.\nThe solution: set GOMAXPROCS to match your Pods CPU limit. For example, if youve allocated two cores, set GOMAXPROCS=2. This alignment prevents throttling, stabilizes latencies, and can actually reduce overall CPU usage while improving performance.\nThe good news? From Temporal 1.21.0 onward, this happens automatically if you havent configured it yourself.\nYoure ready to get started!\nNow youre ready to deploy and operate Temporal on Kubernetes with confidence. By following these patterns, youll build a resilient foundation that scales with your business needs. Remember to iterate on your capacity planning as your workload patterns evolve, and leverage Kubernetes-native tools like KEDA to automate scaling decisions.\nIf you want to focus on building applications and not worrying about clusters, Temporal Cloud handles all the operational complexity for you. Get started for free today or talk to our team about your use case.",featureImage:{title:"social-card-dark-waves",description:"social-card-dark-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2EnRRWXLoTeCWl9m4xuZvn/d01871a31191cc3054b7f6a08f29d628/social-card-dark-waves.jpg"},publishDate:"2025-12-15",metaDescription:"Learn practical tips for deploying and scaling Temporal on Kubernetes. Covers Helm charts, KEDA autoscaling, and production performance tuning.",metaTitle:"Tips for running Temporal on Kubernetes",socialCard:{title:"Blog (57)",description:"Blog (57)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/49diKv8SaO4NERVJCtjp0F/41b63c68a89e7756414075ad15e64034/Blog__57_.png"},tags:"Kubernetes,Python,Go,Scaling,Code Samples",slug:"tips-for-running-temporal-on-kubernetes",contentType:"blogPost",entityId:"2ndzCU1wfSzJBAicoY2Hr7",authors:[{id:"1yrw1pOcC2diZQ4Eh34TIG",name:"Cubby Sivasithamparam",slug:"cubby-sivasithamparam",jobTitle:"Product Marketing Manager, Platform Operations",photograph:{title:"TT31S6VK5-U08R85TH125-f6bfe8629b58-192",description:"TT31S6VK5-U08R85TH125-f6bfe8629b58-192",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5SX3woxXVYFZUsZBlZnbpf/d54322791501d0d22b2ac95f4e462037/TT31S6VK5-U08R85TH125-f6bfe8629b58-192.jpeg"},company:"Temporal",contentType:"person"}],authorsString:"Cubby Sivasithamparam",category:"How-To",readingTime:9},{title:"The city of systems: Temporal, Kafka, and Nexus",content:"\n  Welcome to the vast digital metropolis of Systemville, where every town represents a service.\n  This world feels infinite. Its a mesh of glowing circuits stretching to the horizon, each block is alive with a specific purpose.\n\n\n  \n\nYou have the sleek, systematic city of Order Town, where requests line up in perfect queues. Theyre all stamped, tracked, and validated before their departure filling the skyline up with blinking dashboards and the hum of transaction logs in the air.\nAcross the shimmering river, theres Payment Village. This one is a bit smaller, but a little more intense. The streets here are patrolled by watchful guards of encryption and ledgers and every citizen wears a badge of verification with every handshake cryptographically sealed.\nEven further out is Inventory Borough and this is a place of constant motion. The conveyer belts stock data, scanners flash, and warehouses stretch hiiigh into the cloud.\nThe citizens here are data packets, constantly traveling between towns to keep commerce alive and communication constant.\nPresiding over it all are two legendary builders leading the way:\nKafka, master of the high-throughput freeways\nand\nTemporal, architect of the structured local roads.\nTogether, they do the heavy work of shaping Systemville, where speed and structure come to thrive.\nKafka and the freeways of broadcast\nThe mayor of Kafkas vision was one of throughput and constant motion  a city where information flowed without pause and expansion was built into its very design.\nTo achieve this, the Kafka residents constructed the freeways of broadcast. These are multi-lane highways, where trucks of data race between distant towns at blinding speed.\nAlong these highways stand radio towers (Kafkas publisher and subscriber system).\nThese radio towers broadcast every event:\nOrder created!\nPayment processed!\nShipment dispatched!\nAll to any town that tunes in.\n\n  Publishers are factories and services sending updates onto the highway.\n  Subscribers are towns listening for specific announcements.\n  Consumer groups share the listening workload.\n  Partitions act as separate lanes to keep traffic flowing smoothly.\n\nKafkas freeways and towers made Systemville hum with activity, but there are tradeoffs:\nThe freeways were fire-and-forget, and the towers broadcast without memory.\nThey were perfect for volume and flow, but fragile under strain  a single stalled truck or lost signal could ripple into massive congestion across the city.\nTemporal and the roads of reliability\nThis is where Temporal stepped in to help.\nWhile Kafkas infrastructure buzzed with motion and throughput, Temporal brought fault tolerance to the streets. Inside each town, it built a network of well-engineered roads equipped with detours, recovery lanes, and signal systems that kept traffic flowing even when accidents happened. No journey was lost, only momentarily rerouted until it could safely continue.\n\n  If a delivery truck broke down, the road remembered where it stopped and resumed from that point.\n  If the journey took hours or days, Temporals plan ensured no detail was lost.\n  Each route, or Workflow, represented durable progress through complex operations.\n\nTemporals roads gave Systemville the memory and discipline that Kafkas highways lacked.\nStill, towns often needed to speak directly to one another, not just shout through the radio towers or highways.\nAnd some conversations werent quick. A payment verification could take minutes. A shipping workflow might span days.\nThats when Nexus changed everything.\nNexus: The bridges of durable promises\nNexus is neither a freeway nor a simple road. It was a new kind of infrastructure  a network of durable bridges connecting towns directly.\nEach bridge was built on a durable promise: once a town began an operation with another, that operation would finish, no matter how long it took or what failed in between.\n\n  If a town requested payment authorization, the Nexus bridge carried the request and held it until completion, even if the Payment Village went offline.\n  If the operation took seconds, minutes, or days, the bridge kept the promise alive.\n  When the task was done, the bridge delivered the result safely, exactly once, without any lost or duplicated effort.\n\nIn Systemville terms, Nexus bridges carry entire operations across time rather than just doing the job of delivering messages.\nEach bridge acts as a long-lived channel of execution.\nIt allowed towns to bypass the freeways when they needed direct, guaranteed completion rather than high-speed broadcast.\nHow the city runs today\nNow, the city thrives with all three systems working in harmony:\n\n  Kafkas pub/sub towers and freeways spread updates far and wide\n  Temporals roads handle the local journeys that require structure, retry, and resilience.\n  Nexus bridges connect towns directly for operations of any duration  whether a short query or a multi-day fulfillment - ensuring the promise is always kept.\n\nFor example:\n\n  Order Town publishes an order created event via Kafkas towers.\n  Temporal picks up the event and starts a workflow to handle fulfillment.\n  That Workflow calls Payment Village via Nexus, establishing a durable bridge for payment authorization.\n  The Workflow waits, even for days if needed, until the promise completes.\n  When done, a Kafka event is published to broadcast order shipped across the city.\n\nEvery layer plays its part:\n\n  Kafka moves data in bulk\n  Temporal delivers work with reliability.\n  Nexus operates with certainty, regardless of duration or distance.\n\nThe city in perfect balance\nToday, the citizens of Systemville move confidently.\nSome travel the freeways, some follow the structured roads, and some cross the durable bridges of Nexus.\nThe city runs with both speed and certainty, because its three systems understand their purpose and respect each others domain.\nIn the citys charter, one inscription defines their unity:\nKafka delivers events at bulk. Temporal organizes work with state. Nexus keeps promises for as long as time itself.\nBuild your own bridges. With Temporal Nexus, your services will keep their promises.\nStart building with Nexus today.",featureImage:{title:"city-of-systems-blog-image",description:"city-of-systems-blog-image",url:"https://images.ctfassets.net/0uuz8ydxyd9p/LDAV9ngKAFShWdhFw3gxx/825bdb042322a2adbc8b25decd2663c0/city-of-systems-opt-2.png"},publishDate:"2025-12-10",metaDescription:"Temporal, Kafka, and Nexus create the blueprint for great distributed systems, balancing high-speed event streaming with guaranteed certainty.",metaTitle:"The city of systems: Temporal, Kafka, and Nexus",socialCard:{title:"The-city-of-systems-social-media-image",description:"The-city-of-systems-social-media-image",url:"https://images.ctfassets.net/0uuz8ydxyd9p/OyAXzPInGARxdS9HtTM2Y/26cb17667d091465d32227424dc239dc/The-city-of-systems-social-media-image.png"},tags:"Durable Execution",slug:"city-of-systems-temporal-kafka-nexus",contentType:"blogPost",entityId:"3keZ8tePtsZyzSINmiHvjD",authors:[{id:"1X8y9RWlP8D5TPrughvFd2",name:"Maxim Fateev",slug:"maxim-fateev",jobTitle:"CTO and Co-Founder",photograph:{title:"Maxim Fateev",description:"Maxim Fateev",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7EdtHMKPMc4iH2gcwIzp8U/1909c8a7ab0fb81b122afe6810bb58c1/861A2412.jpg"},biography:"Max is CTO and co-founder of Temporal. He is a 20-year veteran of AWS, Google, and Uber, engineering leadership, having led the development of the SQS replicated message store and the Simple Workflow service at AWS, and then co-creating Cadence (Temporals predecessor) at Uber. Today, millions of Temporal workflows are run daily for high reliability and high scalability workloads from Stripe to Datadog to Snapchat.",twitterUrl:"https://twitter.com/mfateev",company:"Temporal",contentType:"person"},{id:"3tpPddZVxZWz2ed9Lz8CTR",name:"Tao Guo",slug:"tao-guo",jobTitle:"Solution Architect",photograph:{title:"Tao Guo Photo",description:"Tao Guo Photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/F2lo0UY87HlIumy3DmkOS/8efb79d84adeb08229f0fbd5a52742f4/7697484.png"},company:"Temporal",contentType:"person"}],authorsString:"Maxim Fateev, Tao Guo",category:"Temporal Voices",readingTime:5},{title:"AWS re:Invent 2025: Why the future of the cloud is durable",content:"\n  \n\nLas Vegas is always a lot to handle, but AWS re:Invent 2025 felt different. The noise was there, as always, but the signal cutting through it was stronger than I have seen in years.\nWalking the floor and spending time at booth #1382, I saw a fundamental shift in how the industry is building software. The conversation has moved past why we exist. The focus is now entirely on how to scale the patterns everyone knows they need.\nHere are my takeaways from a blur of a week.\nThe validation of Durable Execution\nOne moment defined the week: AWS launching Lambda Durable Functions.\nFor years, we have argued that Durable Execution is the only way to build reliable distributed systems. When the worlds largest cloud provider adopts your terminology and your architectural philosophy, the debate is effectively over. The primitive we championed has become an industry standard.\nThis validates our entire model. The future of cloud computing requires running workflows reliably, over time, without failure.\nThe reality of agentic AI\nThe other undeniable theme was the shift from chatbots to agents.\nEveryone is building AI, but the conversations have matured. We moved past the hello world phase of LLMs into real-world application. It was clear at the booth, with the crowd watching Steve Androulakis demo the OpenAI Agents SDK integration.\n\n  \n\nWe saw this in the packed sessions for our talks on AgentCore and Durable Execution. An AI agent is only as good as its ability to complete a task. If an agent hallucinates, that is a model problem. If an agent hangs or crashes mid-task, that is a reliability problem. Temporal solves the latter, and this week proved that reliable plumbing is the missing piece of the AI stack.\nTemporal on the move\nWe decided to paint the town a little bit this year. If you were moving between the airport, the Venetian, or the various parties on the Strip, you likely saw our fleet of Ziggy cars acting as rides for attendees.\n\n  \n  \n  \n\nIt was a fun way to help folks get around, but it also served as a moving billboard for exactly what we bring to the table. In a city defined by luck and chaos, we bring reliability.\nCommunity energy\nWe punched well above our weight this year.\nBeyond the booth, the capacity crowd at our House of Kube party was a highlight. We hit almost 1,000 attendees, and the room was packed.\n\n  \n\nLooking ahead\nThe market is coming to us. The cloud giants are validating us. And the AI revolution is relying on us. 2026 is going to be an incredible year for Durable Execution.\nSafe travels home, everyone.",featureImage:{title:"IVR52714 Large",description:"IVR52714 Large",url:"https://images.ctfassets.net/0uuz8ydxyd9p/ARdCPLCHOUgCPoFXqVNoN/c96525532b6048af042d402bf8dbfae0/IVR52714_Large.jpeg"},publishDate:"2025-12-04",metaDescription:"Las Vegas is always a lot to handle, but AWS re:Invent 2025 felt different. The noise was there, as always, but the signal cutting through it was stronger than I have seen in years.",metaTitle:"AWS re:Invent 2025: Why the future of the cloud is durable",tags:"Meetups,Industry Events,Durable Execution",slug:"aws-reinvent-2025-recap",contentType:"blogPost",entityId:"4pnggaIjIDrJ62rmDlHLrL",authors:[{id:"1xCMA9tU4DFRKfBJgJaBRo",name:"Samar Abbas",slug:"samar-abbas",jobTitle:"CEO and Co-Founder",photograph:{title:"Samar Abbas",description:"Samar Abbas",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5ET9VSHfvnFpbBEmpfoBDN/f5bd4ea1eeb428c5f8f4bcf02246ec82/861A2427.jpg"},biography:"Samar is CEO and cofounder of Temporal. He is a 20-year veteran of AWS, Microsoft and Uber engineering leadership, having worked on Amazon Simple Workflow Service from inception and led development of the Durable Task Framework at Azure, and then co-creating Cadence (Temporals predecessor) at Uber. Today, millions of Temporal workflows are run daily for high reliability and high scalability workloads from Stripe to Datadog to Snapchat.",twitterUrl:"https://twitter.com/samarabbas77",company:"Temporal",contentType:"person"}],authorsString:"Samar Abbas",category:"Community",readingTime:3},{title:"Introducing the Temporal Constellation Program",content:"We're launching the Temporal Constellation Program, a new initiative  to recognize and support engineers who've shaped our ecosystem through code, talks, articles, and community support. The Constellation Program is our way of saying: we see you, and we're fans of what you're building.\n\n  \n\nOur first cohort\nThe engineers in our inaugural cohort bring diverse perspectives from industries including retail, entertainment, social media, and gaming. They work in different languages, solve different problems, and contribute in different ways. What they share is a track record of creating resources that help others succeed with Temporal.\nFor show & tell, here's some of what they've built! Read on to level up your understanding of all the things Temporal can do\nProduction architecture at scale\nRob Zienert has been sharing how he uses Temporal for years, both the wins and the actual architecture decisions and trade-offs. He leads the Temporal team at Netflix, having introduced the tool during his time as a tech lead for the CI/CD platform Spinnaker. Check out his Replay talk on Nexus and Durable Execution across team boundaries at scale, and the accompanying blog post going in depth on automating Temporal.\n\n  \n\nNaveen Achyuta is a senior software engineer specializing in building powerful software systems for the networking industry. His work bridges the gap between software development and networking, creating systems that enable teams to efficiently manage and monitor complex network environments. He recently spoke at AutoCon about transforming network automation with Temporal.\n\n  \n\nJack Burns builds and scales distributed systems that make AI and data platforms work better together. Hes been working with workflow orchestration since the Cadence days (!!), writing a C# SDK and contributing to the Go one too. These days, he leads Temporal and data streaming platforms at Nordstrom and helps teams design resilient architectures. He spoke at Replay 2024 on orchestrating a Kafka migration with Temporal, a real-life example of orchestrating the migration of a platform that supports 220+ engineering teams and thousands of applications.\n\n  \n\nOpen source tools and SDKs\nGreg Haskins is CTO at Manetu, where he uses Temporal primarily as a high-performance SAGA orchestrator for their Kubernetes-based knowledge protection platform. He maintains the community-led Temporal Clojure SDK, in addition to other Temporal Code Exchange projects like the CustomDataStore for Yugabyte YCQL.\n\n  \n\nJ.D. Nicholls is a full-stack Web3 engineer, an open-source contributor, mentor, and speaker, and the creator of proyecto26 and ProjectX, a comprehensive full-stack template designed to simplify the development of scalable and resilient applications using React and Temporal. Hes active in Medellns tech community and passionate about sharing knowledge through talks and workshops. Check out his Temporal Community Live session on Event-driven Architectures for Full-Stack Devs with Temporal and React.\n\n  \n\n\n  Enny Frick is a software engineer with a focus on reliability, currently at ConductorOne and previously a site reliability engineer at Box. She has run Temporal Cluster on-premise, migrated those workloads to Temporal Cloud, and made contributions to the Temporal Cloud Terraform provider.\n  Enny built the Terraform provider for Temporal Cloud and the ConductorOne connector.\n\n\n  \n\nTechnical writing and education\nSanil Khurana is a software engineer with experience across backend, platform, and DevOps roles, who uses Temporal in both production and exploratory contexts, and writes in-depth technical articles on systems architecture  including databases, data infrastructure, and workflow orchestration. Sanil authored an in-depth step-by-step breakdown of Temporal's internal architecture that makes all this much easier to understand!\n\n  \n\nRebecca Powell leads two software engineering teams at Lichtblick SE, a renewable energy company focused on the German B2B sector. She has 25+ years experience working with Microsoft technologies, and their complex business critical processes are being moved to durable workflows using Temporal. Among her many technical articles is a three-part series on combining .NET Aspire with Temporal, complete with working code examples on GitHub.\n\n  \n\nEdmondo Porcu is a software engineer with 17+ years in scalable data infrastructure and distributed systems, currently working at Pinterest. He discovered Temporal after experiencing the pain of legacy workflow engines as a CTO at Credimi in 2016. He realized its potential for Durable Executions while investigating a lab management system. As a Distinguished Engineer at Capital One, he advocated for Temporal adoption at scale and co-founded the Durable Executions Center of Practice. He maintains the Awesome Durable Executions repository, contributes to the DataFusion community, and is active in the NYC tech community (Rust NYC, NixOS).\n\n  \n\nInternal champions\nSome contributions happen inside organizations, where engineers push for adoption, solve integration challenges, and help their teams succeed with Temporal.\nAnastasiya Melentyeva is a Senior Engineer at Xero, part of the small, dedicated group responsible for successfully adopting Temporal. For the past two years, her work has involved building resilient workflows leveraging .NET SDK and creating internal tooling and processes for shipping code to production with confidence.\nShabnam Emdadi is currently a Staff Engineer at Shopify. Her recent project work has focused on merchant communications. She first got introduced to Temporal at my previous company, Peloton, where she stood up their self hosted cluster and where it is still used today! Shabnam is working in Ruby these days but more of a Go lady.\nAbout the Constellation Program\nThe Temporal Constellation Program brings together standout community members into a small, curated network of engineers building with Temporal. Constellation members are individuals whove made an impact: writing technical content, speaking at events, answering questions, and building open source tools that help others succeed with Temporal.\nBenefits of Temporal Constellation Program membership:\n\n  Be the first to know: Early looks at new features, Q&As with key Temporalites, and a private space just for program participants.\n  Meet your peers: Swap insights and solve challenges with peers in your field whove been there too.\n  Join us at Replay: The VIP experience at Temporal's flagship conference, Replay, in SF 2026.\n  Be in the spotlight: Well co-promote your work through Temporals channels to reach a wider audience. Build skills, credibility, and visibility.\n  Brag-worthy swag: Limited-edition Constellation gear for looking fresh both on Zoom and in person.\n  Shape Temporal: Help build the future of Temporal with us. Hear about our upcoming features from the people building them, and provide feedback on whats most valuable to you.\n\nThe Temporal Constellation Program is currently invite-only. We invite new members to the program periodically based on a number of factors, including:\n\n  An established track record of making meaningful contributions that help others succeed with Temporal. For example: writing technical content, speaking at events, answering questions, and building open source tools.\n  Nominations from Temporal employees and Constellation Program members.\n  Engineers doing particularly notable things with Temporal and/or using Temporal at particularly notable companies.\n\nLooking to get more involved?\n\n  Learn more about the Constellation program and the first cohort at temporal.io/community/constellation\n  Join Temporals Community Slack, where you can interact with these folks, Temporal Staff, and our large community of users\n  Submit something youve built to Temporals Community Code Exchange\n  Feel free to reach out to us with any questions in our Temporal Community Slack in #community-meta\n",featureImage:{title:"hazel-z-45AHiklPJH4-unsplash",description:"hazel-z-45AHiklPJH4-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Potp6G9LHoZ780AhLw3vs/861da43ba6e469417a7a9084b708e71f/hazel-z-45AHiklPJH4-unsplash.jpg"},publishDate:"2025-12-02",metaDescription:"We've launched the Temporal Constellation Program to recognize all the amazing developers that shape Temporal.",metaTitle:"We've launched the Temporal Constellation Program",tags:"Contributions,Code Samples",slug:"introducing-the-temporal-constellation-program",contentType:"blogPost",entityId:"6tvLLYhCfDSCz8D05BGohN",authors:[{id:"tJd1spOLkwkyBQxp064XZ",name:"Kara Deloss",slug:"kara-deloss",jobTitle:"Open Source Community Outreach Lead",photograph:{title:"Kara-Deloss-headshot-pfp",description:"Kara-Deloss-headshot-pfp",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5knqPSXB9n1VQX8WXxNXBe/9485a5f698d214e0b043cba5d92f0646/Kara-Deloss-headshot-pfp.jpeg"},company:"Temporal",contentType:"person"}],authorsString:"Kara Deloss",category:"Community",readingTime:6},{title:"Monitoring Temporal Cloud Workflows with Grafana Cloud",content:"\n  \n    \n      \n        This is a guest post from Ishan Jain, Senior Developer Experience Engineer at Grafana Labs, the company behind the open observability cloud. In this post, Ishan explores how the new Temporal Cloud integration for Grafana Cloud gives teams a simple way to visualize, monitor, and alert on the health of their Temporal Workflows.\n      \n    \n  \n\nOperating Temporal Workflows at scale requires deep visibility into Executions, Task Queues, and capacity usage. The new Temporal Cloud integration for Grafana Cloud delivers that visibility in minutes with no extra infrastructure required.\nWith Grafana Cloud, you get a fully managed observability platform that brings together metrics, logs, traces, dashboards, and alerts into a single experience. Now, by integrating Temporal Cloud metrics, you can visualize Workflow health, monitor Task Queue backlogs, track service latency, and uncover hidden bottlenecks, all using Grafana Cloud's powerful observability capabilities.\nWhat you get\nTemporal Workflows generate high volumes of telemetry across multiple dimensions  such as Namespace, Task Queue, and Workflow type. This data is already available through Temporal Clouds OpenMetrics-compatible endpoint, but making sense of it typically requires teams to operate and maintain their own observability stack to collect, store, and visualize those metrics.\nThats where Grafana Cloud comes in. As a fully managed observability platform, it gives you a unified view of your Temporal telemetry, dashboards, and alerts  without the operational overhead.\nWith the new Temporal Cloud integration for Grafana Cloud, you gain:\n\n  Expanded and improved metrics  including new dimensions like temporal_task_queue and workflow_type, accurate percentiles, and broader coverage.\n  A prebuilt, always up-to-date dashboard  purpose-built for Temporal Cloud to visualize Workflow performance, Task Queue depth, and usage trends at a glance. \n    \n  \n  Cost control and noise reduction  via Grafana Clouds Adaptive Telemetry and metric optimization features.\n  \n    AI-assisted exploration  using Grafana Assistant, an AI-powered agent in Grafana Cloud, to query metrics, build dashboards, and troubleshoot in natural language.\n    Together, these updates make it easier to understand whats happening inside your Temporal Cloud workloads, helping you detect issues faster, optimize performance, and keep your system healthy at scale.\n  \n\nHow it works\nThe integration operates by periodically scraping metrics from Temporal Clouds OpenMetrics endpoint and pushing them into your Grafana Cloud Metrics instance. The integration runs entirely within Grafana Cloud infrastructure. All metrics are automatically labeled with your scrape job name, making it easy to organize and filter data across multiple environments or teams.\n\n  Setting up the Temporal Cloud integration in Grafana Cloud takes just a few minutes. You can learn more in Grafana Cloud documentation.\n  \n  \n\nNext steps\nThe integration is available now for all Grafana Cloud users. If you're already using Temporal Cloud, you can set up monitoring in just a few minutes by following the configuration steps above. If youre ready to get started, check out the Temporal Cloud OpenMetrics documentation and the Grafana Cloud integration instructions.",featureImage:{title:"social-card-newsletter",description:"social-card-newsletter",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3k9UpZsjFZDXElTHI4BCLz/3a72dd7f1c60ada1f5bd28f46f684810/social-card-newsletter.jpg"},publishDate:"2025-11-21",metaDescription:"In this post, Ishan explores how the new Temporal Cloud integration for Grafana Cloud gives teams a simple way to visualize, monitor, and alert on the health of their Temporal Workflows.",metaTitle:"Monitoring Temporal Cloud Workflows with Grafana Cloud",socialCard:{title:"Blog (56)",description:"Blog (56)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/60fO6T4AzzluyL57atviA9/0b900c488ffe99ebdb9813e39a7925fe/Blog__56_.png"},tags:"Observability,Cloud",slug:"monitoring-temporal-cloud-workflows-with-grafana-cloud",contentType:"blogPost",entityId:"1IbhSYQ0ZGvVG0GwgaHYPO",authors:[{id:"4Bg8o3jCgsbsvQWlBbrhnK",name:"Ishan Jain",slug:"ishan-jain",jobTitle:"Senior Developer Experience Engineer",photograph:{title:"1760524908010",description:"1760524908010",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6iSess4J9W20eYMNcV1IF2/edad81fa94e3b203615b5b43a159faa5/1760524908010.png"},linkedInUrl:"https://www.linkedin.com/in/ishanjainn/",company:"Grafana Labs",contentType:"person"}],authorsString:"Ishan Jain",category:"Announcements",readingTime:3},{title:"The journey to shippable AI systems: Patterns that work",content:"\n  AI isnt hypothetical anymore. It shows up in day-to-day developer work and in customer-facing products. Most teams say theyre using it in their work, and a large share is either already building AI/ML systems or learning how.\n  \n  \n  Where AI hits hardest today is in our code generation. Its the top area of perceived impact, with other lifecycle stages trailing behind. That matters because the places AI touches code paths are exactly where reliability problems surface first.\n\nIn our latest survey of over 150 developers and technical leaders  largely from enterprise-scale companies across North America and Europe  nearly half are still exploring or prototyping, while 38% say AI is essential or actively scaling in production. However, confidence is still low: only 13% feel very confident observing and debugging AI workflows at scale, and 62% report measurable time or revenue lost to reliability issues each year.\nMeanwhile, day-to-day operations are still bumpy. Only about a quarter of teams describe workflow operations as smooth, and many report overhead, fragile long-running work, and messy recovery. You can feel that in incident reviews and in the glue code holding things together.\n\n  The near-term focus reflects this reality. Our State of Development 2025 study found that reliability and compliance top the 1224 month priority list, followed closely by automation and debt reduction. If youre planning where to invest, start there.\n  \n  \n\nWhat production AI actually asks of your platform\nAI systems stretch the parts of your stack that already creak:\n\n  Non-deterministic steps: LLM calls, retrieval, and external APIs fail in partial, creative ways.\n  Long-running, multi-actor flows: planning, tool use, human approvals, and compensations dont fit a single request/response.\n  Audit and cost: you need a record of prompts, decisions, and spend tied to business outcomes.\n\n\n  Its familiar distributed-systems pain turned up to 11=\n  \n  \n\nFive patterns that make AI shippable\n1. Guarded tool calls\nWrap each LLM or tool step with timeouts, retries with backoff, circuit breaking, and explicit fallbacks. Persist inputs/outputs and attach cost metadata. Promote to human review when thresholds trip.\n2. Idempotent side-effects\nWrite once semantics with idempotency keys. When you cant guarantee exactly-once, pair the write with a compensating action you can run automatically.\n3. Human checkpoints\nTurn DM me before sending into a real approval step that pauses the run and resumes cleanly. Treat reviewer timeouts as first-class outcomes.\n4. Deterministic plans, versioned prompts\nStabilize the orchestration while allowing variability inside steps. Record prompt and model versions so replays are faithful.\n5. Cost and policy budgets\n\n  Track tokens and spend per run. Degrade gracefully or halt when budgets or safety checks fail. Escalate instead of silently dropping work.\n  These patterns map directly to the operational issues teams report: overhead, long-running complexity, and brittle recovery.\n\nWhy Durable Execution becomes the backbone\nTeams turn to Durable Execution for state, retries, visibility, and long-running task management. Its tightly linked with orchestration adoption, and usage is already widespread  even more so in large companies. The benefit is simple: durable workflows complete or resume after crashes without ad-hoc glue.\n\n  If youre already investing in agents, note the trend lines: OpenAI Agents SDK leads reported usage, followed by Googles ADK and then LangChain  and theres a native path to bring orchestration into those flows.\n  \n  \n\nThe takeaway\nAI is here across the SDLC, and teams are at different stages: using assistants, building AI/ML into products, and building the reliability to run those systems at scale. The fastest way to make progress is to standardize on durable, observable workflows and treat reliability as a product requirement, not an afterthought.",featureImage:{title:"social-card-dark-waves",description:"social-card-dark-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2EnRRWXLoTeCWl9m4xuZvn/d01871a31191cc3054b7f6a08f29d628/social-card-dark-waves.jpg"},publishDate:"2025-11-18",metaDescription:"Move from AI features to resilient AI systems. Use Durable Execution and five patterns to improve reliability, compliance, and day-to-day operations.",metaTitle:"The journey to shippable AI systems: Patterns that work",socialCard:{title:"Blog (55)",description:"Blog (55)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4T49EPy9YISBfhIka6Yze4/811e106d07690b88d1191eb7334db443/Blog__55_.png"},tags:"AI/ML",slug:"the-journey-to-shippable-ai-systems-patterns-that-work",contentType:"blogPost",entityId:"2Mr3x3PmOpswNbmXhsmUMI",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"Community",promoCard:{title:"State of Dev 2025",eyebrow:"The State of Development 2025",heading:"Find out what 226 tech professionals have to say.",content:"Want a deeper look at our findings? Get your copy of Temporals State of Development 2025 report.",callsToAction:[{text:"Download now",href:"/pages/state-of-development-2025",variant:"primary",leadingIcon:null,trailingIcon:"arrow-right",entityId:"1eOw5MPvvDUef4Xl46TLCx",large:false,theme:"pink"}],entityId:"N3aCYyQMCp9iGXMKim3Pq",contentType:"noise"},readingTime:4},{title:"Of course you can build dynamic AI agents with Temporal",content:"Over the past few weeks Ive heard some variation of the following statement: \"We can't use Temporal for our AI agent. LLMs are inherently non-deterministic and our agent doesnt follow a predefined path like Do Step 1, then Step 2, then Step 3. And since Temporal requires determinism we cant use it for our very clever and dynamic agents.\" Every time I hear this, I have a similar reaction:\n  \n\nThis is 100% incorrect. Not only can you build AI agents with Temporal, Id argue its the best way to do it. Heck, OpenAIs Codex web agent is built on Temporal. So is Replits new long-running Agent 3. Temporals determinism requirement doesnt limit the behavior of your agent, its actually what makes AI agents reliable in production.\nLet me show you why this misconception exists, and how Temporal's architecture is perfectly designed for powerful agents that follow very dynamic paths and trajectories.\nSo lets bust this myth.\n  \n\nWhat Temporal actually requires\nSo I get where this is coming from. If you look at Temporals documentation, or take an online tutorial or course, you may come across the phrase Temporal requires your Workflows to be deterministic and automatically jump to this conclusion. And thats fair, but there are tons of people using Temporal for all sorts of things, including AI agents. So where are the wires crossed?\nSo heres the critical distinction that people are missing. While Temporal requires that your Workflow code is deterministic, your AI Agent can absolutely make decisions based on non-deterministic LLM outcomes.\n\n  Let me show you what this means visually:\n  \n  \n\nYour Workflow is the orchestration layer, the blueprint that defines the structure of your application. It needs to be deterministic so Temporal can help your agent survive through process crashes, outages, and other failures.\nYour Activities are where the actual work happens: calling LLMs, invoking tools, making API requests. These can be as unpredictable and non-deterministic as needed.\nThis separation is exactly what makes Temporal perfect for AI agents. In fact, the longer running your agents are, the more valuable Temporals Durable Execution superpowers become.\nNot all who wander are lost\nIn sum, Temporal AI Agents are:\n\n  Deterministic in execution: An agent will always take the same path given the same context and LLM decisions\n  BUT NOT predetermined: You don't know what the LLM will decide until runtime\n\nDeterministic execution unlocks durability. If the Workflow has to recover from a crash, it replays your agents progress to date. But the Workflow does not ask the agent for a new plan for decisions it has already made... The agent instead uses Temporals Event History as a record of past decisions. This makes the execution durable and is what makes the agent able to survive a crash and resume exactly where it left off.\nFrom the point of recovery, the agent is free to dynamically plan its next steps as it always does, make decisions and generally be the clever cookie it is. Because the agent is using non-deterministic LLM results to make decisions, its path is not pre-determined.\nWithout Temporal\nIf your agent fails, youre back to step one. You restart the process from the beginning, repeating LLM calls that take time and cost money. Even worse, your restarted agent takes a different path: your agents first execution can absolutely make decisions that are inconsistent with the restarted execution. For example, your vacation agent booked flights for a ski trip to Whistler, Canada before crashing at the find hotels step. The restarted process decided to book flights to Japan. That flight to Whistler is going to need cancelling.\nOr perhaps youve checkpointed your agents progress with an external database. Are you sure youve saved all relevant state in those checkpoints so the agent can reliably continue? Do you have a strategy for quickly detecting an agent crash, restoring its state from the last checkpoint, and then continuing its progress from that point forward?\nWith Temporal\nThe Workflow replays your agents progress using the recorded LLM decisions from the Event History. Your vacation planning agent picks up right at find hotels in Whistler, Canada using the exact same state. No re-analysis. No different decisions nor different path. No inconsistency. The user never knows anything went wrong.\n\n  \n  \n\nThis is why OpenAI uses Temporal for Codex. Thats an AI coding agent running on Temporal in production, handling millions of requests. Codex will write code then execute it, evaluating the result and deciding whether it has more coding work to do or if its completed the users request. If Temporal couldnt handle the twists and turns of sophisticated AI agents, OpenAI wouldn't be using it.\nSo you want truly dynamic, free-flowing agents, but ones that can automatically survive failures and pick up where they left off? Temporal will durably follow your non-predetermined, LLM-driven AI plans. In other words, you get the power of surviving failures while keeping all the agentic smarts.\nThe architecture that makes this work\nHeres the visual breakdown of how a Temporal AI Agent handles the split between deterministic and non-deterministic components:\n\n  \n\nIn this example, a user is booking a flight to Austin, Texas. They ask their Agent to do so. The Workflow then kicks off a loop, working towards accomplishing the users goal. When the goal is not achieved, it provides the context to the LLM so the LLM can decide the next step to take. That step may be asking for more clarification from the user, searching for flights using Expedias MCP server, or any other step the LLM thinks will help it accomplish its goal.\nThe distinction here is that while the orchestration of the LLM and tool calls is deterministic, the calls, the plan, the tools executed are completely non-deterministic.\nLets look at another example:\n\n  \n\nIn this example we are saving our precious donkey from an evil dragon (although the donkey is annoying and wont stop singing). Again we ask the LLM what to do, it provides the tool, and we save our jabbering donkey.\n  \n\nNote how while the prompts are wildly different, the workflow control logic didnt change at all. The LLM is still in the drivers seat. It is dynamically determining which tools to execute based on the given context (flight bookings vs slaying dragons). The Workflow is the orchestrator. It ensures that these tools are executed reliably. And to the Agent, its all the same. It executes towards a defined goal using the tools it needs.\n\n  \n\nThis gives us non-deterministic Agents with durable execution. And this is exactly the type of problem Temporal is primed to solve.\nJust show me the code\nLet me show you what this looks like in practice. Here's a simplified AI agent Workflow:\n@workflow.defn\nclass AIAgentWorkflow:\n    @workflow.run\n    async def run(self, user_goal: str) -> str:\n        conversation_history = []\n\n        while not self.is_goal_achieved(conversation_history):\n            # THIS is where non-determinism lives:\n            # next_action.tool could be ANY of your activities\n            # It's determined at runtime by the LLM, not hardcoded\n            next_action = await workflow.execute_activity(\n                llm_decide_next_action,\n                LLMRequest(\n                    goal=user_goal,\n                    history=conversation_history,\n                    available_tools=self.get_available_tools()\n                ),\n                start_to_close_timeout=timedelta(seconds=30),\n            )\n\n            # But the execution? Completely deterministic.\n            result = await workflow.execute_activity(\n                next_action.tool,  # Could be send_email, search_web, calculate, etc.\n                next_action.params,\n                start_to_close_timeout=timedelta(seconds=30)\n            )\n\n            conversation_history.append({\n                \"action\": next_action,\n                \"result\": result\n            })\n\n        return self.format_final_result(conversation_history)\nLook at whats happening here:\n\n  The Workflow structure (the while loop, the sequence of operations) is deterministic\n  The LLM's decisions (which tool to call, what parameters to use) are dynamic\n  The tool executions have dynamic results that can alter the LLMs decision making\n\nThis is exactly what you want. The LLM can make different decisions in different runs based on context, but given the same sequence of LLM responses, the Workflow will always execute the same way. This is what allows Temporal to resume your Workflow after failures without duplicating work or making different decisions.\nAnother neat thing about the code sample above is that the agent can evaluate its own results. It may decide the goal isnt achieved (maybe the while loop condition is_goal_achieved() calls an LLM to judge the current outcome). It might loop a few times over, making decisions and running tools until its finally ready to return a final result to the user. You can see how the execution path can vary widely each time depending on input, context, and the probabilistic nature of LLMs.\nBut my agent dynamically generates plans!\n  \n\nOoh, fancy. So your agent generates a to-do list of steps to complete? Awesome. Sounds like the kind of thing you want to keep track of and *certainly* ensure you dont re-execute any steps.\nLets re-use the previous example and introduce a parent Workflow to wrap it. This code uses an LLM to generate a plan and works through. In pseudocode, for brevity:\n            # LLM generates a multi-step plan as a list\n            plan = execute_activity(llm_generate_plan...)\n            context = []\n\n            # Execute each step in the plan\n            for step in plan:\n\t\t   # Each step runs the workflow in the sample above\n                result = execute_child_workflow(step)\n                context.add(result)\nThe agent might generate a list of 2 steps to fulfill a request. The next time it may generate a list of 10 completely different ones. These steps can execute in sequence or in parallel.\nMaybe you say plan me a bunch (!!!) of vacations for next year. The LLM might break down your request into 3 major steps: ski in Canada, road trip to eat BBQ in Austin Texas, pet Koalas in Australia. Each of those vacation bookings is running its own LLM decision loop  calling tools, evaluating results, deciding next steps  exactly like the first code sample showed (I hope you have the funds, globetrotter!).\nThe important thing is the llm_generate_plan step runs inside a Temporal Activity, so the Workflow is unfazed by this unpredictability in agent execution path.\nAnd if something goes wrong during this lengthy multi-vacation booking process, the Event History of each Workflow automatically saves it all so you dont lose a thing.\nSee? Your Workflows can absolutely be a harness for powerful, free-flowing agents. Temporal allows them to be dynamic, yet durable.\nMyth busted\nSo I think its safe to say the myth that Temporal can't handle dynamic, non-deterministic AI agents is officially busted.\n  \n\nSo lets review:\nWhat Temporal actually requires:\n\n  Workflow orchestration code must be deterministic\n  .and thats it. Thats all thats required\n\nWhat Temporal does NOT require:\n\n  Activities to be deterministic\n  LLM responses to be predictable\n  Your agent to always make the same decisions\n\nYour LLM can be as creative, adaptive, and non-deterministic as you want. Temporal just ensures that whatever your LLM decides to do gets executed reliably and can be recovered if something goes wrong.\nThats not a limitation. Thats exactly what you need to build production-grade AI agents.\nWant to build AI agents with Temporal?\nCheck out these resources:\n\n  Temporal AI Agent Bundle  comprehensive guide to building agents\n  Mental Model for Agentic AI Applications  understanding the architecture\n  AI Cookbook  practical examples and patterns\n  Temporal Community  join the discussion on Slack, GitHub, or our forum\n\nAnd if you run into someone spreading the Temporal cant do AI agents myth? Send them here. Lets put this one to bed.",featureImage:{title:"social-orb",description:"social-orb",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Tk0k2JzNldP4WvVCZzJzA/08592218f1fd8de9b5efd2ee10cf0364/social-orb.jpg"},publishDate:"2025-11-12",metaDescription:"Temporal can absolutely handle your AI agents. This guide shows you how Temporal Workflows and Activities make the perfect foundation for reliable agents.",metaTitle:"Of course you can build dynamic AI agents with Temporal",socialCard:{title:"Blog (54)",description:"Blog (54)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/Vv5OMu57ZwEgzOx00vtC4/856ffe0174780b8460e8db0b78536ab5/Blog__54_.png"},tags:"Python,Temporal Primitives,AI/ML,Architecture,Code Samples",slug:"of-course-you-can-build-dynamic-ai-agents-with-temporal",contentType:"blogPost",entityId:"1bMudhfbomRPs2MkXsdBBz",authors:[{id:"1VQRqr0fVS9svnoX57cPKm",name:"Mason Egger",slug:"mason-egger",jobTitle:"Sr. Technical Curriculum Developer",photograph:{title:"mason egger",description:"mason egger",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7ouhODOdbYXBCMY8wynrGa/a184aa85abb1880f8857a60dc99ca825/11214847"},contentType:"person"},{id:"1v9PSw1EtI4GSexvsgab2m",name:"Steve Androulakis",slug:"steve-androulakis",jobTitle:"Sr. Staff Solutions Architect",photograph:{title:"Steve Androulakis photo",description:"Steve Androulakis photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3VYCWEfnobcFUrlJCZP6pT/43ca653fceadf513a4663e444906702f/steve-androulakis-2.jpg"},biography:"Steve helps developers at companies like Netflix, Stripe and Airbnb thrive using Temporal. Before that, he worked at Amazon in Sydney and Seattle for more than 5 years. He brings a decade of full stack developer experience helping biomedical researchers process and make sense of their data.",company:"Temporal",contentType:"person"}],authorsString:"Mason Egger, Steve Androulakis",category:"Temporal Voices",readingTime:10},{title:"Use Swift with Temporal",content:"Last month in London the Temporal Swift SDK was announced at ServerSide.swift during a talk on how to Write durable and resilient workflows in Swift. I was happy to be invited on stage during the talk to explain Temporal and how it enables Durable Execution for distributed systems. The ServerSide.swift conference, solely run for the love of server-side Swift, was the perfect place to make this announcement.\nI started collaborating with the Swift community to create examples for this SDK in the time leading up to the talk. Getting to be one of the first people to write Swift code using this SDK has been a great experience. Im very excited to be able to share all the details about what the Temporal Swift SDK offers and how you can start using it to build fault-tolerant distributed systems with Swifts modern concurrency features.\nToday the Swift community has published an announcement with more details about the Temporal Swift SDK. I wanted to share how this can be adopted by the Temporal community.\nGetting started\nThe Temporal Swift SDK lets you write reliable, long-running Workflows with Swifts native async/await and structured concurrency. This SDK enables you to build applications in Swift that survive crashes and can handle failures, retries, and persistence automatically.\n\n  Docs: https://swiftpackageindex.com/apple/swift-temporal-sdk/main/documentation/\n  SDK source on GitHub: https://github.com/apple/swift-temporal-sdk\n\nGet started by adding the SDK to your Package.swift:\ndependencies: [\n    .package(url: \"https://github.com/apple/swift-temporal-sdk.git\", upToNextMinor: \"0.1.0\")\n]\nYoull need Swift 6.2+, and the Temporal CLI for local development:\nSwift-first design\nThis SDK is designed for Swift developers building distributed systems. Full Swift 6.2 structured concurrency support means that you use TaskGroup, async/await, and other concurrency primitives directly in your workflows. Compile-time type safety and macro-based APIs eliminate boilerplate code.\nUnder the hood, the Swift SDK wraps the Temporal Core SDK through Swifts C interop, using the same battle-tested state machines that power other Temporal SDKs. The SDK uses gRPC-swift for communication with Temporal Service.\nThe SDK provides four core components:\n\n  @Workflow and @ActivityContainer macros for defining Workflows and Activities\n  @WorkflowSignal, @WorkflowQuery, and @WorkflowUpdate for interacting with running Workflows\n  TemporalWorker for executing Workflows and Activities\n  TemporalClient for starting and managing Workflows\n\nWorkflows and Activities\nHere's a basic Workflow with a single Activity:\nimport Temporal\nimport Logging\n\n// Define an Activity\n@ActivityContainer\nstruct GreetingActivities {\n    @Activity\n    func sayHello(input: String) -> String {\n        \"Hello, \\(input)!\"\n    }\n}\n\n// Define a Workflow\n@Workflow\nfinal class GreetingWorkflow {\n    func run(input: String) async throws -> String {\n        try await Workflow.executeActivity(\n            GreetingActivities.Activities.sayHello.self,\n            options: ActivityOptions(startToCloseTimeout: .seconds(30)),\n            input: input\n        )\n    }\n}\nActivities run in the standard Swift environment with no restrictions. Bring along your existing URLSession code, file operations, and database calls. By leveraging Temporal, you gain a robust retry and timeout system without writing a mountain of code:\ntry await Workflow.executeActivity(\n    Activities.fetchData.self,\n    options: ActivityOptions(\n        startToCloseTimeout: .seconds(30),\n        retryPolicy: RetryPolicy(\n            maximumAttempts: 3,\n            initialInterval: .seconds(1),\n            backoffCoefficient: 2.0\n        )\n    ),\n    input: request\n)\nThe SDK handles retries and exponential backoff automatically when dealing with network failures, API timeouts, and service disruptions. Your Activity code stays clean.\nRunning Workflows\nA Worker connects to the Temporal Servicer, polls for tasks, and executes your Workflows and Activities. Configuring and starting the Worker is straightforward:\nlet worker = try TemporalWorker(\n    configuration: .init(\n        namespace: \"default\",\n        taskQueue: \"my-queue\"\n    ),\n    target: .ipv4(address: \"127.0.0.1\", port: 7233),\n    transportSecurity: .plaintext,\n    activityContainers: MyActivities(),\n    workflows: [MyWorkflow.self],\n    logger: Logger(label: \"worker\")\n)\n\ntry await worker.run()\nClients are able to start Workflows from anywhere in your application (servers, CLI tools, and even iOS apps):\nlet client = try TemporalClient(\n    target: .ipv4(address: \"127.0.0.1\", port: 7233),\n    transportSecurity: .plaintext,\n    logger: Logger(label: \"client\")\n)\n\nlet result = try await client.executeWorkflow(\n    MyWorkflow.self,\n    options: .init(id: \"business-meaningful-id\", taskQueue: \"my-queue\"),\n    input: \"data\"\n)\nMore than just Workflows\nThe SDK includes comprehensive support for Temporal's full feature set:\nWorkflow interaction\n\n  Signals  Send data to running Workflows\n  Queries  Read Workflow state without modifying it\n  Updates  Modify Workflow state, with optional validation, and wait for results\n\nAdvanced patterns\n\n  Child Workflows  Compose Workflows for complex orchestration\n  Continue-as-New  Handle long-running Workflows without exceeding history limits\n  Local Activities  Execute fast operations without full activity overhead\n  Search Attributes  Locate and filter Workflows in the Temporal UI\n\nProduction-ready\n\n  Interceptors  Add cross-cutting concerns like authorization, logging, such as metrics\n  OpenTelemetry  Built-in distributed tracing and metrics\n  Custom Data Converters  Control serialization and applying client-side encryption to protect your data\n  Retries & Timeouts  Declarative failure handling at every level\n\nExamples to help you get started: Learning by doing\nThe SDK includes examples that show real patterns youll use in production:\n\n  Async Activities  Parallel Activity execution using NYCs Open Data API to process film permits\n  Child Workflows  Parent-child Workflow orchestration with a pizza restaurant order system\n  Schedule  Temporal schedules with live NASA APIs monitoring the ISS\n  Signals  Interact with running Workflows via Signals, Queries, and Updates\n  Error Handling  Retry policies, compensation logic, and failure-recovery patterns\n\nEach example runs against real external APIs (NASA, NYC Open Data) or simulates a business process so you see how to handle timeouts, retries, and rate limiting in practice.\nWhats next?\nThis SDK is under active development. The Swift community is iterating quickly based on feedback, adding features, and improving the developer experience.\nTry it out:\ngit clone https://github.com/apple/swift-temporal-sdk.git\ncd swift-temporal-sdk\nswift build\ntemporal server start-dev  # in another terminal\nswift run GreetingExample\nBuilding something cool? Share it in the Community Slack (#community-swift-sdk) or on the community forum.\nHave feedback or hit a snag? Open an issue on GitHub.\nIf youre building distributed systems with Swift (whether thats server-side applications, data pipelines, or business process automation), Id love to hear from you.",featureImage:{title:"blog-temporal-swift",description:"blog-temporal-swift",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6hgCN7R3WNZc6jMk8qCdCA/ff249585d66d7613501fa1046ebe289f/Blog-temporal-swift.png"},publishDate:"2025-11-10",metaDescription:"Announcing the Swift Temporal SDK. Build durable, fault-tolerant Workflows in Swift 6.2 with async/await and structured concurrency.",metaTitle:"Use Swift with Temporal",socialCard:{title:"Social-swift-1",description:"Social-swift-1",url:"https://images.ctfassets.net/0uuz8ydxyd9p/78MxixAZ7mXNmKRYBSom6G/a5030443fe442f197c65851ce7a48218/Social-swift-1.png"},tags:"Durable Execution,Industry Events",slug:"temporal-now-supports-swift",contentType:"blogPost",entityId:"lfaPhZa1NPPslttSljLit",authors:[{id:"2OEttjgfmRLmQfHqO5YLlQ",name:"Shy Ruparel",slug:"shy-ruparel",jobTitle:"Senior Developer Advocate",photograph:{title:"Shy Ruparel Headshot.",description:"Shy Ruparel Headshot.",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2apitzQRzLDriiJqG3SCbt/77eca358e97163231091dd044cb74034/Headshot.jpg"},biography:"Shy is currently a Senior Developer Advocate at Temporal. Building on a rich career that includes impactful roles at Docker, Superblocks, Contentful, hackNY, and Major League Hacking, Shy has spent a decade dedicated to empowering developer communities. Shy combines technical expertise with a passion for teaching.\n\nBeyond his professional work, Shy spends his time building unconventional IoT projects, reading long science fiction and fantasy novels, hosting dinners for 10-30 friends every other week.",linkedInUrl:"https://www.linkedin.com/in/shyruparel/",website:"https://shy.dev/",company:"Temporal",contentType:"person"}],authorsString:"Shy Ruparel",category:"Announcements",readingTime:5},{title:"Durable under pressure: How developers kept running during the AWS us-east-1 outage",content:"On October 20th 2025, the internet came to a halt.\nAmazon Web Services's (AWS) most popular cloud region, named us-east-1, virtually went offline and took many other businesses applications with it. The effects of the outage  which happened in two phases  impacted consumers worldwide and made major headlines.\nBut perhaps even more significant than the number of household names that made the news was the number of names that didnt. Applications that had a multi-region high availability/disaster recovery (HA/DR) strategy continued running during the outage, even if they had a dependency on the affected cloud region.\nHow to survive an outage\nAt Temporal, weve built a platform for Durable Execution: running workflows while handling the inevitable errors that hit production software at scale. A Durable execution platform must operate under all failure scenarios, including a cloud region failure. Thats why Temporal Cloud offers Multi-region and Multi-cloud Replication.\nThese high availability features make it simple for Temporal Cloud customers to execute a multi-region HA/DR strategy. After a Temporal Namespace enables replication, Temporal Cloud syncs its Workflows to a different cloud region. Then, if the primary cloud region becomes unstable  like us-east-1 did on October 20th  the user can trigger a failover on the Namespace. Temporal will trigger a failover automatically if it detects a region outage.\nOne such application that benefited from these features was FireHydrant, an All-in-One Alerting, On-Call, and Incident Management platform that depends on Temporal Cloud. FireHydrant incorporated Temporals multi-region product into their HA/DR strategy last year. They picked Namespaces that serve business-critical workflows to enable Multi-region Replication (this must be done ahead of time, not mid-outage). They provisioned multi-region flows for the rest of their infrastructure, including Temporal Workers and other data systems. Finally, they tested the process with a game day, proving they could move their architecture to a different region.\nThe October 20 us-east-1 outage (Temporals version)\nAt 12:11 AM (PDT), AWS announced an increase in error rates in us-east-1, and soon the DynamoDB service went offline. Temporal detected the incident 12 minutes before it was reported. The on-call Temporal Cloud engineers quickly confirmed that customer workflows continued to execute normally.\nUnfortunately, this issue blocked the creation of new Temporal Namespaces in us-east-1. Since this did not affect customer Workflows, Temporal did not failover Namespaces in us-east-1. However, some Temporal customers, concerned about these events in the region, proactively failed over their us-east-1 Namespaces that had Multi-region Replication. This turned out to be a wise decision, as more regional issues were coming.\nAWS restored DynamoDB after 3 hours, but lingering effects in us-east-1 caused a cascading series of failures in hundreds of critical AWS services. This affected virtually every service that runs in the region, including Temporal Cloud.\nAt 8AM (PDT), Temporal detected network instability that prevented a small percentage of requests from reaching Temporal Namespaces in us-east-1. Temporals on-call engineers monitored the situation; because the network error percentage was small, they left Multi-region and Multi-cloud replicated Namespaces in us-east-1, as did Temporals auto-failover detection rules.\nAround this time, FireHydrant detected errors from various customer-facing vendors in their stack, affecting end users. At 9:34AM (PDT) they triggered a failover of their Temporal Namespaces. The multi-region Temporal architecture performed exactly as designed, keeping workflows uninterrupted throughout the entire event.\n\n  Thanks so much for being so damn rock solid with Temporal Cloud [during the AWS outage]. Our on-call didnt flinch when us-east-1 went down, and being able to trigger a failover to us-east-2 was    Robert Ross, CEO of FireHydrant\n\nOver the next hour, the network error rate grew rapidly on one Temporal cell in us-east-1. Temporals on-call engineers decided that this warranted a failover. They triggered a failover on Temporals internal Namespaces out of us-east-1, to validate that moving to another region would resolve the observed issues. While these progressed, Temporals automation requested approval to failover all replicated Namespaces in us-east-1; the on-call team chose to wait for validation from the internal failovers first.\nEight minutes after triggering failover on internal Namespaces, the on-call engineers validated that these workflows were running as expected in their failover regions. They began Temporals proactive auto-failover for customer Namespaces in us-east-1 that had Multi-region or Multi-cloud Replication.\nAs failovers progressed, the network error rate in the degraded cell grew, eventually hitting 100%, meaning a full network partition. Most customer Namespaces completed their failovers without issue and resumed processing customer workflows in other regions; but a few Namespaces lingered in the unhealthy cell. These stalled  we later discovered  because the Temporal workflow that triggers auto-failovers had a previously-undetected dependency on the source region, us-east-1. When the unhealthy cell became network partitioned, these calls blocked the Workflow from triggering auto-failovers, prolonging the recovery time for affected Namespaces by several minutes. The on-call engineers detected this and used internal tooling to trigger failover on the remaining Namespaces.\nIn the end, all customer Namespaces with Multi-region or Multi-cloud Replication evacuated us-east-1. After the Namespace failover, Temporal customers like FireHydrant only had to scale up Temporal Workers in the replica region to keep their Workflows running. The outage lasted 3 hours according to the Temporal status page.\nOver the following days, most customer Namespaces returned to us-east-1 with a seamless failback. They moved their Temporal Workers back to us-east-1 at their own convenience, independently of the Namespace, since Temporal Cloud forwards requests between active and replica regions. Some Temporal customers chose to keep their Namespaces active in other regions, a practice known as fail-forward or fail-and-stay. No matter which region each Namespace ultimately settled in, Temporal Cloud kept the active and replica regions in sync.\nLooking ahead\nAt Temporal, the October 20th outage grew our trust in our multi-region product and revealed several ways to harden it. While the vast majority of customer Namespaces executed a failover without issue, the auto-failover call that blocked on the source region prolonged the recovery time for a handful of customers.\nWe will fix this urgently, so that all users of Temporal Cloud replication can beat their Recovery Time Objectives (RTOs) in the next outage, and test it during our internal game days that simulate real-world disruptions. We will also have our automation detect this type of network partition more quickly and trigger auto-failover earlier in the next outage. For Namespaces with Multi-region and Multi-cloud Replication, Temporal stands by its RTO of sub-20 minutes for cloud region outages.\nYou can get started on your own multi-region journey with Temporal by signing up for Temporal Cloud, if you havent already, or reaching out to your Temporal account manager. To make your Namespace multi-region or multi-cloud, simply add a Replica when creating it or in its settings page, and choose the replicas region or cloud provider.\n\n  \n\nWe get it\nIf you were on-call during the us-east-1 outage, the adrenaline, confusion, and the stressful triage that you experienced is a battle we understand. We built Temporal Cloud for these moments because were a product built for developers, by developers.\nTo us, durable is the dividing line between code that crumbles when shipped and software that scales in real-world environments.\nThis is why we obsess over durability and recovery. We know that behind every workflow is you  a developer who deserves to know that their system wont fold under pressure.\nDont take our word for it. Start building with Temporal Cloud to find out what it can do for your workflows and applications.",featureImage:{title:"image-3D-waves",description:"image-3D-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/62stYfm7wc5gZJaaldJ4jy/4f585ec2bd98307d1b4593c6c5f6ca92/Screenshot_2024-11-13_at_12.44.34_PM.png"},publishDate:"2025-11-07",metaDescription:"The AWS us-east-1 outage affected many, but some devs were able to stay afloat. Find out how.",metaTitle:"How developers kept running during the AWS us-east-1 outage",socialCard:{title:"How developers kept running during the AWS us-east-1 outage social card",description:"How developers kept running during the AWS us-east-1 outage social card",url:"https://images.ctfassets.net/0uuz8ydxyd9p/17JvCkNaAiLxUcbw3UF00O/5f9de8d32934d15a37a0db280891449d/How_developers_kept_running_during_the_AWS_us-east-1_outage.png"},tags:"Cloud,Durable Execution",slug:"how-devs-kept-running-during-the-aws-us-east-1-oct-20-2025",contentType:"blogPost",entityId:"5YohE5IYMOVppyjpPmiPCM",authors:[{id:"1KFFJ6vkDomZqm8xO7Eo5n",name:"Luke Knepper",slug:"Luke-Knepper",jobTitle:"Senior Product Manager, Connectivity and Replication",photograph:{title:"Luke Knepper Headshot",description:"Luke Knepper Headshot",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3MlbP2eJePxFbnnSfGOJz6/404966951e6fd2e081060baa6e9c9063/luke-knepper.jpeg"},company:"Temporal",contentType:"person"}],authorsString:"Luke Knepper",category:"Temporal Concepts",relatedPosts:[{title:"High availability and disaster recovery with Temporal Cloud",content:"Temporal makes your applications more reliable. But from an operational perspective, any complex software is hard to run reliably at scale. In this post, well give a brief overview on the challenges with self-hosting Temporal at scale, and the ways in which Temporal Cloud provides high availability. For more details, you can [watch our webinar recording on this topic](https://www.youtube.com/watch?v=X1hMWY1xxzc).\n\n## Challenges of maintaining high availability when self-hosting Temporal\n\nThe core challenge of achieving high availability with Temporal is that the [Service](https://docs.temporal.io/clusters) is composed of multiple independently scalable components. You must tune each and maintain their availability:\n\n- A database, typically Cassandra or Postgres, which is usually sharded and deployed in a highly available way, preferably across multiple availability zones.\n- Four independent services that make up the [Temporal Server](https://docs.temporal.io/clusters#temporal-server). These services must be resourced properly so there are no bottlenecks in the critical path of serving requests.\n- As with any distributed system, failures are inevitable, and understanding how to operate under different failure conditions is necessary to keep the service stable and available at all times. Some failures are relatively easy to deal with (a machine going down), while some are subtle and require careful attention (a network partition).\n\nManaging each of these services at smaller scales is straightforward. But to run them at scale in production, you must have a lot of expertise. Thats not to say its impossible. Many developers successfully self-host Temporal. But they may have difficulty meeting high availability SLAs, and often spend significant time and resources operating Temporal. For mission-critical applications and high-scale use cases, we always recommend evaluating [Temporal Cloud](https://temporal.io/cloud).\n\n## High availability with Temporal Cloud\n\nWith Temporal Cloud, our team delivers Temporal-as-a-service. We properly tune the supporting database and services for your load, and ensure theyre highly available. Because our team has deep Temporal expertise and manages thousands of namespaces, we can provide better service reliability, higher availability, lower latency, and we have a higher buffer of resources reserved for unexpected events.\n\nAs a Temporal Cloud customer, you're only responsible for deploying and managing your [Workers](https://docs.temporal.io/workers) and [Workflows](https://docs.temporal.io/workflows) in your applications, and connecting your application to your managed Temporal Service.\n\nHere are the details of the high availability guarantees Temporal Cloud provides:\n- __Fault tolerance__ - Temporal Cloud namespaces are deployed across three availability zones for fault tolerance by default. So any AZ failure would be a non-event for your namespace.\n- __99.99% service level objective (SLO)__ - As a service, Temporal Cloud regularly provides four 9s of availability; in other words, thats the availability of the endpoint.\n- __99.9% service level agreement (Contractual SLA)__ - the Temporal Cloud Contractual SLA is based on the average number of gRPC service errors over five minute intervals for the month. Contractually, if we do not meet this objective, we will issue back Cloud credits based on the outage.\n\nFor disaster recovery, Temporal Cloud provides the following:\n- __RTO/RPO for availability zone failures:__ the RTO/RPO are zero for availability zone failures, due to Temporal Cloud being replicated across multiple availability zones\n- __RTO/RPO for region failures:__ the RTO/RPO are eight hours at maximum, which is two backup periods for Temporal Cloud.\n- __COMING SOON: Multi-Region Namespaces:__ currently in [pre-release](https://docs.temporal.io/temporal/release-stages#pre-release), this capability will provide failover capabilities to mitigate service outages due to regional failures. It will also extend our contractual SLA to 99.99%. With Multi-Region Namespaces, your cloud service will be defined by a primary cloud region and a standby cloud region. History events automatically ship into the standby region asynchronously. In the event of the primary region failure, you can manually switch traffic to the standby region without disrupting ongoing Workflows. We recommend this capability if disruption of your workflow will cause loss of revenue, poor end-user experience, or issues with regulatory compliance. \n\nThis is just a brief overview of the topic of high availability in Temporal Cloud. For more details, we recommend watching the webinar: \n\n\u003Ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/X1hMWY1xxzc?si=xeQtGFv6yZomq2lq\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen>\u003C/iframe>\n\nThis post is part of a series about Temporal Cloud. Check out the other posts below:\n- [Higher throughput and lower latency with Temporal Cloud custom persistence layer](https://temporal.io/blog/higher-throughput-and-lower-latency-temporal-clouds-custom-persistence-layer)\n- [Exploring Temporal Cloud Automation Features](https://temporal.io/blog/exploring-temporal-cloud-automation-features)\n- [Estimating the cost of Temporal Cloud](https://temporal.io/blog/estimating-the-cost-of-temporal-cloud)\n- [How to migrate your self-hosted service to Temporal Cloud](https://temporal.io/blog/how-to-migrate-your-self-hosted-service-to-temporal-cloud)\n",featureImage:{title:"social card - green waves",description:"social card - green waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4GBHZR0vUnoRSbPtSTCH4s/daf7308a10e469059827e2169065d7ea/social_card_-_green_waves.jpg"},publishDate:"2024-03-27T00:00-06:00",metaDescription:"Learn how Temporal Cloud supports high availability and disaster recovery to keep your applications reliable at scale.",metaTitle:"High Availability & Disaster Recovery with Temporal Cloud",socialCard:{title:"social card - green waves",description:"social card - green waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4GBHZR0vUnoRSbPtSTCH4s/daf7308a10e469059827e2169065d7ea/social_card_-_green_waves.jpg"},tags:"Durable Execution",slug:"high-availability-and-disaster-recovery-with-temporal-cloud",contentType:"blogPost",entityId:"4VxV6nP8wMLRcFdQxYZH9P",authors:[{id:"4dsODPDNXZPwvTMknnOR7N",name:"Meagan Speare",slug:"meagan-speare",jobTitle:"Sr. Manager, Product Marketing",photograph:{title:"headshot-megan-speare",description:"headshot-megan-speare",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4cU6Eil7AyPgQDtc52XeS8/935bb30acca03ba2e011e5cc90be909c/meagan-speare.jpg"},contentType:"person"}],authorsString:"Meagan Speare",category:"Temporal Concepts",readingTime:4},{title:"How to migrate your self-hosted service to Temporal Cloud",content:"Temporal Cloud offers an improved experience over self-hosted Temporal, such as greater scale, higher availability, lower latency, and consumption-based costs. If youre currently self-hosting Temporal and considering migrating to Temporal Cloud, you might think a migration sounds daunting. In this post, well provide an overview of what goes into a migration. \n\n\u003Ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/4OoLT8s1vLE?si=bSRxv27LgOi7-TYh\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen>\u003C/iframe>\n\n## What we mean when we talk about migrations\n\nWith [Temporal Cloud](https://temporal.io/cloud), our team manages the Temporal Service and dependencies, while you still manage your Workflow code and Workers (see diagram below). When migrating to Temporal Cloud, a member of our team will guide you through each step.\n\n![image-blog-migrate-cloud1](//images.ctfassets.net/0uuz8ydxyd9p/2hU76bUqz6GJhTiIU8qM0r/295966188b3226e137cc94b6eb805f95/image-blog-migrate-cloud1.png)\n\nA migration involves routing new executions to start in the Temporal Cloud namespace. It also requires you to resume existing executions in that namespace while gracefully completing them in the self-hosted instance, under load.\n\nAs of today, migrations occur at the application-level, not the database-level. Theres no straightforward way to migrate data (e.g. Event Histories) from your self-hosted Temporal Service to your Temporal Cloud Namespace. The good news is this means you dont have to manage a complex database migration. Instead, migrations typically require a few minimal code changes. If you need to continue accessing Event Histories from your self-hosted Service for reporting or compliance, there are strategies to do so.\n\n## An overview of tasks required to migrate\n\nTo migrate to Temporal Cloud, here are the key tasks you must complete and considerations you should keep in mind:\n\n1. __Introduce a new Temporal Client to your application.__ With Temporal Cloud your application must point to a different endpoint. The Temporal Cloud Client connects your new Workflow Executions to Temporal Cloud. Until you fully switch to Temporal Cloud, you can run the old Client and the new Client in tandem. You must also secure that connection, which you can do using [API Keys](https://docs.temporal.io/cloud/api-keys) and [mTLS](https://docs.temporal.io/self-hosted-guide/security#encryption-in-transit-with-mtls).\n2. __Decide on a data encryption strategy.__ Your application will pass Workflow-related data to Temporal Cloud. Many Temporal Cloud customers choose to use a [Data Converter](https://docs.temporal.io/dataconversion), a simple form of middleware, to encrypt this data on the wire.\n3. __Choose the lifetime strategy of your Workflow Executions.__ To migrate Workflow Executions that are open (i.e. in progress), you must decide whether to let them run to completion or whether to migrate them while theyre in progress. The former strategy is more straightforward, because once the Workflow Execution completes, you can simply point it to Temporal Cloud to start again. But oftentimes, customers have migration deadlines. Your Workflow Executions may not complete before your deadline. In these situations, you must refactor your Workflow Code so it passes the state to Temporal Cloud. Our team can provide guidance and help with your code to accomplish this type of migration safely. Ultimately, you should evaluate each Workflow and their individual requirements to decide which strategy is appropriate.\n4. __Update code calling your Workflows.__ Your application has code that calls Workflows; you need to make some minimal changes to this code to route the requests to your Temporal Cloud Namespace.\n5. __Create a test and verification plan.__ Like with any migration, you should plan out how youll test your new deployment before turning it live.\n\n## So how long does a migration take?\n\nMigrating to Temporal Cloud is generally straightforward. It may take a day or so of creating a plan for each Workflow, to understand whether you can drain them or must make code changes. Most Workflows can be drained and easily restarted on Temporal Cloud. Longer running or mission-critical Workflows that cannot be drained will require more work.\n\nMost importantly, our team will guide you through every step of your migration, for no extra fee. Weve migrated thousands of Namespaces and will help you successfully migrate yours.\n\n## Next steps to migrate\n\nTo learn more, we recommend watching the [webinar recording on this topic](https://www.youtube.com/watch?v=4OoLT8s1vLE&list=PLl9kRkvFJrlTn2blb5FG0aBrkLcrr_18F&index=2). You can also check out the [docs](https://docs.temporal.io/production-deployments/migration). If youre considering migrating, [contact us](https://pages.temporal.io/contact-us) to start working with a member of our team, or drop a question into our [community Slack](https://t.mp/slack).\n\nThis post is part of a series about Temporal Cloud. Check out the other posts below:\n- [Higher throughput and lower latency with Temporal Cloud custom persistence layer](https://temporal.io/blog/higher-throughput-and-lower-latency-temporal-clouds-custom-persistence-layer)\n- [Exploring Temporal Cloud Automation Features](https://temporal.io/blog/exploring-temporal-cloud-automation-features)\n- [High availability and disaster recovery with Temporal Cloud](https://temporal.io/blog/high-availability-and-disaster-recovery-with-temporal-cloud)\n- [Estimating the cost of Temporal Cloud](https://temporal.io/blog/estimating-the-cost-of-temporal-cloud)\n",featureImage:{title:"social-card-brandon",description:"social-card-brandon",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1oX4jNjimgeS45r7uoaMha/d54d7043f6f959dc26a493a2e74d98c7/social-card-brandon.jpg"},publishDate:"2024-04-17T00:00-04:00",metaDescription:"Learn how migrating to Temporal Cloud enhances scalability, availability, and reduces latency, offering a more efficient, consumption-based solution.",metaTitle:"How to Migrate to Temporal Cloud from Self-Hosted",socialCard:{title:"social-card-brandon",description:"social-card-brandon",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1oX4jNjimgeS45r7uoaMha/d54d7043f6f959dc26a493a2e74d98c7/social-card-brandon.jpg"},tags:"Cloud,Self-Hosted",slug:"how-to-migrate-your-self-hosted-service-to-temporal-cloud",contentType:"blogPost",entityId:"2Y3rSzUOBevhWHjCQwFdog",authors:[{id:"4dsODPDNXZPwvTMknnOR7N",name:"Meagan Speare",slug:"meagan-speare",jobTitle:"Sr. Manager, Product Marketing",photograph:{title:"headshot-megan-speare",description:"headshot-megan-speare",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4cU6Eil7AyPgQDtc52XeS8/935bb30acca03ba2e011e5cc90be909c/meagan-speare.jpg"},contentType:"person"}],authorsString:"Meagan Speare",category:"How-To",readingTime:4}],promoCard:{title:"high-availability-developer-stress",eyebrow:"Stress less",heading:"Stay up and running during disaster",content:"Keep PagerDuty quiet. Temporal Cloud has your back. Learn more about our High Availability features.",callsToAction:[{text:"Learn more",href:"https://docs.temporal.io/cloud/high-availability/enable",variant:"primary",leadingIcon:null,trailingIcon:null,entityId:"6w9LLqZjnd5iG9TcGHzur5",large:false,theme:"ultraviolet"}],entityId:"3dwwAzE6y64y2FsJ3xrDLi",contentType:"noise"},readingTime:7},{title:"Build durable AI agents with Pydantic AI and Temporal",content:"At Pydantic, we pride ourselves on building production-grade developer tooling that Python developers love. Pydantic itself became the foundation for countless libraries, including the OpenAI and Anthropic SDKs, because it brought type safety, speed, and reliability to everyday development.\nWe built Pydantic Logfire, our developer-first observability platform, because we believed observability tools could be both production-ready and pleasant to use. When you make essential infrastructure more ergonomic, developers actually use it. In AI development, observability is borderline essential for understanding LLM behavior, and working with AI developers using Logfire exposed us to how they were building agents. But when we evaluated the available agent frameworks ourselves, none met our bar for production use.\nSo we built Pydantic AI, an agent framework focused on production-grade AI applications. That means:\n\n  Type safety everywhere  structured inputs and outputs validated at runtime\n  Built-in observability  semantic convention-compliant OpenTelemetry instrumentation\n  100% test coverage  boring but essential for reliability\n  Unit-tested documentation  examples that actually work\n\nBut we also know that some problems are better solved by specialized tools than by building everything ourselves. Durable execution is one of those problems. That's why we've built native Temporal support in Pydantic AI, combining our type-safe agent framework with Temporal's durable execution to give you agents that:\n\n  Survive API failures, exceptions, app restarts, and deploys\n  Handle long-running, async, and human-in-the-loop interactions\n  Preserve progress and state with replay-based fault tolerance\n\nWhy Durable Execution matters for production AI\nBuilding reliable AI agents means handling the messy reality of production:\nYour agent is halfway through a multi-step research task when the OpenAI API times out. With Temporal, your agent automatically picks up exactly where it left off, even after API timeouts or system crashes. This means no lost progress and no need for manual checkpointing.\nYour agent needs human approval before executing an action. The workflow can sleep for hours or days for user input, then resume exactly where it stopped. The entire conversation history and agent state is preserved through Temporal's deterministic replay without any manual synchronization with a database.\nYour deployment restarts while an agent is coordinating multiple tool calls. If your deployment restarts, Temporal ensures your agent restores its exact state and continues from where it left off, without re-running completed tasks.\nThis is what Temporal's durable execution model gives you. Your agent coordination logic runs deterministically and can be replayed. The non-deterministic work (LLM calls, tool calls, external API calls) runs once as Activities, and the results are recorded in workflow history.\nDo I really need Temporal?\nIf youre new to Temporal, you might think: Why introduce a whole framework? I could just save state to the database, add some exception handling, make sure everything is idempotent (Famous last words.)\nAnd yes, in principle, you could do all that for each feature you add  just like you could rewrite your app in C to make it faster. But now youre spending engineering time on fragile retry logic, tangled reliability code, and brittle assumptions about failure modes.\nTemporal's model handles all the retry logic, state persistence, and fault tolerance for you, allowing you to focus on your agent's core business logic.\nIn fact, Temporal enables patterns that usually feel wrong  like sleep for a week or pause until a user clicks approve  because it virtualizes execution. Your workflow looks like its blocking, but its not. When the worker resumes, it replays from history deterministically.\nGetting started\nHere's a regular Pydantic AI agent:\nfrom pydantic_ai import Agent\n\nagent = Agent(\n    model=\"anthropic:claude-sonnet-4-5\",\n    system_prompt=\"You are a helpful research assistant\"\n)\n\n# You can now make use of the agent inside an `async def` function via:\n...\nresult = await agent.run(\"What are the best Python web frameworks?\")\n...\nNice and simple. The only catch is that agent calls arent deterministic  they depend on external APIs  so Temporal requires them to run as activities. The Pydantic AI Temporal integration takes care of that for you, wrapping all the I/O so you can keep using your agent normally inside workflows.\nHere's that same agent, now ready for durable execution running on Temporal:\nfrom pydantic_ai import Agent\nfrom pydantic_ai.durable_exec.temporal import TemporalAgent\n\nagent = Agent(\n    model=\"anthropic:claude-sonnet-4-5\",\n    system_prompt=\"You are a helpful research assistant\"\n)\n\n# Wrap it for Temporal execution\ntemporal_agent = TemporalAgent(agent)\n\n# Now it survives failures and can be part of long-running workflows\n# Inside a temporal workflow, you can just call:\n...\nresult = await temporal_agent.run(\"What are the best Python web frameworks?\")\n...\nThat's it. One wrapper. When you run an agent with TemporalAgent, all the non-deterministic work (model calls, tool executions, external API calls) gets automatically offloaded to Temporal Activities with built-in retry policies. Your coordination logic runs deterministically as a Workflow. (For more details, see the Pydantic AI Temporal documentation.)\nWant to see this in action? Join our live coding session  where we'll build a production AI agent system with the Pydantic team.\nA real-world example: Multi-agent systems\nLet's look at something more interesting than a single agent. As a more fully-fledged demonstration of how to use Pydantic AI and Temporal together, I built a Slack bot that helps you decide what to order for dinner. It's deliberately low-stakes, but it demonstrates many patterns you'd use in production.\nThe bot uses a two-agent system:\n\n  Dispatcher agent (fast, cheap): Figures out user intent and gathers information\n  Research agent (thorough, expensive): Searches for restaurants and creates recommendations\n\nHere's what it looks like to have a Temporal Workflow orchestrate both agents:\nfrom temporalio import workflow\nfrom pydantic_ai.durable_exec.temporal import TemporalAgent\n\ntemporal_dispatcher = TemporalAgent(dispatch_agent)\ntemporal_researcher = TemporalAgent(research_agent)\n\n@workflow.defn\nclass DinnerBotWorkflow:\n    @workflow.run\n    async def run(self, user_message: str):\n        # Run dispatcher to determine intent\n        dispatch_result = await temporal_dispatcher.run(user_message)\n\n        if isinstance(dispatch_result.output, NoResponse):\n            return None\n\n        if isinstance(dispatch_result.output, AskForMoreInfo):\n            return dispatch_result.output.response\n\n        # We have enough info, run research agent\n        research_result = await temporal_researcher.run(\n            dispatch_result.output\n        )\n        return research_result.output.recommendations\n(Note: this code snippet is purposely not self-contained  its simplified from the SlackThreadWorkflow in the full example repository, but still demonstrates the core pattern of using Pydantic AI agents within a Temporal Workflow.)\nEach agent call is durable. If OpenAI times out during the dispatcher call, Temporal retries it. If your worker crashes after the dispatcher succeeds but before the researcher starts, Temporal replays the workflow, but it doesn't re-run the dispatcher. It uses the recorded result from history and picks up at the research agent call.\nThe full example on GitHub includes additional production patterns: maintaining conversation state per Slack thread, handling asynchronous messages with Signals, coordinating Slack API calls as Activities with retries, and managing concurrent conversations, and implementing human-in-the-loop approval flows where agents wait for user confirmation before executing actions. This is what production AI systems actually look like, and Temporal handles the orchestration complexity so you can focus on your agent logic.\nWhat you can build with this\nThe patterns here apply to way more than dinner recommendations:\nCustomer support agents that handle long-running issues, coordinate with human agents, and maintain context across days of conversation.\nResearch assistants that gather information from multiple sources, wait for API rate limits to reset, and produce structured reports.\nApproval workflows where an AI agent does preliminary work, waits for human approval, then executes actions, all with full audit history.\nMulti-step pipelines that coordinate multiple specialized agents, handle partial failures gracefully, and retry only what's needed.\nAny time you need more than a basic request-response interaction, Temporal's workflow model shines. And with Pydantic AI's integration, you get durable execution plus the production-grade features that set Pydantic AI apart: type safety throughout, built-in OpenTelemetry observability (works great with Pydantic Logfire), structured outputs with validation, first-class MCP support, and more.\nTry it yourself: Join the live coding session\nI'm hosting a live coding session with other members of the Pydantic and Temporal teams where we'll build a real AI agent system from scratch using Pydantic AI and Temporal. We'll go deeper than this blog post: handling failures, debugging workflows, scaling patterns, and production considerations.\nRegister for the live coding session  here\nCome with questions. Bring your AI agent horror stories. Let's build something that actually works in production.\nGet started now\nWant to dive in before the session?\nInstall Pydantic AI with Temporal support:\npip install pydantic-ai[temporal]\nStart a local Temporal server:\nbrew install temporal\ntemporal server start-dev\nCheck out the docs and examples: Pydantic AI Temporal documentation\nCheck out the getting started with Temporal and Python Docs: Python Temporal Getting Started\nExplore the full Slack bot example: GitHub: pydantic-ai-temporal-example\nJoin the conversation:\n\n  Temporal Community Slack: Check out the #python channel\n  Pydantic Logfire Slack: There's lots of great Pydantic AI discussion here\n  Temporal Community Forum\n\n\nWe're constantly working to make Pydantic AI better, and your feedback is invaluable. Whether you're building production systems or just experimenting, we'd love to hear about your experience.\nJoin our public Slack, open issues or discussions on GitHub, or come to the live coding session with questions.\nSee you at the live coding session!",featureImage:{title:"li-zhang-ZvVydsVkyTI-unsplash",description:"li-zhang-ZvVydsVkyTI-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3WwtmBoVCX8MFqaV2ZTQUq/fc4fc75dd2e1d75a6a36d292827b8d80/li-zhang-ZvVydsVkyTI-unsplash.jpg"},publishDate:"2025-11-06",metaDescription:"Find out how you can combine Pydantic AI's type safety with Temporal's Durable Execution to build prod-ready AI agents.",metaTitle:"Here's how to build durable AI agents with Pydantic and Temporal",socialCard:{title:"Build durable AI agents with Pydantic AI and Temporal social card",description:"Build durable AI agents with Pydantic AI and Temporal social card",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6FPdB1484Cm6kKUpCUgy8c/6835565e69c6b376ae84b6cf80e989d6/Build_durable_AI_agents_with_Pydantic_AI_and_Temporal.png"},tags:"AI/ML,Code Samples,Python",slug:"build-durable-ai-agents-pydantic-ai-and-temporal",contentType:"blogPost",entityId:"7c50dzjQhYQlubG6fT4iZ4",authors:[{id:"1rpYxgSKBXui13STxL5SWS",name:"David Montague",slug:"david-montague-pydantic",jobTitle:"CTO at Pydantic",photograph:{title:"David Montague PFP",description:"David Montague PFP",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5y6PKME4ywZ0SOeYUgAvpp/e3b427d5e1671d7cc5f187c456fa5d04/David-Montague-Pydantic-AI.jpeg"},company:"Pydantic",contentType:"person"}],authorsString:"David Montague",category:"How-To",promoCard:{title:"Live coding session with Pydantic",eyebrow:"Check it out",heading:"Live coding with Pydantic",content:"In case you missed it: on November 20, we built an AI agent live with the Pydantic team. Catch the full recording here.",callsToAction:[{text:"Watch now",href:"https://www.youtube.com/watch?v=3rpwaKQXI7A",variant:"primary",leadingIcon:null,trailingIcon:"arrow-right",entityId:"623E9ImeUSQeZEeFwQN41u",large:false,theme:"ultraviolet"}],entityId:"abFntcOUvxiM1lflTM3hP",contentType:"noise"},readingTime:8},{title:"Durable Digest: October 2025",content:"This blog post is a public copy of our monthly newsletter. If youd like to receive upcoming updates by email, you can subscribe to our newsletter here.\nIn this issue, catch Server v1.29.0, Ruby SDK GA, Eager Workflow Start in Public Preview, a new Langfuse integration, Cloud Audit Logging in Public Preview, and Saved Views GA, plus real-world fixes from the field, a Justworks Builder Spotlight, fresh AI how-tos, and where to meet us in November.\nFor more information on these updates and other things weve been working on, just keep reading! And as always, wed love to hear from you. Feel free to share feedback in our Community Slack, or on X (@temporalio).\nQuestions from the field\n\n  Younes Mahmoudi is designing a marketing automation system using Temporal, where users can be active in multiple independent Campaign Workflows simultaneously. Maxim suggests the Actor pattern to help with the challenge of enforcing global, user-level rules like frequency capping across all these separate workflow executions for a given user.\n  John Koehn experienced high CPU usage on their Workflow Workers, and they were unsure of the root cause. Tiho provided suggestions to address the issue, including optimizing imports. Rob mentioned a common pattern of storing some state externally when frequent querying is required.\n\nRecently shipped\n\n  Temporal Server v1.29.0 is here. This release includes Task Queue Fairness (pre-release), versioning improvement, Nexus updates, and more.\n  Temporals Ruby SDK is now generally available. This SDK has feature parity with other languages. Use the power of Ruby to create durable applications with Temporal!\n  Eager Workflow Start is now in Public Preview. This reduces the time it takes to start a Workflow, and is great for short-lived Workflows that interact with other services using Local Activities.\n  New integration alert: Langfuse + Temporal! With Langfuse, you can now trace every step of your agents built with Temporal, alongside your LLM runs.\n  Audit Logging UI and API in Temporal Cloud are in Public Preview. Users can now view up to the last 30 days of Audit Logs and programmatically access the API to build their own viewing experience if they wish.\n  Saved Views is generally available for all users. You can now save and reuse frequently used visibility queries in the Temporal Web UI. Save them once and apply them with a single click.\n\nBuilder spotlight\nThis month were sharing a cool project from Justworks, a payroll and benefits admin platform for small businesses. They recently rebuilt their time-tracking tool for hourly workers to run on Temporal, using the power of long-running Temporal Workflows to hold state for any open shift that is started by web or mobile-based clients.\nUnlike traditional state machines, where we would have had to build and maintain complex logic to track and manage thousands of concurrent shift states, Temporal abstracts that complexity away. It provides a durable, fault-tolerant runtime that allows us to model each open shift as its own isolated Workflow. This not only simplifies our system architecture but also lets us scale to tens of thousands of open shifts with minimal infrastructure overhead and operational burden. - Dhruv Oberoi, Senior Software Engineer\nHow to Temporal\nBuild a Hello World app that calls an LLM, a simple tool-calling agent, and more in the Temporal AI Cookbook, which is filled with recipes to help you build reliable AI apps with Temporal.Start cooking AI \nBuilding Durable MCP Tools with Temporal: A Complete Guide, written by our friends over at Bitovi, provides step-by-step instructions on building reliable, scalable AI tools.View the guide \nJoin us live\nConnect with our team at upcoming events to see live demos from real humans. Wed love to show you how were helping organizations build resilient, scalable applications.\nNovember 5: Meetup | Paris, France: Whether youre already orchestrating durable Workflows with Temporal or curious about how to elevate your AI agents, weve built this meetup for engineers, dev-ops wizards, and data-driven builders like you.\nNovember 6: Humans in the (Agentic) Loop Webinar: Join us to learn patterns that support Human In The Loop use cases. Save your spot for multiple demos including when agents are long running.\nNovember 18: Launch and Learn | San Francisco, CA: A full-day, hands-on workshop designed for developers, architects, and technical leaders who want to move beyond prototyping and learn how to build durable, production-ready GenAI applications. Join us as we dive deep into AI development with Temporal!\nNovember 19-20: Ruby Conference | San Francisco, CA: Heads up, Ruby devs! Swing by our booth, talk durable Workflows, and see how Temporal Technologies can power your next big build!\nDecember 1-5: AWS re:Invent | Las Vegas, NV: Were heading back with even more ways to connect, learn, and have fun. Stop by Booth #1382 to see Temporal in action, giveaways, or to set up a dedicated chat while youre there.",featureImage:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},publishDate:"2025-10-30",metaDescription:"Explore Temporals latest developer updates: questions from the field, new releases, builder spotlights, learning resources, and ways to connect with our team.",metaTitle:"Durable Digest: October 2025",socialCard:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},tags:"",slug:"durable-digest-october-2025",contentType:"blogPost",entityId:"1uuvj344vRNemKBhDuM4ei",authors:[{id:"17hGmNrCwtXdBh7fhsLUnZ",name:"Temporal Technologies",slug:"temporal-technologies",photograph:{title:"temporal technologies logo",description:"temporal technologies logo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3g56zRXtFQYMeJxBBkVBIZ/7771670e5fc7da59f555837b086c35d6/temporal_technologies_logo.avif"},company:"Temporal Technologies",contentType:"person"}],authorsString:"Temporal Technologies",category:"Announcements",readingTime:5},{title:"How to get your boss to send you to Replay",content:"Weve all felt this before: youve been staring at your computer screen for hours. Your eyes are red and blurry. Youre overwhelmed by an overstuffed backlog, juggling on-call alerts, trying to carve out ten quiet minutes just to think.\nMeanwhile, the conference you want to attend catches your eye each time you open your calendar. This year its Replay. Its where devs like us finally step out of the weeds and into a room full of people who get it. The place where you hear someone describe the exact failure thats been blowing up PagerDuty, and suddenly the fix is clear to you. You want to go. You need to go. But first, youve got to sell it to your manager.\nYou and your team know the pain in your bones. But your boss doesnt feel it the same way. Even if theyre as empathetic as possible, theyre not the one with their hands on the keyboard and their boots on the ground. That disconnect is half the story and the connection is whats going to get you in the door at Moscone Center in San Francisco, May 57, 2026.\nThe developer-manager disconnect\nThe State of Development 2025 report laid it bare:\n\n  64% of ICs (individual contributors) say theyre drowning in workload, but only 38% of DMs (decision makers) admit its a problem. On infrastructure, its almost the same exact split  53% of ICs call their systems fragile, compared to just 29% of DMs.\n\nThat gap is a chasm of misunderstanding. Were the ones stitching together retries at 2 a.m. and holding our breath every time traffic spikes, while leadership thinks the system is fine.\nReplay is one of the few places where that gap can close. Its where you can grab tools and patterns that work, and where your boss gets peace of mind that youre investing in whats next instead of only fighting fires.\nWhy you deserve a ticket\nDont go to Replay for free hoodies or time away from Jira. Go because it makes your job better.\n\n  The State of Development report showed 71% of developers are craving opportunities to learn new tools and frameworks.\n\nBut we keep running into the same blockers: no time, no budget, no air cover. Replay is the antidote.\nIts three full days of accelerated learning, conversations with engineers whove already solved the problem youre staring down, and ideas you can plug back into production immediately.\nThe alternative? Keep burning out. Keep patching together pipelines. Keep pretending brittle systems are good enough. The cost of not sending you is way higher than the flight and ticket.\nWhat to look forward to\nEach year, Replay is chock full of value  talks, a hackathon, workshops, commiserating with your peers about dev issues over lunch  everything you want.\nThe talks are a big draw, so heres a quick look back to give you a taste of what to expect. These examples come from earlier this year at Replay 2025. (You can check out the entire playlist of the Replay 2025 videos here).\nSalesforces Migrating a monolithic cloud with Temporal\nThe Salesforce Marketing Cloud team faced an Olympic-level migration challenge: moving hundreds of terabytes of tenant data from on-prem data centers to Salesforces new Hyperforce platform all without taking customers offline. Their solution was to orchestrate the entire process with Temporal.\nThey built migration-as-a-service Workflows that coordinated over 1,200 Activities across 34 Child Workflows, hitting a downtime goal of under 10 minutes per customer. Using Temporal allowed them to parallelize massive SQL migrations, automate rollbacks, and track every operation with heartbeats and retries. What couldve been a months-long coordination nightmare turned into an elegant, observable system that scaled across thousands of databases.\nFor developers, this talk is a goldmine on taking something impossibly large and making it reliable, repeatable, and visible. For managers, its proof that investing in orchestration is the operational insurance theyre looking for.\nMaersks The saga of orchestrating a seamless developer experience\nGlobal logistics giant Maersk learned that 70% of its developers time wasnt going into writing code; the team struggled with infrastructure. Spinning up environments could take weeks or even months, strangling innovation and burning cycles on toil instead of shipping business value.\nSo they set out to fix it. Enter the Developer Experience (DevX) initiative: a company-wide effort to streamline infrastructure delivery, standardize tooling, and build what they called their golden path.\nBy re-architecting their internal developer platform (IDP) around Temporal, Maersks engineering team built durable, asynchronous Workflows to power a new Infrastructure API and control plane. Temporal became the invisible engine behind everything from provisioning databases to managing deployment pipelines. This reduced setup times from three months to mere minutes.\nWith over 3,000 engineers worldwide, Maersk used Temporal to orchestrate complex, multi-team Workflows with reliability, retries, and visibility built in. Temporal made it possible to scale infrastructure provisioning without manual approvals, all while maintaining transparency and debuggability through Temporals Workflow UI.\nFor developers, this talk shows how to kill infrastructure friction and reclaim your time from YAML files and Terraform scripts to actually ship. For managers, its proof that developer is a system problem you can fix with orchestration and Durable Execution.\nAirwallexs Tucking in your legacy tech debt with Temporal\nWhen Airwallex, a global fintech unicorn, built its accounting integrations, things got messy. What started as a simple pipeline to sync expenses and receipts turned into a tangled web of Kafka topics, retry queues, and brittle error handling. Developers were spending their time fighting architecture instead of building value, and the system was generating 350+ alerts a year.\nTheir challenge: improve reliability and velocity without derailing the product roadmap.\nBy rebuilding their integration layer with Temporal, the Airwallex team untangled the chaos into a clean, durable Workflow. Temporal replaced complex retry queues and rollback logic with transparent orchestration and built-in resilience. In just three weeks, the team migrated from their legacy architecture to a production-ready system; cutting alerts to near zero and improving development speed 6x.\nDevelopers gained a single, readable Workflow file instead of 45 scattered code files, better error recovery through automatic retries and sagas, and easier local testing with Temporals replay capabilities. For managers, its a model for how to modernize without stopping momentum: a faster, more reliable architecture that makes engineers more productive and systems more stable without a total rewrite.\nMaking the pitch\nSo how do you get a yes? Dont overcomplicate it; treat it like debugging youre all too familiar with:\n\n  Reproduce the bug: Tell the story of your teams pain (retry storms, brittle pipelines, endless on-call fatigue).\n  Show the logs: Drop in the State of Development 2025 stats (data gets it done).\n  Propose the fix: Replay is the most efficient way to close knowledge gaps, strengthen the stack, and stop wasting cycles. A few days away from your computer will make a huge difference to your team.\n\nAnd if your boss still hesitates? Remind them Replay sells out fast. Missing it is your problem, their problem, and a company problem.\nReplay 2026 is the room where the people who build the future come to trade notes. Make sure youre in it.",featureImage:{title:"social card - green waves",description:"social card - green waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4GBHZR0vUnoRSbPtSTCH4s/daf7308a10e469059827e2169065d7ea/social_card_-_green_waves.jpg"},publishDate:"2025-10-28",metaDescription:"How to get your manager to send you to Temporal Replay 2026: use data, talks, and takeaways to boost reliability and developer productivity.",metaTitle:"How to get your boss to send you to Replay",socialCard:{title:"Blog (53)",description:"Blog (53)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7bsNGF2jK6YDTLNUde2Fmb/590cf3bd3ebf1bb858a0ff92b890f625/Blog__53_.png"},tags:"Replay,Durable Execution,Industry Events",slug:"how-to-get-your-boss-to-send-you-to-replay",contentType:"blogPost",entityId:"25DayL7EcNQrNgxjIM29PD",authors:[{id:"7GQtiP7y4Dmrje9sFWcVKl",name:"Lauren Bennett",slug:"lauren-bennett",jobTitle:"Content Marketing Manager",photograph:{title:"Lauren-Bennett-profile-photos",description:"Lauren-Bennett-profile-photos",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6jEqojw9RxBBjX5pytMzYf/4df0ef856a9efe4b7b52d5ebe7e83686/Lauren-Bennett-profile-photos.jpeg"},linkedInUrl:"https://www.linkedin.com/in/lauren-n-c-bennett/",contentType:"person"}],authorsString:"Lauren Bennett",category:"Community",promoCard:{title:"Replay 2026",eyebrow:"Replay 2026",heading:"The developer conference you actually want to attend",content:"Replay 2026 is the room where the people who build the future come to trade notes. Make sure youre in it.",callsToAction:[{text:"Learn more",href:"https://replay.temporal.io/",variant:"primary",leadingIcon:null,trailingIcon:"arrow-right",entityId:"18Ek1lPFNdjlKw637e9sS4",large:false,theme:"ultraviolet"}],entityId:"247zy0HpcsNw0j0mGIUzaY",contentType:"noise"},readingTime:7},{title:"How to think about agentic solutions for the enterprise",content:"Your AI agent demo went perfectly. The team loved it. Leadership is excited. Then you try to put it in production, and everything falls apart.\n\n  If this sounds familiar, youre not alone. We recently surveyed over 150 developers and technical leaders across industries to understand how teams are really building with AI. What we found reveals a critical gap between experimentation and production-ready systems, and its costing teams real time and money.\n  \n  \n\nThe experimentation trap\n\n  Heres the state of AI development today: 49% of teams are still experimenting: exploring use cases or prototyping in development. Only 38% have reached what wed call mature adoption, with AI either essential to their business or actively scaling in production.\n  \n  \n  But heres whats more concerning: of those who have pushed agents to production, only 13% feel very confident in their ability to observe and debug AI workflows at scale. Nearly 60% fall somewhere between neutral and not confident at all.\n\nOur findings show that theres a fundamental mismatch between what todays AI frameworks enable (fast prototypes) and what enterprises actually need (reliable, observable, production-grade systems).\nThe hidden tax of fragile AI\nThe cost of this gap is something that shows up in the bottom line  were far beyond hypothetical scenarios here. 62% of teams report measurable time or revenue losses due to reliability issues. For many, thats 1050 developer hours or $110k annually. For some, its 200+ hours or over $100k per year.\nWhen we asked developers what theyd eliminate with a magic wand, the answers were telling:\n\n  LLM inconsistencies\n  Hallucinations. We really depend on accurate responses\n  Orchestration failures\n\n48% of respondents identified LLM inconsistency as the most fragile part of their AI systems. And when failures happen, teams lack the observability and recovery mechanisms to handle them gracefully.\nWhat makes enterprise AI different\nBuilding agents for the enterprise isnt the same as building a prototype. Enterprise AI systems need to:\n\n  Run reliably over extended periods: Your agent cant lose state halfway through a multi-day workflow.\n  Handle failures gracefully: When an API times out or an LLM hallucinates, the system should retry intelligently, not crash.\n  Maintain visibility: You need to know what your agents are doing, why they made specific decisions, and where things went wrong.\n  Scale predictably: What works for 10 concurrent agents needs to work for 10,000.\n\nYet most AI tooling today focuses on iteration speed, not production durability. Agent frameworks give you structure but not orchestration. Memory systems help with context but not state management. Observability tools show you logs but not whether your model outputs are actually correct.\nDurable Execution: The missing backbone\nWhat enterprises need (and what our research shows is most often missing) is orchestration thats built for durability. The ability for workflows and agents to:\n\n  Automatically track state across long-running processes\n  Retry failures without losing progress\n  Recover from crashes without developer intervention\n  Provide complete visibility into what happened and why\n\nThis is what we call Durable Execution, and its the backbone todays agent stacks are missing.\n\n  Companies like Replit, ZoomInfo, and Gorgias have already made this shift, moving from brittle, homegrown orchestration to systems designed for production reliability. The results speak for themselves: faster deployment, fewer failures, and teams that can focus on building better agents instead of debugging broken workflows.\n   Thinking long-term\n  When we asked respondents about the next 1224 months, 88% predicted at least a moderate boost to efficiency or revenue from AI, with more than half expecting significant or transformative change.\n  \n  \n  But growth doesnt come for free. The top priorities teams identified for the next two years align perfectly with the weaknesses theyre experiencing today:\n\n\n  Improving reliability and scalability\n  Better observability and debugging\n  Robust infrastructure that integrates with existing systems\n\nThe teams that will win are the ones building systems that last, with the orchestration, observability, and reliability that production AI demands.\nReady to build production-ready AI?\nThis post only scratches the surface. Our Production AI stack report dives deeper into:\n\n  Complete breakdown of the modern AI stack (LLMs, agent frameworks, memory, databases, tools, orchestration, observability, and infrastructure)\n  Detailed findings from 150+ developers on whats working and whats broken\n  Comprehensive data visualizations that bring these findings to life\n  Real-world case studies from Replit, ZoomInfo, and Gorgias\n  Actionable guidance for building agents that survive in production\n",featureImage:{title:"rick-rothenberg-JP-d0V5UBxs-unsplash 1",description:"rick-rothenberg-JP-d0V5UBxs-unsplash 1",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Q3MJsvD1ujCkIoEbicDUD/91e1dc92fa47018f97057873b03ff3c6/rick-rothenberg-JP-d0V5UBxs-unsplash_1.png"},publishDate:"2025-10-21",metaDescription:"Enterprise AI demos impress, production hurts. From 150+ teams: why agents fail at scale and how Durable Execution delivers reliability, observability, and recovery.",metaTitle:"How to think about agentic solutions for the enterprise",socialCard:{title:"Blog (52)",description:"Blog (52)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7pEKIGm0SUUkwSr7X8ME3f/5f8a368b1bff3a9b5379b0b16ce45645/Blog__52_.png"},tags:"AI/ML,Durable Execution",slug:"how-to-think-about-agentic-solutions-for-the-enterprise",contentType:"blogPost",entityId:"18T7axGcoSYcczRS0pJuzk",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"Community",promoCard:{title:"Enterprise AI white paper",eyebrow:"The 2025 production AI stack report",heading:"Want a deeper dive? ",content:"Read the full report to get the complete picture  and give your AI the backbone it needs to thrive in production.",callsToAction:[{text:"Get your copy now",href:"/pages/ai-production-stack-report",variant:"primary",leadingIcon:null,trailingIcon:"arrow-right",entityId:"LlAD7Hzo9dCImdVQ4DO8Y",large:false,theme:"pink"}],entityId:"7yt8Esi9zrqIoauHQxxxvL",contentType:"noise"},readingTime:4},{title:"Temporal Ruby  crash-proof fibers",content:"After a long effort, Temporal Ruby is now GA. The Temporal Ruby SDK allows Ruby developers to author durable software with a native Ruby feel. Ruby at Temporal is a fully-supported language with the same level of support and features as every other official Temporal-supported language.\nIn this post, we will cover what Temporal Ruby is at a high level. Then we will delve into some advanced technical details of how we used Rust, how we made durable fibers work, how we prevent illegal calls, and some interesting challenges we faced along way.\nIntroduction to Temporal and Temporal Ruby\nTemporal is a system and programming model for writing durable code that can run a long time and can survive crashes. In a nutshell, Temporal Workflows are sets of deterministic code that record side-effecting actions as events and then, upon crash or for other reasons, can use those events to resume from where the code left off. There are many other components to Temporal, such as Activities which are an abstraction over those side-effecting actions. See the high-level explainer docs and evaluation docs for more understanding of the system.\nTo support this in Ruby, Temporal offers the Ruby SDK. Here are some important links:\n\n  Ruby SDK repository\n  Ruby developer guide  with a quick-start guide\n  Ruby getting started\n  Ruby samples\n  Ruby API documentation\n  #ruby-sdk channel on Slack\n\nIt is MIT-licensed like all Temporal open-source software and is much more than a smart client, it translates imperative Ruby Workflow code into durable software.\nTo give you a taste of the Ruby SDK, well create a simple one-click buying Workflow in Ruby where a purchase is started and then, unless cancelled, will be performed in 10 seconds.\nImplementing an Activity\nActivities are automatically retryable functions in Temporal that allow arbitrary side-effecting code to run. In Ruby, these are classes. Heres an implementation of a sample Purchase Activity:\nrequire 'json'\nrequire 'net/http'\nrequire 'temporalio/activity'\nrequire 'uri'\n\nclass Purchase \u003C Temporalio::Activity::Definition\n  def execute(purchase_details)\n    # Could HTTP.start in initialize and reuse session as an optimization\n    resp = Net::HTTP.post(\n      URI('https://api.example.com/purchase'),\n      JSON.generate(purchase_details),\n      { 'Content-Type' => 'application/json' }\n    )\n    # Fail if not 2xx\n    unless (200..299).include?(resp.code.to_i)\n      raise Temporalio::ApplicationError.new(\n        \"Client error #{resp.code}: #{resp.body}\",\n        # 4xx is considered non-retryable\n        non_retryable: (400..499).include?(resp.code.to_i)\n      )\n    end\n  end\nend\nThis Activity posts to HTTP and raises an exception on failure, taking care to not make that exception retryable if its not a retryable HTTP status code.\nImplementing a Workflow\nNow that we have an Activity that performs a purchase, we can write the Workflow to do time-limited one-click buy:\nrequire 'temporalio/workflow'\nrequire_relative 'purchase' # Our Activity\n\nclass OneClickBuy \u003C Temporalio::Workflow::Definition\n  workflow_query_attr_reader :purchase_status\n\n  def initialize\n    @purchase_status = :pending\n  end\n\n  def execute(purchase_details)\n    @current_purchase ||= purchase_details\n\n    # Give user 10 seconds to cancel or update before we send it through\n  begin\n\t  Temporalio::Workflow.sleep(10)\n  rescue Temporalio::Error::CanceledError\n\t  # Canceled workflow/purchase\n\t  return @purchase_status = :canceled\n  end\n\n    # Update the status, perform the purchase, update the status again\n    @purchase_status = :confirmed\n    Temporalio::Workflow.execute_activity(\n      Purchase,\n      purchase_details,\n      schedule_to_close_timeout: 2 * 60 # 2 minutes\n    )\n    return @purchase_status = :completed\n  rescue\n    @purchase_status = :failed\n    raise\n  end\n\n  workflow_update\n  def update_purchase(purchase_details)\n    # Disallow if not pending (this logic could be in an update validator)\n    raise Temporalio::ApplicationError, 'No longer pending' unless @purchase_status == :pending\n    # Update current purchase (no need to return it)\n    @current_purchase = purchase_details\n    nil\n  end\nend\nWorkflows have to be deterministic and Temporal has a custom fiber scheduler to make sure all asynchronous work is deterministic (explained later).\nThat sleep is a durable timer. If the process this ran on crashed, no problem, it picks right back up where it left off. Sleeping for weeks is not uncommon.\nThis relies on Workflow cancellation to cancel the pending purchase and relies on Workflow update to be able to update the purchase in that window. See the Ruby developer guide for more details on everything a Workflow can do.\nRunning a Worker\nWorkflows and Activities are run via Workers, like so:\nrequire 'temporalio/client'\nrequire 'temporalio/worker'\nrequire_relative 'purchase' # Our Activity\nrequire_relative 'one_click_buy' # Our Workflow\n\n# Create a Client to localhost on \"default\" Namespace\nclient = Temporalio::Client.connect('localhost:7233', 'my-namespace')\n\n# Create a Worker with the Client, Activities, and Workflows\nworker = Temporalio::Worker.new(\n  client:,\n  task_queue: 'my-task-queue',\n  workflows: [OneClickBuy],\n  # This could be an instance if it needs state\n  activities: [Purchase]\n)\n\n# Run the Worker until SIGINT\nworker.run(shutdown_signals: ['SIGINT'])\nWhen run, this Worker will communicate with the Temporal Server and handle all Workflow and Activity work given to it by the server.\nExecuting a Workflow\nA client can run our Workflow like so:\nrequire 'temporalio/client'\nrequire_relative 'one_click_buy' # Our Workflow\n\n# Create a client to localhost on \"default\" Namespace\nclient = Temporalio::Client.connect('localhost:7233', 'my-namespace')\n\n# Start a Workflow\nhandle = client.start_workflow(\n  OneClickBuy,\n  { item_id: 'item1', user_id: 'user1' }, # This is the input to the workflow\n  id: 'my-workflow-id',\n  task_queue: 'my-task-queue'\n)\n\n# We can update the purchase if we want\nhandle.execute_update(\n  OneClickBuy.update_purchase,\n  { item_id: 'item2', user_id: 'user1' }\n)\n\n# We can cancel it if we want\nhandle.cancel\n\n# We can query its status, even if the Workflow is complete\nputs \"Status: #{handle.query(OneClickBuy.purchase_status)}\"\n\n# We can also wait on the result (which for our example is the same as query)\nputs \"Result: #{handle.result}\"\nThis is a small sample showing some of the Ruby features, but there are many many more. See the Ruby developer guide and Ruby SDK README for more details.\nAdvanced SDK implementation details\nWith the Temporal Ruby primer covered, the sections below provide some advanced, interesting implementation details about the SDK.\nRust Core + Ruby C extension\nLike TypeScript, Python, and .NET before it, Temporal Ruby leverages Temporals common Rust Core to handle complexities with gRPC clients, Worker state machines, and more. In addition to not having to reimplement the advanced Workflow state machines and Worker logic in each language, using a Rust Core allows the SDK to reduce its dependency count. In this case, the Ruby SDK does not have to take on a Ruby gRPC dependency which means it will not transitively impose gRPC library version constraints on its users.\nTo leverage this Core library, we create a Ruby C extension with Rust. Like wasmtime and others, we use Magnus and rb-sys to provide a relatively easy-to-use bridge between Ruby and Rust. We include the sdk-core repository as a submodule and reference it via our Ruby-specific Rust project.\nThe Rust Core uses async/Tokio extensively, and on the Ruby side, we expect all of our constructs to be asynchronous (via thread or fiber, user choice). So we must bridge the two. After research, it became apparent that a single-use Ruby Queue was both thread-aware and fiber-aware when it blocked waiting for response. So having the Ruby side pass in a queue as essentially a completable promise allows us to resolve the Ruby call asynchronously.\nHowever, invoking a Queue#push even from Ruby C code requires holding the GVL. The GVL can only be acquired in a Ruby thread, and Ruby threads are only threads Ruby creates. There is no acceptable way to cheat this and have a Rust/Tokio thread masquerade as a Ruby thread for purposes of a simple GVL-held invocation. So the Temporal Ruby Runtime, that is meant to be global and often lazily created, has this in its initialize:\nThread.new do\n  @core_runtime.run_command_loop\nend\nThis runs the blocking Rust code:\npub fn run_command_loop(&self) {\n  enter_sync!(self.handle);\n  loop {\n    let cmd = without_gvl(\n      || self.async_command_rx.recv(),\n      || {\n        if let Err(err) = self.handle.async_command_tx.send(AsyncCommand::Shutdown) {\n          log_error!(\"Unable to send shutdown command: {}\", err);\n        }\n      },\n    );\n    match cmd {\n      Ok(AsyncCommand::RunCallback(callback)) => {\n        if let Err(err) = callback() {\n          log_error!(\"Unexpected error inside async Ruby callback: {}\", err);\n        }\n      }\n      Ok(AsyncCommand::Shutdown) => return,\n      Err(err) => {\n        // Should never happen, but we exit the loop if it does\n        log_error!(\"Unexpected error receiving runtime command: {}\", err);\n        return;\n      }\n    }\n  }\n}\nWhats happening here is we are waiting on a Tokio channel receiver under the Ruby rb_thread_call_without_gvl C function (abstracted as without_gvl). Once we receive a callback to run, we are under the GVL and therefore can execute the Ruby callback. Usually, this callback is a simple Queue#push. We make sure that any callback is incredibly cheap since it is all handled by this single-threaded reactor loop. We also provide a way to shut it down either from the outside or as the rb_unblock_function_t function parameter that interrupts the thread.\nDurable fiber scheduler\nA Temporal Workflow is actually a custom, deterministic Fiber::Scheduler. Temporal requires Workflow code be deterministic. This is so the SDK can replay the same Workflow code path to get to where it left off when it needs to resume. Traditionally asynchronous code is not deterministic, so while doing something like waiting for two racing concurrent fibers to complete may not be deterministic in most schedulers, it is in the Temporal scheduler.\nHow Ruby Workflows work is that all events (e.g.,Signal received, Timer fired, Activity completed) are applied to the Workflow state and fibers are created in cases where they are needed (e.g.running a Signal handler). If were on the first Workflow task, a fiber is created representing the primary Workflow execute method. When a fiber needs to be run/resume, it calls #fiber or #unblock on the scheduler, and we enqueue those fibers on an array. Then our scheduler instance has the following method:\ndef run_until_all_yielded\n  loop do\n    # Run all fibers until all yielded\n    while (fiber = @ready.shift)\n      fiber.resume\n    end\n\n    return unless pending_wait_conditions\n    # \u003C... code omitted for wait_condition handling ...>\n  end\nend\nThis is your basic event loop. It pops fibers off @ready array and calls resume on them, which may in turn add more fibers on @ready via #fiber or #unblock. When there are no more fibers on @ready, it means they are all waiting on external stimulus from Temporal Server (e.g., Activity completion). We invoke this when we receive a Workflow task, and when it is done, we collect the commands that occurred during invocation and send them to the server (e.g., schedule Timer).\nAnd since our Fiber::Scheduler implements #kernel_sleep and #timeout_after, technically sleep and Timeout.timeout are automatically made durable. However, we have disabled them by default, see Implicitly Used Sync Constructs under Lessons Learned later to understand why.\nAdditional async constructs\nRubys standard library only offers basic Ruby fiber constructs and is missing some high-level forms users need. In this section we will discuss three  cancellation, future, and wait condition.\nTemporal needs to be able to cancel things. Unlike some languages, Ruby does not offer a native concept of cancellation that is potentially hierarchical/linked, can be shielded against, can be waited on, and generally can interrupt any async call. To support cancellation, we developed Temporalio::Cancellation which is basically a cancellation token like you may see in .NET. It is general purpose and is used for Activities and Workflows in Temporal. All asynchronous Workflow calls (e.g.Workflow.sleep) accept a cancellation and default to the workflow-level one. For calls like sleep, a cancel will raise and tell the server to cancel the timer. For others like execute_activity, cancel will depend on the cancellation type, but defaults to raising and sending cancel to the Activity. Cancellation supports adding callbacks, waiting for cancel, shielding, and more.\nFibers are a low-level abstraction for running code concurrently, but they are hard to use at a high level and lack high-level primitives. Temporal::Workflow::Future was created to provide high-level concurrent code control. With a future, it is relatively easy to wait for multiple concurrent things to complete like so:\nTemporalio::Workflow::Future.all_of(\n  Temporalio::Workflow::Future.new { Temporalio::Workflow.execute_child_workflow(SomeChild1, 'my-param1') },\n  Temporalio::Workflow::Future.new { Temporalio::Workflow.execute_child_workflow(SomeChild2, 'my-param2') },\n  Temporalio::Workflow::Future.new { Temporalio::Workflow.execute_child_workflow(SomeChild3, 'my-param3') }\n).wait\nSee the future docs for details on how exceptions are handled and which other utilities are available to assist concurrent execution in a Workflow.\nFinally, and arguably most importantly, there is Temporalio::Workflow.wait_condition. This is an extremely powerful primitive to wait on a block to be truthy before returning its value. It is very normal to use this to literally wait on an attribute to be set in a Ruby Workflow. wait_condition is a feature only made possible by Temporal via our control over the durable fiber scheduler and our ability to re-evaluate wait conditions in the event loop. For this reason, the block/condition given to wait_condition must have no side effects since it is invoked frequently. The wait_condition primitive is so powerful that it is the backing primitive leveraged by cancellation waiting, future waiting, Activity/child waiting, etc.\nIllegal call tracing\nFor Workflow code to be deterministic, certain calls are disallowed. Doing things like asking for the current time, using threads, using system/secure random, etc. are non-deterministic and therefore illegal in Workflows. In TypeScript and Python SDKs, there is a sandbox that helps prevent use of these calls (or replaces them). In Go, there is static analysis tooling to help catch invalid calls made from a Workflow. Finally, in .NET, we use an event listener that is notified if the async code leaves the Workflow thread which doesnt catch all illegal calls, but at least thread ones.\nIn Ruby, we are using TracePoint. This lets us check every call only on the Workflow thread, leaving other non-Workflow threads alone. The set of Workflow calls considered illegal is configurable via the illegal_workflow_calls parameter on the Worker. The default is Worker.default_illegal_workflow_calls which includes all obviously illegal classes/calls in the standard library. Since this is for each method call, it can also detect when one of these calls is used transitively (e.g.,multiple calls deep).\nIn some cases, simply checking fully-qualified method name is not enough. For instance, Time.new('2000-12-31 23:59:59.5') is deterministic whereas Time.new with no parameters is not. For this specifically, we use the TracePoint binding to access the parameters to tell whether its safe or not.\nLessons learned during development\nDuring development of the SDK, we altered some of our original plans based on feedback from users of the alpha and beta releases. A few of these lessons learned are described in detail below.\nImplicitly used sync constructs\nOriginally, the Ruby SDK supported standard library use of sleep, Timeout.timeout, Queue, Mutex, etc. in Workflows because they are fiber-aware and therefore are automatically made durable by the fiber scheduler. So this was a very reasonable Workflow:\nclass WaitForSignalOrTimeout \u003C Temporalio::Workflow::Definition\n  def execute\n    # Wait 5 minutes for something to process or fail\n    to_process = Timeout.timeout(300) do\n      Temporalio::Workflow.wait_condition { @to_process }\n    end\n    # Process it\n    Temporalio::Workflow.execute_activity(Process, to_process, start_to_close_timeout: 30)\n  end\n\n  workflow_signal\n  def process(to_process)\n    @to_process = to_process\n  end\nend\nNote the Timeout.timeout in there. This worked well for many users for many months. But then one user reported a rare case where a Workflow would get hung inexplicably. It was very hard to replicate, but the user was eventually able to replicate it with a Workflow that used logging and lots of loops and timers in a certain way to get the Workflow to hang a very small percentage of the time. Given this replication, we began to dig in. The first step was to increase logging, however increasing logging actually made the problem go away. Ugh.\nAt this point it was clear it was a rare race and adding logging would actually make the race less likely to appear. With some more non-logger logging we finally traced it down. In the Ruby logger, a Mutex is used on write. A Ruby mutex does not tell the fiber scheduler that it is blocked on synchronize unless it actually is blocked by another thread/fiber. So most of the time, the synchronize block for the Ruby logger was never considered blocking and never communicates with the fiber scheduler.\nWe implicitly made Mutexes durable with Temporal. Therefore, we assume the only reason a synchronize would ever be blocked/unblocked would be due to Workflow/Event stimulus. But in this case the mutex is a local-process mutex, and therefore it is unblocked by another thread that is completely unrelated to the Workflow at hand. So the fiber scheduler was told about the synchronize blocking, then we considered all coroutines yielded, and then removed ourselves as fiber scheduler so another Workflow task could use the thread. The unblock of synchronize came a split second later after the fiber scheduler was removed, so the Workflow never knew it was unblocked. And adding logging made Workflow tasks run just long enough to not give up their thread and fiber scheduler as quickly, so thats why it was hard to detect with added logging.\nWe have seen other issues in other languages where implicitly treating built-in constructs as durable can be surprisingly unsafe. For instance, in Python we found asyncio.wait and asyncio.as_completed both use non-deterministic sets. In .NET, we found Task.WhenAny in rare cases used the thread pool instead of our task scheduler. Over the years we have come to recognize that magically making standard library constructs durable can cause problems mostly because they were not authored with durable execution in mind.\nAfter discussion, we decided to forbid sleep, Timeout.timeout, Queue, Mutex, Logger, etc., and we have provided Workflow-safe alternatives in the Temporalio::Workflow module. The Workflow-safe Queue and Mutex classes actually just delegate to the standard library ones but surround each call with Unsafe.durable_scheduler_disabled to disable the durable scheduler. That gets us full queue/mutex support, but still requires Workflow authors to explicitly use them instead of accidentally and implicitly using standard library forms by calling Logger or similar.\nIO wait in fiber schedulers\nWhen we first developed the durable fiber scheduler, we intentionally raised NotImplementedError from Fiber::Scheduler#io_wait. After all, Workflows do not allow IO because IO is non-deterministic. However, for certain behaviors it can make sense to violate determinism. This is especially true for telemetry such as tracing, metrics, logs, failure tracking services, etc., which doesnt need to be recorded in history but still does a side-effecting action. Another common use case is for debuggers like Pry or RubyMine that use IO to communicate with separate processes.\nRuby does not have a default scheduler implementation you can fall back to. The documented Fiber::Scheduler class doesnt even really exist. Instead, with some testing and the help of AI, we made a non-durable/blocking form that just reuses IO.select. But users must opt-in to it via a block passed to Temporalio::Workflow::Unsafe.io_enabled. Use of this and any other illegal blocking construct in a Workflow can make the task more likely to hit task timeout which defaults to 10s.\nConversion and runtime type hinting\nIn most Temporal SDKs, Temporal leverages types to tell the converter what to deserialize payloads into. This occurs for things like a Workflow receiving parameters or a client receiving a Workflow result. For serialization, simply serializing the objects given is acceptable, but for deserialization, the converter often needs to know the desired type.\nStatically typed runtimes like Go, Java, and .NET can simply use reflection for this. Even dynamically typed languages like Python provide runtime-accessible type hints that can be used. For TypeScript users, they are used to defining type-check-time-only interfaces to represent JSON objects, so it is reasonable to have untyped JSON objects at runtime.\nBy default in Ruby, the JSON module is used for (de)serialization. This means that if there is a JSON object payload in Temporal, it is deserialized as a Hash. This can be surprising to users that prefer to work with certain class objects. Ruby does not have a clear winner in the JSON/object-mapping arena. Options like ActiveModel and Oj are popular, but as a framework that is meant for general use, picking a winner and imposing dependencies with transitive version constraints would be harmful. The standard library JSON module does offer a JSON additions which are effectively just putting the fully-qualified class name into the JSON object, but this is a less-popular approach and is not language-agnostic. Still, Temporal does support JSON additions natively since it imposes no dependencies on users.\nTemporal allows custom converters to be written for those not wanting default standard library JSON behavior. Users of object-mapping libraries stated that writing a custom converter was no problem, but they need to allow users to provide the desired type at the declaration site. We designed a concept called hints for this. Now, everywhere conversion may occur, hints can be provided. For instance, here is a Workflow that accepts hints:\nclass TransferFunds \u003C Temporalio::Workflow::Definition\n  workflow_arg_hint MyModels::TransferDetails\n  workflow_result_hint MyModels::TransferComplete\n\n  def execute(transfer_details)\n    # Require approval if certain amount\n    if transfer_details.amount > 5000\n      Temporalio::Workflow.wait_condition { @approved }\n    end\n\n    # Run Activity to do transfer\n    Temporalio::Workflow.execute_activity(DoTransfer, transfer_details, start_to_close_timeout: 300)\n    MyModels::TransferComplete.new(id: Temporalio::Workflow.info.workflow_id)\n  end\n\n  workflow_update arg_hints: [MyModels::ApprovalDetails]\n  def approve_transfer(approval_details)\n    # Log and run Activity to apply the approval\n    Temporalio::Workflow.logger.info(\"Approval requested by #{approval_details.approver}\")\n    Temporalio::Workflow.execute_activity(ApplyApproval, approval_details, start_to_close_timeout: 300)\n    @approved = true\n    nil\n  end\nend\nThis sets hints for the Workflow parameter, workflow result, and update parameter. The hint is passed to the converter at (de)serialize time. The default Temporal converter does nothing with hints. Custom converters can leverage this information to know the data type to convert the JSON into (and/or validate its the correct type when converting to JSON). Not only are the hints provided on the Worker side at Workflow parameter/result (de)serialization time, but the client side use of running a Workflow and getting a result will also use these hints. The hints dont even need to be classes, they can be any object the converter may need.\nSummary\nTemporal Ruby is now Generally Available and provides a great way to write durable software in a developer-friendly language like Ruby. In addition to the Temporal overview, we covered advanced implementation details and challenges encountered during development.\nTo get started with Ruby, see the Ruby SDK repository, Ruby getting started, and Ruby quick start guide. Feel free to join us on the #ruby-sdk channel on Slack or ask a question with the ruby-sdk tag on our Forums.",featureImage:{title:"image (3)",description:"image (3)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5pPdjipy5IqZGWBawf8OSy/45852815a0b0ed246d5a39da59870c15/image__3_.png"},publishDate:"2025-10-16",metaDescription:"Temporal Ruby SDK is GA. Build durable Ruby Workflows with native APIs, a Rust-powered core, a deterministic fiber scheduler, and guardrails for safe execution.",metaTitle:"Temporal Ruby  crash-proof fibers",socialCard:{title:"Blog (51)",description:"Blog (51)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Rm7GUkJXrqs5eLRL1nMPe/b46ed11eb44c63d8bd4ecb6284286915/Blog__51_.png"},tags:"Ruby,Code Samples",slug:"temporal-ruby-crash-proof-fibers",contentType:"blogPost",entityId:"2XfXjqn1YgXGqAVAwSUdKH",authors:[{id:"54HCUkZ1FzXSVjuPgLdbrm",name:"Chad Retz",slug:"chad-retz",jobTitle:"Language Runtime Engineer",photograph:{title:"chad avatar",description:"chad avatar",url:"https://images.ctfassets.net/0uuz8ydxyd9p/466YHdnNYWtGFCOMR3is5J/29dfa0790135812058d2b0e458ccc524/chad-avatar.png"},company:"Temporal",contentType:"person"}],authorsString:"Chad Retz",category:"Announcements",readingTime:9},{title:"Building a persistent conversational AI chatbot with Temporal",content:"A carefree, infinitely scalable chatbot architecture\nHow do you build a chatbot that remembers every conversation, scales infinitely, and never loses context  even during deployments?\nThis is a problem that many companies have faced when building customer service chatbots that need to handle millions of concurrent conversations while maintaining perfect context awareness. Traditional chatbot architectures fail at scale: they lose conversation context during restarts, cant scale horizontally due to stateful sessions, and struggle with long-running interactions.\nEnter Temporal  the workflow orchestration platform that transforms how we think about conversational AI. By treating each conversation as a persistent workflow, we can build chatbots that are truly stateless, infinitely scalable, and resilient to failures.\nIn this post, Ill walk you through building a telecommunications customer service chatbot that demonstrates these principles. Users can inquire about mobile devices, check subscriptions, manage consents, and get general support  all while the system maintains perfect conversation context across any number of pod restarts, deployments, or scaling events.\nThe key point? One Temporal Workflow per conversation, with automatic lifecycle management that ends conversations after N minutes/hours/days of inactivity or when users explicitly say goodbye.\nRequirements\nLets start from the beginning: what does it take to implement a proper chatbot, and how would it typically be built without Temporal?\nFunctional requirements\n\n  Users must be authenticated.\n  An AI-powered chatbot that provides information on consents, subscriptions, devices, stock availability, and general user details.\n  The chatbot must be able to scale indefinitely to support new features and conversation scenarios.\n  Multilingual support (at minimum Spanish, French, and English).\n  Conversations can last as long as the user needs, without forced timeouts.\n  When a conversation ends, the system must generate a concise summary of the interaction and make it retrievable later.\n  Each conversation should produce a satisfaction score based on its context, and conversations should be retrievable by score.\n\nNon-functional requirements\n\n  If a user loses their connection and reconnects later, the conversation should seamlessly continue.\n  Conversations must persist across server/backend restarts or updates.\n  The system should support effectively unlimited concurrent conversations.\n  All conversations must be tracked with full state transparency  allowing developers or operators to inspect not only live conversations but also the exact sequence of steps that led to the final state.\n  If any dependency (API, tool, database, or LLM) goes down and later recovers  regardless of the outage duration  the conversation must resume exactly where it left off, with full history intact. Dropping or resetting conversations is not acceptable.\n  Chatbot backend must be implemented in Java.\n\nNow that we have a clear picture of what our chatbot must do, lets take a step back and see how we would implement it without Temporal.\nDesign\nMeeting all of these functional and non-functional requirements is not trivial. Traditional chatbot architectures typically rely on in-memory sessions, which leads to several challenges:\n\n  Session loss during server restarts or deployments.\n  Limited horizontal scalability because each session is tied to a specific server.\n  Difficulty maintaining long conversations, especially if users disconnect and reconnect.\n  Complex error handling when dependencies (APIs, databases, or LLMs) go down.\n\n\n  To illustrate this, heres a high-level design of a traditional chatbot system:\n  \n  \n\nIn this setup, the conversation state is kept inside each application instance, which means several problems immediately appear:\n\n  State tied to a single app: if the application restarts or crashes, the users session is lost and the conversation context disappears.\n  Sticky sessions required: every user must always be routed back to the same instance to preserve their context. This reduces flexibility and scalability, and becomes problematic in real scenarios  for example, if a user loses their connection mid-flight and resumes from another country, they may no longer land on the same instance.\n  Difficult prompt management: all the business logic tends to be packed into a single, monolithic prompt. As use cases grow, this quickly becomes hard to maintain, and any error forces the conversation to restart from scratch.\n  Fragile error handling: if one external service call fails (e.g., fetching subscriptions), the user only sees an error and must manually start the process over. The system has no way of resuming the workflow automatically once the dependency recovers.\n\nWhile there are manual ways to work around some of these issues  storing state externally, implementing retries, etc.  they add significant complexity without fully solving the core problem. This is exactly why a workflow-orchestration approach like Temporal offers such a powerful alternative.\n\n  Now, lets take a closer look at what our state machine/conversation graph might look like when modeling the chatbot:\n  \n  \n  Based on the requirements, the chatbot needs to support the following scenarios:\n\n\n  Consents: the user can retrieve their accepted, rejected, or pending consents.\n  Subscriptions: the user can view their active subscriptions and even ask more complex questions about them  for example, whether any of their subscriptions are currently flagged for fraud investigation.\n  Product catalog: the chatbot returns the full catalog of available products (e.g., devices or mobile phones), including prices and stock levels.\n  Helper: if the user asks about something outside the supported scenarios, the chatbot should redirect them towards the available features.\n  \n    Farewell: when the user ends the conversation, the chatbot should politely close the interaction and trigger two additional closing states.\n     Satisfaction score: evaluates customer satisfaction based on the entire conversation context.\n     Summary: generates a short summary of the conversation, enabling future retrieval of conversations by score or by scanning their summaries.\n  \n\nThis graph-based approach makes the flow explicit and makes it easy to maintain and scale in terms of new functionality.\nAs readers may have noticed, this Workflow runs indefinitely during a user conversation or until a timeout signals the user has stopped interacting. The workflow is iterative, returning to an initial listening state after processing each message (Temporal Signal per message).\nThe conversation session isnt stored in the application, but in Temporal, each Workflow corresponds to a unique user and conversation. When a user sends a message, we first retrieve their active conversation (Workflow) or create a new one if none exists.\n\n  This approach enables stateless applications, eliminating the need for a load balancer with sticky sessions or app-managed sessions. Any application instance can handle any user request at any time by retrieving the conversation state from Temporal.\n  \n  \n  Basically, the application acts as a proxy between the user and the Temporal Workflows, where all the actual work takes place. Communication with the user can be handled through a protocol like SSE or WebSockets, while communication with Temporal is managed via Workflow signals.\n\nFrom a workflow design perspective, each Activity/state in the Workflow interacts with the LLM, often requiring specific company data (tools) to provide the necessary context. In practice, an Activity implements a call to the LLM (a prompt) and uses one or more tools to enrich that call with user context.\nAdditionally, the full conversation history is stored as a Workflow property and passed as input to the LLM on every call. This ensures that the LLM always has complete context to deliver accurate responses to the users requests.\nAdvantages compared to a traditional implementation\nThis approach provides several key benefits when measured against both the functional requirements and the limitations of traditional architectures:\n\n  Simplified state management: Storing sessions in Temporal eliminates in-memory session management, reducing application complexity and enabling stateless apps.\n  Infinite scalability: Applications become stateless proxies. Any instance can pick up any request at any time, removing the need for sticky sessions and enabling true horizontal scaling.\n  Resilient Workflows: If an API, tool, or the LLM itself goes down, the Workflow simply pauses and resumes automatically when the dependency recovers  no need for the user to restart the conversation. Think in app restarts, deployments, or dependency outages (e.g., APIs, LLMs).\n  Maintainable design: Each Activity maps to a clear step in the conversation (e.g., fetch subscriptions, check devices, update consent). This modularity avoids the giant monolithic prompt problem and adding new features (e.g., new conversation scenarios) is straightforward with Temporals Workflow design.\n  Rich context management: By storing and replaying the conversation history, the LLM always has full awareness, resulting in more precise, coherent, and human-like interactions.\n  Transparent state inspection: Developers and operators can inspect any conversation Workflow at any time, including its history and decisions  something nearly impossible in traditional chatbot setups.\n  Robust error handling: Temporal.io automatically retries failed activities (e.g., during API outages), ensuring seamless conversation continuity without manual intervention.\n\nIn short, by combining Temporal Workflows with LLM-driven activities, we get a chatbot architecture that is scalable, fault-tolerant, and context-aware by design, far surpassing the fragility of traditional session-based implementations.\nA note on MCPs\nIn my implementation, the tools interact directly with a REST API. However, adapting this design to consume services from an MCP server would be trivial. Instead of calling the REST API directly, each tool could be replaced by an authenticated MCP client that communicates with the MCP server providing the desired service.\nIn my case, the telco API Im consuming does not expose any MCP services, which is why I have to integrate with it directly via REST.\nImplementation walkthrough\nPerhaps one of the most interesting classes from an implementation perspective is ChatbotService.java, since this is the class responsible for processing all incoming messages from the UI.\npublic String processMessage(String userEmail, String message) { \n    LOG.info(\"[ChatbotService] - processMessage | Processing message for user: \" + userEmail); \n    IvrWorkflow workflow = getOrCreateWorkflowForUser(userEmail); \n    String requestId = generateRequestId(); \n    workflow.processMessage(message, requestId); \n    return waitForResponse(workflow, userEmail, requestId); \n}\nThe method getOrCreateWorkflowForUser essentially handles session-less management. In other words, for each incoming message, it verifies whether we already have an open conversation/workflow for that user. If it exists, it is returned; if not, a new one is created and returned.\nprivate IvrWorkflow getOrCreateWorkflowForUser(String userEmail) { \n    LOG.debug(\"[ChatbotService] - getOrCreateWorkflowForUser | Getting workflow for user: \" + \nuserEmail); \n    String workflowId = \"ivr-session-\" + userEmail.replaceAll(\"[^a-zA-Z0-9]\", \"-\"); \n\n    WorkflowOptions options = WorkflowOptions.newBuilder() \n            .setTaskQueue(IVR_TASK_QUEUE) \n            .setWorkflowId(workflowId) \n            .build(); \n\n    IvrWorkflow workflow = workflowClient.newWorkflowStub(IvrWorkflow.class, options); \n\n    try { \n        WorkflowClient.start(workflow::startSession, userEmail); \n        LOG.info(\"[ChatbotService] - getOrCreateWorkflowForUser | New workflow started \nsuccessfully for user: \" + userEmail); \n    } catch (WorkflowExecutionAlreadyStarted e) { \n        LOG.info(\"[ChatbotService] - getOrCreateWorkflowForUser | Workflow already exists for \nuser: \" + userEmail + \", connecting to existing workflow\"); \n    } catch (Exception e) { \n        String errorMessage = e.getMessage(); \n        if (errorMessage != null && (errorMessage.contains(\"ALREADY_EXISTS\") || \nerrorMessage.contains(\"already running\"))) { \n            LOG.info(\"[ChatbotService] - getOrCreateWorkflowForUser | Workflow already running \nfor user: \" + userEmail + \", connecting to existing workflow. Error type: \" + \ne.getClass().getSimpleName()); \n        } else { \n            LOG.error(\"[ChatbotService] - getOrCreateWorkflowForUser | Failed to start \nworkflow for user: \" + userEmail + \". Error type: \" + e.getClass().getSimpleName(), e); \n            throw new RuntimeException(\"Failed to create or connect to workflow for user: \" + \nuserEmail, e); \n        } \n    } \n\n    return workflow; \n} \nOnce we have an active conversation/Workflow, we proceed to process the message by invoking the processMessage method.\n@Override \npublic void processMessage(String message, String requestId) { \n    var logger = Workflow.getLogger(IvrWorkflowImpl.class); \n    logger.info(\"[IvrWorkflowImpl] - processMessage | Received message for requestId: \" + \nrequestId); \n    pendingRequests.add(new MessageRequest(message, requestId)); \n}\nThis method simply adds the message to a queue of pending requests, which will be processed asynchronously by IvrWorkflowImpl.\nThis class contains the main implementation of our Workflow. Lets highlight three methods:\n\n  runSessionLoop  defines the magic that keeps the workflow running indefinitely (it only ends if the user explicitly says goodbye or if a configured inactivity timeout is reached).\n  processPendingRequests  iterates through the queue of pending messages waiting to be processed.\n  processMessageInternal  defines the actual workflow logic, i.e., the states we will transition through.\n\nEverything else is mostly boilerplate: the implementation of tools (consuming a REST API) or the activities, which are generally straightforward. For example, the Activity that determines which scenario we are in: ScenarioDispatcher/getScenario.\n@ApplicationScoped \npublic class ScenarioDispatcherImpl implements ScenarioDispatcher { \n\n    private static final Logger LOG = Logger.getLogger(ScenarioDispatcherImpl.class); \n\n    @Inject \n    ScenarioDispatcherPrompt promt; \n\n    @Override \n    public String getScenario(String request, String conversationHistory) { \n        LOG.info(\"[ScenarioDispatcherImpl] - getScenario | Determining scenario for request\"); \n        try { \n            String scenario = promt.getScenario(request, conversationHistory); \n            LOG.info(\"[ScenarioDispatcherImpl] - getScenario | Scenario determined: \" + \nscenario); \n            return scenario; \n        } catch (ToolException e) { \n            LOG.error(\"[ScenarioDispatcherImpl] - getScenario | ToolException occurred: \" + \ne.getMessage()); \n            throw ApplicationFailure.newFailure(e.getMessage(), e.getErrorType()); \n        } catch (Exception e) { \n            LOG.error(\"[ScenarioDispatcherImpl] - getScenario | Error retrieving scenario for \nrequest, error: \" + e.getMessage()); \n            throw ApplicationFailure.newFailure(\"Error retrieving scenario for request: \" + \nrequest + \". Cause: \" + e.getMessage(), \"GetScenarioFailure\"); \n        } \n    } \n} \n\n@RegisterAiService \n@ApplicationScoped \npublic interface ScenarioDispatcherPrompt { \n    @SystemMessage(\"\"\" \n        You are a scenario classifier for the MasOrange chatbot system. \n\n        Your task is to analyze the message and return exactly one of the following scenario \nlabels: \n        CONSENTS \n        USER_DETAILS \n        PRODUCT \n        STOCK \n        SUBSCRIPTIONS \n        FAREWELL \n        UNKNOWN \n\n        Definitions of scenarios: \n        CONSENTS          : Questions about consent, agreements, permissions, or privacy \npreferences \n        USER_DETAILS      : Questions about user name, email, account details, address, or \nprofile \n        PRODUCT           : Questions about mobiles (brands like Nokia, iPhone, Samsung, \netc.), models, specs or pricing \n        STOCK             : Inquiries about product availability or units in stock \n        SUBSCRIPTIONS     : Inquiries about plans, billing, subscription status, activation, \ncancellation \n        FAREWELL          : User is saying goodbye, ending conversation, or expressing thanks \nand satisfaction (like \"adis\", \"gracias\", \"hasta luego\", \"bye\", \"that's all\", \"nothing else\") \n        UNKNOWN           : Message does not match any of the scenarios above \n\n        Rules: \n         - Respond with exactly one of the scenario labels above \n         - Do not explain your answer \n         - Do not call any tools \n         - Do not greet the user or add any extra text \n         - Use plain text only; do not use markdown or formatting syntax \n        \"\"\") \n    @UserMessage(\"\"\" \n        Conversation History: {{conversationHistory}} \n\n        Current Message: {{message}} \n        \"\"\") \n    String getScenario(String message, String conversationHistory); \n} \nThis is essentially a prompt that doesnt need any tools  it only has to infer the scenario based on the users request. If no valid scenario is found, the request will be handled by the Helper (another state/Activity).\nFor instance, lets look at how consents is implemented:\n@ApplicationScoped \npublic class ConsentsSupportImpl implements ConsentsSupport { \n\n    private static final Logger LOG = Logger.getLogger(ConsentsSupportImpl.class); \n\n    @Inject \n    ConsentsSupportPrompt promt; \n\n    @Override \n    public String retrieveConsents(boolean hasGreeted, String userId, String userName, String \nmessage, String conversationHistory) { \n        LOG.info(\"[ConsentsSupportImpl] - retrieveConsents | Processing consents request for \nuserId: \" + userId + \", userName: \" + userName + \", hasGreeted: \" + hasGreeted); \n        try { \n            String response = promt.retrieveConsents(userId, userName, hasGreeted, message, \nconversationHistory); \n            LOG.info(\"[ConsentsSupportImpl] - retrieveConsents | Successfully retrieved \nconsents response for userId: \" + userId); \n            return response; \n        } catch (ToolException e) { \n            LOG.error(\"[ConsentsSupportImpl] - retrieveConsents | ToolException occurred: \" + \ne.getMessage()); \n            throw ApplicationFailure.newFailure(e.getMessage(), e.getErrorType()); \n        } catch (Exception e) { \n            LOG.error(\"[ConsentsSupportImpl] - retrieveConsents | Error retrieving consents \nfor userId: \" + userId + \", userName: \" + userName + \", error: \" + e.getMessage()); \n            throw ApplicationFailure.newFailure(\"Error retrieving consents for userId: \" + \nuserId + \", userName: \" + userName, \"RetrieveConsentsFailure\", e); \n        } \n    } \n} \n\n@RegisterAiService(tools = {ConsentsTools.class}) \n@ApplicationScoped \npublic interface ConsentsSupportPrompt { \n\n    @SystemMessage(\"\"\" \n    You are a customer support agent for MasOrange telecommunications company. Your job is to \nhelp users with their consents, based on their requests. \n\n    You have access to the following tools: \n\n    - Use `get-accepted-consents-for-a-customer` if the user asks about consents they have \nalready accepted. \n    - Use `get-pending-consents-for-a-customer` if the user asks about consents they still \nneed to accept or are awaiting action. \n    - Use `get-rejected-consents-for-a-customer` if the user asks about consents they have \ndeclined. \n\nGuidelines: \n    - Always respond in the same language the user used, if any data is in a different \nlanguage translate the response. \n    - Always choose the most appropriate tool based on the user's question. \n    - Reply to the user by his/her User Name only if greeted is false \n    - Never ask the user to choose or confirm the tool. \n    - Do not explain the tool usage, just provide the answer. \n    - Always respond in the same language the customer used. \n    - Be polite, helpful, and clear. \n    - Never ask for credentials or passwords. \n    - Do not use markdown syntax, better plain text.  \n\nIf the question is unclear or not related to consents, politely ask the user to clarify \ntheir request. \n\"\"\")\n    @UserMessage(\"\"\" \n    Conversation History: {{conversationHistory}} \n\n    Customer ID: {{customerId}} \n    User Name: {{userName}} \n    greeted: {{greeted}} \n\n    Current Message: {{message}} \n    \"\"\") \n    String retrieveConsents(String customerId, String userName, boolean greeted, String \nmessage, String conversationHistory); \n} \nHere we can see that this Activity does use a tool (implemented in com.inorganic.tools.ConsentsTools.java). This tool exposes several services, and the prompt decides which one to invoke based on the request context.\nAll these details belong to the implementation layer, which in practice will depend partly on the library or API you are using to interact with LLMs.\nConclusions\nWell, if youve made it this far  congratulations! I hope you found this article interesting. Together, weve explored how conversational chatbots can be implemented using Temporal Workflows. This approach provides scalability, resilience, and the ability to maintain full conversational context  something traditional architectures struggle to achieve.\nThe reference implementation, built in Java (with Quarkus) and available on GitHub, demonstrates the maturity of Temporals/Quarkus Java API for production-ready chatbot systems. This approach not only meets the demanding requirements of modern customer service chatbots but also sets a new standard for building reliable, scalable conversational AI.\nYou can learn more and dive into the code on our GitHub.",featureImage:{title:"hassaan-here-Ype8P9pAjXQ-unsplash (1)",description:"hassaan-here-Ype8P9pAjXQ-unsplash (1)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/KvEfARajfbO29cCpW6LFk/41429439f78f47be8e077b611fe16f23/hassaan-here-Ype8P9pAjXQ-unsplash__1_.jpg"},publishDate:"2025-10-14",metaDescription:"Build a persistent, infinitely scalable chatbot with Temporal Workflows  stateless apps, full conversation history across restarts, and resilient retries in Java/Quarkus.",metaTitle:"Building a persistent conversational AI chatbot with Temporal",socialCard:{title:"Blog (49)",description:"Blog (49)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2103uwBf6nb17AUA7zeIhx/b8b1516d589fe85ce864d3ebfe57feec/Blog__49_.png"},tags:"AI/ML,Java,Code Samples",slug:"building-a-persistent-conversational-ai-chatbot-with-temporal",contentType:"blogPost",entityId:"WGsYBR9wqvRtaR3jPUBt9",authors:[{id:"1vwln1GV98ib8LT8WZu0XA",name:"Pablo Gonzlez Granados",slug:"Standard format: firstname-lastname",jobTitle:"Backend Software Engineer, HiveMQ",photograph:{title:"pablo-hivemq",description:"pablo-hivemq",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4MPNuc5HoAOrFyc7Q9qYIm/43e86cad1def81375fbdf2f0eb41c3ce/pablo.jpg"},linkedInUrl:"https://www.linkedin.com/in/pablogonzalezgranados/",company:"HiveMQ",contentType:"person"}],authorsString:"Pablo Gonzlez Granados",category:"Community",readingTime:15},{title:"Introducing Saved Views in Temporal Web UI",content:"Picture this: you and a couple of teammates have been developing a complex agent with your favorite Temporal SDK to answer all of lifes big questions. Its a general-purpose teaching agent you want to share with the rest of the company  not only to fill out the TPS reports, but to pick your outfit and help with Juniors homework before the big client pitch.\nYou want to check on the agent after the latest updates, so you open the Temporal Web UI. Ugh lots of Workflows running today. Time to filter. Click Filter, choose Workflow Type, type agent. Right  dont want the terminated ones; filter those out. And only the Workflows that passed the agent evaluation with high confidence. Now repeat this process every day.\nSound familiar? If youve spent any meaningful time with Temporal, youve probably rebuilt the same query dozens (or hundreds) of times. That changes this week. Saved Views let you preserve frequently used queries and save valuable time.\nLets revisit the scenario above. To start, create an Agent Evals view with two filters: WorkflowType and ExecutionStatus, so you see only agent Workflows that are Running or Completed.\n\n  \n\nAlright, this is easy! You quickly add Failed Evals and Passed Evals views, filtering on agent Workflows and the EvaluationPassed boolean.\n\n  \n\nNow you want a High Confidence Evals view to see only the agent Workflows that pass with flying colors. First, open the Passed Evals view as a starting point.\n\n  \n\nClick Edit, update the name to High Confidence Evals, and click Create New to make a new view using the attributes from Passed Evals.\n\n  \n\nGreat  now you have a custom view based on an existing one. Add a filter to see only agents with an EvaluationScore  85.\n\n  \n\nNow click Save to update the view.\n\n  \n\nWhat are Saved Views?\nSaved Views transform how you interact with your Workflow Executions in the Temporal Web UI. Instead of manually rebuilding queries every time, you can save your most important views and access them with a single click. Think of it as bookmarks for your Workflow queries.\nThe problem were solving\nLets be honest: nobody enjoys repetitive work. Before Saved Views, every time you needed to check on a specific set of Workflows, you had to:\n\n  Navigate to the Workflows page\n  Click through the Status filter\n  Set your time range (again)\n  Add Search Attributes (one by one)\n  Finally see your data\n\nThis might only take 30 seconds, but those seconds add up. More importantly, it breaks your flow when youre trying to diagnose an issue or monitor production Workflows. And if youre sharing investigation steps with a teammate? Good luck explaining which dozen filters they need to applyor jumping into every Slack channel pasting the URL whenever someone asks.\nHow it works\nSystem Views: Your new defaults\nRight out of the box, Saved Views come with a set of System Views that cover common use cases:\n\n  All Workflows  Your default unfiltered view\n  Parent Workflows  Filter out Child Workflows\n  Running  Active Workflows currently executing\n  Today  All Workflows that started today\n  Last Hour  All Workflows that started in the past 60 minutes\n\nThese System Views give you instant access to queries you run constantly with no setup required. Well continue expanding them to help you quickly find critical Workflows.\nCustom Views: Make it yours\nHeres where things get personal. When you craft a query that perfectly captures what you need to monitor  maybe its Failed October payments with high-priority customers  you can save it as a Custom View.\nCreating a Custom View is simple:\n\n  Build your query using the enhanced filter dropdowns (more on those in a second).\n  Click Save View.\n  Give it a memorable name.\n  Done.\n\nThat complex query now lives in your left sidebar, ready whenever you need it.\nThe new filter experience\nWhile building Saved Views, we also streamlined filtering. Each filter type now has its own dropdown, making it much easier to build and edit queries on the fly. Each one has a clean interface to view and edit Search Attribute values in one place.\nWhat else can you do?\nCopy and edit\nFind a view thats almost perfect? Copy it and tweak the filters to create a new variant. Its great for related views without starting from scratch.\nShare with your team\nWhen youre investigating an incident and a colleague asks, What are you looking at?, share a link to your exact view. No more Filter by Status equals Failed, then add Search Attribute CustomerId, set the operator to equals, enter Just click Share and send the link. Theyll see exactly what you see, and it automatically saves with the same name.\nExpandable navigation\nSaved Views live in a collapsible left sidebar next to the Workflows table. If you have a lot of views and want more screen space, collapse it. Need quick access to all your views? Expand it. The UI remembers your preference.\nSmart limits\nTheres a 20-view limit for custom Saved Views per Namespace. The limit prevents frustration if you ever need to clear your browsers localStorage, which is where views are stored.\nWhy this matters\nAt first glance, Saved Views might feel like a small quality-of-life improvement. But improvements like this compound.\nEvery second youre not rebuilding a query is a second you can spend solving problems. Every time you share a view instead of explaining filter configurations, you reduce cognitive load and potential errors. Every time you jump straight to the data you need, you make better decisions faster.\nThis is especially critical during incidents. When things are on fire, you need your tools to get out of the way. Saved Views do exactly that.\nTry it out\nSaved Views are available now in the latest version of the Temporal Web UI. If youre on Temporal Cloud, you already have them. If youre self-hosted, update to version 2.41.0 or later.\nStart by exploring the System Views. Then, the next time you build a query youll need again, save it. Within a week, youll wonder how you ever worked without it.",featureImage:{title:"buddha-elemental-3d-br5JFHhkoIA-unsplash (1)",description:"buddha-elemental-3d-br5JFHhkoIA-unsplash (1)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6KZNZOYRsAXONUbNuA5V7f/2f1ec7f2dd615ca6d4bb766d98271bff/buddha-elemental-3d-br5JFHhkoIA-unsplash__1_.jpg"},publishDate:"2025-10-10",metaDescription:"Saved Views in Temporal Web UI lets you save and share Workflow queries so you can jump to the right executions faster and reduce investigation time.",metaTitle:"Introducing Saved Views in Temporal Web UI",socialCard:{title:"Blog (50)",description:"Blog (50)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2TrXfeZTBZHr5Ew0v9Tn7C/f2b436bba320f9354fdaf03a53a5946c/Blog__50_.png"},tags:"Cloud",slug:"introducing-saved-views-in-temporal-web-ui",contentType:"blogPost",entityId:"61oH5PX5F9x5G8f10GuYq3",authors:[{id:"6CycG5a057YIpHYbBjKEzV",name:"Alex Tideman",slug:"alex-tideman",jobTitle:"Staff Software Engineer",photograph:{title:"Alex Tideman",description:"Alex Tideman",url:"https://images.ctfassets.net/0uuz8ydxyd9p/F1Q03VGnLE5lUXwWpRHe3/bc05ec1aa31c4dcf38c56f87e3f5bc9d/alex-tideman.jpg"},company:"Temporal",contentType:"person"}],authorsString:"Alex Tideman",category:"Product News",readingTime:6},{title:"How to protect sensitive data in a Temporal Application",content:"One of the best things about working at Temporal is seeing the look of joy on an engineers face when they discover how our software gives them unparalleled insight into their applications runtime behavior.\nIt seems like magic at first, so this joy is often preceded by disbelief.\nAre you telling me that I can look back in time and see exactly what happened when my application ran at 6:08 PM last Friday evening? Yes! Wait, youre saying that Ill be able to see when it started, the input data provided at start, the sequence of steps it followed, how long each step took, and the result it returned upon completion? Exactly!Figure 1: Screenshot of the Detail and Timeline sections of the Temporal Web UI\nThis information is clearly helpful for investigating application behavior, but its also essential to how Temporal achieves Durable Execution. Its what enables a Temporal Workflow to overcome a crash, even one caused by hardware failure, and continue running from where it left off. From the developers perspective, its as if that crash never happened.\nOur free Temporal 102 training course explains how that works. To summarize, the Worker reconstructs the pre-crash state based on details from the Event History, which tracks the input, status, and result for each significant step of the execution. The following screenshot of the Temporal Web UI shows an excerpt of the Event History for an order-processing Workflow.Figure 2: Screenshot of the Event History in the Temporal Web UI\nIn this case, the Event History contains payment card details. This is sensitive data that must be kept confidential. A variety of laws and industry regulations mandate protections for certain types of data, including financial transactions, medical records, and personally identifiable information (PII).\nThis raises a question: If the Event History contains sensitive data, how can I keep it confidential?\nHow can I keep sensitive data confidential in Temporal?\nTemporal offers a comprehensive, layered approach to data security. Understanding how best to protect your data starts with understanding how it flows through the system and the interactions among the three actors involved in every Workflow Execution:\n\n  The requester is the user or application that issues a request to run the Workflow. It may also retrieve the result upon completion, as is the case in this example.\n  The Temporal Service consists of one or more running instances of the Temporal Server software. This can be self-hosted, in which case the developer deploys, manages, and operates the service. Alternatively, it can be Temporal Cloud, the fully managed SaaS offering from Temporal that provides a secure, high-performance Temporal Service.\n  The Worker is what executes your Workflow and Activity code. Its part of your application and is external to the Temporal Service. Regardless of whether you use Temporal Cloud or a self-hosted Temporal Service, you deploy and manage Workers on the infrastructure of your choice.\n\nHow does the data flow in a Temporal Application?Figure 3: Diagram illustrating the data flow in a basic Temporal Application\n\n  The requester initiates execution by submitting a Workflow Execution request to the Temporal Service. This specifies the type of Workflow to run and the data to supply as input. In the order-processing example above, the Workflow Type is ProcessOrder and the input data specifies the customer, products, payment details, and shipping address relevant to the order.\n  Upon receiving this request, the Temporal Service adds a Workflow Task to a Task Queue that it shares with the Worker. When the Worker polls this Task Queue, it accepts the task and executes the Workflow code by invoking the ProcessOrder function with the input data specified in the task.\n  When the execution is complete, the Worker reports the result back to the Temporal Service. In the example above, the result is a string that includes the order status, confirmation number, and shipment tracking number.\n  The requester, which has been waiting for execution to complete, then retrieves the result from the Temporal Service.\n\nAt each step, the Temporal Service appends information about the progress of the Workflow Execution to the Event History, which is persisted to the data store associated with the Temporal Service. Temporal Cloud uses a custom-built data store called CDS, while a self-hosted Temporal Service typically uses MySQL, PostgreSQL, or Apache Cassandra.\nThere are two key aspects of data confidentiality in a Temporal Application: protecting data in motion as its transmitted across the network and protecting the data at rest when its persisted to this data store.\nHow can I protect data transmitted across the network?\nThe requester uses a Temporal Client, provided by the SDK, to interact with the Temporal Service. The Temporal Web UI and CLI, which are frequently used to interact with the Temporal Service, also contain a Temporal Client.\nTemporal Clients and the Temporal Service communicate using gRPC, which is unencrypted by default. This simplifies the case of running everything locally on your laptop during development, as it eliminates the need to set up digital certificates. However, this is not acceptable in a production environment, where data passing over the network between the Temporal Client and Temporal Service could be intercepted by an attacker with access to the network.\nTo mitigate this, the Temporal Service and Temporal Clients support the use of TLS, an industry-standard protocol also used to secure communication between web browsers and web servers. The use of TLS is optional for a self-hosted Temporal Service, but mandatory in Temporal Cloud.\nTLS uses a server-side certificate, which enables the client to validate the identity of the Temporal Service. It optionally supports the use of client certificates, a configuration known as mutual authentication (mTLS), which enables both parties to authenticate one another.\nTLS uses asymmetric cryptography to securely exchange a key thats used to encrypt subsequent communications during the session. Because encryption takes place below the application layer, it effectively creates a tunnel in which all data exchanged between the Temporal Client and Temporal Service is protected from eavesdropping.Figure 4: Diagram illustrating how TLS protects data moving between clients and the Temporal Service\nHowever, even if youre using TLS, any Temporal Client that can successfully issue requests within a given Namespace for the Temporal Service could potentially access input and result data for its Workflow Executions. Furthermore, since the data is decrypted upon receipt, payload data is persisted in unencrypted form to the data store. Therefore, an attacker who gains access to either the Temporal Service or its data store could potentially read sensitive information.\nHow can I further protect my data with Temporal?\nTemporal Cloud automatically protects data at rest using AES-256-GCM encryption. An operator of a self-hosted Temporal Service should also consider using database and/or filesystem encryption to protect their data.\nMany organizations also choose to encrypt data within the application itself, which offers extra protection. Temporal SDKs support transforming data before its transmitted by the Temporal Client and again when its received. This feature is often used for application-level data encryption, ensuring that sensitive information remains protected throughout its journey.\nWith this approach, data is encrypted on the client side, so the Temporal Service only ever sees data in encrypted form. The Temporal Service has no ability to decrypt this data because it neither has the key nor knowledge of the cipher used. To understand how this works, consider how Temporal serializes and deserializes the data sent across the wire during a Workflow Execution.\nConverters and Codecs\nA Temporal Data Converter is responsible for converting language-native values (such as strings, numbers, booleans, and custom objects) into the language-independent format that the Temporal Client sends across the network to the Temporal Service. It uses three components to achieve this, later employing them in reverse order to convert data from the response back into language-native values for the application.\nThe first of these three components is the Payload Converter, which serializes the data supplied as input or returned as output from the application into bytes. In other words, it serializes function parameters and return values that need to be sent over the wire and deserializes the bytes to convert this data back into their original representation. Although each Temporal SDK provides a built-in Payload Converter, developers can also create their own implementation to customize how payload data is serialized and deserialized.\nThe second component is a Failure Converter. Temporal handles serialization of payloads separately from serialization of failures, and its the Failure Converters job to convert between Temporal's language-agnostic (protobuf) representation of a Failure and the language-specific representation used by a given SDK. For example, the Failure Converter for the Java SDK can convert between a Temporal Failure and a java.lang.Exception instance. Although it is possible for a developer to create a custom Failure Converter, this is extremely rare in practice, as very few users require capabilities beyond whats available in the default implementation.\nThe third component is a Payload Codec, which transforms the series of bytes resulting from payload conversion into a different series of bytes. The name is short for encoder/decoder. Codecs are commonly used to compress or encrypt messages before transmission and to decompress or decrypt them upon receipt before they're processed. Temporal supports chaining multiple Payload Codecs, so a developer could both compress and encrypt messages before theyre sent across the wire.\nTo summarize, a Data Converter is responsible for the overall conversion from objects to bytes. Payload Converters handle this conversion of input parameters and return values, while Failure Converters handle this conversion for Failures. Codecs apply transformations, such as compression or encryption, on the serialized bytes following the conversion.\nUsing a Payload Codec to encrypt data\nAs mentioned above, developers can create their own Payload Codec implementation to perform application-level encryption. The following illustration includes a human-readable representation of the bytes emitted by both the Payload Converter and Payload Codec for the charge_payment Activity input data shown earlier.Figure 5: Illustration of the payload data at two points in the conversion process\nNotably, the Failure Converter does not pass data through the Payload Codec, so sensitive information contained within error messages remains unencrypted by default even if youre encrypting payloads. However, you can configure the Temporal Client to encrypt the Failures message and stack trace fields using the Payload Codec, as described in the Failure Converter documentation.\nNow, lets look at what the Temporal Web UI shows for a Workflow Execution that uses a Payload Codec for encryption. As you can see, both the input and output data are encrypted. Although not shown here, the same is also true for all information within the Event History, including the payment card details passed as input to the Activity that charges the customer for the purchase.Figure 6: Screenshot showing encrypted information in the Web UI\nTemporals design, which allows a Temporal Client to encrypt payload and failure data before its transmitted, ensures that the Temporal Service only ever sees encrypted data. From the perspective of the Temporal Service, this data is just a bunch of bytes. The Client is responsible for decoding those bytes, while the application that uses the Client (such as the Worker) is responsible for interpreting the underlying data.\nUsing a Payload Codec to replace data\nA Payload Codec isnt limited to performing encryption. It simply transforms one series of bytes into another. With that in mind, consider that the best way to protect confidential data is to avoid transmitting it in the first place.\nYou can use a Payload Codec to replace data with a token (such as a UUID) before transmitting it and then perform the reverse transformation on data sent in the response. This requires a system that your application can use to map the UUID to the original message and back again. Choose a highly available system (such as a clustered transactional database) that can handle peak demand without becoming a bottleneck or single point of failure.Figure 7: Diagram illustrating how a Payload Codec can perform token substitution\nAnother benefit of this approach is that it can significantly reduce overall payload size, thus avoiding the limit enforced by the Temporal Service. This is evident in the screenshot below, which shows payload data from the order-processing Workflow when using this type of codec. The data, which is Base64-encoded, is a UUID that maps to payload data inserted into the message store.Figure 8: Screenshot of the Temporal Web UI showing data transformed by a Payload Codec that replaces the payload with a UUID\nConfidentiality and observability: The role of the Codec Server\nObservability is one of Temporals most important benefits. If youve ever used Temporals Web UI or CLI, you know that having the ability to see precisely what took place during every execution is like having a superpower. Yet, as you can see from the last two screenshots, using a Payload Codec to protect the data has rendered it unreadable.\nDoes that mean Temporal forces you to choose between confidentiality and observability? Absolutely not!\nA Codec Server gives you the best of both worlds. Its a simple application that you write and run on a machine you control, and it makes your Payload Codec available over HTTP. You configure the Temporal Web UI to use it, and when you view a page containing data encoded by your Payload Codec, JavaScript in your browser passes the encoded data through your Codec Server and then displays it to you. The decoding happens entirely on the client side, so neither the Temporal Service nor the server-side components of the Temporal Web UI are involved in this communication.\nThe diagram below illustrates the data flow involved in displaying a page in the Temporal Web UI. The Temporal Service first loads the relevant information from the data store and provides it to the Web UI server, which produces the HTML and JavaScript that it serves to the client. The Web browser passes the encoded data to the Codec Server (which, like the browser, is running locally on the developers workstation). The data remains encoded for all steps (14) leading up to this point; step 5 is where its decoded and rendered within the browser using client-side JavaScript.Figure 9: Diagram illustrating how the Codec Server decodes data from the Temporal Web UI\nThe diagram above depicts a Codec Server running on the developers own workstation, a common scenario during the development stages of a project. In production, the Codec Server might be deployed to a machine on a separate network, where it can access a key management server (KMS) and allow connections only from approved hosts. Additionally, you can configure the Temporal Web UI to include a JWT access token and/or cross-origin credentials, which you can use to authenticate and authorize requests sent to your Codec Server.\nHow does the browser know where to find the Codec Server? You configure this by clicking the eyeglasses icon near the upper-right corner of the Web UI, which displays the page shown here.Figure 10: Screenshot of the Temporal Web UI Codec Server configuration page\nIf the Pass the user access token option is enabled, the Temporal Web UI will include a JWT access token in the Authorization header of each request it sends to your Codec Server. This allows you to authenticate and authorize requests, ensuring that only permitted users can decode sensitive payloads.\nIf the Include cross-origin credentials option is enabled, the Temporal Web UI will include cross-origin credentials (such as cookies) in requests sent to your Codec Server. This is necessary if your Codec Server uses browser-based authentication mechanisms or needs to verify the origin of requests.\nThe Temporal CLI also supports the use of a Codec Server. Heres the result for this Workflow Execution without using the Codec Server, which corresponds to Figure 8:\n$ temporal workflow result --workflow-id process-order-6127779311\nResults:\n  Status          COMPLETED\n  Result          \"metadata\":{\"encoding\":\"YmluYXJ5L3V1aWQtc3Vi\"},\n                  \"data\":\"SNS99VOCQGyPz4r5lqFkFA==\"}\n  ResultEncoding  binary/uuid-sub\nHeres the same command, updated to specify the Codec Server address:\n$ temporal workflow result --workflow-id process-order-6127779311 --codec-endpoint http://localhost:8081\nResults:\n  Status          COMPLETED\n  Result          \"Order paid (Confirmation #: 31415926535) and \nshipped (Tracking #: TT8675309)\"\n  ResultEncoding  json/plain\nConclusion\nIn this article, we explored the data flow in a Temporal Application and explained several ways to protect confidential information. Temporals layered approach to data security gives you the flexibility to choose a solution that best meets the needs of each application independently. Based on your specific requirements, you may wish to:\nUse TLS to protect data in motion\nTLS can be an effective way to protect data in motion. It encrypts communications between Temporal Clients and the Temporal Service, mitigating eavesdropping by an attacker who has gained access to the network. However, since the data is only encrypted between the two endpoints of the connection, TLS does not protect data beyond those endpoints. With TLS alone, an attacker who gains access to the Temporal Service or its data store could read sensitive information in unencrypted form.\nUse a Payload Codec to protect data throughout the system\nA Payload Codec lets you transform data before its transmitted and after its received. This enables developers to choose between two application-level approaches to data security:\n\n  \n    Encrypting sensitive data:\n    You can use a Payload Codec to encrypt the data on the application side using your own key and preferred cipher. This ensures that the Temporal Service only receives, and therefore only stores, encrypted data. Because the Temporal Service does not know the cipher nor has access to the encryption key, this can be an effective mitigation against an attacker who gains control of the service or its data store.\n  \n  \n    Replacing sensitive data with a token:\n    An alternative to encryption is to use a Payload Codec to replace the actual payload with a token, such as a UUID, before sending it, and then replacing the token with the original payload upon receipt. This can be an effective solution, although the developer must take care to design the system used to map tokens to payloads so that it does not negatively affect overall performance and availability.\n  \n\nUse a Codec Server to maintain observability\nWhether you use a Payload Codec for encryption or message substitution, you dont have to sacrifice observability. Writing and running a Codec Server, which can decode payloads supplied in HTTP calls, allows you to perform client-side decoding of data shown by the Temporal Web UI or CLI.\nHow to learn more about security in Temporal\nWe invite you to join the #security channel in the Temporal Community Slack workspace, where you can ask questions about whats in this article or other aspects of security in Temporal. If youre a Temporal Cloud customer with a Business, Enterprise, or Mission Critical support plan, you are also eligible for a code and design implementation review from a member of our Developer Success team.\nHere are some resources that can help you learn more about data security in Temporal.\n\n  Temporal Trust Center\n  Temporal Cloud security model\n  Temporal Cloud security white paper\n  Code samples that demonstrate how to configure the Temporal Client for mTLS\n    \n      .NET SDK\n      Go SDK\n      Java SDK\n      Python SDK\n      Ruby SDK\n      TypeScript SDK\n    \n  \n  Code samples that demonstrate how to implement a basic Payload Codec\n    \n      .NET SDK\n      Go SDK\n      Java SDK\n      Python SDK\n      Ruby SDK\n      TypeScript SDK\n    \n  \n  The Order Management System (OMS) reference application contains a more comprehensive example of using a Payload Codec and Codec Server (in the Go SDK).\n    \n      These instructions explain how to use the applications built-in support for payload encryption, which is demonstrated in this video. The portion of the video starting at 1:57 shows how to configure the CLI and Web UI to use the applications Codec Server. Watching that part is a quick way to see a Codec Server in action.\n    \n  \n  Temporal Cloud Security Overview (YouTube video by Solution Architect Peter Sullivan, which provides an overview of user, application, and data security in Temporal Cloud)\n",featureImage:{title:"social-card-image",description:"social-card-image",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1NfzbiO64uLGYOtl5hBwnw/8e88e819b8ef01edc766b2fb0f0b35fe/social-card-image.jpg"},publishDate:"2025-10-09",metaDescription:"Learn how to protect sensitive data in Temporal apps using TLS, Payload Codecs, and a Codec Server without losing Web UI or CLI observability.",metaTitle:"How to protect sensitive data in a Temporal Application",socialCard:{title:"Blog (48)",description:"Blog (48)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3XVlWswHLsIp2BSDta8S5p/989566817f590649a9c22defb67d2afa/Blog__48_.png"},tags:"Security",slug:"how-to-protect-sensitive-data-in-a-temporal-application",contentType:"blogPost",entityId:"3UcTwTWz15JvXaFHB7Bu2f",authors:[{id:"6NFooJhrzJdVAxMRWhgeTl",name:"Tom Wheeler",slug:"tom-wheeler",jobTitle:"Principal Developer Advocate",photograph:{title:"Tom Wheeler",description:"Tom Wheeler",url:"https://images.ctfassets.net/0uuz8ydxyd9p/53ysX1Y47NqQaThXEVUny4/b1d9bbb620188ffc23a6a5098a80cfa5/tomwheeler-2024-headshot-800x800.webp"},biography:"Alternating between software engineering and technical education roles, Tom Wheeler's career spans more than 25 years in the financial, healthcare, defense, and tech industries. Prior to joining Temporal as the founding member of the Education team in 2022, he wrote training courses at Cloudera, developed aerospace engineering software at Object Computing, helped create a distributed system for high-volume data processing at WebMD, and built some of the earliest web applications at brokerage firm A.G. Edwards. When Tom manages to step away from the computer, you can probably find him cooking, traveling, or playing guitar.",company:"Temporal",contentType:"person"},{id:"6SCT7ktnc7C7malyJV3UsQ",name:"Joshua Smith",slug:"joshua-smith",jobTitle:"Staff Solutions Architect",photograph:{title:"Josh Smith photo",description:"Josh Smith photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2DHNWCAITAPlTgzovWEEyW/1e105a12a16a24ca6db7f3c7ae0ef44b/1678726677795.jpeg"},contentType:"person"}],authorsString:"Tom Wheeler, Joshua Smith",category:"Temporal Concepts",readingTime:17},{title:"Temporal raises secondary funding, reaching $2.5B valuation",content:"Today were excited to share that Temporal has completed a secondary funding round, bringing our valuation to $2.5 billion. Our investor at GIC led the ample $105 million investment, with help from Tiger Global and Index Ventures.\nThis milestone comes just months after our $146 million Series C at a $1.72 billion valuation. It reflects both the progress weve made as a team and the belief our investors have in our future; one making Durable Execution the foundation of how modern software gets built.\nBuilding on strong foundations\nWhen we announced our Series C, we said it was just the beginning of Temporals next chapter. Since then, were proud to say that our growth has only accelerated through:\n\n  Expanding enterprise adoption across industries like FinTech, e-commerce, and AI\n  Scaling support and reliability features for workloads critical to production\n  Continuing to advance our open-source project that started it all\n\nDurable Execution is becoming the enterprise standard for building reliable systems and doing so at scale. This funding milestone reflects the confidence our investors, customers, and community have in that trajectory.\nPowered by community\nOf course, what interests many about announcements like this are the statistics about the capital. While these are important and they do matter, what matters even more to us are the people behind the product.\nTemporal is all about developers. Our team is full of excellent engineers, product thinkers, and go-to-market leaders who all share the belief that distributed systems can and should be simpler, safer, and more powerful for our community of developers.\nWere growing fast, and this secondary funding helps us double down on one of our biggest priorities: creating an even better team. If youre excited about shaping the future of software reliability, wed love for you to join us.\nPrepared for the age of AI\nThe rise of AI has only made Temporal more relevant. Behind every promising AI application is an orchestration challenge involving long-running processes, flimsy pipelines, complex agent coordination, and the need for systems that can recover from inevitable failures. Temporal was built for exactly these conditions.\nDevelopers building with AI are turning to Durable Execution because it guarantees that critical workflows complete. It doesnt matter how unpredictable the path. Whether its coordinating multiple models, integrating AI into customer-facing applications, or scaling experiments into production, Temporal provides the backbone that AI innovation needs to succeed.\nStrengthening our leadership\nInvestments drive growth and allow us to further invest in our team so we can continue moving our mission forward. With that said, were thrilled to welcome John Bonney as Temporals Chief Financial Officer and Jonathan Chadwick to our Board of Directors.\nJohn Bonney brings extensive experience guiding high-growth SaaS and cloud companies through scale and capital expansion. He most recently served as Chief Financial Officer of Harness, and previously held senior finance leadership roles at companies such as FinancialForce and SAP.\nJonathan Chadwick has decades of experience scaling category-defining software companies, including prior roles as Chief Financial Officer, Chief Operating Officer, and Executive Vice President of VMware, Inc. He currently serves on the boards of Confluent, Databricks, Notion, ServiceNow, Zoom, and more.\nLooking ahead\nThis secondary round is a milestone, but its not where we want to end our growth. In fact, we want to use this opportunity as a the foundation for whats next:\n\n  Expanding Temporal Cloud for enterprise scale and security\n  Continuing to grow our global community of developers\n  Investing in the next generation of features that will make Durable Execution accessible to every team out there\n  Hiring and developing first-rate talent to build the best product for developers\n\nOur vision is as ambitious as ever: to make reliability the default. This funding round only gives us more runway, more confidence, and better determination to make this vision a reality.\nWere just getting started.",featureImage:{title:"secondary-funding-blog-featured",description:"secondary-funding-blog-featured",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7z6hS7EfgH4LoaOEqGCmQs/69d166970a530ee58b8f7a0b14f18b93/secondary-funding-blog-featured.png"},publishDate:"2025-10-01",metaDescription:"Temporal completes secondary funding, reaching a $2.5B valuation led by GIC with Tiger Global and Index Ventures, accelerating Durable Execution and hiring.",metaTitle:"Temporal raises secondary funding, reaching $2.5B valuation",socialCard:{title:"secondary-funding-social",description:"secondary-funding-social",url:"https://images.ctfassets.net/0uuz8ydxyd9p/488bmfmqtanl48WYVZELfT/2cd5977becec772d821e91de0af2d29d/secondary-funding-social.png"},tags:"Durable Execution,Industry Events",slug:"temporal-raises-secondary-funding",contentType:"blogPost",entityId:"4FsWtWw0U1RUmSwQZFbgjU",authors:[{id:"4VItFICZ65R9CRGZQLE9un",name:"Allanah Hughes",slug:"allanah-hughes",jobTitle:"Communications Manager",photograph:{title:"Allanah-photo",description:"Allanah-photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4fukLvMAknnWvSkX9j9s4C/16176d8f1f1ffaeeb578a68e19ff05e7/240206-Temporal-DTLA-017-Allanah-Hughes-50NS.jpg"},contentType:"person"}],authorsString:"Allanah Hughes",category:"Announcements",relatedPosts:[{title:"Temporal raises $146M Series C to power the future of durable applications",content:"Since day one, weve believed that the best way to build Temporal was to start with an incredible product, make it freely available to developers, and let adoption drive us forward. Today's results validate our belief: the Temporal community is flourishing, adoption is accelerating, and we've hit a turning point.\n\nTemporals open-source and cloud ecosystem have never been stronger. More than 183,000 weekly active open-source developers adopted Temporal, and deployed it in over 7 million unique Temporal [clusters](https://docs.temporal.io/clusters), marking 600% growth in developer adoption during the last 18 months. [Temporal Cloud](https://temporal.io/cloud), our companys hosted commercial offering, has been adopted by over 2,500 customers globally, with revenue growing 4.4x in the past 18 months. \n\nWere thrilled to [announce](https://techcrunch.com/2025/03/31/temporal-lands-146-million-at-a-flat-valuation-eyes-agentic-ai-expansion/) a $146M Series C funding round at a $1.72B post-money valuation, led by Tiger Global, and joined by existing and new investors. This investment reflects a strong conviction in Temporals [vision](https://temporal.io/how-it-works), our technology, and the future of [Durable Execution](https://www.youtube.com/watch?v=ROJq6_GFbME&list=PLl9kRkvFJrlQ4Hw1U1aGxc2wH7oQ3tisp&index=2).\n\n## Building Whats Next, Together\nThe [AI](https://temporal.io/solutions/ai) revolution is here, and with it comes the need for a new backend: one that is durable, reliable, and built for the demands of intelligent, high-scale applications. Temporal is at the heart of this shift. Our combination of open-source flexibility, polyglot support, and cloud scalability makes us the natural choice for developers looking to build AI-native systems that just work.\n\nIts less about the technology and more about the people. The developers who rely on Temporal every day, the open-source contributors who push the boundaries of whats possible, and the engineers building the next generation of resilient applications. This funding isnt about growth for growths sake; its an investment in the community that made Temporal what it is today.\n## A Community-Led Future\nTemporal has always been driven by its [community](https://temporal.io/community). From our first open-source release to todays global adoption, developers have shaped the way we build, ship, and develop the platform. We believe that when developers have the right tools; they build the future. Our job is to support them, amplify their impact, and remove the roadblocks standing in their way.\n\nWith this Series C, were doubling down on that mission. More learning resources, better SDKs, deeper integrations; everything we do is in service of making sure developers can build without limits.\n\nWere just getting started. Thank you to every developer and contributor who has been part of this journey. The future of Durable Execution is bright, and were excited to build it together.\n",featureImage:{title:"series c announcement",description:"series c announcement",url:"https://images.ctfassets.net/0uuz8ydxyd9p/MVBoG5892YKspGNeJMKCC/297e7798137da896fa52756c23468388/series_c_announcement.png"},publishDate:"2025-03-31",metaDescription:"Temporal announces a $146M Series C funding round led by Tiger Global, reaching a $1.72B valuation. Learn how our thriving open-source community, rapid growth, and AI-focused vision are shaping the future of Durable Execution.",metaTitle:"Temporal raises $146M Series C to power the future of durable applications",socialCard:{title:"series c announcement",description:"series c announcement",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1U8DyM2Yb7TMe0M93cEm0l/89a9c5f2199ab9380166a150b3399635/series_c_announcement.png"},tags:"Industry Events",slug:"temporal-series-c-announcement",contentType:"blogPost",entityId:"2tOml4Y0gYqM1rtknE5CH1",authors:[{id:"4VItFICZ65R9CRGZQLE9un",name:"Allanah Hughes",slug:"allanah-hughes",jobTitle:"Communications Manager",photograph:{title:"Allanah-photo",description:"Allanah-photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4fukLvMAknnWvSkX9j9s4C/16176d8f1f1ffaeeb578a68e19ff05e7/240206-Temporal-DTLA-017-Allanah-Hughes-50NS.jpg"},contentType:"person"}],authorsString:"Allanah Hughes",category:"Announcements",readingTime:3}],readingTime:4},{title:"Durable Digest: September 2025",content:"This blog post is a public copy of our monthly newsletter. If youd like to receive upcoming updates by email, you can subscribe to our newsletter here.\nSeptember is here, and that means Replay 26 is on the horizon! The CFP is live and we want to hear your stories. In this issue, youll also find out how customers are using our product to build durable AI agents, fresh courses like our new one on Worker Versioning to help you learn Temporal, questions from the field (plus the answers from our experts), and more.\nFor more information on these updates and other things weve been working on, just keep reading! And as always, wed love to hear from you. Feel free to share feedback in our Community Slack, or on X (@temporalio).\nQuestions from the field\n\n  Rostero asked about getting Workflow state into a database, the suggestion was to use update instead of signal to Workflows so that the caller can receive any updated state. You can find more details on what update is and when to use it in our Workflow Message Passing docs.\n  Antoine asked about notifying an external system when an Activity completes, answered here. Maxim explained that interceptors that use Activities to send state to external systems during a Workflows execution is a good solution.\n\nRecently shipped\n\n  Pydantic AI + Temporal for Durable Agents is here! The popular Python agent framework now supports Temporal, letting you build durable, long-running, and human-in-the-loop agents.\n  Task Queue Fairness is in pre-release. Get more control over the order that tasks are dispatched from the backlog. This is a great solution; especially for multi-tenant applications!\n  Temporals Kubernetes Worker Controller is in public preview. Easily deploy Temporal workers on Kubernetes and take advantage of worker versioning.\n  Namespace tags are now generally available! Attach tags to namespaces in Temporal Cloud to help operators organize, track, and manage namespaces more easily.\n  The Temporal Cloud control plane is now accessible via AWS PrivateLink. You can now use Terraform, tcld, the web UI, and the Cloud Ops API from networks that aren't allowed to access the public internet, all without compromising security or functionality.\n\nBuilder spotlight\nWere sharing two stories this month about teams building AI agents on Temporal. In both cases, teams needed a platform that could ensure the durability and reliability of their agents.\nRetool is building their Agents on TemporalOut the gate, with Temporal, were able to handle a robust agents platform. Watch a discussion with Lizzie Alvarado Ford, Product Manager at Retool, and learn about why the team built their new Agents product on Temporal, and how they were able to launch in record time with a small team.\nOpenPhone built a real-time voice agent with TemporalTris Lahey, Senior Principal Software Engineer at OpenPhone, wrote about building an ambitious voice agent that can understand and respond to callers in natural language. They needed a system that could maintain conversation state, handle long-running sessions, and provide enough observability into every step of the process. Temporal provides all of this out of the box, enabling the team to achieve their vision.\nHow to Temporal\n\n  Try our new Worker Versioning Course if youre interested to see how our new versioning system works. Note that Worker Versioning is currently in public preview.\n  Kevin Martin guides us through Orchestrating ambient agents with Temporal.\n  Explore our newest SDK Temporal 101 with Ruby.\n\nJoin us live\nOur biggest event of the year returns May 5-7 in San Francisco: Replay 26. The first speakers are live, and the Call for Speakers is open. Share your production story with migrations that moved the needle, AI agents that deliver, and platform wins that unlocked your teams velocity.\nIn the meantime, connect with our team at upcoming events to see live demos from the crew. Wed love to show you how were helping organizations build resilient, scalable applications.\n\n  October 7: SF Tech Week, San Francisco, CA: Join us for a special panel discussion featuring our Sr. Director, Infrastructure & Security, Ryan Cox: From Prototype to Powerhouse: Scaling Startups in the AI Era as part of San Francisco Tech Week.\n  October 7: Ruby SDK Webinar: Weve got a new gem in the toolkit: the Ruby SDK. Save your spot in our next webinar for an introduction to using Temporal with Ruby.\n  October 15-16: LeadDev, New York City, NY: Meet us at our booth to learn how Temporal helps engineering leaders scale teams, streamline complex systems, and drive reliability across critical applications.\n  October 21-22: Open Source in Finance Forum, New York City, NY: Stop by our booth to see how Temporal empowers financial institutions to build durable, compliant workflows, simplify modernization, and reduce operational risk with open source innovation.\n  November 18: Launch and Learn, San Francisco, CA: A full-day, hands-on workshop designed for developers, architects, and technical leaders who want to move beyond prototyping and learn how to build durable, production-ready GenAI applications. Join us as we dive deep into AI development with Temporal - this event is not just about learning, it's about building next-level AI agents!\n",featureImage:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},publishDate:"2025-09-30",metaDescription:"Explore Temporals latest developer updates: questions from the field, new releases, builder spotlights, learning resources, and ways to connect with our team.",metaTitle:"Durable Digest: September 2025",socialCard:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},tags:"",slug:"durable-digest-september-2025",contentType:"blogPost",entityId:"5XVyPMuSkk8tLyi0P9Ftwa",authors:[{id:"17hGmNrCwtXdBh7fhsLUnZ",name:"Temporal Technologies",slug:"temporal-technologies",photograph:{title:"temporal technologies logo",description:"temporal technologies logo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3g56zRXtFQYMeJxBBkVBIZ/7771670e5fc7da59f555837b086c35d6/temporal_technologies_logo.avif"},company:"Temporal Technologies",contentType:"person"}],authorsString:"Temporal Technologies",category:"Announcements",readingTime:5},{title:"10 reasons your CISO will love Temporal Cloud",content:"Security risk is expensive and teams feel it in production.\nIn our State of Development 2025 report, nearly half of respondents say outages lead to customer churn (49%) and higher operational costs (49%). Decision makers rank security as the top challenge in their current systems (36%) and list it as the leading concern when adopting new tools (47%). Reliability and security compliance are also the top priority for the next 1224 months (36%).\nWe designed Temporal for this reality: it orchestrates mission-critical workflows without seeing your plaintext data, without calling into your network, and with controls your security team can verify. The result is simple: higher assurance for the CISO, less friction for the builders. Here are ten reasons that balance holds up in practice.\n1. You keep the keys\n\n  Sensitive payloads are encrypted in your environment with your keys before they ever leave it. Temporal orchestrates opaque, encrypted blobs. The service cant read your data.\n  \n  \n\n2. No inbound connectivity, ever\nTemporal Cloud never calls into your network, and it doesnt run your code. Workers poll Temporal over outbound HTTPS, so you dont open firewall ports or expose internal services.\n3. Mutual TLS anchored to your CA\nEach Namespace has a unique endpoint secured with mutual TLS. Client certificates come from your Certificate Authority, so you control issuance and revocation. Without a valid cert, a connection cant be established.\n4. Enterprise auth that matches real roles\nUse SAML SSO for centralized user lifecycle control, API keys cover CI/CD and serverless. Role-based access control (RBAC) at account and Namespace scopes aligns permissions with real responsibilities.\n5. Private connectivity options\nKeep Workflow traffic off the public internet with AWS PrivateLink or Google Cloud Private Service Connect. Connectivity flows out from workers to Temporal, not the other way around.\n6. Secure debugging without exposing data\nA Codec Server that you host enables developers to decrypt payloads locally in the browser when viewing executions. Developers keep visibility; plaintext stays out of Temporal.\n7. Compliance-ready by design\nSOC 2 Type II controls, HIPAA support with BAA, and GDPR alignment are available  visit our Trust Center for details. Because your code and credentials remain in your environment, many control objectives are simpler to meet.\n8. Operational defense in depth\nProduction access is SSO-gated with MFA, granted just-in-time, time-boxed, fully logged, and regularly audited. No shared accounts. Independent penetration testing is performed on a regular cadence and for major features.\n9. Security that speeds teams up\n\n  The same mTLS and encryption models work in development and production. Workflows get durable retries, audit trails, and deterministic history out of the box. Shipping faster no longer means expanding your attack surface.\n  \n  \n\n10. Proven outcomes at scale\nEnterprises in regulated industries rely on Temporal to run sensitive Workflows while keeping personal and confidential data under their control. The model scales without trading off security for speed.\nIf you tried to build this from scratch\nYou would need to set up and maintain:\n\n  Deep expertise in distributed systems, cryptography, and secure operations\n  Processes for key management, certificate rotation, incident response\n  Highly available infrastructure with disaster recovery and scale characteristics\n  All of the above while still shipping your actual business applications\n\nTemporal Cloud already brings:\n\n  Independently audited SOC 2 Type II controls\n  HIPAA support with signed BAA\n  GDPR-aligned processing with DPA\n  Deterministic, auditable Workflow history and robust failure handling\n\nBringing it together\nThe shortest path to lower risk is to reduce what any outside service can see or do. Temporal Cloud keeps your code and plaintext data in your environment, authenticates every call with mTLS, supports private connectivity, and gives developers secure visibility when they need it. CISOs get provable controls and a smaller blast radius. Builders get a smoother path to shipping reliable systems.",featureImage:{title:"yue-ma-KtEx7LYscXM-unsplash",description:"yue-ma-KtEx7LYscXM-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/66R2v0sappsE9EIPfGDbH5/8afe080b10586bbcecfdd9661de115bf/yue-ma-KtEx7LYscXM-unsplash.avif"},publishDate:"2025-09-30",metaDescription:"Discover 10 reasons CISOs choose Temporal Cloud: no plaintext data, no inbound connectivity, mTLS with your CA, private links, SOC 2/HIPAA, secure debugging.",metaTitle:"10 reasons your CISO will love Temporal Cloud",socialCard:{title:"Blog (45)",description:"Blog (45)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6jzyQHBW9eWbNCqlQRneuf/afcccadece23367acce70ada5e4e6031/Blog__45_.png"},tags:"Security,Self-Hosted,Cloud,CI/CD",slug:"10-reasons-your-ciso-will-love-temporal-cloud",contentType:"blogPost",entityId:"OxSp2Zy9PQaS0obEMgJyv",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"Temporal Concepts",promoCard:{title:"Cloud security white paper",eyebrow:"Provable security by design",heading:"Want a deeper dive? ",content:"Read the Temporal Cloud Security white paper.",callsToAction:[{text:"Get your copy now",href:"/pages/cloud-security-white-paper",variant:"primary",leadingIcon:null,trailingIcon:"arrow-right",entityId:"1t9oN2yUx3w5R7DDJB5yJR",large:false,theme:"pink"}],entityId:"6LnoyRA7irYEjuqqFOCQDf",contentType:"noise"},readingTime:4},{title:"From prototype to production-ready agentic AI solution: A use case from Grid Dynamics",content:"What happens when a promising AI agent prototype hits the real world? We found out the hard way.\nBuilding a production-ready AI agent is a significant challenge. At Grid Dynamics, we've developed dozens of agentic solutions, and through that work, we've gained a deep understanding of what it takes to build a durable, scalable system. This case study shares our journey of building a deep research agent using LangGraph, the unexpected challenges we encountered, and why we ultimately migrated to Temporal.\nWhy is a deep research agent required?\nOur client, a Fortune 500 manufacturer, runs 100+ plants worldwide and thousands of processes, but its incredibly vast and sophisticated knowledge base is disjointed, unactionable, and has no clear way to browse data.\nOur goal was to build a deepresearch agent that searches across internal databases, shared drives, and local repositories. When the agent cant find a relevant answer from internal data, it expands the search online and cites sources. It clearly labels whats sourced internally vs. from the open web. Teams now surface the right information in seconds or minutes, sharply reducing time to insight.\nLangGraph solution\nWhile our deep research agent quickly evolved from a LangGraph prototype to a production solution, running it in the real world exposed significant challenges that forced us to re-evaluate our architecture.\nWe found that the LangGraph-based solution, which initially seemed stable and easy to scale, had hidden costs related to development and support. The key issues we faced included:\n\n  Implementing and supporting robust error handling and retry mechanisms.\n  Managing internal state, keeping it up-to-date, and debugging issues related to caching.\n  The high resource cost of scaling the solution.\n  The expense of supporting custom workflows.\n\nThe need for 'human-in-the-loop' interactions  where a workflow waits for input  forced us to build a custom error-handling and retry mechanism. While this might seem straightforward, we quickly learned that it required maintaining the workflows state manually. This custom implementation often left the workflow in an inconsistent state, making debugging and recovery difficult. This was a significant drain on our development team's resources, shifting their focus from delivering new business value to simply maintaining the existing system.\n\n  LangGraph's reliance on Redis for state management created a new set of problems. We had to carefully manage the lifecycle and expiration of state, ensuring common requests weren't accidentally wiped out by newer cache updates. This was not only complex to implement but also costly to support and debug. For instance, an engineer trying to reproduce a bug related to expired state could spend a significant amount of time on a single issue, significantly increasing the overall cost of development and maintenance.\n  \n  \n  As the solution scaled in production, we needed to guarantee that every user request was processed exactly once, with no duplicated agents racing for the same task. To achieve this, our initial implementation used Apache Kafka, where user requests landed and were consumed by a pool of executors.\n\nWhile this architecture seemed promising, it introduced a new set of 'exactly once' challenges. Our team faced an endless stream of issues, including race conditions, stale state, and agents getting stuck without clear reporting. The solution became extremely costly to support, with no clear path to reducing that burden. It was at this point that we began our search for a new solution  one that could handle workflow management, durability, and flexible retries out of the box since other message brokers add similar implementation concerns.\nTemporal as a solution\nOur initial architecture, which combined LangGraph with Redis for persistence, was powerful in concept but incredibly brittle in practice. We found ourselves constantly fighting the limitations of our tooling instead of focusing on core business logic. Our migration, therefore, had two clear goals: move away from Redis-based state management and eliminate the need for custom-built workflow orchestration and retry logic.\nState management transformation\nWith Temporal, we experienced a fundamental paradigm shift. Instead of treating state as a separate, fragile object that needed to be carefully managed  like a baton being passed between runners  Temporal allowed us to make state an integral part of the workflow itself. In our new architecture, we defined a Python class that represents our workflows state and made it a core variable within the workflow function, eliminating the baton entirely.\nThis change had a transformative effect. While our LangGraph agent had to manually fetch its state from a Redis key at the beginning of each step, our Temporal Workflow now seamlessly passes the state directly into each activity as an argument. As an Activity completes its work  whether fetching sources, analyzing content, or generating insights  it returns the updated state, which Temporal automatically and durably persists in its event history.\nHere is a simplified example using Temporal Workflow:\n# ============================================================================\n# TEMPORAL APPROACH: State as Integral Part of Workflow\n# ============================================================================\n\n@dataclass\nclass ResearchWorkflowState:\n    #State as a Python class - core variable within workflow\n    query: str\n    sources_found: list\n    analysis_results: str\n\n@activity.defn\nasync def fetch_sources_activity(current_state: ResearchWorkflowState) -> ResearchWorkflowState:\n    # State passed directly as argument - no external fetching\n    sources = [\"source1\", \"source2\"]\n\n    # Return updated state (automatically persisted by Temporal)\n    return ResearchWorkflowState(\n        query=current_state.query,\n        sources_found=sources,\n        analysis_results=current_state.analysis_results\n    )\n\n@activity.defn  \nasync def analyze_content_activity(current_state: ResearchWorkflowState) -> ResearchWorkflowState:\n    # State received directly - no Redis lookup needed\n    analysis = f\"Analysis of {len(current_state.sources_found)} sources\"\n\n    # Return updated state\n    return ResearchWorkflowState(\n        query=current_state.query,\n        sources_found=current_state.sources_found,\n        analysis_results=analysis\n    )\n\n@workflow.defn\nclass ResearchWorkflow:\n    @workflow.run\n    async def run(self, initial_query: str) -> ResearchWorkflowState:\n        # State as a core variable within the workflow\n        workflow_state = ResearchWorkflowState(\n            query=initial_query,\n            sources_found=[],\n            analysis_results=\"\"\n        )\n\n        # Pass state to activity, get updated state back\n        workflow_state = await workflow.execute_activity(\n            fetch_sources_activity,\n            workflow_state  # State passed as argument\n        )\n\n        # Pass updated state to next activity\n        workflow_state = await workflow.execute_activity(\n            analyze_content_activity, \n            workflow_state  # Updated state passed as argument\n        )\n\n        return workflow_state\n\n\n  The high-level architecture of the Temporal-based solution is illustrated below:\n  \n  \n  Temporal's implementation helped us overcome the most critical challenges of our Kafka-based architecture, including our custom retry logic, stale state issues, and the inability to gracefully resume execution after a long pause.\n\nBy adopting Temporal, our solution became leaner and more efficient, allowing our team to focus on core business logic rather than on complex, low-level system operations like state management.\nWith that in mind, let's take a closer look at the key changes we made when moving away from LangGraph.\nSimplified error handling and retry logic\nOne of the most satisfying aspects of the migration was the opportunity to delete thousands of lines of custom retry and error handling code. In our LangGraph implementation, every external service call was wrapped in painstaking, hand-crafted try-catch blocks and retry loops designed to handle different types of failures.\nTemporals approach to resilience is fundamentally different. Instead of embedding complex retry logic throughout our business code, we simply attach RetryPolicy configurations to our Activity executions within the Workflow.\nThis declarative approach allowed us to specify backoff intervals, maximum retry attempts, and which types of errors should be retryable  all without cluttering our core research logic. This means our code is now focused solely on what the agent should do, not how to handle every possible failure.\nExample:\n# Temporal implementation with declarative retry policies\n\n@dataclass\nclass ResearchState:\n    sources: List[str]\n    analysis: str\n    error_count: int = 0\n\n# Clean activities without embedded retry logic\n@activity.defn\nasync def fetch_sources() -> List[str]:\n    \"\"\"Clean business logic - no retry code needed\"\"\"\n    ...\n\n@activity.defn\nasync def analyze_content(sources: List[str]) -> str:\n    \"\"\"Clean business logic - no retry code needed\"\"\"\n    ...\n\n@activity.defn\nasync def fallback_analysis(sources: List[str]) -> str:\n    \"\"\"Fallback activity for when main analysis fails\"\"\"\n    ...\n\n# Advanced retry policies for different scenarios\nclass RetryPolicies:\n    \"\"\"Centralized retry policy configurations\"\"\"\n   fetch_sources = RetryPolicy(\n        initial_interval=timedelta(seconds=1),\n        backoff_coefficient=2.0,  # Exponential backoff\n        maximum_interval=timedelta(seconds=60),\n        maximum_attempts=4,\n        non_retryable_error_types=[\"builtins.ValueError\"] # Only retry on specific exceptions\n    )\n\n    analyze_content = RetryPolicy(\n        initial_interval=timedelta(seconds=5),\n        backoff_coefficient=1.0,  # Linear backoff\n        maximum_interval=timedelta(seconds=15),\n        maximum_attempts=3,\n        # Custom retryable error types\n        non_retryable_error_types=[\"builtins.ValueError\", \"builtins.TypeError\"]\n    )\n\n# Workflow with declarative retry policies\n@workflow.defn\nclass ResearchWorkflow:\n\n    @workflow.run\n    async def run(self) -> ResearchState:\n        state = ResearchState(sources=[], analysis=\"\")\n\n        # Fetch sources with declarative retry policy\n        try:\n            state.sources = await workflow.execute_activity(\n                fetch_sources,\n                # Declarative retry configuration - no code in business logic!\n                retry_policy=RetryPolicies.fetch_sources,\n                start_to_close_timeout=timedelta(minutes=5)\n            )\n        except Exception:\n            # Fallback if all retries exhausted\n            state.sources = []\n            state.error_count += 1\n\n        # Analyze content with different retry policy\n        try:\n            state.analysis = await workflow.execute_activity(\n                analyze_content,\n                state.sources,\n                # Different retry policy for analysis\n                retry_policy=RetryPolicies.analyze_content,\n                start_to_close_timeout=timedelta(minutes=10)\n            )\n        except Exception:\n            # Fallback analysis with no retries\n            state.analysis = await workflow.execute_activity(\n                fallback_analysis,\n                state.sources,\n                start_to_close_timeout=timedelta(minutes=2)\n                # No retry policy = single attempt\n            )\n            state.error_count += 1\n\n        return state\nEffortless scaling\nOur original scaling approach with Apache Kafka was a significant engineering undertaking. It required a custom solution where workers would scale based on queue length  a massive, non-reusable investment that we would have had to replicate for every new application.\nTemporals approach to scalability is elegantly simple and requires minimal configuration. We just configured our Kubernetes deployment to run multiple replicas of our Temporal Worker. These Workers are identical and completely stateless; they simply poll the same task queue on the Temporal server, which automatically handles all load balancing and task distribution.\nThis fundamental change transformed scaling from a complex engineering project into a simple operational task. If we experience a surge of research requests, we no longer need to panic or initiate emergency engineering projects. Instead, we simply adjust the replica count of our Worker deployment in Kubernetes, and the system scales automatically to meet the demand.\nThe operational benefits extend beyond just handling traffic spikes. This architecture provided true horizontal scalability that was built once at the platform level. Now, all of our current and future services can leverage this capability without any additional engineering investment.\nArchitectural decoupling\nThe most architecturally significant change in our migration was deconstructing our monolithic LangGraph agent. In our original system, each \"node\" in the research graph was a Python function that operated on a shared, in-memory state object. These nodes were tightly coupled and often relied on common context, like a single, pre-initialized language model client or shared configuration objects.\nTo migrate to Temporal, we had to convert each of these tightly coupled nodes into self-contained Temporal Activities. This transformation required us to explicitly define all the data a node needed as serializable arguments for the activity function. Any shared clients or resources could no longer be assumed to exist; their initialization had to be moved inside the activity itself to ensure it could run independently on any worker.\nIn this transformation, we had to ensure that all inputs and outputs for our Activities were serializable. Our LangGraph state object had evolved to contain complex, in-memory Python objects that couldnt be sent over the network, making this a non-trivial challenge.\nThe transition also required us to completely rethink how we managed dependencies like API clients and configuration objects. In the LangGraph system, we could maintain a single, shared client instance for the entire research process. In Temporal, because Activities must be self-contained, our initial, naive approach was to re-initialize clients at the start of every activity, which proved to be both inefficient and slow.\nWe solved this by implementing intelligent client management within Activities, using techniques like client pooling and lazy initialization. This required us to move from a shared context model to one where each activity was responsible for its own setup, but it resulted in much more predictable and testable code.\nConclusion\nOur journey from a LangGraph prototype to a powerful, production-ready Temporal solution has been a masterclass in building scalable agentic systems.\nWe learned that almost all AI applications and agents require key capabilities: intelligent state management, the ability to retry failed steps without restarting the entire pipeline, and an architecture that scales easily and supports new features.\nWhile many agentic frameworks are excellent for prototyping, turning them into stable, production-ready applications requires significant effort. We've used this article to describe the common pitfalls we faced with our LangGraph implementation and the reasons why Temporal provided a superior path forward.\nSo, where do you start? Before you write a single line of code, our strong recommendation is to begin by defining the production requirements for your application. Ask yourself critical questions about scalability, inter-agent communication, agent orchestration, and how to integrate guardrails into the workflow. Having solid answers to these questions upfront will help you avoid a costly re-architecture down the line.",featureImage:{title:"Amazon Bedrock with Temporal: Rock Solid",description:"Amazon Bedrock with Temporal: Rock Solid",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6vkAcFvdvpPI8GBeiNonrO/48c2d48998507594a0591ae6759f1e0e/bed_rock.jpeg"},publishDate:"2025-09-29",metaDescription:"What happens when a promising AI agent prototype hits the high stakes of a prod environment? Grid Dynamics found out the hard way.",metaTitle:"From prototype to production-ready agentic AI solution: A use case from Grid Dynamics",tags:"AI/ML,Python",slug:"prototype-to-prod-ready-agentic-ai-grid-dynamics",contentType:"blogPost",entityId:"59m6QxzDGrKjuyHneoRUHq",authors:[{id:"75bANqVYSrcM0cXj44SUgH",name:"Dmitry Mezhensky",slug:"dmitry-mezhensky",jobTitle:"Director of Big Data and ML Engineering, Grid Dynamics",photograph:{title:"Dmitry Mezhensky",description:"Dmitry Mezhensky",url:"https://images.ctfassets.net/0uuz8ydxyd9p/51f5UFCPFekNguwEDpXBGm/98896f9f1288172f75a7a445bab4c3d7/Dmitry_Mezhensky.jpeg"},company:"Grid Dynamics",contentType:"person"},{id:"rYJXrv1SmxE68JWAg8qsO",name:"Dmitry Larko",slug:"dmitry-larko",jobTitle:"Principal AI Architect, Grid Dynamics",photograph:{title:"Dmitry Larko",description:"Dmitry Larko",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4hjObiSK6sTVPIbEdPdpvI/d948492df5be7a372a8cb0b924209992/Dmitry_Larko.jpeg"},company:"Grid Dynamics",contentType:"person"},{id:"5uaFmb9NGKM6trlAic1Jl",name:"Eugene Steinberg",slug:"eugene-steinberg",jobTitle:"CTO, Grid Dynamics",photograph:{title:"Eugene Steinberg",description:"Eugene Steinberg",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3YPVCRtnmEnuBfkQq84eg9/504cea93e595a1e2d865f9f2a7acfa44/Eugene_Steinberg_.jpeg"},company:"Grid Dynamics",contentType:"person"}],authorsString:"Dmitry Mezhensky, Dmitry Larko, Eugene Steinberg",category:"Community",relatedPosts:[{title:"Durable Execution meets AI: Why Temporal is the perfect foundation for AI agent and generative AI applications",content:"## Simple question: Is Temporal an AI product/technology?\nMore nuanced answer: Yes! What we built is perfectly suited for AI applications, even if it was originally built for other use cases.\n\nTemporal is built to bring resilience  or as we like to call it, __Durable Execution__  to distributed systems. For example, it makes all of these things more resilient:\n\n- Your website, powered by dozens or hundreds of microservices.\n- Your order processing application that communicates with everything from payment processors to shipping and inventory management systems.\n- The system you use to reliably generate credit card statements for your millions of card members.\n\nThese, and many others, are the use cases that Temporal was originally built for, well before generative AI burst onto the scene in 2022. And now that the industry is to the point where AI agents are moving from the experimentation phase into production, it turns out Temporal is the perfect technology to implement your LLM-powered AI applications and agents.\n\nI've already [spoken about](https://youtu.be/3Ox9Wqjn1Hk) the fact that AI applications and agents are distributed systems. I even suggest they are __distributed systems on steroids__ because your app may end up making an order of magnitude more remote requests to fulfill a user experience. Just like the cloud-native applications of the last couple of decades, AI apps need to operate more reliably even though transient failures in the underlying infrastructure are common. I also captured my [mental model for agents](https://temporal.io/blog/a-mental-model-for-agentic-ai-applications), which helped set a foundation for what I do in this piece.\n\nBut its time for more detail. How exactly does Temporal satisfy the needs of this class of applications? As it happens, Temporal has an answer for every one of the key elements of an AI application or agent.\n## The key elements of a generative AIpowered application\nAt the most basic level, Gen-AI powered applications are those that leverage an LLM to fulfill part of their functionality. The LLM alone does not make up the app. Even ChatGPT (which is an app, not an LLM), while simple, is an app that invokes an LLM, displays its response to the user, accepts input from that user, adds that input to the running history of the chat, and then invokes the LLM again.\n\nOf course, applications come in many shapes and sizes (its not even the case that every UX for a generative AIpowered application includes a chat interface), but at their core, they combine LLMs with actions to deliver some experience.\n\nFor example, you might use an LLM to process a Slack message sent to your `#it-support` channel, have it file an appropriate ticket in ServiceNow, wait for human approval, and then provision some infrastructure. That might look something like this:\n\n\u003Cdiv style=\"text-align:center;\">\u003Cimg src=\"//images.ctfassets.net/0uuz8ydxyd9p/70SBemKQHnqfLxoHgPovQX/33f3a0b6cfc96eae2d17d1a463079560/Screenshot_2025-07-08_at_10.26.26__AM.png\" alt=\"Chain workflow\" style=\"display:block;margin:0 auto;\">\u003Cp style=\"margin-top:0;\">\u003Cem>Chain workflow\u003C/em>\u003C/p>\u003C/div>\n\nwhere a series of LLM calls, actions, and user interactions are strung together.\n\nOr it may look something like this:\n\u003Cdiv style=\"text-align:center;\">\u003Cimg src=\"//images.ctfassets.net/0uuz8ydxyd9p/O0udQjFtCS4RKr3JLcoNQ/589423afb721f595896a978e3d9ca3c2/Screenshot_2025-07-08_at_10.26.59__AM.png\" alt=\"Loop workflow\" style=\"display:block;margin:0 auto;\">\u003Cp style=\"margin-top:0;\">\u003Cem>Loop workflow\u003C/em>\u003C/p>\u003C/div>\n\nwhere the exact trajectory through the business logic is not known at design time but is determined by the system itself, specifically with the LLM being used to drive the flow.\n\nIn both cases, the primary elements of the solution are the same and are well-addressed by Temporal. This table offers an overview  a bit of a cheatsheet. On the left, weve bolded the terms most commonly used to describe a key element of AI applications. On the right, we briefly describe how Temporal satisfies the need. Think of this as a description of Temporal in todays AI lingua franca. In the section that follows, well cover each concept in more detail.\n| Key element in AI                                                                                  | How Temporal addresses it                                                                                                                                                                  |\n|----------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| We stitch together a bunch of steps into __chains, graphs or agentic loops__.                          | This is a Temporal [Workflow](https://docs.temporal.io/workflows). Workflows are equally well-suited to designs that structure steps at design time (first diagram) as those that are dynamic (second diagram).                  |\n| We use __Large Language Models__ (LLMs).                                                               | You invoke these through Temporal [Activities](https://docs.temporal.io/activities), delivering resilience out of the box.                                                                                                        |\n| We invoke __tools__, craft __prompts__, and access __resources__.\u003Cbr>\u003Cbr>We also invoke MCP servers via __MCP clients__. | You invoke these through Temporal [Activities](https://docs.temporal.io/activities), delivering resilience out of the box.\u003Cbr>\u003Cbr>When tools are MCP servers, the MCP client is implemented within an Activity.                   |\n| We implement __MCP servers__.                                                                          | These are implemented as Temporal Workflows and Activities.                                                                                                                                |\n| AI applications, especially AI agents, are responsible for providing __memory__.                       | You just manage your application state in variables in your Workflow. As an added bonus, with Temporal, that state is durable.                                                             |\n| We use __checkpointing__ to keep from having to rerun steps if a process crashes.                      | Temporal delivers this implicitly through its event sourcing and state management architecture. You never have to think about checkpointing.                                               |\n| We must allow for __humans in the loop__.                                                              | This is achieved through [Temporal Signals & Updates, and Temporal Queries](https://docs.temporal.io/encyclopedia/workflow-message-passing).                                                                                                                 |\n| AI applications are often __long-running__.                                                            | In addition to its event sourcing and state management foundation, Temporal handles long-running processes through its [Worker](https://docs.temporal.io/workers) architecture.                                                |\n## Lets take a closer look\nNow, with this very high-level overview showing the alignment of Temporal with the needs of an AI application or agent, lets dive deeper into each element. Understanding these building blocks  and how Temporal handles them  will not only deepen your understanding, but I also hope it will help you get started quickly.\n\n- __Chain, graph or agentic loop__: These are all terms used to describe how the boxes in the diagrams above are composed.\n    * *Chaining* of steps was a term popularized by LangChain through their first offering, one that allowed various steps in an application to be chained together, with outputs from one step flowing as inputs to the next. As depicted in the first diagram, a *chain* is used to define a predetermined, linear flow.\n    * *Agentic loop* is the term used to describe the cycle shown in the second diagram. In this model, the LLM is used to drive the actions that happen on every cycle, and the LLM is also used to determine when a goal has been reached and the cycle is exited.\n    * Clearly, you can model either of these approaches as a *graph*. Graphs are also sometimes used to model more complex, yet still predetermined, flows  think *chains* with added *branches* and *loops*.\n\n\u003Cdiv style=\"border:1px solid #ddd; border-radius:4px; padding:12px;\">\n\nWhen using Temporal to build your AI application, the predetermined flow (simple or complex), or the agentic loop is implemented as a *[Temporal Workflow](https://docs.temporal.io/workflows)*. Its just regular code, providing the most powerful and familiar model for orchestrating components  LLMs, Actions, and UX  into a business application. You can program in your favorite language[^1], so there is no new language or DSL to learn. Since its a general-purpose programming language, there are no abstractions to get in your way. AI application patterns will, without question, continue to evolve in the coming months and years, and we are confident that these general-purpose programming languages will be as well-suited to implement new patterns as they are suited to satisfy the current ones.\n\n\u003C/div>\n\n- __Large (or Small) Language Model (LLM/SLM)__: While the applications we speak of here obviously include the use of an LLM, it is still worth calling it out explicitly, not only for completeness but also because your application is responsible for interfacing with the LLM:\n    * The LLMs your application utilizes could be in the cloud, within your own corporate network, or even locally on your machine (these would be the smaller models I hinted at above). In virtually all cases, they are running in processes outside of your applications main orchestration.\n    * While at the high level, all LLMs operate by taking in tokens and outputting tokens, their models differ, and the way that the input tokens are structured can impact their qualitative performance. The application you are writing is responsible for interfacing with the LLM, possibly structuring the input for the best performance.\n\n\u003Cdiv style=\"border:1px solid #ddd; border-radius:4px; padding:12px;\">\n\nWhen using Temporal to build your AI application, the Workflow will interact with an LLM via a *[Temporal Activity](https://docs.temporal.io/activities)*. A Temporal Activity is code (again, written in your favorite language) that implicitly delivers resilience for distributed systems, and it gives you full control over any logic needed around the LLM invocation.\n\nFor example, when a network glitch renders the LLM unavailable or when the LLM is rate-limiting requests, the Activity automatically retries those requests until conditions allow for completion. As the developer, you dont write the retry logic; that behavior is handled by Temporal. And because Temporal is optimized for distributed systems, retries (and other resilience patterns) are designed to address a wide range of failure scenarios.\n\nAnd because an Activity effectively brokers the LLM invocation, you can structure it as a gateway of sorts, adding logic that, for example, redacts any Personally Identifying Information (PII) before sending it on to a third-party LLM.\n\n\u003C/div>\n\n- __Actions or Tools__: This term represents the actions that the AI application or agent will take, sometimes at the direction of the LLM and sometimes as a step in a predetermined flow. Very often, this will result in the invocation of a downstream API or the access of external data stores. *Tool* was the first term popularized, albeit with a rather vague definition, but the emergence of the __Model Context Protocol (MCP)__ has brought more specificity. MCP defines protocols for interfacing with the following types of entities:\n    * __Tool__: Invoking an API, calling a function, or otherwise interfacing with outside systems.\n    * __Data Source or Resource__: Read/write access to data, either locally or in a remote location.\n    * __Prompt__: Prompt templates that are used to provide direction to the LLM in the next invocation.\n- __MCP servers__: These are services that implement the functionality of a tool or access to a resource.\n\n\u003Cdiv style=\"border:1px solid #ddd; border-radius:4px; padding:12px;\">\n\nWhen using Temporal to build your AI application, tools and resources are accessed via a *[Temporal Activity](https://docs.temporal.io/activities)*. The Workflow  which orchestrates the operations of your applications operations by calling LLMs, invoking tools, and allowing for user interaction  is all running within a single process and is therefore not subject to the challenges posed when calls are made to external systems. But Temporal Activities are explicitly designed to make external calls resilient.\n\nJust like Workflows, you build your Activity as code that invokes the downstream API or accesses external data sources. Temporal Activities implement a host of durability features so that when, for example, a network outage temporarily renders an API inaccessible, the Activity will automatically retry it without the developer having to handle the case explicitly.\n\nActivities may be written for specific downstream APIs: for example, you may create a `FetchWeather` activity that makes a REST call to the national weather service. Alternatively, Temporal supports [dynamic Activities](https://docs.temporal.io/develop/python/message-passing#set-a-dynamic-activity) where the details of the invocation are supplied as arguments to the Activity. This latter approach is particularly useful when your AI agent is built in the form of the second diagram above. If your Workflow calls an MCP server, the Activity is the place where the [MCP client](https://modelcontextprotocol.io/introduction#general-architecture) is implemented.\n\nFinally, MCP servers themselves implement logic that also very often includes calls to external systems. Temporal Workflows and Activities are an ideal implementation for MCP servers.\n\n\u003C/div>\n\n- __Memory__: LLMs are forgetful  that is, they are stateless. Each time they are invoked, they receive entirely fresh input as a sequence of tokens and generate entirely new output. It is the job of the AI application to remember; to manage the state of the application by keeping track of inputs to and outputs from previous steps, and any relevant resources and prompts, so that it may properly assemble them for every LLM invocation.\n\n\u003Cdiv style=\"border:1px solid #ddd; border-radius:4px; padding:12px;\">\n\nWhen using Temporal to build your AI application, you simply use *__variables in your Workflow code__* to store the needed state. You have full control over what data to store, how to store it, and how it is assembled for input to the LLM. This works for flows that are fully specified at design time, as well as for the agentic loops that are driven by the LLM at runtime. There is nothing new to learn, and the approach is sure to work for the yet-to-be-invented, popular AI application patterns.\n\n\u003C/div>\n\n- __Checkpointing__: AI applications beyond the simplest of demos make many calls to LLMs and tools, and they are increasingly leveraging other agents. In the event that the application stops before completion (due to both foreseen and unforeseen causes), checkpointing keeps the application from having to start from the beginning and rerun previous steps in the workflow.\n\n\u003Cdiv style=\"border:1px solid #ddd; border-radius:4px; padding:12px;\">\n\nWhile Temporal is already showing well against the key elements weve covered so far, when it comes to checkpointing, Temporal really shines!! (And wait until you see whats in store in the long-running section below)\n\nYou see, when Temporal executes a Workflow, it records a full [Event History](https://docs.temporal.io/encyclopedia/event-history/)  every single time code in the Workflow is run, every single time an Activity is called or returned, and more. Plus, it records the values returned by every single Activity call, which means the memory we just spoke about is completely visible and debuggable through Temporal tooling. The outcome that checkpointing delivers in other frameworks is realized through the *__event sourcing__* and *__state management__* features that form the foundation of Temporal. As the developer, you are not responsible for implementing any part of this protocol. By structuring your apps as Temporal Workflows and Activities, you get this behavior for free.\n\nIf the application instance were to shut down (crash, be proactively cycled, or because you wanted to fix a bug even while the app was running), as soon as the application starts again, the state will be recreated and processing will pick up where it left off. When building Temporal applications, you never have to think about checkpoints. Your mental model is simply that if the application goes down, it will pick up where it left off when it is brought back up. *__We call this Durable Execution.__*\n\n\u003C/div>\n\n- __Human-in-the-loop__: While some AI applications may operate entirely autonomously, many (if not most) will have humans that interact with them. They may provide input on launch and at various points throughout the execution, including within an agentic loop.\n\n\u003Cdiv style=\"border:1px solid #ddd; border-radius:4px; padding:12px;\">\n\nWhen using Temporal to build your AI application, you use *__[Signals and Updates](https://docs.temporal.io/encyclopedia/workflow-message-passing/)__* to supply input and *__[Queries](https://docs.temporal.io/encyclopedia/workflow-message-passing/)__* to extract state to show the user. These are primary abstractions in the Temporal programming model, and just as with Workflows and activities, you implement these in your programming language of choice. (Insert usual refrain on general-purpose programming languages giving you full flexibility to implement any logic you require. ) The protocols that invoke these methods, which are programmed idiomatically in each of the programming languages Temporal supports, are delivered in the Temporal SDK.\n\n\u003C/div>\n\n- __Long-running__: Long-running apps are not unique to those leveraging LLMs, yet because AI is allowing more and more functionality to be handled autonomously, the amount of work done in one application session is only increasing. That is, long-running applications are becoming ever more commonplace. Checkpointing is certainly part of delivering a good user experience over timelines that may last hours, days, weeks, or even months and years. But beyond maintaining stability for long periods, applications also need to make efficient use of computing resources.\n\n\u003Cdiv style=\"border:1px solid #ddd; border-radius:4px; padding:12px;\">\n\nWe already covered how Temporal delivers on checkpointing, so lets turn to the question of efficient resource utilization. When using Temporal to build your long-running AI application, efficient resource utilization is delivered through the *__Worker architecture__* that is at the core of Temporal.\n\nA Temporal Worker is the process within which your Workflow and Activity code runs. It looks after many concurrently running Workflows, and  key to the questions around long-running Workflows  it manages which are currently in active memory and which are not active but in cache. For those that have been evicted from the cache, it replays the Event History to reconstitute the application state for further processing (see checkpointing explanation above). So solid is the implementation that Workers can be tuned to efficiently look after hundreds or thousands of Workflows at once. Workers may also be sized and tuned for particular workload types.\n\nAs a developer, you can simply write Workflows as if they stayed active in memory at all times. Gone are the days when you had to fragment your business logic into separate pieces purely because of temporal constraints (pun definitely intended! )\n\n\u003C/div>\n\n## Building for whats next\nI didnt set out to write a blog about distributed systems patterns, but here we are. The thing is, once you start building real AI applications and agents, you quickly realize youre not just wrangling LLMs  youre orchestrating complex, multi-step, failure-prone distributed systems, PLUS youve got humans engaged throughout the workings of that complex system.\n\nThese distributed systems are powering the experiences you are delivering to your users, and the fact that they are delivered through a totally new paradigm (AI) doesnt lessen the users expectation that *they just work*.\n\nThe AI landscape is moving fast, and new patterns are emerging every month. But heres my bet: whatever comes next  whether its multi-agent orchestration, hybrid human-AI workflows, or something we havent even thought of yet  its going to need rock-solid distributed systems underneath. And thats exactly what Temporal gives you: real code, in real programming languages, handling real complexity.\n\nAs AI applications continue to evolve, the need for resilient, scalable execution becomes even more critical. Curious to see how Temporal can streamline your generative AI workflows in production? [Sign up for Temporal Cloud](https://temporal.io/cloud) today and get $1,000 in free credits to start building with confidence.\n\n[^1]: Python, Java, Go, Typescript, .NET, Ruby, PHP",featureImage:{title:"social-card-purple",description:"social-card-purple",url:"https://images.ctfassets.net/0uuz8ydxyd9p/UbL8tEOAIBjMrI6OCSeNN/62aecca8ce16e11e288c1fd7ef4e346d/social-card-purple.jpg"},publishDate:"2025-07-10",metaDescription:"Explore why Temporals Durable Execution makes it the ideal foundation for building resilient, reliable AI agents and generative AI applications. Discover how Temporal meets every core requirement of AI-driven workflows.",metaTitle:"Durable Execution meets AI: Why Temporal is ideal for AI agents & Generative AI Apps",socialCard:{title:"Blog (30)",description:"Blog (30)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Z6CwHPOuGrxlKa2uteem0/74501217477aa65c207218096ef927e9/Blog__30_.png"},tags:"Durable Execution,AI/ML",slug:"durable-execution-meets-ai-why-temporal-is-the-perfect-foundation-for-ai",contentType:"blogPost",entityId:"36mirWrzPGqxFsU9CiSFXJ",authors:[{id:"5UNwygCxwqYCdaa27gAYNS",name:"Cornelia Davis",slug:"cornelia-davis",jobTitle:"Senior Staff Developer Advocate",photograph:{title:"Cornelia Davis Headshot",description:"Cornelia Davis Headshot",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6TDAN3Pi1qvx8m6HBdC4Kk/24be44497f96b4236b4e61b054e8568f/image.png"},company:"Temporal",contentType:"person"}],authorsString:"Cornelia Davis",category:"Temporal Voices",readingTime:15},{title:"Building an agentic system thats actually production-ready",content:"Youre in the industry and your hands are on the keyboard. I know you know that every company is clamoring to ship an AI assistant and that many fall flat on their faces before they even reach the finish line.\n\nRight now, Ive noticed theres a massive gap between the exciting potential of agentic AI (conversation, proactive, and helpful) and the reality of building something durable enough to survive production. Everyones flaunting their GPT-powered demos, but few have something that still works even two days later.\n\nIf youve already read [this post](https://temporal.io/blog/from-ai-hype-to-durable-reality-why-agentic-flows-need-distributed-systems) on why agentic systems are just distributed systems in disguise, this is the follow up. Not the *why*, but the *how*.\n\nThats what inspired me to write this article. Not to further hype the trend, but to strip things down to the foundation (definitions, architecture, and flows) to make sure youre building on solid ground.\n\nIf youre an engineer, architect, or technical lead thinking about how to scale agent workflows, Im talking to you!\n\nSince agentic AI is a hot topic now, and there are a lot of terms, ideas, and technologies being discussed, along with the questions:\n\n- Why is this space so interesting? Whats so exciting (and fun!) about it?\n- What do all of these terms mean? Is there a consistent definition?\n- What does an Agentic System actually do? \n- How does Temporal (the technology) help in this space? \n- How is Temporal (the company) helping out companies implement these kinds of systems?\n\nThis blog aims to define some terms, share example architecture and code samples, and offer some helpful opinions on where this is all headed. \n\nIf youre especially curious about how we as a company are helping, check out these awesome stories and posts:\n\n- [Gorgias Uses AI Agents to Improve Customer Service](https://temporal.io/resources/case-studies/gorgias-uses-ai-agents-to-improve-customer-service)\n- [Temporal Use Case Round-Up: Generative AI](https://temporal.io/blog/temporal-use-case-roundup-generative-ai)\n- [How Dust Is Building the Future of Work With Agentic AI and Why it Runs on Temporal](https://temporal.io/blog/how-dust-builds-agentic-ai-temporal)\n- [Building, launching, and scaling ChatGPT Images](https://newsletter.pragmaticengineer.com/p/chatgpt-images)\n\n## Agentic systems: Potential\nAgentic systems have the potential to redefine application architecture because of their amazing capabilities. Agentic Systems can give you an army of qualified assistants that can analyze, execute, and recommend at a massive scale. They can replace a complex UI presenting hundreds of data points with a simple conversation, highlighting points of interest and massively reducing cognitive load. They can make recommendations and take action *in context*, dramatically reducing the burden of creation. They can validate and make judgements, reducing risk and building confidence. \n\nIn terms of the future of agentic AI, I (and my colleagues here at Temporal across Engineering, Solutions Architecture and GTM, Product, and Developer Relations) expect these systems may replace entire applications, in the same way the smart phone replaced CDs players, paper calendars, desk phones, personal computers, VCRs, and *calling people on the phone to get food delivered*. I expect agentic systems will also enable entirely new kinds of applications, just like other technology revolutions did.\n\nIf these systems can deliver on their promises, being a human connected to the internet is about to get a lot easier.\n## Agentic systems: Definitions\nThere are lots of terms floating around in AI. Heres how I define the foundational elements of agentic AI Systems.\n\n- __AI__: In agentic systems, a Large Language Model (LLM) that simulates intelligence. It can recommend how to pursue goals, make decisions, and recommend or decide on actions to take.\n- __Goal__: Something the AI and user both want to finish. Often executed by one or more tools with the steps determined by the AI.\n- __Tool__: A capability of an agentic system.\n  - It performs Actions to be taken to accomplish goals with context to guide the AI about how and when to use the tool.\n  - Often implemented as a simple function making an API call.\n  - Sometimes tools have multiple steps or their own intelligence (see Agents as Tools, below).\n  - Can interact with public and private data sources or APIs.\n  - Can be built for a specific agentic system.\n  - Can be [MCP tools](https://modelcontextprotocol.io/introduction).\n    - MCP tools provide their own context that the AI can use to evaluate their usage for the users goals.\n- __User__: A person who wants something done.\n- __Agent__: Someone or something that acts on behalf and for the benefit of someone or something else.\n- __Agentic__: An attribute of a system, in which an AI acts on behalf of a user, completing tasks, making decisions, and recommendations for next steps.\n- __Agentic system__: An application that interacts with a user and behaves in an agentic way, using AI and tools to accomplish goals.\nHere is a simple model putting all of these concepts together:\n![diag1](//images.ctfassets.net/0uuz8ydxyd9p/JWPbDNjKXwtMZuqdMc5fR/b0cd942e82d34cc8058c8bc5aae114c6/Screenshot_2025-06-24_at_3.20.07__PM.png)\n### Advanced agentic systems\nThe following concepts are an expansion of those above. We are seeing systems being built that have more complex agentic capabilities:\n\n- __Multi-Agent__: An attribute of a system that uses multiple agents. Agents could have different capabilities and roles. Agents could be selected via agent routing or tasks could be delegated to agents, for example by implementing an agent as a tool.\n- __Agents as tools__: in a multi-agent system, Agents can be implemented as tools  a capability of the system. Agents can be tasked with implementing something as part of the users goal. This can be used to delegate a multi-step process that has its own agentic capabilities  deciding how best to implement the process and what tools to use.\n\n![diag2](//images.ctfassets.net/0uuz8ydxyd9p/5pGfOHIv2rm4SCwXa7oOMh/a3e34e595dc574fb718d57da481d4ec5/Screenshot_2025-06-24_at_3.21.43__PM.png)\n## What does an agentic system actually do? The agentic flow:\nAgentic systems operate through three interconnected phases: Interaction (with users/events), Decision (via LLMs), and Action (tools, APIs, sub-agents).\nIn Temporal, these are orchestrated together in a single durable workflow:\n\n1. __Interactions__: Agent responds to user prompts (e.g. chat) or external events (e.g. new data) and responds to the user.\n2. __Decisions__: Agent uses an LLM API to determine what actions to take. The agent may decide it requires additional user input.\n3. __Actions__: Agent executes specific activities, interfaces with external APIs, runs sub-agents, and uses knowledge bases as needed.\n\nHere is a diagram of these three interactions working together as an agentic system, with Temporal orchestrating each:\n![diag3](//images.ctfassets.net/0uuz8ydxyd9p/1Tg6UMe65FOURIj9pX2hBE/7681c7f8f0bcf146cc209f82dabdac7e/Screenshot_2025-06-24_at_3.24.16__PM.png)\nIf you want to see an example of this system in action, check it out on GitHub: [Temporal Agentic Workflow Example.](https://github.com/temporal-community/temporal-ai-agent)\n\nTogether, these make a system that is dynamic, reacting to inputs from users, the LLM, and tool results.\n## Agentic challenges\nSo why isnt the hype real yet? We have all of the ingredients  tools, LLMs, humans who would love assistance getting their tasks done. Whats missing?\n\nWell, at Temporal, weve observed that there are some significant challenges to getting to production AI at scale. \n\n- Humans can be unreliable, inaccurate, or non-responsive. \n- Tool APIs and databases can go down. \n- AI is inherently non-deterministic. \n- Everything in this space is new (and changing constantly). \n- Agentic systems are complex and hard to debug and test. \n- Security is a problem that isnt completely figured out yet.\n\nAgentic systems often struggle to:\n\n- Orchestrate complex multi-step interactions across distributed data stores and tools.\n- Tolerate tool failure.\n- Orchestrate multi-level processes.\n- Hold state, potentially over long periods of time.\n- Be durable: self-heal and retry until the LLM returns valid data.\n- Have simple, generic implementations for human intervention such as approvals and input gathering.\n- Provide insight into the agents performance.\n- Tolerate human error and correction.\n- Securely handle data and access on behalf of users.\n- Ramp to production enterprise scale.\n\nAs we work with so many companies building AI systems, we hear these challenges every day.\n\nThe reasons the hype isnt real can generally be summarized as: *building complex distributed systems is hard and agentic systems are extremely complex distributed systems*.\n\nFor more on this topic, check out [this video](https://www.youtube.com/watch?v=3Ox9Wqjn1Hk) on how AI agents are distributed systems in their own right.\n## Agentic systems must be well-engineered distributed systems\nAgentic systems wont work in production unless theyre well-engineered distributed systems.\n\nThat means they need to be stateful, fault-tolerant, observable, and able to coordinate both machines and humans over time. Which also means they are best built with reliable orchestration.\n\nOur position at Temporal is straightforward: If you want your agent to survive the real world, it needs Durable Execution. Durable Execution [helps you easily solve the hard parts of distributed systems](https://www.youtube.com/watch?v=ROJq6_GFbME) so you can get a reliable system by default, and you can focus on making something fun and useful for your users using this powerful technology.\n\nThats what we do and have done, and why were so invested in helping teams move from breakable demos to scalable, reliable systems.\n## Building an agentic workflow framework\nHere is a simplified version of the [agentic framework](https://github.com/temporal-community/temporal-ai-agent). Key elements of the Agentic Workflow:\n\n1. User interaction is enabled via `Signals` and `self.add_message()`  to send messages to the user\n2. A Tool Planner activity which uses the LLM to plan tools\n3. Activities are used to execute Tools\n4. The interaction waits for user confirmation before running Tools\n\n```python\n# Simplified version of https://github.com/temporal-community/temporal-ai-agent\n\n@workflow.defn\nclass AgentGoalWorkflow:\n\n    def __init__(self): \n\n    @workflow.run\n    async def run(self):\n        while True:\n            await workflow.wait_condition(  # prompt OR confirm\n                lambda: self.prompt_queue\n                or (self.waiting_for_confirm and self.confirm)\n            )\n\n            #  handle prompt outcome: question/confirm/done\n            tool_data = await workflow.execute_activity(\n                ToolActivities.agent_toolPlanner,\n                {\"prompt\": prompt, \"history\": self.conversation_history},\n            )\n            self.add_message(\"plan\", tool_data)\n\n            # The planner thinks all arguments are ready and a tool should run\n            # Ask the user to confirm\n            if tool_data[\"next\"] == \"confirm\":  # agent is ready to run tool\n                self.add_message(\"agent\", tool_data[\"response\"]) \n\n            elif tool_data[\"next\"] == \"question\":  # ask user for more info\n                self.add_message(\"agent\", tool_data[\"response\"])\n\n            elif tool_data[\"next\"] == \"done\":  # end chat\n                return json.dumps(self.conversation_history)\n\n            #  run tool if outcome is confirm and user confirms\n            elif self.waiting_for_confirm and self.confirm:\n                result = await workflow.execute_activity(\n                self.add_message(\"tool_result\", result)\n                self.waiting_for_confirm = self.confirm = False  # reset flags\n\n    @workflow.signal\n    async def user_prompt(self, prompt: str): \n\n    @workflow.signal\n    async def confirm(self):\n        self.confirm = True\n```\nAs a Temporal Worker, this application can be deployed just like any other Python application. Workers are stateless  all state is stored in the Temporal Service. Since they are stateless, any worker application crashes can be recovered from seamlessly, and I can scale this up to thousands of instances, each able to handle many many conversations concurrently.\n\u003Cdiv style=\"text-align:center;\">\u003Cimg src=\"//images.ctfassets.net/0uuz8ydxyd9p/6PbY2FxcomANfHEdAFWq7B/23ba87c21b55af1e2c87a6226fb72647/IMG_6968.png\" alt=\"What the agentic framework looks like\" style=\"display:block;margin:0 auto;\">\u003Cp style=\"margin-top:0;\">\u003Cem>What the agentic framework looks like\u003C/em>\u003C/p>\u003C/div>\n\nI can see the entire conversation and flow using the Temporal Workflow History, which I can also use for analyzing Agent success. We can [add any Goals or Tools (even MCP tools!)](https://github.com/temporal-community/temporal-ai-agent/blob/main/docs/adding-goals-and-tools.md) to this framework, enabling the building of many different Agents. These goals and tool definitions are just passed as input to the workflow.\n\nThe workflow is dynamic, flowing and adapting to the conversation, with the agent planning tools based on user input:\n![diag4](//images.ctfassets.net/0uuz8ydxyd9p/2qPZiEMvK5ad3uOkmbHC3z/9a82af3d9b55629bd16eeda292ad9ac3/Screenshot_2025-06-24_at_3.37.29__PM.png)\nTo try it for yourself, check out the [Temporal Agent Framework](https://github.com/temporal-community/temporal-ai-agent) and explore. Keep in mind, since its just a Temporal application, it will scale and be durable as you need it to. Im excited about this, since it delivers on the needs of agentic applications mentioned above. Plus, its a lot of fun to work with.\n## Production agentic AI at scale  powered by Temporal\nFortunately, Temporal was designed to solve the pain of building complex distributed systems. Durable Execution with Temporal makes orchestration of agentic processes simple.\n\nAgents implemented as Workflows can run for as long as you need them to. Failures are easy to retry, human interaction is simple and flexible, and scale is trivial. It really is that simple.\n\nWant to see what I mean? Check out [this webinar](https://pages.temporal.io/ai-agent-live-coding-2025-on-demand.html?utm_source=marketo&utm_medium=email&utm_campaign=w-ai-agent-2025-5), in which we walk through our [agentic AI framework](https://github.com/temporal-community/temporal-ai-agent), how we built it, and we try to make it break  but Temporal keeps it bulletproof. Ive talked to so many people whove taken the framework for a spin and built cool agents with it  some are in production now. Building with this framework is fun  I hope you enjoy working with it as so many others have.\n\nIf youre like me, then Im sure you want to dive deeper into how Temporal makes systems of all kinds durable, scalable, flexible, flexible, and simple to build. If so, you can check out these resources:\n\n- [Why Temporal Replaces Traditional State Machines for Distributed Applications](https://temporal.io/blog/temporal-replaces-state-machines-for-distributed-applications)\n- [Building Reliable Distributed Systems with Temporal: Error Handling & Workflow Management (on the AWS Developers Youtube channel)](https://www.youtube.com/watch?v=-8u56F_506s)\n- [A Better Way To Build Modern Applications](https://www.youtube.com/watch?v=CdEi2387VKM)\n- [Events are the wrong abstraction](https://temporal.io/blog/events-are-the-wrong-abstraction-rethinking-distributed-systems)\n\nIf you have questions and want to learn more, feel free to reach out:\n- Join the [Temporal Community Slack](https://t.mp/slack) (channel __#topic-ai__). Im there and always willing to chat!\n- [Talk to an expert](https://pages.temporal.io/ask-an-expert) and discuss your specific use case.\n- Take us for a whirl for yourself: sign up for [Temporal Cloud](https://temporal.io/cloud) and get $1,000 in free credits.",featureImage:{title:"buddha-elemental-3d-br5JFHhkoIA-unsplash (1)",description:"buddha-elemental-3d-br5JFHhkoIA-unsplash (1)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6KZNZOYRsAXONUbNuA5V7f/2f1ec7f2dd615ca6d4bb766d98271bff/buddha-elemental-3d-br5JFHhkoIA-unsplash__1_.jpg"},publishDate:"2025-06-26",metaDescription:"Learn to build production-ready, scalable agentic AI systems. This guide for engineers and architects covers foundational concepts, architecture, and a durable framework using Temporal to overcome common development and reliability challenges.",metaTitle:"Building an agentic system thats actually production-ready ",socialCard:{title:"Blog (27)",description:"Blog (27)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3wCvBCq3sUB7uEBPJDQuy2/46b8120930e101662dd12051ec01da78/Blog__27_.png"},tags:"AI/ML",slug:"building-an-agentic-system-thats-actually-production-ready",contentType:"blogPost",entityId:"XxCCyAY903HtJhAarv783",authors:[{id:"6SCT7ktnc7C7malyJV3UsQ",name:"Joshua Smith",slug:"joshua-smith",jobTitle:"Staff Solutions Architect",photograph:{title:"Josh Smith photo",description:"Josh Smith photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2DHNWCAITAPlTgzovWEEyW/1e105a12a16a24ca6db7f3c7ae0ef44b/1678726677795.jpeg"},contentType:"person"}],authorsString:"Joshua Smith",category:"Temporal Voices",readingTime:11}],promoCard:{title:"AI (General) Promo Card",eyebrow:"Temporal for AI",heading:"Ship AI features & agents 2x faster",content:"Keep your LLMs on track, state management intact, and handle debugging with ease.",callsToAction:[],entityId:"494ggdQln6U0ZG40qI1bcE",contentType:"noise"},readingTime:11},{title:"Announcing Worker Versioning Public Preview: Pin Workflows to a single code version",content:"As internet software grows more sophisticated, automated, and autonomous, it is becoming more asynchronous and longer-running. Longer-running Workflows can hop between multiple processes, making them resilient after process shutdowns and code bugs, and able to scale different steps independently.\nThinking beyond single processes presents challenges related to sleeping, checkpointing, and retries, which Temporal Workflows make significantly easier. Most often, the remaining complaint is that its hard to deal with Workflow Versioning  cases when two processes are running two different versions of your code.\nWith our new feature, Worker Versioning, you can now virtually eliminate version compatibility problems for most Workflows by guaranteeing that each Workflow will run on a single version of your code. We call this Workflow Pinning.\nWith Pinned Workflows, you dont have to think about interface compatibility between your Workflows and Activities, nor versioning problems when your Workflow code switches from one version to another.\nTo enable this, youll need a good deployment strategy to manage your Workers. Its worth taking a step back to talk about this  what are deployment strategies and how do you pick the right one?\nIll define and weigh three strategies. From least to most robust, they are called rolling, blue-green, and rainbow deploys. Rainbow deploys arent widely known today, but over time, they will become standard practice for high-availability, asynchronous, multi-process Workflows.\nRolling the dice with rolling deploys\nIn a rolling deploy, Worker nodes are gradually cycled in place from the old version to the new version. These have limitations for high-availability services  even synchronous services. When something goes wrong with the new code being deployed, it can take a long time to roll back to the previous version.\nAnother notable issue with this process is the lack of control over where your Workflows are routed, making your rollouts inherently unsafe.\nMean, lean, blue-green machine\nDuring a Worker deployment, a blue-green strategy temporarily rolls out a second green version of your Workers while keeping the old blue one around. With two available copies, you can route traffic to each version as you see fit. There are several major reliability advantages of this. It allows you to:\n\n  Easily run tests on a new version before cutting over traffic.\n  Ramp up traffic at a pace you choose.\n  Instantly roll back when something is wrong.\n\nBlue-green deploys are a big win for synchronous and asynchronous services alike. Still, theres a problem with blue-green deploys for long-running multi-process Workflows  there are only two colors! This brings us to rainbow deploys.\nTaste the rainbow\nRainbow deploys can route like blue-green deploys, but to more colors.\nTo pin Workflows to a code version, you must be able to track the usage of old versions and keep them around until all the Workflows complete, i.e., the version is drained. Doing this with high availability requires rainbow deploys. Thats because, when you ship a bug, or if you want to deploy twice in quick succession, its easy to get into situations where you need to keep three or more builds around.\nWorker Versioning helps you set up rainbow deploys, and Temporal will track when your Worker versions have drained.\nNow that Ive introduced the three deployment strategies, let me talk about how Temporal enables seamless revisions of Workflows through blue-green and rainbow deployments.\nIntroducing Worker Versioning\nWe embrace our asynchronous, long-running future with Worker Versioning, a powerful new tool for managing your Worker deployments. The magic comes as you maintain your Workflows. Each time you declare a Workflow type, youve got two options.\n\n  Pinned Workflows stay on a single version through their lifetimes, removing the need for you to think about versioning or interface compatibility between your Activities and Workflows. Declare your Workflow type as pinned like so, and you can freely make changes without affecting old Workflows (unless you want to affect old Workflows).\n\n@workflow.defn(versioning_behavior=common.VersioningBehavior.PINNED)\nclass MyPinnedWorkflow:\n    @workflow.run\n    async def run(self) -> None:\n        workflow.logger.info(\n            \"Whee! I can make changes without worrying about versioning!\")\n\n  Auto-upgrade Workflows automatically hop to a new version as part of a blue-green or rainbow deployment, benefitting from pre-deployment testing, gradual ramp-ups, and instant rollbacks. They still should be patched when modifications have been made, but it is easier to catch patching bugs early. When using rainbow deploys, you can tag Workflows as Auto-upgrade when they will run longer than youd like to keep versions of your code around.\n\n@workflow.defn(versioning_behavior=common.VersioningBehavior.AUTO_UPGRADE)\nclass AutoUpgradingWorkflow:\n    @workflow.run\n    async def run(self) -> None:\n        workflow.logger.info(\n            \"I need to patch if I make changes, but I can do it more safely with\" +\n            \"blue-green or rainbow deploys!\")\nWhat makes this work? Temporal now provides, in both open source and Cloud:\n\n  A built-in task router to help you instantly cut between versions or gradually ramp them up. (This substitutes for a traditional load balancer that you would use for blue-green deploys of a synchronous service.)\n  First-class support for rainbow deployments which allows you to pin Workflows to a single version of your Workers, eliminating most version and interface compatibility problems.\n  A fully supported Worker Controller for Kubernetes, co-developed with Jacob LeGrone at DataDog, as an easy way to adopt rainbow deployments.\n\nAdopting Worker Versioning will let you change your applications safely, confidently, and with higher ambition.\nIn the remainder of this post, Ill describe:\n\n  Building Worker Versioning  our design philosophy and the challenges we faced.\n  Getting started with Worker Versioning  links to get you started.\n  Project status  what we have and whats to come.\n\nBuilding Worker Versioning\nOur four overriding design goals were ease of adoption, reliability, deployment safety, and flexibility.\nEase of adoption\nApplication developers tell us every day that they dont want to deal with Workflow versioning problems. However, to have nice things, they often need to upgrade deployment systems that another team at the company might manage. To help such teams, we obsessed over ease of adoption:\n\n  We believe rainbow deploys are the future and want to make them really easy to adopt, which is why we polished the APIs to make them as simple as possible, and also created the Temporal Worker Controller for Kubernetes as a drop-in solution.\n  We know that blue-green is a more established deployment strategy in the industry, so we added some features to unlock the value of blue-green deploys independently of rainbow deploys.\n\nReliability\nWith Worker Versioning, task queues can now be routed based on version. This is a fundamental change to Temporals architecture, so we wanted to make sure we nail it and scale it. To this end, weve been dogfooding it within Temporal Cloud for several months, as well as stress testing it.\nDeployment safety\nWe prioritized making deployments as safe as possible:\n\n  Code revisions shouldnt affect old Workflows. When they do, users should be able to use testing and controlled rollouts to minimize damage.\n  Zero downtime is the goal. This meant providing features like instant rollback, pre-deployment testing, and tracking when versions are drained of Workflows.\n  Recovery is always possible  we never want users to get stuck.\n\nFlexibility\nWe know customers have a great variety of systems set up to manage Worker deployments, and a variety of Workflow patterns. We provided primitives for managing diverse deployments, Workflows of varying run lengths, and the ability to override default task routing. We plan to add more flexibility over time based on demand  please tell us about your scenarios.\nGetting started with Worker Versioning\nTo get started with Worker Versioning, you have a few options:\n\n  Integrate directly with our APIs and commands. Start here.\n  Use the Worker Controller for Kubernetes.\n  Weve also recently released a free, self-paced Worker Versioning course.\n\nProject status and roadmap\nBoth Worker Versioning and our Worker Controller are in public preview, which means they are recommended for staging and for production usage after careful testing.\nWe need feedback! Let us know whats working and what else you need. This will help make our GA great. Find us in #safe-deploys in our Community Slack.\nWorker Versioning plans\n\n  A light refresh is due at the end of September with some improvements.\n  We expect to make it generally available (GA) in Q4 2025.\n  We plan to also add a third Workflow type annotation, Pinned-until-Continue-as-New, for very long-running Workflows. They will stay pinned and be awoken when its time to continue as new. Dates are TBD.\n  We plan to make it more scalable to move broken Workflows en masse to a patch build, and also to add replay testing. Dates are TBD.\n\nWorker Controller plans\n\n  As of September 2025, our next priority is auto-scaling. With rainbow deploys, we know its particularly important to scale down old builds as they drain to ease resource usage.\n  Please let us know if you would like support for other deployment infrastructure besides Kubernetes.\n\nGet in touch\nWe want to hear from you! Find #safe-deploys in our Community Slack to join the conversation and to keep up with news about Worker Versioning.",featureImage:{title:"image-3D-waves",description:"image-3D-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/62stYfm7wc5gZJaaldJ4jy/4f585ec2bd98307d1b4593c6c5f6ca92/Screenshot_2024-11-13_at_12.44.34_PM.png"},publishDate:"2025-09-24",metaDescription:"Announcing Worker Versioning in public preview  pin each Workflow to a single code version for safer blue-green and rainbow deploys, with Kubernetes support.",metaTitle:"Announcing Worker Versioning Public Preview: Pin Workflows to a single code version",socialCard:{title:"Blog (41)",description:"Blog (41)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5DQFfMyDbF8UCn45oxuYfW/b2b45f443bd2aa54ed04532f5d861a71/Blog__41_.png"},tags:"Temporal Primitives,Versioning,Python,Kubernetes",slug:"announcing-worker-versioning-public-preview-pin-workflows-to-a-single-code",contentType:"blogPost",entityId:"5TjRIO2tJsg2aDVnHIcr4f",authors:[{id:"LS7zQaCnktCD3qgirNPPc",name:"Drew Hoskins",slug:"drew-hoskins",jobTitle:"Staff Product Manager",photograph:{title:"Drew Hoskins",description:"Drew Hoskins",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6GobjHlaiDrKY2bzxlg2Am/da3be8bc14fe893c6db62178b96ce7f1/Drew_Hoskins_Headshot.png"},biography:"Drew Hoskins is a Staff Product Manager at Temporal focusing on improving the developer experience. Hes spent his whole career building developer technology, most recently as a Staff Engineer at Stripe where he founded and built out the Workflow Engine, a popular internal framework built on Temporal. You can follow his writings on software engineering at The Product-Minded Engineer, https://drewhoskins.substack.com/.",website:"https://drewhoskins.substack.com",company:"Temporal",contentType:"person"}],authorsString:"Drew Hoskins",category:"Product News",readingTime:8},{title:"Individual contributors vs. decision makers: Same systems, different realities",content:"When individual contributors (ICs) and decision makers (DMs) describe the problem, they are often talking about different things. ICs talk about the incidents they touch. DMs talk about the risks they own. Our State of Development 2025 survey puts those two views on the same page so teams can plan with the same facts and stop talking past each other.\nTL;DR: ICs report daily friction. DMs see business exposure. Both groups point to the same fix: more reliability, less manual effort, and decisions that reflect how tool choices actually get made.\nWhat ICs feel, and what DMs fear\n\n  \n\nICs live in the failure path. The most common pain points are latency and performance (31%), complex workflows that feel fragile (31%), debuggability and observability gaps (28%), and manual failure recovery that still shows up in too many places (19%). That list reads like an oncall rotation.\nDMs zoom out to the risk register. Security ranks first (36%), followed by technology complexity (33%), integration friction (32%), and the double bind of cost management and scaling (both 30%). Reliability (28%) remains near the top, which tracks with what customers notice and what boards ask about.\nBoth are right. They are the same story at two time horizons. IC symptoms today become DM risks tomorrow if they arent addressed.\nOperations are still noisy\nOnly one in four teams describe work operations as smooth. The rest point to high operational overhead (35%) and complex failure recovery (34%) as routine. Longrunning work continues to be a sticking point, landing around the 3035% mark depending on role. The pattern is all too familiar: teams can start work, but finishing cleanly without human babysitting is hard.\nSatisfaction numbers echo that gap. Orchestration gets 84% satisfaction while automation sits at 77%. Orchestration helps you kick things off. Automation keeps them alive, observable, and recoverable when reality intervenes. Most organizations havent closed that second mile.\nWho actually picks the tools\nPower shifts with company size. In smaller orgs, developers often drive tooling decisions. Overall, developers show 50% influence in selection. In enterprises, gravity moves upward: CIOs and IT managers lead at 53%, and developer influence drops to 35%.\nThat shift explains a lot of stalled rollouts. If youre pitching a tool the same way at 80 employees and at 8,000, you will miss the mark. The buyer changes, the evidence they need changes, and the story must change with it.\nWhat each side optimizes for\n\n  When you ask what matters in tool selection, the lists rhyme but differ in emphasis.\n  DMs weight security (67%), reliability (63%), cost efficiency (55%), and ease of integration (49%). This is portfolio thinking: minimize exposure, keep systems steady, prove the spend.\n\nICs put security (57%) in the top three as well, then lean to performance (51%), reliability (49%), flexibility and customization (49%), and integration with other tools (47%). Thats daytwo thinking: can we debug it, tune it, and evolve it without brittle glue?\nBoth lists point at the same destination. The fastest way there is to translate proposals into both languages. Durable retries reduce MTTR speaks to the IC. Fewer incidents and lower overtime spend speaks to the DM. Its the same improvement framed for the accountability it serves.\nWhat failure actually costs\nDecision makers draw a direct line from incidents to business outcomes. Customer churn or dissatisfaction leads at 48%, followed by increased operational costs (47%), revenue loss (45%), and brand damage (45%). Only 5% say failures would have no major impact. Reliability is not a tooling opinion. Its a revenue, retention, and reputation issue with a clear price tag.\nThis is where the IC list and the DM list meet. Manual recovery and opaque flow logic turn into missed SLAs and support spikes. Better execution models and shared visibility turn into fewer tickets and calmer quarters.\nThe nearterm North Star\nAcross roles, the next 1224 months cluster around three goals: enhance reliability and security compliance (36%), increase automation and workflow efficiency (33%), and reduce operational costs and technical debt (30%). That is a workable roadmap you can bring into planning. It matches what ICs need to ship and what DMs need to report.\nWhere Temporal fits\nThe report shows meaningful adoption of Durable Execution already: 49% overall and 60% in large companies, with only 8% unfamiliar. That maps cleanly to what both groups want. ICs get a programming model that completes work even when systems restart. Retries, backoff, and state persistence come standard, so workflows become easier to debug and safer to change. DMs get higher reliability without a growth in operator headcount. Incidents fall, recovery times improve, and the cost curve bends the right way.\nTemporal was built around that model. You write straightforward code for business logic and let the platform provide the survivability. Its a pragmatic way to move from we can start it to we can finish it every time, which is the difference customers feel.\nGet the full picture\nThis post is the highlevel read on where ICs and DMs agree, where they diverge, and how to use the split to make better decisions. The full State of Development 2025 report includes the segment cuts by role, company size, and region, plus the charts behind each number here. If youre planning next quarters reliability work or making a tooling case, it belongs in that meeting.",featureImage:{title:"social-card-water-effect",description:"social-card-water-effect",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6k8jGdFtBZEH3ltyuVQKwm/27cd3afdcda2b8032c6e120c5eb67d0f/social-card-water-effect.jpg"},publishDate:"2025-09-23",metaDescription:"ICs feel daily friction. DMs see business risk. State of Development 2025 puts both views on one page so teams share facts, cut toil, and raise reliability.",metaTitle:"Individual contributors vs. decision makers: Same systems, different realities",socialCard:{title:"Blog (42)",description:"Blog (42)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3JJDfmhcANv9c9Ozszvbxf/3237c93b62fcd5cee888076fb377ce6d/Blog__42_.png"},tags:"Durable Execution,Architecture",slug:"individual-contributors-vs-decision-makers-same-systems-different-realities",contentType:"blogPost",entityId:"1fZRJxLhzPejqqAziZC5oP",authors:[{id:"7GQtiP7y4Dmrje9sFWcVKl",name:"Lauren Bennett",slug:"lauren-bennett",jobTitle:"Content Marketing Manager",photograph:{title:"Lauren-Bennett-profile-photos",description:"Lauren-Bennett-profile-photos",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6jEqojw9RxBBjX5pytMzYf/4df0ef856a9efe4b7b52d5ebe7e83686/Lauren-Bennett-profile-photos.jpeg"},linkedInUrl:"https://www.linkedin.com/in/lauren-n-c-bennett/",contentType:"person"}],authorsString:"Lauren Bennett",category:"Community",promoCard:{title:"State of Dev 2025",eyebrow:"The State of Development 2025",heading:"Find out what 226 tech professionals have to say.",content:"Want a deeper look at our findings? Get your copy of Temporals State of Development 2025 report.",callsToAction:[{text:"Download now",href:"/pages/state-of-development-2025",variant:"primary",leadingIcon:null,trailingIcon:"arrow-right",entityId:"1eOw5MPvvDUef4Xl46TLCx",large:false,theme:"pink"}],entityId:"N3aCYyQMCp9iGXMKim3Pq",contentType:"noise"},readingTime:5},{title:"The agentic future with Temporal: A fireside chat",content:"Last week, we hosted a tech meetup at Essents offices in Den Bosch, exploring the relevance of todays software engineering wisdom in the agentic future. We brought together developers, architects, and technology leaders to discuss the practical realities of implementing agentic AI systems and what this shift means for software engineering.\nIn this post, Id like to capture the key takeaways from the fireside chat about agentic AI, and the path ahead of us. This is a joint blog post between Temporal, Essent, and Navara.\nWere in the Wild West of agentic AI\nOne of the most honest takeaways from our discussion acknowledged that were in the Wild West phase of agentic systems. This field moves fast, with constant uncertainty and few established best practices.\nFor both engineers and decision makers, this means adaptability and willingness to experiment are vital. Theres no playbook yet, and what works today might be outdated in six months. This uncertainty isnt necessarily bad news. It creates opportunities for organizations willing to invest in agents and systematic experimentation.\nTesting when things arent predictable or repeatable\nOne of our liveliest discussions was about quality assurance for agentic systems. Traditional software testing breaks down when the same input doesnt always give the same output.\nJosh (Engineering Manager  Conversational AI, Sinch) talked about how QA for their agentic systems rely heavily on evals (evaluations) and guardrails, which are often implemented using LLMs themselves. This creates interesting new challenges around cost, reliability, and defining what good enough means. When you can always improve aspects by spending more tokens, when do you stop? When does certainty reach a level that is acceptable?\nWe all agreed on the importance of making a conscious choice about what kind of task you delegate to an LLM, and which tasks you should delegate to deterministic and tested code. By lowering the set of actions an agent can take, and by implementing deterministic guardrails in which that action can be executed, its possible to control the impact of how far an agent is able to deviate from the intent we want it to deliver on. This approach resembles the way we treat humans a lot: Its a very bad idea to give every human agent raw direct administrative access to your production database, so why should we trust an agent with it? Rather, we should focus our efforts on making sure the agent is able to request data mutations or queries in the exact way that makes sense in the context of achieving its goal. This adds additional demands to our security architecture and internal documentation, but those demands do not differ from anything we consider to be good engineering practices today.\nThe bottom line: We dont have established best practices for testing the LLM components of agentic systems yet. The deterministic parts, especially the actions taken by the agent, can still be tested with traditional methods. Were all figuring out as we go how to handle quality assurance for the unpredictable, AI-driven parts, and we should limit the extent to which it can go off-track as a result.\nMost enterprises struggle with AI agent implementation\nA major theme in our conversations was this infrastructure readiness gap. Recent McKinsey research indicates that while 78% of companies are using generative AI, over 80% report no material earnings impact, and fewer than 10% of vertical AI use cases make it past the pilot stage. This suggests that the AI technology itself isnt the bottleneck: Its the underlying IT foundations that arent up to the task. To deliver a high-quality agent that does exactly what its supposed to, we need to provide it with the right tools and context to complete its goal. We also should not have to completely replace existing software with AI-driven replacement but rather augment them.\nThe usual suspects are to blame:\n\n  Legacy workflow tools that cant be augmented with dynamic AI-driven orchestration\n  Poorly documented interfaces that break reliable system integration\n  Manual edge-case handling that stops automated workflows dead and loops in humans\n  Weak internal security that creates vulnerabilities\n\nThe result: Based on early implementation experiences and industry data, organizations see 35x longer implementation times and frequent project failures when they try to deploy AI agents without proper groundwork. McKinsey reports that many companies are even retrenching  rehiring people where agents have failed.\nDynamic vs. static workflows\nWe had a great discussion about the trade-offs between different workflow approaches:\n\n  Dynamic workflows are flexible but harder to predict and test\n  Static workflows are more reliable but less adaptable\n\nThe consensus: A hybrid approach probably works best. Start with dynamic, agentic workflows to explore whats possible, then lock in successful patterns as static workflows once you understand them better. The reverse approach can be applied to existing workflows. Enable agents to assist or replace human interventions, and lock in the successful patterns as well.\nThis fits in extremely well with Temporals platform, which supports both flexibility and reliability without forcing you to choose one or the other.\nFrom prompt engineering to context engineering\nOur conversation highlighted an important shift in how we work with LLMs. The field is moving from prompt engineering to context engineering, focusing on giving LLMs exactly the right amount of context to get better results and reduce hallucinations.\nThis represents a real shift toward treating context as a strategic resource that we can build up from previous executions and event logs to make future agent behavior better.\nThe learn-codify-optimize cycle\nBut how do you provide the right context and actions to an agent? Especially if youre designing future AI-Ready systems:\n\n  Deploy agents for new processes (or existing process augmentations)\n  Capture decision patterns and outcomes\n  Analyze what works and what doesnt\n  Codify successful patterns into deterministic workflows\n  Scale across the organization\n\nThis is what organizations are doing to gradually build competitive advantages through adaptive, self-improving business processes. Its also a cycle that can be heavily optimized by letting several agents collaborate. A process-oriented AI agent can reduce manual labor inside processes, while an analytical learning agent can help to capture successful patterns. A coding agent can then suggest (deterministic) process improvements to the codebase, so the first agent is no longer required to step in. If this process turns into a well-oiled machine, it starts to provide agility and iteration cycles that will be very hard to beat as a human.\nUse a foundation-first approach\nIn all these scenarios, there is one constant: a need for increasingly solid software engineering practices. Multiple speakers stressed that organizations need proper foundations embedded in their action library before trying to implement agentic systems. Its a very dangerous risk when companies start to consider agents as a full replacement for software engineering instead of an augmentation.\nThe insight: Poorly designed legacy systems dont just slow you down: they create serious risks when autonomous agents start accessing them at scale.\nGood engineering fundamentals remain critical, even as new paradigms emerge. Organizations shouldnt abandon best practices while chasing innovation.\nThe economics matter\nWhen you start to run LLMs for continuous evaluation and guardrails, it quickly gets expensive, and organizations need to factor that into their planning. We need to start treating tokens as a resource. How many tokens do we want to spend on security? How many on testing? And how many on the business process itself? Do we want to spend tokens on creating a deterministic workflow, or do we want to spend tokens on being inside the process?\nThe entire group talked about finding a justification for spending LLM-credits: weighing flexibility against computational costs and unpredictability risks. This economic reality pushes us to systematically convert successful agentic behaviors into deterministic code once we understand the patterns.\nThe window is closing\nThroughout the event, we all emphasized the urgency. Industry analysis suggests that leading organizations started their foundation investments 1218 months ago, and every month of delay increases transformation costs exponentially. McKinsey notes that fewer than 30% of companies have CEO-sponsored AI agendas, indicating that many organizations are still in the early stages of strategic AI adoption.\nWere at a critical point where organizations face a clear choice: invest in proper foundations now for competitive advantage, or delay and permanently fall behind competition.\nWhats next: Practical steps\nFor organizations ready to start their agentic AI journey, our discussions made the path forward clear:\n\n  Start with infrastructure assessment  Understand your current capabilities and gaps\n  Invest in API-first architecture  Make sure all systems can be accessed reliably by both humans and agents\n  Implement dynamic orchestration  Choose platforms that support both deterministic and intelligent components inside the same workflows\n  Begin with human augmentation  Enhance existing decision points rather than replacing entire processes\n  Establish learning cycles  Create systematic approaches to capture and codify successful patterns\n\nKeep the conversation going\nAgentic AI is moving fast, and no single organization has all the answers. We need to keep sharing knowledge, learning from each others experiences, and collectively figuring out what works.\nThe future belongs to organizations that can combine human judgment with intelligent automation in ways that adapt and improve over time. The infrastructure decisions you make today will determine your competitive position for the next decade.\nThe question isnt whether agentic AI will transform your industry: its whether youll lead that transformation or struggle to catch up.\nReferences and notes\n McKinsey & Company. Seizing the agentic AI advantage. June 13, 2025. (link) McKinsey & Company. One year of agentic AI: Six lessons from the people doing the work. September 12, 2025. (link) Temporal Technologies. The fallacy of the graph: Why your next workflow should be code, not a diagram. August 20, 2025. (link)\nThe field of agentic AI is rapidly evolving, with most implementation data coming from early pilot programs and organizational case studies rather than comprehensive peer-reviewed research. Statistical claims reflect industry observations and early adopter experiences as of September 2025.",featureImage:{title:"social card - green waves",description:"social card - green waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4GBHZR0vUnoRSbPtSTCH4s/daf7308a10e469059827e2169065d7ea/social_card_-_green_waves.jpg"},publishDate:"2025-09-22",metaDescription:"Key takeaways on agentic AI: testing unpredictable systems, hybrid workflows with Temporal, context engineering, cost tradeoffs, and practical next steps.",metaTitle:"The agentic future with Temporal: A fireside chat",socialCard:{title:"Blog (40)",description:"Blog (40)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5KV3oMgyeaR0yYVz11hYD8/19c99a0176dcafd9ad5a7394c8d1b601/Blog__40_.png"},tags:"AI/ML",slug:"the-agentic-future-with-temporal-a-fireside-chat",contentType:"blogPost",entityId:"78IhuV4aNEUHQPyQeg2VRm",authors:[{id:"40LAknF73876x2QIpGLfwh",name:"Jeroen Vollenbrock",slug:"jeroen-vollenbrock",jobTitle:"Enterprise Architect at Essent; Principal Consultant at NAVARA",photograph:{title:"1670571029337",description:"1670571029337",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2ktPFhgaSMAKFgYpDMhbSi/892d20777bff5c1982f89d031812bbb6/1670571029337.jpeg"},linkedInUrl:"https://www.linkedin.com/in/jeroen-vollenbrock-58217052/",company:"Essent, NAVARA",contentType:"person"}],authorsString:"Jeroen Vollenbrock",category:"How-To",readingTime:9},{title:"Orchestrating ambient agents with Temporal",content:"\nBuilding a proactive, 247 crypto trading platform with multiple AI agents has been both challenging and enlightening. Using Temporal for orchestration and the Model Context Protocol (MCP) for tool interfaces, I designed a system around three core agents: a broker agent (the user-facing entry point that manages intents and orchestrates Workflows), an execution agent (responsible for making and executing trading decisions), and a judge agent (that continuously evaluates performance and updates the execution agents system prompt and strategy). Surrounding these are supporting Workflows for market data, order placement, and ledgering.\nThe inspiration came this past June at the AI Engineers Worlds Fair in San Francisco, where I first encountered the concepts of ambient intelligence and proactive AI at a breakout hosted by AWS and Anthropic. The idea of agents that run continuously  quietly nudging the system forward without waiting for explicit prompts  sparked this project. Then in July, at IBMs AI Agent Meetup, Claire Longos talk introduced the idea of an LLM as judge. It was such a compelling concept that I quickly extended my architecture with a judge agent, turning the system into one that is not only proactive but also self-refining over time.\n\n  Along the way, I discovered several key advantages of using Temporal in such an AI-driven system. In this post, Ill dive into what I learned about five crucial features of Temporal and how they benefited my multi-agent architecture: Schedules, Signals & Queries, Temporals UI, workflow orchestration, and Temporal primitives as MCP tools.\n  \n  \n\nTemporal Schedules: Enabling proactive agents\nOne of the first challenges was ensuring the trading agents act proactively at regular intervals without a user having to take action. Crypto markets never sleep, so my trading agent needed to wake up periodically, analyze data, and make decisions continuously. Temporals Schedules feature turned out to be perfect for this. Instead of writing custom cron jobs or sleep loops, I defined a Temporal Schedule that triggers a nudge Workflow every few seconds to prompt the execution agent to analyze the portfolio status and market data. This made the agent truly ambient  always running on a schedule managed durably by Temporals Server, not by ad-hoc timers in my code. This led to a powerful realization for me: LLM providers, like OpenAI & Anthropic, will provide the brain for ambient agents, but Temporal will provide the ever-beating heart that keeps the system running durably.\nFor example, I created a schedule called \"ensemble-nudge\" to run a Workflow every 25 seconds. In code it looks like this:\nschedule = Schedule(\n    action=ScheduleActionStartWorkflow(\n        workflow=EnsembleNudgeWorkflow.run,\n        id=\"ensemble-nudge-wf\",\n        task_queue=\"mcp-tools\",\n    ),\n    spec=ScheduleSpec(intervals=[ScheduleIntervalSpec(every=timedelta(seconds=25))]),\n)\nawait client.create_schedule(\"ensemble-nudge\", schedule)\nWith a few lines, Temporal ensures a Workflow (EnsembleNudgeWorkflow) is started on that interval. This built-in scheduling freed me from managing threads or external cron services. If the Worker or process restarts, the schedule is still tracked by Temporal and will fire the next Workflow on time. Temporal Schedules thus made it easy to implement an always-on agent that reacts regularly without human intervention.\nSignals & Queries: The language of inter-agent communication\nIn a multi-agent system, the agents need to talk to each other. Temporals Signals and Queries became the backbone of communication between my agents Workflows. Each AI agent (broker, execution, judge) is implemented as a long-running Workflow that maintains state and waits for Signals. This is similar to an actor model: agents are always alive (durably so, thanks to Temporal) and react to incoming Signals/Events, and they expose Queries to fetch their internal state. I found this far cleaner and more reliable than building custom messaging or polling mechanisms.\n@workflow.signal\ndef update_system_prompt(self, prompt: str) -> None:\n    \"\"\"Update the system prompt for the execution agent.\"\"\"\n    self.system_prompt = prompt\n    workflow.logger.info(f\"System prompt updated (length: {len(prompt)} chars)\")\n\n@workflow.query\ndef get_system_prompt(self) -> str:\n    \"\"\"Get the current system prompt.\"\"\"\n    return self.system_prompt\nWith these in place, the LLM-as-judge agent can dynamically tune the execution agents behavior. After each performance evaluation, the judge uses Temporals client API to get a handle to the execution agents Workflow (by ID) and send it a Signal with a new prompt.\nFor example, the judge agent code calls:\nawait handle.signal(\"update_system_prompt\", improved_prompt)\nThis is done whenever it determines a prompt update is needed. This Signal delivery is asynchronous and reliable  Temporal ensures the Signal is delivered to the Workflow instance, even if the target Workflow is running on a different Worker or the process restarts. In my case, I could see the ExecutionAgentWorkflow received the prompt update and logged the change (\"System prompt updated...\" appears in the Workflow logs).\nI also used Signals for other interactions: a nudge Signal triggers the execution agent Workflow to begin its analysis, and logging Signals are used to record decisions and actions in each agents log Workflow. Queries complement this by allowing an agent to pull data from another agent. For example, the judge agent queries the execution agent for its current system prompt, and the broker agent queries the ledger Workflow for recent portfolio status & transaction history. Signals and Queries gave me a simple, strongly ordered way for inter-agent communication without needing an external message bus. This decoupling via Temporal constructs kept each agent Workflow isolated yet cooperative.\nObservability with Temporal UI: Watching agents in action\n\n  When orchestrating multiple intelligent agents, understanding what happened when is crucial. Temporals Web UI became an invaluable tool for observing the systems behavior in real time. Every agent and tool in my system runs as a Temporal Workflow, which means I have a timeline of each Workflows execution and Events accessible in the UI. This proved extremely helpful for debugging and trustworthiness: I could literally watch the agents interactions step by step.\n  \n  \n  For example, whenever the judge agent updated the execution agents prompt via a Signal, I could open the ExecutionAgentWorkflow in Temporals UI and see the Signal Event recorded at that timestamp. Right next to it, Id see the log entry confirming the prompt change. Similarly, the schedule-triggered Workflows (the nudges) showed up as runs of the EnsembleNudgeWorkflow every 25 seconds, visible in the history. Having this chronological view made it easy to answer questions like: Did the execution agent receive the nudge on time? Did the judge agent run its evaluation cycle after 10 minutes as expected? I could trace all these events in one place.\n\nThe Temporal UI also gave me confidence in the systems auditability. Each Workflows history is stored, so I have an exact record of every decision and action the agents took (with timestamps and inputs)  a critical requirement in financial systems. Instead of logging to scattered files, I relied on Temporals histories (and some custom Workflow logs) to inspect what the agents were doing. This observability was especially useful when the agents behavior became complex; being able to visualize their coordination in the UI helped me fine-tune the Schedules and Signal handling. In short, Temporals UI turned the black-box nature of AI agents into a glass box, where I could see and debug the internals of the multi-agent orchestration easily.\nOrchestrating multiple agents with Temporal Workflows\nCoordinating several agents and services  ticker feeds, a trading agent, a performance judge, and more  can get complicated fast. Temporal simplified this by acting as the central orchestrator for all agent workflows. In my design, each major component is a separate Workflow (or set of Workflows) and Temporal manages their lifecycles and interactions. This yielded a system where agents can run truly 247 with resilience and clarity in how they interact.\nAs I mentioned above, the architecture consists of three primary agents: a broker agent (user interface Workflow), an execution agent (trading decisions Workflow), and a judge agent (LLM-as-judge evaluator Workflow), plus supporting Workflows for market data streaming, order execution, and an execution ledger. Temporal allowed these to be broken into modular Workflows that each handle their domain. The broker starts a market data subscription Workflow which streams data from Coinbase. The execution agent Workflow listens for nudge Signals (from the Schedule) and uses MCP tools as Workflows/Queries/Signals to fetch data and place orders. The judge Workflow wakes up periodically (or on demand) to analyze performance and then signals the execution agent with adjustments. All of this is orchestrated by Temporal in a single connected system.\nThe benefit was huge: continuous orchestration without downtime, and guaranteed state tracking. Temporals fault tolerance means if one agent Workflow or Activity fails, it can be retried or continued without bringing down the whole system. This was critical because crypto trading must not stop; Temporal gave me the building blocks to ensure the agents coordinate reliably around the clock. Additionally, because Temporal Workflows are deterministic and replayable, I gained deterministic audit trails of the agents decision processes  an important factor if I ever need to explain a trade or comply with regulations.\nOrchestrating with Temporal also simplified the design: rather than writing complex multi-threaded code or managing distributed state, I let Temporal Workflows handle concurrency and state isolation. Each agent had its own Workflow instance (for example, an ExecutionAgentWorkflow with a well-known ID) and could maintain internal variables (like the current prompt or recent actions) in memory safely. Temporals single-responsibility Workflows made the multi-agent system easier to extend too. I can add another agent or tool by just creating a new Workflow and perhaps scheduling or signaling it, without touching the core loop of other agents. This modular orchestration on Temporal proved to be a robust way to manage a complex ensemble of AI components.\nTemporal primitives as MCP tools: Durable actions for AI Agents\nOne of the most powerful patterns I implemented was using Temporal primitives (Workflows, Signals, Queries) as the tools that the AI agents call to interact with the world. In the Model Context Protocol (MCP) framework I used, agents invoke tools like get_historical_ticks, place_order, get_portfolio_status, etc., to gather data or execute trades. Instead of these tools being simple functions or external APIs, I made each one a Temporal primitive under the hood. This marriage of MCP tools with Temporal brought significant reliability, observability, and scalability benefits.\nFor example, when the execution agent wants to execute a trade, it calls a place_mock_order tool. That tool is actually implemented as a Temporal Workflow (PlaceMockOrder) which wraps an Activity to simulate the trade fill. Heres a glimpse of that Workflow code:\n@workflow.defn\nclass PlaceMockOrder:\n    @workflow.run\n    async def run(self, intent: OrderIntent) -> Dict:\n        logger.info(\"Placing mock order: %s\", intent)\n        result: Dict = await workflow.execute_activity(\n            mock_fill,\n            intent,\n            schedule_to_close_timeout=timedelta(seconds=5),\n            retry_policy=RetryPolicy(maximum_attempts=1),\n        )\n        return result\nEvery time the agent places an order, its invoking this Workflow. The use of Temporal here means the action is durable, and if the underlying Activity fails (say the exchange API is down, in a real scenario), Temporal can retry or timeout gracefully. In fact, every @mcp.tool() in the system is backed by a deterministic Temporal Workflow, which gives us automatic retries and full replay for audit/compliance out of the box. The AI agents tools became durable operations. I didnt have to worry about inconsistent state if an agents tool call crashed midway  Temporal ensures either the whole Workflow completes or it doesnt happen at all, and we can always inspect what happened from the history.\nUsing Temporal for tool implementations also kept the agents reasoning loop deterministic. The agent (an LLM) would decide on an action, call a tool, and receive the result  all that heavy lifting (fetching market data, logging a trade, etc.) was done inside a Temporal Workflow which is isolated from the agents prompt and handled by a Temporal Worker, keeping the MCP servers load low. This maintains a clear separation: the MCP server shows what can be done, the LLM decides what to do, and Temporal Workflows handle how its done reliably. The result is an AI trading system that marries the flexibility of LLM-driven decision-making with the robustness of Temporals Workflow execution.\nReal-time feedback routing\nIn this multi-agent crypto trading system, the broker agent acts as a coordinator that relays human feedback to the appropriate specialist agent (either the execution or judge agent) without needing to interrupt their operation. The broker leverages an MCP tool called send_user_feedback for this purpose. When the broker receives a users feedback, it invokes this tool with a target parameter indicating which agent should get the message. Internally, the tool uses the target to fetch the corresponding Temporal Workflow handle and sends an asynchronous Signal to that agents Workflow. For example, if target_agent=\"execution\", it grabs the execution agents Workflow (\"execution-agent\") and signals its add_user_feedback method with the feedback payload; if targeting the judge, it does the analogous call on the judge agents Workflow:\n# Broker routes feedback by signaling the target agent's workflow\nif target_agent.lower() == \"execution\":\n    handle = client.get_workflow_handle(\"execution-agent\")\n    await handle.signal(\"add_user_feedback\", feedback_data)\n    # ... feedback sent to execution agent ...\nelif target_agent.lower() == \"judge\":\n    handle = client.get_workflow_handle(\"judge-agent\")\n    await handle.signal(\"add_user_feedback\", feedback_data)\n    # ... feedback sent to judge agent ...\nThis simple routing logic ensures the right agent receives the users note in real time. Because the broker uses Temporal Signals, the feedback delivery is fire-and-forget  it does not interrupt the agents ongoing Workflow. The broker agent merely acts as a messenger, letting the specialized agents handle the feedback when they are ready.\nOn the receiving end, both the execution and judge agents Workflows define an add_user_feedback Signal handler to record these incoming messages. In the ExecutionAgentWorkflow, for instance, add_user_feedback simply timestamps the feedback, assigns a unique ID, marks it unprocessed, and appends it to an internal list of feedback messages:\n@workflow.signal\ndef add_user_feedback(self, feedback_data: Dict[str, Any]) -> None:\n    \"\"\"Add user feedback to be incorporated into the agent's conversation.\"\"\"\n    feedback_entry = {\n        **self._get_timestamp(),\n        \"feedback_id\": f\"feedback_{len(self.user_feedback) + 1}\",\n        \"message\": feedback_data.get(\"message\", \"\"),\n        \"source\": feedback_data.get(\"source\", \"user\"),\n        \"processed\": False\n    }\n    self.user_feedback.append(feedback_entry)\n    workflow.logger.info(f\"User feedback received: {feedback_data.get('message', '')[:100]}...\")\nThe JudgeAgentWorkflow implements the same pattern for its own feedback list (GitHub). Storing feedback in a queue with a processed=False flag allows the agent to defer processing until a convenient moment. The running agent (e.g., the execution agents loop) can periodically query its Workflow for any pending feedback (via a get_pending_feedback query) and incorporate those messages into its context. For example, the execution agents client checks for new feedback and injects it into the conversation as a special user message (e.g., prefixing with [USER FEEDBACK]), then marks it as processed. This design lets a human trader nudge or guide the agents on the fly  the feedback is delivered instantly and queued, to be digested by the agent without halting its autonomous flow. In short, the Brokers feedback relay and the agents Signal handlers work together to enable real-time human guidance of the trading agents without any interruption to their Workflows.\nConclusion\nBuilding an always-on, multi-agent trading system with an AI and a human-in-the-loop taught me just how much a platform like Temporal can simplify complex automation. Here are the key takeaways from this project:\n\n  Proactive orchestration with Schedules  Agents can operate continuously without custom schedulers or external cron jobs.\n  Real-time communication with Signals and Queries  Agents can coordinate, share state, and accept human feedback seamlessly without pausing their loops.\n  Visibility with the Temporal UI  Every agent action, Signal, and update is captured in Workflow history, making the system transparent, debuggable, and auditable.\n  Reliability from Temporals core guarantees  Durable Execution, retries, and durable state tracking ensure the system runs 247 without drift or data loss.\n  Durability by implementing tools as Workflows  Every agent action is executed as a Temporal Workflow, giving audit trails and fault tolerance for free.\n  Extendability  Adding a new agent or tool is as simple as creating another Workflow. The modular architecture makes it straightforward to experiment, iterate, and grow the system.\n  Team-friendly design  Temporal enforces a clean separation of concerns: one engineer can focus on a single Workflow, develop and test it locally, and deploy it independently. This makes collaboration easy, even on a multi-agent system.\n\nIn the end, Temporal handled the timing, communication, reliability, and observability, freeing me to focus on the higher-level logic of the agents. Thats what made it possible to turn a set of experimental AI agents into a robust, proactive trading system  a pattern I expect to reuse in future projects where complex agents need dependable orchestration.",featureImage:{title:"hazel-z-45AHiklPJH4-unsplash",description:"hazel-z-45AHiklPJH4-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Potp6G9LHoZ780AhLw3vs/861da43ba6e469417a7a9084b708e71f/hazel-z-45AHiklPJH4-unsplash.jpg"},publishDate:"2025-09-18",metaDescription:"How Temporal and MCP power a 24/7 crypto trading system of ambient agents: Schedules, Signals and Queries, durable tools, and auditability.",metaTitle:"Orchestrating ambient agents with Temporal",tags:"AI/ML,Code Samples,Finance,Python,Temporal Primitives",slug:"orchestrating-ambient-agents-with-temporal",contentType:"blogPost",entityId:"5tH2iuRPYt0J93ocSQ25YZ",authors:[{id:"6o3jzEvdJJ2BGf8hYHFlPH",name:"Kevin Martin",slug:"kevin-martin",jobTitle:"Sr. Strategic Account Executive",photograph:{title:"kevin-martin-headshot",description:"kevin-martin-headshot",url:"https://images.ctfassets.net/0uuz8ydxyd9p/zgFcGzBwVwP7Vk6Qoujc6/e5eca529c6261ddb28daaad3a0072412/TT31S6VK5-U04HVHG9D6W-31cb48b66c24-512.jpeg"},company:"Temporal",contentType:"person"}],authorsString:"Kevin Martin",category:"How-To",readingTime:14},{title:"How banks are cutting development time in half while avoiding million-dollar outages with Temporal Cloud",content:"\n  \n  When a major financial services firm couldnt scale their payment settlements during peak load, watching execution times balloon from sub-seconds to 45+ seconds, they knew their homegrown workflow system had hit its limit. Within weeks of adopting Temporal Cloud, those same settlements ran at sub-second speeds even during their highest volume events.\n\nThis story, captured in Forresters Total Economic Impact study, reflects whats happening across the banking industry: institutions are replacing fragile, homegrown workflow systems with Temporal Cloud and seeing immediate, measurable returns.\nThe reliability dividend: $14.3M in preserved revenue\nEvery bank knows the true cost of downtime. Forresters analysis quantifies what Temporal Cloud customers already experience: one to two major outages avoided annually, each preventing roughly 20 hours of downtime.\nFor the composite organization in the study (modeled on real Temporal customers), this translates to:\n\n  $14.3 million in preserved revenue over three years\n  $1.5 million in protected operating profit\n  Near-elimination of manual payment reconciliation processes\n\n\n  \n  One engineering manager put it simply: Temporal has never caused an incident. We have two exact examples of teams saying Temporal made them NOT have an incident while other systems were failing.\n\nSpeed that compounds: Features delivered 50% faster\nBanks operate in a world where competitive advantage is measured in weeks, not quarters. The Forrester study documents teams consistently delivering features in half the time:\nBefore Temporal:\n\n  Three months to build a new payment feature\n  Fear of making changes to critical workflows\n  Weeks spent on distributed systems complexity\n\nWith Temporal:\n\n  1.5 months for the same feature\n  Changes that once took months completed in days\n  Engineers focused on business logic, not infrastructure\n\nA VP of Engineering captured the shift with one remarkable example: What was going to be a several-month effort became twelve lines of code. We spent longer testing it than coding it.\nThe productivity multiplier effect\nThe study reveals a pattern that CFOs will appreciate: productivity gains that grow with adoption. Engineers directly using Temporal see a 15% productivity improvement, but the impact doesnt stop there. Adjacent teams benefit from the more stable foundation, capturing an additional 1% productivity lift even without touching Temporal directly.\nStarting with just nine developers in Year 1 and growing to 60 by Year 3, the composite organization captured over $1 million in productivity value  hours previously lost to incident response now reinvested in innovation. The compound effect becomes clear as adoption spreads: each team that adopts Temporal makes the next teams adoption easier, creating a virtuous cycle of improvement.\nReal paths to production: Weeks, not quarters\nUnlike traditional infrastructure overhauls, teams describe remarkably fast paths to value:\n\n  Week 12: Platform running, prototype working\n  Month 13: First production use case live\n  Month 36: Full migration of initial workflows\n\nThe learning curve proves equally manageable. The study models 50 hours of training per developer, aligning with the one to two weeks teams consistently report for becoming productive. As one senior engineering manager put it: Temporal is a quick spin-up.\nThe Cloud advantage: Focus on business, not infrastructure\nFor organizations that previously self-hosted Temporal, the Cloud migration math was clear: If we had to host our own Temporal, we would need four more high-level SRE engineers. Thats $2 million a year in salary and benefits.  Engineering Manager, Financial Services\nThe composite organizations total Temporal Cloud investment over three years:\n\n  Cloud services: $811K (risk-adjusted PV)\n  Implementation and management: $345K\n  Developer training: $226K\n  Total: $1.38M against $4.16M in benefits\n\n\n  \n\nBuilt for banking: Security and compliance by design\nFor regulated environments, the architecture matters as much as the economics. The study confirms what banking security teams need to hear:\n\n  Data sovereignty maintained: Temporal never receives or processes sensitive customer data\n  Encryption supported: End-to-end encryption available for workflow data\n  Compliance-ready: Retained storage for audit trails and regulatory requirements\n\nWe had a security team member audit all our SaaS solutions including Temporal and had no qualms. Nothing came up as an issue.\nBeyond the numbers: Strategic advantages\nWhile Forresters model focuses on quantifiable benefits, interviewed organizations highlighted additional strategic value:\nTalent and retention\nWeve had people specifically apply because they want to work with Temporal, one senior engineer reported. *Its increased the quality of our hiring pipeline. *\nDeveloper retention improved as well, with teams attributing reduced turnover to the improved daily work experience Temporal enables.\nEnabling transformation initiatives\nMultiple banks reported Temporal as crucial for monolith decomposition and core modernization efforts  transformational initiatives where failure carries enterprise-level consequences. These competitive non-negotiables determine whether a bank can launch products in weeks while competitors take months.\nCompetitive differentiation\nAs one senior engineering manager reflected: Were building foundations that allow us to deliver bigger and better features faster that didn't even seem possible years ago.\nThis compounds over time: each successful workflow makes the next one easier to build, creating accelerating returns that dont show up in Year 1 ROI models but reshape whats possible by Year 3.\nYour next steps\n\n  \n\nThe full Forrester TEI study includes detailed financial models you can customize with your banks specific metrics:\n\n  Your incident costs and frequency\n  Your feature delivery timelines\n  Your developer productivity baseline\n  Your infrastructure and staffing costs\n\nEvery assumption is transparent, every calculation risk-adjusted, and every benefit traced to actual customer experiences.\nDownload the complete Forrester Total Economic Impact study to see the full methodology, detailed calculations, and interview insights.\nReady to see Temporal Cloud in action with your workflows? Schedule a technical discussion with our team.\n\nThe Total Economic Impact of Temporal Cloud is a commissioned study conducted by Forrester Consulting on behalf of Temporal, April 2025. Results are for a composite organization based on interviewed customers and will vary.",featureImage:{title:"li-zhang-ZvVydsVkyTI-unsplash",description:"li-zhang-ZvVydsVkyTI-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3WwtmBoVCX8MFqaV2ZTQUq/fc4fc75dd2e1d75a6a36d292827b8d80/li-zhang-ZvVydsVkyTI-unsplash.jpg"},publishDate:"2025-09-09",metaTitle:"How banks are cutting development time in half while avoiding million-dollar outages with Temporal Cloud",tags:"Finance,Durable Execution,Cloud",slug:"how-banks-are-cutting-dev-time-in-half-with-temporal-cloud",contentType:"blogPost",entityId:"36MiX4Qgt9wkhpK62K29gk",authors:[{id:"34cWvSvA3k7OXa2mTLiObI",name:"Hannah Short",slug:"hannah-short",jobTitle:"Senior Campaign Manager",photograph:{title:"IMG 7573",description:"IMG 7573",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2NbDEiJTsL6S8rgybVuVtN/55aed833cc81917a2c804d026f5a2396/IMG_7573.jpeg"},linkedInUrl:"https://linkedin.com/in/hjmoyer",company:"Temporal",contentType:"person"}],authorsString:"Hannah Short",category:"Announcements",readingTime:5},{title:"Temporal and the next frontier: Scaling AI reliably ",content:"Building for the next wave: AI, infrastructure, and what's ahead for Temporal\nSoftware is moving at a pace Ive never witnessed before. AI agents that were weekend experiments just six months ago are now running in production, making big decisions for real businesses. Its unprecedented and just as exciting as it is nerve-wracking.\nCompanies are orchestrating complex workflows that combine traditional business logic with AI decision-making, but infrastructure challenges haven't gotten easier; in fact, they've only gotten more difficult.\nAt Temporal, we've always focused on one thing: making it simpler to build systems that work and keep working  reliably at scale and in the messy reality of prod. That mission matters more today than ever.\nSupporting developers in the AI era\nJust in the past year, Ive watched our community tackle increasingly complex challenges I couldnt have even imagined a few years ago. Teams are building agentic workflows, integrating multiple AI models, and managing stateful processes that span both traditional and AI-driven systems.\nIm continually inspired by how our team shows up for the developer community. Weve doubled down on meeting developers where they are  whether thats through powerful integrations, hands-on learning, or collaborative partnerships. Some of which include:\n\n  \n    [Updated SDKs] Our work with OpenAI integrated their Agents SDK with Temporal, making it simpler to build production-ready AI agents that stay resilient when things go wrong.\n  \n  \n    [Technology Partnership] Weve deepened our partnership with MongoDB to enable developers to orchestrate reliable AI use cases built on MongoDB, including agents, RAG, and context engineering pipelines.\n  \n  \n    [Technology Partnership] Pydantic's recent integration with Temporal as the underlying durable runtime will help developers build fault-tolerant agents that are production ready.\n  \n  \n    [Services Partnership] Weve partnered with Grid Dynamics to help leading global enterprises bring their vision for AI to life with durable, observable agentic solutions engineered to thrive in the complexity of real-world environments.\n  \n  \n    [Education] And were investing in education sparking aha moments at the AI Engineers Worlds Fair and creating practical guides, and tutorials packed with tools and guidance to help you strengthen your agentic workflows with Temporal.\n  \n\nIm so proud of my team not just for talking the talk, but working together when and where we can to make better solutions for you.\nTaking the next step\nI'm excited to announce that we've acquired Crystal DBA. The team has deep systems and AI expertise. Key members, including Founder and CEO Johann Schleier-Smith, have joined Temporal. Crystal DBAs mission aligns closely with Temporals  both companies have been working to remove complexity from software development, improving velocity while supporting reliability and scalability. As we join forces, we are committed to delivering this vision for the full range of AI applications, including agents, ambient AI, and more.\nWhat's driving this\nTemporal exists because Max and I are just like you: often frustrated engineers without the tooling to meet the mark. That same spirit (a deep respect for developer time and focus) guides everything we do. When developers tell us they're spending too much time managing infrastructure instead of building features, we listen. When they need better tools for AI workflows, our team and partners deliver them, and well keep doing it because our job is to make your job easier.\nMoving forward\nWe're committed to this mission. Its why were invested in our people just as much as our product. I'm thrilled to welcome Kate Caulfield as our VP of People. Kate is focused on fostering a thriving culture, evolving our hiring practices, and shaping an internal community that reflects the same values we bring to our products: clarity, reliability, and collaboration.\nIf you're passionate about simplifying how software is built and want to work alongside a team committed to solving hard problems, wed love to hear from you.",featureImage:{title:"Temporal and the next frontier",description:"Temporal and the next frontier",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7tSC5znZDAYjP8Mq4wkbpc/cfff7853e7aa45274e39620d9b52ee64/temporal-openai-Samar-blog-card.png"},publishDate:"2025-09-03",metaDescription:"At Temporal, we've always focused on one thing: making it simpler to build systems that work and keep working  reliably at scale and in the messy reality of prod. That mission matters more today than ever.",metaTitle:"Temporal and the next frontier: Scaling AI reliably ",socialCard:{title:"Temporal and the next frontier",description:"Temporal and the next frontier",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7tSC5znZDAYjP8Mq4wkbpc/cfff7853e7aa45274e39620d9b52ee64/temporal-openai-Samar-blog-card.png"},tags:"AI/ML,Architecture,Scaling",slug:"temporal-and-the-next-frontier-scaling-ai-reliably",contentType:"blogPost",entityId:"1KAmgehf8wdOZIDEl9gB4S",authors:[{id:"1xCMA9tU4DFRKfBJgJaBRo",name:"Samar Abbas",slug:"samar-abbas",jobTitle:"CEO and Co-Founder",photograph:{title:"Samar Abbas",description:"Samar Abbas",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5ET9VSHfvnFpbBEmpfoBDN/f5bd4ea1eeb428c5f8f4bcf02246ec82/861A2427.jpg"},biography:"Samar is CEO and cofounder of Temporal. He is a 20-year veteran of AWS, Microsoft and Uber engineering leadership, having worked on Amazon Simple Workflow Service from inception and led development of the Durable Task Framework at Azure, and then co-creating Cadence (Temporals predecessor) at Uber. Today, millions of Temporal workflows are run daily for high reliability and high scalability workloads from Stripe to Datadog to Snapchat.",twitterUrl:"https://twitter.com/samarabbas77",company:"Temporal",contentType:"person"}],authorsString:"Samar Abbas",category:"Announcements",relatedPosts:[{title:"Production-ready agents with the OpenAI Agents SDK + Temporal",content:"AI agents have become the dominant approach to building applications that leverage LLMs. They are AI-powered applications that dont just respond to input, but actively pursue objectives using LLMs, memory, and tools. While I dont believe there will ever be a single way to build these agents, some patterns are proving to be broadly applicable, and they are starting to show up as primitives in AI-centric programming frameworks, like the [OpenAI Agents SDK](https://openai.github.io/openai-agents-python/).\n\nI [worked](https://www.linkedin.com/posts/corneliadavis_i-got-a-sneak-peek-of-openais-new-typescript-activity-7335715652113965056-W0x3?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAAhTwsBq4aUmU3cyayfty14XAtw6XElih8) with the [TypeScript](https://openai.github.io/openai-agents-js/) version of OpenAIs SDK a couple of months ago, but as of late have had a reason to dig deeper into the original [Python](https://openai.github.io/openai-agents-python/) one, and its pretty darn slick. I personally love anything where one of the stated goals is to keep the model as simple as possible, but only when it also stays the heck out of the way of the developer (nod to my friend and former boss Tom). These are the two stated goals of the OpenAI Agents SDK.\n\nBut the reason I come to you today is to share the news that things just got even better.\n\n__OpenAI and Temporal have teamed up to add [*Durable Execution*](https://temporal.io/blog/what-is-durable-execution) to agents built using OpenAIs Agents SDK, and today we released the new integration in Public Preview.__\n\nThis means that AI agents you build with the OpenAI Agents SDK will stand up to any manner of challenges thrown at them in production. Rate-limited LLMs? Your apps will hang on and automatically progress when there is once again sufficient capacity. Sporadic network connectivity? Your app will retry downstream requests until they get through. Your app crashes when its just about done with a long-running task? Restart it, and Temporal will see to it that it picks up where it left off, saving you compute and token costs! That crash was due to a bug you hadnt caught yet? Yup, you can even fix that bug and continue execution of running apps.\n\n\u003Cdiv style=\"position: relative; width: 100%; overflow: hidden; padding-top: 56.25%;\">\n  \u003Ciframe \n    style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;\"\n    src=\"https://www.youtube.com/embed/fwh21RV6bRo?si=473USfNYHOzcuRAp\" \n    title=\"YouTube video player\" \n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" \n    allowfullscreen>\n  \u003C/iframe>\n\u003C/div>\n\nThats what Durable Execution gives you  crash-proof execution. Once the app starts running, Temporal will keep it running even in the face of all of these types of problems.\n\nBut heres the thing. You get all of this without an increase in code complexity. In fact, if you are new to Temporal, let me share with you one of the core Temporal values: With Temporal, you get to code the happy path, and Temporal does the error handling for you.\n\nThats right. __Both OpenAI and Temporal share the foundational tenet of making the developer productive, yet both also give the developer the agency to do any manner of complex things.__ This is an integration thats making this developers heart sing!\n\nAnd let me draw your attention to the title of this post  it carries the word production-ready. While there are a fair number of frameworks out there that can help you build AI agent proof-of-concepts with relative ease, solutions that allow you to carry those experiments forward to production with comparable ease are few and far between.\n\nIn this post, I want to tell you about the new integration that does exactly that  allows you to get started quickly, and helps you achieve the durability you need for deploying this in the real world. Ill cover how it works, what you can do with it, and the value it brings. Ill start with a super quick intro to the most relevant parts of the Agents SDK and of Temporal  just enough to understand the magic that the integration brings. (Feel free to skip those parts if you are already aficionados thereof.) Then Ill jump into the details of the magic. Ill also share a set of steps you can follow to take your existing Agent SDK apps and add the Temporal integration.\n## OpenAI Agents SDK: Easy-to-use agent primitives\nWith the goal of simplicity, the OpenAI Agents SDK defines only four primitives:\n- Agents\n- Handoffs\n- Guardrails\n- Sessions\n\nFor today, well focus on only the first two, but for a bit of context, guardrails are about putting some bumpers around user input (prompts), and sessions are about managing your applications memory.\n\nAn agent is, if you will, the core compute abstraction for your agentic apps. It starts with an LLM (and yes, each agent you define can point to a different model) and attaches to it:\n- Instructions that focus the LLM on very specific goals (e.g., you are a research assistant),\n- Tools that the LLM can decide to execute in pursuit of that goal,\n- A list of other agents that it may handoff control to,\n- And a bit of other configuration.\n\nHeres a definition of a triage agent that will take in user input and decide whether it should hand off to a weather reporting agent or a local businesses agent:\n\n```python\nfrom agents import Agent\nagent = Agent(name=\"Triage Agent\", \n              model=\"gpt-4o-mini\",\n              instructions=\"You are to decide whether the user is asking about \" +\n                           \"weather or information about local businesses. You \" + \n                           \"will handoff to the appropriate agent.\",\n              handoffs=[weather_agent, local_biz_agent],\n)\n```\n\nA handoff is just what you think  it passes application control from one agent to another.\n\nIn order to understand how the Temporal/OpenAI Agents SDK integration works, its important for you to think of these agents as independent units, and your application will orchestrate a bunch of these units  agents  to get a job done. Handoffs are one way to orchestrate agents (well come to the other momentarily).\n\nTo run an agent, you will use another entity supplied by the Agents SDK  a Runner. A Runner establishes a context and then runs the agent in that context. To run the above agent, for example, you would execute the following:\n\n```python\nresult = Runner.run_sync(agent, \"How late is Costco open?\")\n```\n\nOf course, you can write application logic that runs an agent, takes the output and uses that as input to the next agent, and so on. This is the second way that you can orchestrate the agents that make up your application. The triage agent could, for example, have been written as follows:\n\n```python\nfrom agents import Agent\ntriage_agent = Agent(name=\"Triage Agent\", \n              model=\"gpt-4o-mini\",\n              instructions=\"You are to decide ...\",\n)\nweather_agent = Agent(...)\nlocal_biz_agent = Agent(...)\nquery=\"How late is Costco open?\"\nresult = Runner.run_sync(triage_agent, query)\nif \"weather\" in result:\n    Runner.run_sync(weather_agent, query, ...)\nelif \"business\" in result:\n    Runner.run_sync(local_biz_agent, query. ...)\nelse:\n    \u003Cthrow an exception>\n```\n\nThe difference between handoffs and orchestrations written in native Python code is an interesting discussion for another time. For today, just know that whether an agent is invoked with a `Runner.run` or via agent-to-agent handoffs, each agent runs as its own independent unit of execution (I promise the relevance of this will become clear very shortly).\n\nWith the OpenAI Agents SDK model, you will find yourself building a set of smaller agents that do one thing and do one thing well (Any Unix fans out there? Yeah, this makes me really happy too!), and then stitching them together to form your agentic applications.\n\nOkay, I think thats enough Agents SDK context for us to carry on.\n## Temporal: Guaranteed reliable execution of your agents\nTemporal has a similarly minimalistic (yet extremely powerful) set of core primitives:\n- Workflows\n- Activities\n- Updates\n- Queries\n\nAgain, we will focus on the first two today, but for context, Updates are a way to inject control and data into a running Workflow, and Queries are a way to get data out.\n\nA Temporal Workflow holds the orchestration logic of your application, and its just native code. Today well be looking at Python examples, but know that Temporal also supports TypeScript, Java, Golang, .Net, Ruby and PHP. Dont let the name Workflow fool you  this isnt the BPM (Business Process Management) of the 90s. Its not some obscure representation of your business logic. Its just code (with some fairy dust sprinkled on it ). Really, just think of the Workflow as your applications `main`. \n\nWhat a Temporal Workflow primarily orchestrates are Temporal Activities. Where Workflows house the boring control flow things  loops, branching, parallelism, etc., Activities are where the most unpredictable parts of your application are implemented. A downstream call to an API (that might be unavailable due to a network hiccup). A call to an LLM (that might be rate-limited, or most certainly gives back a different response even when the same question is repeatedly asked). These are the things that Activities are expressly designed for (and yes, I am foreshadowing a bit here  check out [this video](https://www.youtube.com/watch?v=3Ox9Wqjn1Hk) for a good, quick overview.)\n\nBut Temporal Activities have some special properties. Whenever Activities are run, Temporal steps in and oversees progress. Temporal doesnt get into the details of what is happening inside of an Activity, but it does keep track of when an Activity is invoked, what the arguments were, whether the Activity has completed, and if so, it also keeps track of the return values.\n\nAnd the Workflow, which is orchestrating a bunch of Activity calls, keeps track of how all of those Activity calls have come together. If you follow up an LLM invocation with a tool execution and then a handoff to another agent, Temporal keeps track of all of that progress, and if something goes wrong, Temporal will compensate. Remember what I said earlier about Temporal picking up where it left off in the event of a crash? This is how you get that Durable Execution: Temporal keeps track of application progress and stores all Activity results, and thats how it can simply keep going when latent troubles have been resolved.\n\nThe following shows how you might implement an agentic loop in Temporal. Implemented in the Workflow, its just a simple Python loop in which a couple of activities are called:\n\n```python\nwhile True:\n   # Call the first activity: invoke model\n   result_one = await client.execute_activity(\n       \"invoke_model\",\n       agent_memory,\n       task_queue=\"openai-agents-task-queue\",\n       schedule_to_close_timeout=10,\n   )\n\n   if result_one.next_step == \"done\"\n       break\n\n   # Call the second activity: invoke tool\n   result_two = await client.execute_activity(\n       \"invoke_tool\",\n       result_one,\n       task_queue=\"openai-agents-task-queue\",\n       schedule_to_close_timeout=10,\n   )\n```\n\nIn short, Temporal is a Durable Execution framework that makes distributed systems more resilient, even as the development thereof gets easier.\n\nAnd AI agents are distributed systems.\n## Lets put them together: Durable, scalable agents\nAt this point, I bet youre getting a sense of how these two technologies can come together to deliver more than the sum of their parts. The OpenAI Agents SDK provides a framework specially designed to enable developers to rapidly build AI agents. And Temporal provides a framework specially designed to enable developers to rapidly build production-ready distributed systems. Production-ready AI agents? That sounds good.\n\nWhen using these two products together, you will:\n- Define your AI agents exactly as you normally would using the OpenAI agents SDK. You will designate an LLM, provide it instructions, supply it with a list of tools it may leverage, and designate a set of agents this one may hand off to.\n- Orchestrate your agents in Temporal Workflows. This is not much of a departure from what you were already doing, as Temporal Workflows are Python code, just as your agent orchestrations were before. Using the [Temporal Python SDK](https://github.com/temporalio/sdk-python), you will define a class and annotate it as a Temporal Workflow definition, and within that class you will define a method and designate it as the entrypoint for that Workflow.\n- In the Workflow, you will define your agents (as shown above) and run them with the appropriate call to the OpenAI Agents SDK Runner class (as shown above).\n- Handoffs designated as a part of an agent definition operate exactly as they did before.\n\nSo the programming model is largely the same as it would be if you were using the Agents SDK alone, but under the covers, weve done things to make the agents and your agentic application durable. Specifically, and here are the key insights:\n\n every agent invocation is executed through a Temporal Activity, \n\n __and because the orchestration is now running as a Workflow, Temporal automatically delivers all of the reliability we talked about above.__\n\nThe following is a very simple agent built using the OpenAI Agents SDK and Temporal integration:\n\n```python\nfrom agents import Agent, Runner\nfrom temporalio import workflow\n\n@workflow.defn\nclass HelloWorldAgent:\n   @workflow.run\n   async def run(self, prompt: str) -> str:\n       agent = Agent(\n           name=\"Assistant\",\n           instructions=\"You only respond in haikus.\",\n       )\n\n       result = await Runner.run(agent, input=prompt)\n       return result.final_output\n```\n\nHow this is all done is at once simple and clever. Around a month or two ago, OpenAI [made the Runner an abstract base class](https://github.com/openai/openai-agents-python/pull/720), which allowed Temporal to [provide an implementation](https://github.com/temporalio/sdk-python/blob/main/temporalio/contrib/openai_agents/_openai_runner.py) of that class that would create an Activity for each agent invocation. The integration goes one step further and also emits data that integrates the execution running in these activities into the Open AI tracing system.\n\nThe behavior I am describing is most easily seen by viewing the dashboards of both Temporal and OpenAI. Lets run the very simple Haiku agent defined above:\n\n```bash\n$ uv run openai_agents/run_hello_world_workflow.py \"Tell me about quantum computing\"\nResult: Bits dance in twilight,\nQuantum whispers unfold dreams,\nNew worlds in a chip.\n```\n\nId like to draw your attention to the fact that the above code has __nary a mention of a Temporal Activity__. An agent is defined and run, with the `await Runner.run(agent, input=prompt)` call, yet in the following screenshot from the Temporal GUI, you can clearly see that an Activity was invoked.\n\n![event-history-agents](//images.ctfassets.net/0uuz8ydxyd9p/6SaRrL8kQu1UXmBauxCEjA/8144fcc09904c98f132bd3f843f4d7a9/Screenshot_2025-07-28_at_4.15.09__PM.png)\n\nOkay, so the first time I saw this  implicit Temporal Activities  I thought, Oh. Now, oh. Thats so cool.\n\nTo show you the power of the integrated tracing, let me show you the dashboards for a more involved application. My colleague [Steve](https://www.linkedin.com/in/steveandroulakis/) has also been working with this integrated offering and built a [version of deep research](https://github.com/temporal-community/openai-agents-demos)  an extension of the [research bot example](https://github.com/openai/openai-agents-python/tree/main/examples/research_bot) that was inspired by the [deep research API cookbook](https://cookbook.openai.com/examples/deep_research_api/introduction_to_deep_research_api_agents). This agent takes in a user prompt, uses a triage agent to decide whether more input is needed from the user, if so, it leverages a clarification agent to guide that engagement, uses instruction, planning, and search agents to conduct research and a writing agent to produce a final report.\n![diagram-agent](//images.ctfassets.net/0uuz8ydxyd9p/1btdmmSKgTLLI6z09tWzRj/82cd755b3045a80c706a694f42f88a17/Screenshot_2025-07-28_at_4.16.31__PM.png)\nIn the Temporal GUI, this Workflow execution looks like this:\n![event-history-agent-2](//images.ctfassets.net/0uuz8ydxyd9p/2wQ7RJ7hayh3m2NGHIJPGP/65d54e0978c69e312ba56b8101693f92/Screenshot_2025-07-28_at_4.18.18__PM.png)\nYou can see that every agent execution was done with a separate Activity invocation, whether invoked via handoff  as done when the triage agent handed off to the instruction agent, or whether invoked from the Temporal Workflow  as done when the numerous (not predetermined) search agents were invoked in parallel. The corresponding trace is shown in the OpenAI dashboard:\n![oai-dashboard](//images.ctfassets.net/0uuz8ydxyd9p/76Zau8aEAQEHJVLmRYJitT/49be32baf3de6c6ba75ac09220fd8b35/Screenshot_2025-07-28_at_4.19.15__PM.png)\nYou saw a short version of this demo in the video at the top of this post. Steve also put together a [more comprehensive one](https://www.youtube.com/watch?v=fFBZqzT4DD8)  I assure you its worth a view. Youll find this sample and a few others in [this repo](https://github.com/temporal-community/openai-agents-demos). Do also have a look at the [README here](https://github.com/temporalio/sdk-python/tree/main/temporalio/contrib/openai_agents) for some guidelines on how to configure your Workflows with the integration.\n\n***\n\nSo heres the tl;dr: you can build durable, reliable, production-ready AI agents using the OpenAI Agents SDK, along with Temporal. And all of that reliability comes without adding any extra complexity to your implementation. \n## But wait, thats not all! You also get horizontal scale\nI try my best not to bury the lede in these types of blogs, yet perhaps today Ive done just that. In my defense, I do think that all of the above context is needed to get to the following point.\n\n__In addition to delivering retries, state management and implicit checkpoint-like recovery in the case of an agent crash, this integration brings another very important production-ready feature: scalability!__\n\nWithout Temporal, your Agents SDK applications effectively run in a single process. If you want to scale the app, you are going to have to figure out how to manage a bunch of instances of your app and how to distribute work among them (plus many other challenges). And what happens when you need different capacity for different (micro)agents? For example, in the deep research example above, you might not need a lot more triage capacity, but you need a whole lot more search agent capacity. Hmm, this sounds eerily reminiscent of microservice scaling challenges, and its just as tricky.\n\n__When you integrate Temporal with the Agents SDK, each (micro)agent is run in its own process or thread.__ Thats right  as soon as you use this approach, your agents are loosely coupled from an operational perspective. Need more capacity? Just add more workload (Workflow and Activity/agent) capacity. That added capacity will be used for whatever work shows up. If your search agents are doing more work than your triage agents, Temporal simply uses the capacity for that work. The details of how this works are beyond what we can cover here, but if you're thinking this sounds like an event-driven system, you are absolutely right. I do hope Ive convinced you that its worth a deeper look.\n## Get started building production-ready agents\nYou want to build some experimental agents and see potential before investing too much effort in prod-readiness. At the same time, youd love to avoid throwing away proof-of-concept code when your ideas are ready for prime time.\n\nWith the integration weve announced here today, you get it all: the ability to get started quickly, all while being on the track for production deployment. You can either take your existing Agent SDK applications and make them production-ready using the steps weve outlined above, or you can build your orchestrations as Temporal Workflows from the get-go. The programming model is intuitive, and we offer a local dev instance to start prototyping with zero friction. To learn more and get started:\n- Watch the [demo video](https://www.youtube.com/watch?v=fFBZqzT4DD8).\n- Check out the Temporal Python SDK [GitHub repo](https://github.com/temporalio/sdk-python) and be sure to follow the configuration steps [found here](https://github.com/temporalio/sdk-python/tree/main/temporalio/contrib/openai_agents).\n- [Sign up for our webinar](https://pages.temporal.io/webinar-bringing-resilience-to-agents.html?utm_source=temporal&utm_medium=website&utm_campaign=launch-openai-agents-sdk&utm_content=webinar-openai-agents-sdk) on September 23rd to learn exactly how the integration works and how you can achieve production-readiness.\n  - The first 100 registrants get a limited-edition t-shirt!\n  - Presented by my colleague Steve, Dominik Kundel from OpenAI, and yours truly.\n\nAs always, wed love to hear from you. The integration is open-source and in Public Preview  we welcome feedback and contributions from the community. Or, let us know what youre building and what we can do to help. Come join us in the [Temporal community](https://temporal.io/community), in __#topic-ai__!",featureImage:{title:"Temporal + OpenAI Public Preview Launch",description:"Temporal + OpenAI Public Preview Launch",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4zie1jYnopUq4BAtw0VKuQ/b89692d1e07622c64f853e4a4104b25a/temporal-openai-blog-card.png"},publishDate:"2025-07-30",metaDescription:"OpenAI and Temporal have teamed up to add Durable Execution to agents built using OpenAIs Agents SDK, and today we released the new integration in Public Preview.",metaTitle:"Production-ready agents with the OpenAI Agents SDK + Temporal",socialCard:{title:"OpenAI + Temporal Public Preview Social Card",description:"OpenAI + Temporal Public Preview Social Card",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4b9n7F0ikt5dtdaA2MHEHi/d2a23f345ec1aa2daa280a02501d3bdd/cornelia-post-social.png"},tags:"AI/ML,Industry Events",slug:"announcing-openai-agents-sdk-integration",contentType:"blogPost",entityId:"7DEbdxvgChlxGT4y9SyA4z",authors:[{id:"5UNwygCxwqYCdaa27gAYNS",name:"Cornelia Davis",slug:"cornelia-davis",jobTitle:"Senior Staff Developer Advocate",photograph:{title:"Cornelia Davis Headshot",description:"Cornelia Davis Headshot",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6TDAN3Pi1qvx8m6HBdC4Kk/24be44497f96b4236b4e61b054e8568f/image.png"},company:"Temporal",contentType:"person"}],authorsString:"Cornelia Davis",category:"Announcements",promoCard:{title:"Open AI Promo Card",eyebrow:"Dive Deeper",heading:"Learn more & get started",content:"Check out the [demo video](https://www.youtube.com/watch?v=fFBZqzT4DD8) and GitHub repository",callsToAction:[{text:"View the Repo",href:"https://github.com/temporalio/sdk-python/tree/main/temporalio/contrib/openai_agents",variant:"primary",leadingIcon:"github",trailingIcon:null,entityId:"1ZCaVANdznrqvrIWWcnFLu",large:false,theme:"ultraviolet"}],entityId:"10k3IXxOGVfwSlLJLD6LuO",contentType:"noise"},readingTime:16},{title:"Durable MCP: How to give agentic systems superpowers",content:"Its been said by punnier people than me that there are three problems in computer science: naming things and off-by-one errors.\n\nI think thats dryly hilarious. But I also think the two hardest problems in computer science are *configuration* and *integration*:\n- __Configuration__: making the computer solve your problems the way you want them solved \n- __Integration__: making the computers talk together to cooperate and solve your problems\n\nNo matter how well you build or buy software, modern applications always come down to these two challenges. You have to make the computers solve your particular problem and talk to the other computers.\n\u003Cdiv style=\"text-align:center;\">\u003Cimg src=\"//images.ctfassets.net/0uuz8ydxyd9p/6aBKJum30N42NeprGeENbO/e6b07201d1b26cd95a5411fd996aee7f/Screenshot_2025-07-07_at_1.43.07__PM.png\" alt=\"Me and all my software engineering friends\" style=\"display:block;margin:0 auto;\">\u003Cp style=\"margin-top:0;\">\u003Cem>Me and all my software engineering friends for my entire IT career. Source: ChatGPT \u003Ca href=\"https://newsletter.pragmaticengineer.com/p/chatgpt-images\">enabled by Temporal\u003C/a>\u003C/em>\u003C/p>\u003C/div>\n\nOver the years, weve tried many different ways to manage __configuration__: modular, object-oriented, functional, domain-driven, several other kinds of -oriented, BRM, BPM. Despite all these approaches, its still a complex problem. Why? Because computers arent like people: they do *exactly* what we tell them, but we humans are imperfect translators of our own intentions.\n\nIntegration has seen similar evolution. Weve moved through mainframe multi-user systems, client-server, monolith, peer-to-peer, SOAP, REST, microservices, event-driven, event-sourced, choreography, and orchestration. Each approach has been useful and made things incrementally easier. Yet integration remains hard and prone to troubles because the integration code is made by people, all these systems are run by people, were all imperfect, and integration error rates [stack](https://www.oreilly.com/library/view/implementing-service-level/9781492076803/ch01.html).\n\nIn this piece, I will discuss how these core problems may have a new solution on the horizon, opening up new ways to simplify configuration and integration. Ill also talk about how making MCP durable with Temporal enables durable tool execution, opening up possibilities for tools and enabling people to build agentic tools that are durable, scalable, and enterprise-grade.\n## Enter agentic\nBut what if we could change the game entirely? What if, instead of humans translating problems and solutions into computer instructions, the computers could just talk to you directly? This is possible with agents! Configuration suddenly becomes easy when you can just tell an AI what you want to do in plain language.\n### Goals\nAgentic systems solve problems *for you and on your behalf*. They act as your *agents*, getting things done the way you need them done. One way to define what you want done (configuration) is to define goals for the agent to do.\n\nAt Temporal, weve [demonstrated](https://www.youtube.com/watch?v=LBGeejpKh5o) systems with pre-defined goals that can focus on specific tasks, and weve also [built more flexibility into these agentic systems](https://github.com/temporal-community/temporal-ai-agent) that can handle multiple goals and switch between them as needed.\n\nAt their core, goals are about getting things done, and agents accomplish their work through tools. Goals provide the context that helps an agentic system understand how to complete multi-step processes.\n\nGoals can be defined with human language:\n\n```python\n# sample goal definition \n description=\"The user wants to schedule paid time off (PTO) after today's date. To assist with that goal, help the user gather args for these tools in order: \"\n    \"1. CurrentPTO: Tell the user how much PTO they currently have \"\n    \"2. FuturePTOCalc: Tell the user how much PTO they will have as of the prospective future date \"\n    \"3. BookPTO: Book PTO after user types 'yes'\",\n\n\"Welcome me, give me a description of what you can do, then ask me for the details you need to do your job.\"\n```\n### Tools\nWhile goals define what needs to be done, tools are how things actually get done. Tools can be local processes (read this local file and give me its output) or remote calls (read this database with these input keys because I need specific results).\n\nTools can be combined and sequenced  something we might have called [microservices orchestration](https://medium.com/@surajsub_68985/temporal-revolutionizing-workflow-orchestration-in-microservices-architectures-f8265afa4dc0) in a non-agentic system. But heres where it gets interesting: tools can be defined as part of an agentic system, with [human language context](https://github.com/temporal-community/temporal-ai-agent/blob/main/adding-goals-and-tools.md#adding-tools) being provided by the system as configuration. Even better, tools can be implemented by other agents with their own defined goals and tools.\n\nThis framework of goals, intelligence, and tools achieves something fascinating. Configuration  that eternal challenge of making systems solve your specific problems with your data and APIs  becomes a matter of human language:\n\n```python\n# sample goal definition\ngoal_hr_schedule_pto = AgentGoal(\n    id=\"goal_hr_schedule_pto\",\n    agent_name=\"Schedule PTO\",\n    agent_friendly_description=\"Schedule PTO based on your available PTO.\",\n    tools=[\n        tool_registry.current_pto_tool,\n        tool_registry.future_pto_calc_tool,\n        tool_registry.book_pto_tool,\n    ],\n    description=\"The user wants to schedule paid time off (PTO) after today's date. To assist with that goal, help the user gather args for these tools in order: \"\n    \"1. CurrentPTO: Tell the user how much PTO they currently have \"\n    \"2. FuturePTOCalc: Tell the user how much PTO they will have as of the prospective future date \"\n    \"3. BookPTO: Book PTO after confirms the proposal with 'yes'\",\n)\n\n# sample tool definition\nbook_pto_tool = ToolDefinition(\n    name=\"BookPTO\",\n    description=\"Book PTO start and end date. Either 1) makes calendar item, or 2) sends calendar invite to self and boss? \"\n    \"Returns a success indicator. \",\n    arguments=[\n        # \u003Csnip arguments definition for brevity>\n    ],\n)\n```\n\n> This is a powerful way to make *configuration* easier. You define how to solve your problems in simple, human-readable terms, and the agentic AI works with you using the available tools.\n\nBut youve probably noticed a limitation: the system is constrained by its pre-defined tools. What if you wanted to use tools without pre-defining them in your application? *What if we could make integration easy too?*\n## Model Context Protocol (MCP)\n[MCP](https://modelcontextprotocol.io/introduction) is automatic, AI-powered integration. MCP transforms agentic tools into something [pluggable, discoverable, and dynamically composable](https://www.youtube.com/watch?v=FLpS7OfD5-s).\n\nThe magic of MCP is that tools can describe themselves. Their capabilities and APIs are provided right in the server definition:\n\n```javascript\n// MCP tool definition from https://github.com/modelcontextprotocol/servers/blob/main/src/filesystem/index.ts\n      {\n        name: \"read_file\",\n        description:\n          \"Read the complete contents of a file from the file system. \" +\n          \"Handles various text encodings and provides detailed error messages \" +\n          \"if the file cannot be read. Use this tool when you need to examine \" +\n          \"the contents of a single file. Only works within allowed directories.\",\n        inputSchema: zodToJsonSchema(ReadFileArgsSchema) as ToolInput,\n      },\n```\n\nWith MCP, *tools* can present their capabilities to an *agentic system* and allow for dynamic goal solutions. Combining tools and building agentic capabilities becomes much easier.\n\nNow, Ill be honest  adding tools can still be [a bit complicated](https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/overview) for some agentic MCP clients. But Im writing this blog with the assumption that this will become much easier soon. [Great work](https://block.github.io/goose/docs/getting-started/using-extensions/) is being done to simplify the process, and I foresee a future where entire agentic applications are composed simply by plugging different MCP tools into dynamic agent systems.\n### Durable MCP: Give agents superpowers\nAs of the time of writing, MCP is both super powerful and *really new*. Agentic systems can call local MCP servers and remote MCP servers, but the current implementation uses simple [JSON RPC](https://modelcontextprotocol.io/specification/draft/basic#messages) without much durability built in. Visibility, security, reliability, and long-running capability are all still being figured out. MCP has tons of potential, but also much to deliver on.\n\nMCP can do great things, but the protocol doesnt provide durability. Users want their tools to work every time, and in a business context, we want the important tools we call to do their important work successfully, every time.\n\u003Cimg src=\"//images.ctfassets.net/0uuz8ydxyd9p/6jWL96lipz4DdgQBKLyock/0e89aedd03266c8d1dc5de754d151ab9/Screenshot_2025-07-07_at_3.03.23__PM.png\" alt=\"Diagram 1\" style=\"border:2px solid #444CE7;\">\nAt Temporal, were admittedly a bit obsessive about [durability](https://temporal.io/blog/building-reliable-distributed-systems-in-node-js-part-2). Our mission is making all systems fault-tolerant and reliable. MCP tools have tremendous potential, but we think these tools should be ready for the scale and durability requirements of the enterprise. We want these tools to have durability and fault-tolerance built in. So when we look at MCP, we see a huge opportunity: what if we could add robust durability to these systems by implementing MCP tools with a Durable Execution framework like Temporal?\n### MCP tools as workflows\nHeres a simple model to add a lot of desirable architectural qualities to MCP tools quickly: implement MCP tools as workflows.\n\n[Heres an example](https://github.com/Aslan11/temporal-durable-mcp-weather-sample/blob/4b93f93132f7045efcb52631f452863fe2828800/weather.py#L29) of a tool that executes a Temporal Workflow and returns the result:\n\n```python\n@mcp.tool()\nasync def get_forecast(latitude: float, longitude: float) -> str:\n    client = await get_temporal_client()\n    handle = await client.start_workflow(\n        workflow=\"GetForecastWorkflow\",\n        args=[latitude, longitude],\n        id=f\"forecast-{latitude}-{longitude}\",\n        task_queue=\"weather-task-queue\",\n    )\n\n    return await handle.result()\n```\n\nThis tool then calls a Workflow that looks like this:\n\n```python\n @workflow.run\n    async def run(self, latitude: float, longitude: float) -> str:\n        points_url = f\"{NWS_API_BASE}/points/{latitude},{longitude}\"\n        points_data = await workflow.execute_activity(\n            \"make_nws_request\",\n            points_url,\n            schedule_to_close_timeout=timedelta(seconds=40),\n            retry_policy=retry_policy,\n        )\n\t #\u003Csnip>\n```\n\nThat Activity call is guaranteed to execute durably and retry until it successfully retrieves weather data from the Weather Service.\n\nThis approach delivers some fascinating architectural benefits:\n1.  Tools automatically gain remote capabilities\n2.  Durable Execution comes baked in, bringing visibility, reliability, and scalability out of the box\n    * Every downstream call is automatically retried until it succeeds\n3.  Tools continue progressing even if the MCP client or server crashes\n4.  Tools can be built in *[any language Temporal supports](https://docs.temporal.io/encyclopedia/temporal-sdks#official-sdks)*, meaning a developer can build agentic capabilities in Go, Java, .NET, or several other languages\n5.  Existing Workflows become reusable  if you already have a workflow that does what your tool needs, youve got a great head start\n    * Maybe this isnt useful for everybody, but for Temporal users reading this blog, its real nice\n6.  Tools can run for any duration without timing out\n7.  Tools can maintain a lifecycle independent of the agent session\n    * Weve been exploring that capability [here](https://github.com/Aslan11/temporal-invoice-mcp), wherein a long-lived Workflow backs several tools and the agentic system can interact with the Workflow over its lifetime\n8.  It creates an easy path for agents-as-tools (but thats a topic for another post)\n\n\u003Cimg src=\"//images.ctfassets.net/0uuz8ydxyd9p/26t4SwsjnUJHpJy8vyZOAM/8357530cbb4df285125bcf0e30ecaedb/Screenshot_2025-07-07_at_3.04.27__PM.png\" alt=\"Diagram 2\" style=\"border:2px solid #444CE7;\">\n\n### Putting it together: A simple application defined by a user and some tools\nLet me show you what this means in practice. Say I want to figure out when the weather will be good to mow my lawn, and I need two hours of free time to do the mowing. With the durable weather tool above, I can check forecasts reliably. Add a calendar tool, and suddenly I can have an intelligent conversation with an agentic system that combines these tools  all without writing a line of integration code or configuring how the data meshes together. Heres how that conversation might look in Claude:\n![claude-convo-j](//images.ctfassets.net/0uuz8ydxyd9p/57V5wcqYNufMAFdw4lEIu4/c5d6acd7561f0842f357a10d4749dfa1/Screenshot_2025-07-07_at_2.13.22__PM.png)\nBuilding a weather-plus-scheduler application traditionally would require significant developer time, but the combination of agentic systems and MCP tools makes it trivial. Temporal makes these tools durable.\n\nThe possibilities become even more exciting when you imagine dynamically putting together all kinds of APIs and data sources across different contexts. As long as the tools exist, you can compose them in endless ways:\n\n- __As a developer__, I could use MCP-powered monitoring tools to hunt for production problems, then leverage other tools to repair those problems, with me as a human in the loop, directing and approving changes along the way.\n- __As a product owner__, I could connect tools that pull feature requests from customer feedback systems, analyze and refine them, write them into my teams project backlog, and update the sprint planning documents in my teams wiki  all through natural conversation with an agent.\n- __As a foodie__, I could have tools that connect my [home grocery inventory system](https://mcpmarket.com/server/notion-pantry), a [recipe system](https://playbooks.com/mcp/disdjj-cook), and a food delivery system like [Uber Eats](https://github.com/ericzakariasson/uber-eats-mcp-server). A simple conversation like I feel like eating sushi. Do I have the ingredients to make it? If not, can you recommend some restaurants in the area to deliver it to me? *becomes a complete application*.\n\nToday, theres still a bit of work to set up MCP tools, and if an MCP server doesnt exist, setting one up for an existing API or data source is a bit of work. This space will continue to mature and get easier, and I expect soon people will be building many kinds of data interactions powered by agentic AI and MCP tools.\n\n## Conclusion\nThe combination of agentic systems and MCP enables the creation of powerful, flexible systems defined in simple terms. Human interaction, configuration, and integration can all be driven by human language. When you add Temporals Durable Execution to this architecture, these systems become highly reliable (our customers sometimes say bulletproof)  something required to run in production in an enterprise.\n\nTemporal provides a rock-solid foundation for building these powerful distributed systems. [Kevin Martin](https://www.linkedin.com/in/gtm-kev/), [myself](https://www.linkedin.com/in/joshua-smith-b1a01336/), and others at Temporal are convinced that a new generation of applications will emerge  built quickly and durably using these technologies. I expect a new architecture to form, with agents, MCP, and Durable Execution combining to enable simple-to-build applications that are configured by end users to dynamically solve problems in ways traditional architectures never could.\n\nWe suggest you explore implementing your MCP tools as Temporal Workflows. Youll find these systems not only reliable but genuinely enjoyable to build.\n\nCheck out our [demo repository](https://github.com/Aslan11/temporal-durable-mcp-weather-sample/), or even better, check out [this course](https://learn.temporal.io/tutorials/ai/building-mcp-tools-with-temporal/introducing-mcp-temporal/). And feel free to:\n- Join the [Temporal Community Slack](https://t.mp/slack) (channel __#topic-ai__).\n- [Talk to an expert](https://pages.temporal.io/ask-an-expert).\n- Sign up for [Temporal Cloud](https://temporal.io/cloud) and get $1,000 in free credits.",featureImage:{title:"Amazon Bedrock with Temporal: Rock Solid",description:"Amazon Bedrock with Temporal: Rock Solid",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6vkAcFvdvpPI8GBeiNonrO/48c2d48998507594a0591ae6759f1e0e/bed_rock.jpeg"},publishDate:"2025-07-09",metaDescription:"Explore how combining Model Context Protocol (MCP) with Temporal's Durable Execution can solve the core challenges of configuration and integration, creating reliable, enterprise-grade agentic systems.",metaTitle:"Durable MCP: Using Temporal to give agentic systems superpowers",socialCard:{title:"Blog (29)",description:"Blog (29)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/Tjdg0tVfeIXLv1vWp27fO/c99790c4b7d1cdaa5e7cfec99c3fcf58/Blog__29_.png"},tags:"AI/ML",slug:"durable-mcp-how-to-give-agentic-systems-superpowers",contentType:"blogPost",entityId:"2zT7ddn4UkmzW4Rcev7tvq",authors:[{id:"6SCT7ktnc7C7malyJV3UsQ",name:"Joshua Smith",slug:"joshua-smith",jobTitle:"Staff Solutions Architect",photograph:{title:"Josh Smith photo",description:"Josh Smith photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2DHNWCAITAPlTgzovWEEyW/1e105a12a16a24ca6db7f3c7ae0ef44b/1678726677795.jpeg"},contentType:"person"}],authorsString:"Joshua Smith",category:"Temporal Voices",readingTime:11}],readingTime:4},{title:"Durable Digest: August 2025",content:"This blog post is a public copy of our monthly newsletter. If youd like to receive upcoming updates by email, you can subscribe to our newsletter here.\nWelcome to your August 2025 update! The OpenAI Agents SDK now pairs with Temporal so you can run agents with real durability. Terraform support for Temporal Cloud is Generally Available, SCIM user management and namespace tags are in public preview, and the Python SDK picked up Task Queue Fairness and Nexus cancellation types.\nFor more information on these updates and other things weve been working on, just keep reading! And as always, wed love to hear from you. Feel free to share feedback in our Community Slack, or on X (@temporalio).\nQuestions from the field\n\n  Jingcheng Kou asked about integrating LangGraph with Temporal. Temporal generally eliminates the need to use LangGraph, although LangChain can still be useful. Read the thread on our Community Slack.\n    \n      For more, read our recent blog post on using of graphs for agentic workflows.\n    \n  \n  Khalid Karim asked about patterns for variable retry times for Activities. We suggest using our nextRetryDelay feature. You can do this in our Typescript SDK by throwing an ApplicationFailure and setting nextRetryDelay:throw ApplicationFailure.create({// nextRetryDelay: '15s',});You can find the documentation for that here and read the full thread on our Community Slack.\n\nRecently shipped\n\n  OpenAI Agents SDK + Temporal integration is here! Use OpenAIs primitives and best practices with Temporals durability to build production-ready AI agents.\n  SCIM user management is now in Public Preview. Assign new users to groups within your identity provider, and theyll be automatically added to Temporal.\n  Temporal Cloud Terraform provider is now Generally Available, so you can use Terraform to automate Temporal Cloud resource management.\n  Namespace tags are now in Public Preview. Attach tags to namespaces in Temporal Cloud to help operators organize, track, and manage namespaces more easily.\n  Python SDK v1.16.0 is here, adding pre-release support for Task Queue Fairness and Nexus cancellation types.\n  New quickstart guides are available for .NET, Python, Ruby, Java, TypeScript, and Go.\n  The State of Development 2025 report is out. We talked to developers and compiled the most important insights about common roadblocks and how to overcome them.\n\nBuilder spotlight\nWere excited to share Jason Stevings AgentOfCode project as our inaugural builder spotlight! Jason created this project to iteratively solve Advent of Code puzzles and runs it as a Temporal Workflow.\nTemporals platform makes it easy to inspect the full process the agent follows as it works through problems. Jason also configured timeouts and scheduled Activity execution to avoid overloading the Advent of Code server. Nice!\nHow to Temporal\n\n  New to Temporal? Start with our new quickstart guides.\n  Learn how to use Temporal as part of long-running MCP tools.\n  Explore how Temporal can be used for platform engineering.\n\nJoin us live\nConnect with our team at upcoming events this September to see live demos from real humans. Wed love to show you how were helping organizations build resilient, scalable applications.\n\n  September 810  Finovate Fall, New York City, NY: Stop by our booth for interactive demos on reliable workflow orchestration, fault-tolerant microservices, and scalable stateful app development without the operational burden.\n  September 810  Disney Data and Analytics Conference, Orlando, FL: Visit Booth 319 to explore live demos, connect with our team, and see how Temporal advances data-driven innovation.\n  September 17  MongoDB.Local, New York City, NY: Catch us at our booth for demos showing how to orchestrate MongoDB transactions, recover seamlessly from failures, and scale stateful apps without added complexity.\n",featureImage:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},publishDate:"2025-08-28",metaDescription:"Explore Temporals latest developer updates: questions from the field, new releases, builder spotlights, learning resources, and ways to connect with our team.",metaTitle:"Durable Digest: August 2025",socialCard:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},tags:"",slug:"durable-digest-august-2025",contentType:"blogPost",entityId:"7DIfENKbIr6Hhc6sFIOTTu",authors:[{id:"17hGmNrCwtXdBh7fhsLUnZ",name:"Temporal Technologies",slug:"temporal-technologies",photograph:{title:"temporal technologies logo",description:"temporal technologies logo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3g56zRXtFQYMeJxBBkVBIZ/7771670e5fc7da59f555837b086c35d6/temporal_technologies_logo.avif"},company:"Temporal Technologies",contentType:"person"}],authorsString:"Temporal Technologies",category:"Announcements",readingTime:4},{title:"Using the power of multi-agent architectures with Temporal",content:"Multi-agent architecture enables several powerful patterns. Here, Ill start from the basics, and describe how Temporal can be used to make building multi-agent systems simple, durable, and fun.\nWhy multi-agent architectures?\nAI Agents are powerful, but they can get overwhelmed by too many tools or too much to think about while having a limited context window. You may want to limit the access a particular agent has, or take advantage of a particular model for an agent. In addition, general purpose do-everything agents can be more challenging to evaluate than special-purpose agents that do one task well.\nOrchestrating agents together is a particularly good fit for Temporals orchestration architecture, as Temporal is great at durable orchestration of many tasks as part of an overall process.\nIn this post, well talk briefly about agent routing orchestration with Temporal, and then go deeper into task delegation.\nAgentic term definitions\nHere are some definitions to help you out.\n\n  \n    \n      Term\n      Definition\n    \n  \n  \n    \n      Agent Routing\n      Switching goals and agents with a Routing Agent orchestrating the routing between agents.\n    \n    \n      Task Delegation\n      Delegation of tasks by an orchestrator agent to sub-agents specializing in those tasks.\n    \n    \n      Conversational Agents\n      Agents that can have multi-turn conversations with a human to refine the tasks, elicit arguments, and add context to inform the agent.\n    \n    \n      Automation Agents\n      Agents that are designed to take input, take action independently and intelligently, but without multiple conversation steps.\n    \n    \n      Proactive Agents\n      Agents that work autonomously, operating without a human trigger, and may be continuously monitoring and even taking action without human intervention.\n    \n  \n\nAgent routing\nOne multi-agent pattern is Agent Routing: switching goals and agents with a Routing Agent orchestrating the routing between agents.\n\n  \n  Here, our user is trying to plan a trip. They speak with the Routing Agent, which routes them to the Flights Booking agent to look for events and book flights.\n\nThen, after booking flights, the system redirects the user to the Paid Time Off agent to check their PTO, and book their vacation time.\nYou can explore Agent Routing further with the Temporal Agent Demo here, and theres a video of it in action below.\nTask delegation\nA more powerful model for managing complexity with many agents is to delegate responsibilities to agents by task.\nThink of this as having a team of specialists, with each agent being good at their part of a problem. We call this Task Delegation, and it mirrors how teams can work in real life. Think of the team that you work on at your company. Each of you has a distinct role, scoped responsibilities, and collaboration protocols. Your agents can use a similar structure.\n\n  \n\nIf you want to skip to the end and see the final result in action, check out this video:\nA simple example: detection and repair with an analysis agent\nSo lets say Im a wizard in the Harry Potter universe, and I work in Scribbulus Supplies, a paper and magical goods shop in Diagon Alley. The students and staff of Hogwarts get all their quills, parchment, school supplies, etc. from me.\nLately, I notice there are various problems with orders: not enough inventory, orders needing approval, etc. I dont want to solve these problems by hand  I want to build a system that magically executes order repairs so I dont have to worry about them (there are so many Quidditch matches to be seen this season).\nLuckily, I know just how to fix this. Heres how.\nThe repair process\n\n  To start, lets build a simple agent to detect if there are any problems in my orders system. I have the orders and inventory data in databases, and tools that can read the data.\n  \n  \n\n@activity.defn\nasync def analyze_order_problems(input: dict) -> dict:\n   #\u003Csnip> \n   # Define the messages for the LLM completion\n    context_instructions = \"You are a helpful assistant that detects and analyzes problems in orders. \" \\\n    \"Your task is to analyze the provided orders and identify any issues or anomalies. \" \\\n    \"You will receive a list of orders in JSON format, \" \\\n    \"each containing an 'order_id', 'order_date', 'status', 'items', and 'quantities'. \" \\\n    \"Look for common problems such as orders needing approval, orders stuck or delayed for various reasons for more than two weeks, \" \\\n    \"or other anomalies. \" \\\n    \"Ensure your response is valid JSON and does not contain any markdown formatting. \" \\\n    \"The response should be a JSON object with a key 'issues' that contains a list of detected issues, \" \\\n    \"each with an order_id, item with key 'issue' that describes the issue, \" \\\n    \"the customer_name the order is for, and  \" \\\n    \"a confidence_score of how sure you are there is a problem. \" \\\n    \"Feel free to include additional notes in 'additional_notes' if necessary. \" \\\n    \"If there are no issues, note that in additional_notes. \" \\\n    \"The list of orders to analyze is as follows: \" \\\n    + json.dumps(orders_to_detect_json, indent=2)\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": context_instructions\n            + \". The current date is \"\n            + DATE_FOR_ANALYSIS.strftime(\"%B %d, %Y\"),\n        },\n    ]\n\n    try:\n        completion_kwargs = {\n            \"model\": llm_model,\n            \"messages\": messages,\n            \"api_key\": llm_key,\n        }\n\n        response = completion(**completion_kwargs)\n\n        response_content = response.choices[0].message.content\n\n    except Exception as e:\n        activity.logger.error(f\"Error in LLM completion: {str(e)}\")\n        raise\nThe agent produces output that looks like this:\n{\n\t\"issues\": [\n\t\t{\n\t\t\t\"customer_name\": \"Rubeus Hagrid\",\n\t\t\t\"order_id\": \"ORD-004-RHG\",\n\t\t\t\"issue\": \"Order contains restricted item requiring approval.\",\n\t\t\t\"confidence_score\": 0.9,\n\t\t\t\"additional_notes\": \"Order includes 'Dragon Egg - Norwegian Ridgeback' which requires Ministry approval.\"\n\t\t}\n]\n}\nSo now with the power of AI, we can determine that Hagrids order requires approval before packaging and shipping. I can run this Activity from a Temporal Workflow, and it will durably execute and be tolerant of my database being down, slow to respond, or the LLM having temporary issues. The analysis agent tells me that its 90% sure in its analysis that the order is stuck because it needs approval.\nI can use this information to understand whats going on with my magical orders  but it would be better if I could also do repairs.\nAdding agentic repair\nLets add two more steps to our workflow: plan creation and plan execution.\n\n  Plan creation combines our found problems, the inventory and order data, and tools we give to the agent to repair orders, and creates a plan to repair the orders.\n  \n  \n\nHeres what the plan looks like for Hagrids order:\n{\n\t\"proposed_tools\": {\n\t\t\"ORD-004-RHG\": [\n\t\t\t{\n\t\t\t\t\"tool_name\": \"request_approval_tool\"\n\"confidence_score\": 0.9,\n\t\t\t\t\"tool_arguments\": {\n\t\t\t\t\t\"approval_request_contents\": \"Request to Approve Order\",\n\t\t\t\t\t\"approver\": \"approve-orders@diagonalley.co.uk\",\n\t\t\t\t\t\"order_id\": \"ORD-004-RHG\"\n\t\t\t\t}\t\t\t\t\n\t\t\t}\n\t\t]\n\t}\n}\nPlan execution is the step where we execute the tools per the plan. Temporal durability ensures the tools execute successfully.\nWe separate these steps so a human can review the plan and approve or reject it.\nThis necessitates our process having the ability to wait for human approval as well as accepting human input. Temporal Workflows make this easy. Heres what our Workflow looks like now:\n@workflow.run\n    async def run(self, inputs: dict) -> str:\n        #execute the analysis agent\n        await self.analyze_problems(self.context)\n\n        # Execute the planning for this agent\n        await self.create_plan(self.context)\n\n        # Wait for the approval or reject signal\n        await workflow.wait_condition(\n            lambda: self.approved is not False or self.rejected is not False,\n            timeout=timedelta(hours=12),\n        )\n\n        if self.rejected:\n            return f\"Repair REJECTED by user {self.context.get('rejected_by', 'unknown')}\"\n\n        # Proceed with the repair\n        await self.execute_repair()\nAdding conversational capability with MCP\nUp to this point, Ive built agents that work in the background. Lets connect these to a conversational agent via Model Context Protocol (MCP). For this example, Ill use goose, created by our friends at Block.\n@mcp.tool(description=\"Get the proposed tools for the repair workflow.\",\n          #tags={\"repair\", \"order management\", \"workflow\", \"proposed tools\"},\n          )\nasync def get_proposed_tools(workflow_id: str, run_id: str) -> Dict[str, str]:\n    \"\"\"Return the proposed tools for the repair workflow. This is the result of the planning step. \n    This should not be confused with the tools that are actually executed.\n    This won't have results before the planning step is complete.\"\"\"\n    load_dotenv(override=True)\n    user = os.environ.get(\"USER_NAME\", \"Harry.Potter\") \n    client = await get_temporal_client()\n    handle = client.get_workflow_handle(workflow_id=workflow_id, run_id=run_id)\n\n    try:\n        planning_result: dict = await handle.query(\"GetRepairPlanningResult\")\n        proposed_tools_for_all_orders: dict = planning_result.get(\"proposed_tools\", [])\n        additional_notes = planning_result.get(\"additional_notes\", \"\")\n    except Exception as e:\n        print(f\"Error querying repair planning result: {e}\")\n        proposed_tools_for_all_orders = \"No tools proposed yet.\"\n\n    return {\n        \"proposed_tools\": proposed_tools_for_all_orders,\n        \"additional_notes\": additional_notes\n    }\nI created a Query in my workflow to enable this MCP tool:\n @workflow.query\n    async def GetRepairPlanningResult(self) -> dict:\n        if \"planning_result\" not in self.context:\n            raise ApplicationError(\"Planning result is not available yet.\")\n        return self.context[\"planning_result\"]\n\n  Here you can see me chatting with goose:\n  \n  \n  So now I have a conversational agent that connects with my repair agents, building an agentic application that talks to a human to solve real problems.\n\nI dont have to use goose, I can connect to these tools via Slack chat, integrating with Claude, integrating with VSCode, or other conversational agents that can work with MCP.\n\n  These steps form a common pattern for Agentic applications:\n  \n  \n  (green boxes indicate agentic steps)\n\nBuilding a proactive agent\nWith Temporal, its easy to build proactive agents that can monitor and even act on their own. Im going to set this one to start and look for problems. If problems are found, the agents will go deeper: analyzing problems and proposing solutions. Ill set it up to notify me that problems are found, and wait for my review and approval.\n\n  Heres what it looks like in the Temporal Workflow History:\n  \n  \n  One of the great things about Temporal is I can see every step  inputs, outputs, errors for each. If any step fails, it will automatically Retry until the step succeeds. I can quickly diagnose any problems and if needed, fix bugs or prompts and redeploy.\n\nHeres what my Workflow looks like now:\n@workflow.defn\nclass RepairAgentWorkflowProactive(RepairAgentWorkflow):\n    def __init__(self) -> None:\n    # \u003Csnip> initialization\n\n    @workflow.run\n    async def run(self, inputs: dict) -> str:\n        while True:\n            self.approved = False\n\n            await workflow.wait_condition(\n                lambda: self.stop_waiting is True,\n                timeout=timedelta(days=1), # Wait a day for the next detect->analysis->repair cycle.           \n            )  \n\n            # Execute the detection agent\n            self.problems_found_confidence_score = await self.perform_detection(self.context)\n\n            self.problems_found_confidence_score = self.context[\"detection_result\"].get(\"confidence_score\", 0.0)\n            if self.problems_found_confidence_score \u003C 0.5:\n                analysis_notes = self.context[\"detection_result\"].get(\"additional_notes\", \"\")\n                workflow.logger.info(f\"Low confidence score from detection: {self.problems_found_confidence_score} ({analysis_notes}). No repair needed at this time.\")\n                self.set_workflow_status(\"NO-REPAIR-NEEDED\")\n                continue  # Skip to the next iteration if no repair is needed\n\n            #execute the analysis agent      \n            await self.analyze_problems(self.context)\n\n            # Execute the planning for this agent\n            await self.create_plan(self.context)\n\n            # for low planning confidence scores, \n            # we will notify the user and wait for approval\n            if self.planning_confidence_score \u003C= 0.95:\n                # Notify the user about the planned repairs\n                await self.execute_notification()\n                # Wait for the approval or reject signal\n                await workflow.wait_condition(\n                    lambda: self.approved is not False or self.rejected is not False,\n                    timeout=timedelta(hours=20),  # Wait for up to 24 hours for approval\n                )\n\n                if self.rejected:\n                    continue # Skip to the next iteration if repair is rejected\n\n            else:\n                # If the planning confidence score is high enough, we can proceed without waiting for approval\n                self.approved = True\n                self.context[\"approved_by\"] = f\"Agentically Approved with confidence score {self.context['planning_result'].get('overall_confidence_score', 0.0)}\"\n\n            # Proceed with the repair\n            await self.execute_repair()\n\n            # Create the report with the report agent\n            report_summary = await self.generate_report()\n\n  Heres our architecture model now:\n  \n  \n\nOur system is now proactive, detecting and analyzing problems on its own, automatically repairing them if its sure of its repairs. If its not more than 95% confident, it notifies me and waits for my review and approval. I can interact with it via MCP, Temporal Workflow Signals and Queries, and goose, reviewing order problems and proposed repairs.\nThis system delegates tasks to multiple agents which fulfill multiple roles in the overall system and have only role-related access to the backing database. Temporal orchestrates all of these agents easily, transparently, and durably. The agents are resilient due to Temporal Activities.\nDesign patterns\nHere are the design patterns and decisions I made while building this system:\nLifecycle and interaction\nOne question I get asked often is, Should I build an agent as a Workflow or as an Activity?\nFor me, the answer is: it depends on lifecycle and interaction:\n\n  Conversational Agents: interactive, long running, orchestration: Workflows\n  LLM Calls: call to external system: Activities\n  Simple Automation Agents: short-lived, no interaction: Activities\n  Long-Running Agents: long duration, often have interaction: Workflows\n  Proactive Agents: interactive, long-running: Workflows\n\nDAPER\nThis system implements a pattern that is useful for agents that solve problems and execute on a users behalf:\n\n  Detect: notice there are problems\n  Analyze: understand the nature of the problems\n  Plan: create a plan to fix the problems\n  Execute: execute the plan\n  Report: analyze the system and report on problem resolution\n\n\n  \n  A dapper gentleman\n\nUses for this pattern could include:\n\n  Proactive issue detection\n  On-call support\n  Monitoring or SRE tooling\n  Transaction repair in flight\n\nTry it out!\nTemporal gives agents and tools superpowers: durability, visibility, simplicity. Workflows enable interaction, orchestration, dynamic decision making, unlimited duration, and auto-save for state & memory. Activities enable reliable execution of external calls with automatic retries.\nIf you havent yet, check out the video of this system in action and check out the code here.",featureImage:{title:"bedrock-post-micke-lindstrom-6REIcx1yeuI-unsplash",description:"bedrock-post-micke-lindstrom-6REIcx1yeuI-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6UsfEJOHJYe9px5G02SzYS/8370488f6dc6b817001daee185b11321/micke-lindstrom-6REIcx1yeuI-unsplash.jpg"},publishDate:"2025-08-27",metaDescription:"Multi-agent architecture helps create powerful patterns. Learn how Temporal can be used to make multi-agentic systems even better.",metaTitle:"Durable multi-agentic AI architecture with Temporal",socialCard:{title:"Using the power of multi-agent architectures with Temporal",description:"Using the power of multi-agent architectures with Temporal",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1JkXcT9bIACE7V76Bn3m1i/eb87e9ff35d4785c7aafabfdc4b11ccc/Using_the_power_of_multi-agent_architectures_with_Temporal.png"},tags:"Python,AI/ML",slug:"using-multi-agent-architectures-with-temporal",contentType:"blogPost",entityId:"1oJ1juCZ2WHk2YVPvkEuKG",authors:[{id:"6SCT7ktnc7C7malyJV3UsQ",name:"Joshua Smith",slug:"joshua-smith",jobTitle:"Staff Solutions Architect",photograph:{title:"Josh Smith photo",description:"Josh Smith photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2DHNWCAITAPlTgzovWEEyW/1e105a12a16a24ca6db7f3c7ae0ef44b/1678726677795.jpeg"},contentType:"person"}],authorsString:"Joshua Smith",category:"How-To",readingTime:12},{title:"Cargo: Engineering a smarter go-to-market with Temporal",content:"\n  All our orchestration relies on Temporal. When a signal hits  someone visits the site or a CRM field changes  we create a Workflow and run the actions as Activities. Thats the heart of Cargo.  Aurelien Aubert, CEO at Cargo\n\nThe typical go-to-market (GTM) tech stack often feels less like a streamlined machine and more like a collection of disconnected parts. CRMs, marketing automation, sales engagement tools  they all hum along, generating data, but rarely in perfect harmony. This fragmentation can lead to siloed data, disjointed customer experiences, and sales reps spending far too little time actually selling.\nCargo, a Y Combinator S23 company, looked at this GTM complexity and saw an engineering challenge. Theyre building a revenue orchestration platform, aiming to be the central hub connecting these disparate tools and data streams. The goal, according to CEO Aurelien Aubert, is to ensure AEs focus on the right lead, at the right time, with the right context. Cargos vision also leans toward smart automation over large SDR teams.\nWhat makes Cargo different is its engineering-led philosophy. Aurelien explains they take more of an engineering approach to solving GTM use cases. Rather than adding another tool, they provide the architecture companies use to build their own growth engine, with the data warehouse as the central source of truth.\nAn engineering mindset from day one\nThis technical focus is woven into Cargos fabric. As a lean startup  about five full-time employees  they fostered a culture where technical understanding is shared. Aurelien notes that essentially everyone on the early team knew how to code, which helped in fixing bugs, building integrations, and making decisions faster, regardless of role.\nThis environment bred autonomy. Without a dedicated CTO or CPO in the early days, engineers took ownership of features from start to finish, defining specs and timelines. They were capable of taking a feature from understanding the problem to releasing and implementing, as Aurelien describes it.\nThe scalability tightrope: Infrastructure vs. UI\n\n  Building a powerful GTM platform requires a delicate balancing act. Doing interesting things in go-to-market, as Aurelien puts it, demands deep infrastructure and data capabilities  connecting to numerous sources, transforming data, and ensuring scalability. But all that backend power needs a usable frontend.\n  The team constantly faced the trade-off: invest heavily in infrastructure or prioritize shipping user-facing features.\n\n\n  Investing too much in infrastructure without a good UI is useless, but a great UI without robust infrastructure to support it is equally ineffective.  Aurelien Aubert, CEO at Cargo\n\nThis tension shaped their early architecture. They run a single backend (monolith) and deploy workers on Kubernetes, including dedicated workers for some customers or plans when needed. Orchestrating multi-step workflows  enriching leads, scoring accounts, routing opportunities  across various third-party APIs, each with unique limitations, was particularly demanding.\nData storage became a critical bottleneck. The team knew that their initial choice, Postgres, wouldnt scale indefinitely for the analytical workloads central to Cargos value proposition. We knew Postgres at some point wont do the job anymore, Aurelien recalls, but it was simple to build on top of Postgres at the beginning. As usage grew, the limitations became clear, forcing a migration. Moving to ClickHouse, a columnar database optimized for OLAP queries, provided the necessary performance for their data-intensive features.\nFinding the right conductor: Temporal\nWith ClickHouse handling analytics, the core challenge became orchestrating the complex, often long-running, and failure-prone workflows that fed it data and interacted with the GTM ecosystem. Simple background job queues often struggle with the statefulness and reliability required.\nCargo chose Temporal. When asked about critical architecture components, Aubert is direct: All our orchestration relies on Temporal today. Drawing on prior experience with Redis/RabbitMQ-style queues, he acknowledged Temporals initial learning curve but emphasized its scalability and reliability.\nTemporals Durable Execution was a game-changer. Workflows are stateful and resilient by design; their progress is automatically saved, allowing them to survive worker crashes or restarts and resume precisely where they left off. This is crucial for GTM processes that might run for days or weeks.\nCargo leverages Temporal for several key functions:\n\n  Event-driven GTM workflows: External signals, like a website visit or CRM update, trigger Temporal Workflows. An event automatically creates a Temporal Workflow, and the subsequent actions become Activities within that Workflow. These Workflows coordinate sequences of Activities  fetching data, calling APIs, running models, updating systems. Temporals built-in retries handle the inevitable failures when dealing with external services.\n  Data synchronization (ETL): Temporal ensures reliable, scheduled syncs between tools like Salesforce or HubSpot and Cargos warehouse (ClickHouse). Pipelines also handle fan-out to customer-preferred stores (e.g., Snowflake/BigQuery) when needed. These dependable ETL jobs (often hourly) fetch, transform, and load data, retrying failed steps and tracking progress.\n  AI workflow orchestration: Cargo uses AI for tasks like scoring companies, summarizing context for AEs, and drafting outreach. These are multi-step processes (prepare  model call  post-process). Temporal orchestrates the steps, manages dependencies, and handles retries amid rate limits and variable prompts.\n\n\n  \n\nA concrete example: when an opportunity moves to Closed Won, Cargo can automatically identify similar companies (look-alikes) and assign new outreach to the same AE.\nexport const orchestrationWorkflowRunHandle = async (\n uuid: string,\n workspaceUuid: string\n): Promise\u003Cvoid> => {\n const { nextExecutionConfig } = await activities.startRun({\n   uuid,\n   workspaceUuid,\n });\n\n let currentExecutionConfig = nextExecutionConfig;\n\n while (currentExecutionConfig !== undefined) {\n   const executeNodeResult = activities.executeNode({\n     currentExecutionConfig,\n   });\n\n   if (executeNodeResult.outcome === \"notExecuted\") {\n     await activities.finishRun({\n       uuid,\n       workspaceUuid,\n       status: \"error\",\n       errorMessage: executeNodeResult.errorMessage,\n     });\n\n     return;\n   }\n\n   if (executeNodeResult.outcome === \"executed\") {\n     if (executeNodeResult.nextExecutionConfig !== undefined) {\n       currentExecutionConfig = executeNodeResult.nextExecutionConfig;\n     }\n   }\n }\n\n await activities.finishRun({\n   uuid,\n   workspaceUuid,\n   status: \"success\",\n });\n};\nThis is a Temporal Workflow that runs an orchestration run. It initializes with startRun, then iterates through an execution graph one node at a time by invoking executeNode as an Activity (I/O and heavy work live in Activities). On failure, it records the error via finishRun and exits; otherwise it advances to the next node until completion, then marks the run success. Because the loop and branching live in Workflow code, Temporal durably persists progress and can resume after worker crashes or deploys.\nLessons from the trenches\nBuilding a platform like Cargo inevitably involves learning curves. One early insight in Cargos Temporal journey: Workflows arent meant to carry large payloads. The team initially treated them like traditional job queues, which led to inefficiencies. After shifting the approach  keeping Workflows lightweight and pushing heavier data into Activities  performance improved dramatically.\nAdopting Temporal requires a change in mental model: treat Workflows as durable, event-driven state machines. Embracing that model is what unlocks Temporals reliability and scalability.\nBeyond Temporal, Aurelien highlights a familiar startup tension: deciding when to invest in infrastructure versus when to keep shipping features. The move from Postgres to ClickHouse, and tuning orchestration patterns, both came down to timing. The theme is consistent: evolve the architecture just in time while continuing to deliver value.\nConclusion\nCargo is applying engineering rigor to the fragmented GTM landscape. Their platform aims to unify disparate tools and automate complex processes so revenue teams can work with better timing and context. That requires a sophisticated backend capable of handling large data volumes and reliably orchestrating workflows across third-party systems. Technologies like ClickHouse and Temporal are central to this mission. Temporal is at the heart of Cargo, powering the stateful orchestration that keeps modern revenue operations moving.",featureImage:{title:"clair-feature-image",description:"clair-feature-image",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41Sp92v0l4764RVqMDivBG/04ac2f7f28ef2e3654bab1b77e4734ba/clair-feature-image.png"},publishDate:"2025-08-27",metaDescription:"Cargo uses Temporal to deliver a better GTM ops experience to GTM engineers across the globe. Learn how.",metaTitle:"How Cargo engineers a smarter go-to-market process with Temporal",socialCard:{title:"Cargo Engineering a smarter go-to-market with Temporal",description:"Cargo Engineering a smarter go-to-market with Temporal",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5aOGudVTM9DwtuoEEk2sTa/6b8a4897c1128b441ee0c7653896a778/Cargo_Engineering_a_smarter_go-to-market_with_Temporal.png"},tags:"Typescript,Code Samples,AI/ML,Architecture",slug:"cargo-smarter-go-to-market-with-temporal",contentType:"blogPost",entityId:"4shTLSyPAMfBrPQEdzlAIj",authors:[{id:"780p8MZSlKh9AuMzW5FrA0",name:"Clair Byrd",slug:"clair-byrd",jobTitle:"CMO",photograph:{title:"Clair Byrd",description:"Clair Byrd",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2ENA9j4df6EfXCLgoWmt46/bb029b33e3f92fb2a7973348c8ccce88/861A2507.jpg"},biography:"Clair Byrd is the Chief Marketing Officer at Temporal, the company defining durable execution in software engineering. Before joining Temporal, Clair held senior marketing and leadership roles at Twilio, InVision, and Sauce Labs, and co-founded the front end builder platform Mason. Her work centers on elevating developer experience, connecting open-source ecosystems, and building brands that inspire technical creativity and trust. Clair is passionate about storytelling that helps engineers build faster, smarter, and with lasting impact.",company:"Temporal",contentType:"person"}],authorsString:"Clair Byrd",category:"How-To",readingTime:7},{title:"The State of Development 2025: Everything you need to help your team succeed",content:"Every engineering team has one: the system nobody wants to touch. The one held together by cron jobs, wishful thinking, and a README that just says good luck. You ship on Friday and spend the weekend with one eye on your phone, waiting for the inevitable page.\nWhat if its not just you feeling anxious? What if its the entire industry?\n\n  We had to know. In March 2025, we surveyed 226 developers, architects, and engineering leaders to map the reality were all living in. From software engineers and tech leads writing the code to engineering managers and executives making the decisions, we asked about the brittle systems, the manual recovery nightmares, and all the blockers between you and actually building great software.\n  \n  \n  The results are so eye-opening that we turned them into The State of Development 2025 report. And now, you can get your own copy.\n\nYour boss thinks everythings fine. You know its not.\nHeres the kicker: engineers and their managers are living in completely different universes. When we asked about challenges, the responses split like they came from different planets.\n\n  Case in point: 34% of engineers are struggling with failure recovery. It doesnt even crack the top three concerns for decision makers. What are they worried about instead? Heres a chart from our report:\n  \n  \n\nWhat else is in there?\nThis report gives you the data you need to understand where you stand and to start meaningful conversations with your team.\nA few of the striking findings we explore in the full report include:\n\n  94% use AI, 42% are building it, and 39% are working on the reliability backbone.\n  Only 1 in 4 teams report having smooth workflow operations. The other 75% are firefighting.\n  At companies with over 1,000 employees, developers barely get a say in tooling decisions. We show you whos really calling the shots.\n\nThe full report goes much deeper, answering questions like:\n\n  Whats the #1 factor teams consider when choosing new tools? (Hint: it depends on who you ask.)\n  How do the priorities of a small startup differ from a large enterprise?\n  What keeps decision makers up at night when systems fail?\n  How do you stack up against the competition? (Use our readiness checklist to figure it out.)\n\nStop guessing\nThis report is your golden ticket. Use it to benchmark your team, build your tooling case, or finally have that we need to talk conversation  with receipts to back you up.\nReady to stop firefighting and start building? Download the full State of Development 2025 report now.",featureImage:{title:"state-of-dev-report-blog-thumb",description:"state-of-dev-report-blog-thumb",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5SzLSwLBitYyVCp9mtaWcb/50c3267fb4fa637e004f9554e64bcaf1/state-of-dev-report-blog-thumb.png"},publishDate:"2025-08-21",metaDescription:"Find out what 226 developers and engineering leaders really think about AI, failure recovery, and automation. Get The State of Development 2025 report.",metaTitle:"The State of Development 2025: Everything you need to help your team succeed",socialCard:{title:"state-of-dev-report-social",description:"state-of-dev-report-social",url:"https://images.ctfassets.net/0uuz8ydxyd9p/rCsL21jMYyXg2XphqOHsa/2bed91cebde3f81c1168f808987a4e8e/state-of-dev-report-social.png"},tags:"",slug:"the-state-of-development-2025",contentType:"blogPost",entityId:"5l5Gx6mz8XpvqzVHsDA3Nh",authors:[{id:"7GQtiP7y4Dmrje9sFWcVKl",name:"Lauren Bennett",slug:"lauren-bennett",jobTitle:"Content Marketing Manager",photograph:{title:"Lauren-Bennett-profile-photos",description:"Lauren-Bennett-profile-photos",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6jEqojw9RxBBjX5pytMzYf/4df0ef856a9efe4b7b52d5ebe7e83686/Lauren-Bennett-profile-photos.jpeg"},linkedInUrl:"https://www.linkedin.com/in/lauren-n-c-bennett/",contentType:"person"}],authorsString:"Lauren Bennett",category:"Announcements",readingTime:3},{title:"Building long-running interactive MCP tools with Temporal",content:"In a previous post, I talked about Anthropics Model Context Protocol (MCP), how to implement MCP tools as workflows to add durability, and the ability to run for an indeterminate (or even a very long) time. One thing I didnt talk about was how to interact with a long-running tool workflow using MCP. A lot of developers building AI systems with Claude (or even other MCP hosts) ask the same question: how do I make my tools long-running, interactive, and reliable?\nThis blog post will cover a way to build long running MCP tools, how to interact with them, and how to orchestrate a complex multi-step process.\n(There is discussion of how to do this differently in the MCP Protocol itself, see for example here. For this blog post, well work with the protocol as it is, and add Temporal for durability.)\nRecently, Temporals Kevin Martin created an excellent application that demonstrates a long-running tool powered by Temporal Workflows, and in this post I want to explain what the application did that was so powerful.\nThe Invoice sample\nIn Kevins Temporal Invoice MCP, there are multiple tools:\n\n  Trigger invoice processing\n  Check status\n  Approve\n  Reject\n\n# Trigger Invoice MCP tool from https://github.com/Aslan11/temporal-invoice-mcp/blob/main/server.py\n@mcp.tool()\nasync def trigger(invoice: Dict) -> Dict[str, str]:\n    \"\"\"Start the InvoiceWorkflow with the given invoice JSON.\"\"\"\n    client = await _client()\n    handle = await client.start_workflow(\n        InvoiceWorkflow.run,\n        invoice,\n        id=f\"invoice-{uuid.uuid4()}\",\n        task_queue=\"invoice-task-queue\",\n    )\n    return {\"workflow_id\": handle.id, \"run_id\": handle.result_run_id}\n\n  \n  You can check out this video to see this in action:\n\nHuman interaction with MCP, powered by Workflows\nWhats so powerful about this architecture is that it enables long-running tools for Agentic AI Systems. These tools can run for an unlimited time, and can be interacted with as part of an Agentic System.\n\n  \n\nThis enables a user to trigger a tool via MCP, and then check on the status of it and interact with it as it executes. Because Temporal handles all orchestration, your AI tool doesnt have to worry about memory, timeout issues, or ad hoc retries. AI can handle confusing and ambiguous user input with aplomb, and can interact with the Temporal Workflow orchestration as it executes:\n\n  \n  Goose executing the Invoice Workflow\n\nAgentic Systems can also query Workflows and report back to the user. Note it remembers what were working on and doesnt make me input the invoice parameters or workflow ID to continue the conversation about this invoice process:\n\n  \n  Goose checking the status of the the invoice process for me\n\nAn architecture for durable, long-running agentic AI tools\nThis architecture is built from Agentic AI, MCP Tools, and Temporal Workflows:\n\n  \n\nFirst, start with a Temporal Workflow. Heres some of the relevant code:\nclass InvoiceWorkflow:\n    def __init__(self) -> None:\n        self.approved: bool | None = None\n        self.status: str = \"INITIALIZING\"\n\n    @workflow.run\n    async def run(self, invoice: dict) -> str:\n        self.status = \"PENDING-VALIDATION\"\n        await workflow.execute_activity(\n            validate_against_erp,\n            invoice,\n            start_to_close_timeout=timedelta(seconds=30),\n            retry_policy=RetryPolicy(\n                initial_interval=timedelta(seconds=1),\n                maximum_interval=timedelta(seconds=30),\n                maximum_attempts=5,\n            ),\n        )\n\n        self.status = \"PENDING-APPROVAL\"\n        # Wait for the approval signal\n        await workflow.wait_condition(\n            lambda: self.approved is not None,\n            timeout=timedelta(days=5),\n        )\n\n        if not self.approved:\n            self.status= \"REJECTED\"\n            return \"REJECTED\"\n\n        self.status = \"APPROVED\"\n        # Process each line item in parallel\n        for line in invoice.get(\"lines\", []):\n            handle = await workflow.start_child_workflow(PayLineItem.run, line,)\n        # \u003Csnip details of tracking error counts>    \n        workflow.logger.info(\"All line items paid successfully\")\n        self.status = \"PAID\"\n        return self.status\nFull Workflow code is here. Any Workflow that you want to use as a tool will fit well into this system, but well need to add a few things to connect it via MCP. Our Workflow is waiting for a human to approve the processing. It can wait forever, but in our case, we set it up to wait for 5 days for approval.\nLets create some tools to define the Workflow interactions you want to expose, such as this tool to approve the invoice:\n@mcp.tool()\nasync def approve(workflow_id: str, run_id: str) -> str:\n    \"\"\"Signal approval for the invoice workflow.\"\"\"\n    client = await _client()\n    handle = client.get_workflow_handle(workflow_id=workflow_id, run_id=run_id)\n    await handle.signal(\"ApproveInvoice\")\n    return \"APPROVED\"\nThis sends a Signal to the workflow that can be very simple:\n    @workflow.signal\n    async def ApproveInvoice(self) -> None:\n        self.approved = True\nTo get information from the Workflow, add a status tool:\n@mcp.tool()\nasync def status(workflow_id: str, run_id: str) -> str:\n    \"\"\"Return current status of the workflow.\"\"\"\n    client = await _client()\n    handle = client.get_workflow_handle(workflow_id=workflow_id, run_id=run_id)\n    desc = await handle.describe()\n    status = await handle.query(\"GetInvoiceStatus\")\n    return f\"Invoice with ID {workflow_id} is currently {status}. \" \\\n           f\"Workflow status: {desc.status.name}\"\n\nAnd a Workflow Query:\n @workflow.query\n    async def GetInvoiceStatus(self) -> str:\n        return self.status\nThese could be much more complex, passing more information, or sending much more complicated information than a simple approval. Signals, Queries, and Updates make interacting with Workflows very simple.\n\n  Now well use the approve tool to approve the invoice processing and let it complete:\n  \n  \n  Goose handling multiple tool calls at once - approving the invoice, then checking on the status - its complete!\n\nMultiple tools, one process\nUsing multiple MCP tools, you can start, control, make progress on, and understand a long-running process implemented in a Workflow. Tools can initiate, follow, and control a complex, long-running process.\nEnabling human-in-the-loop tools with Temporal\nTool interactions dont have to be short  MCP partnered with Durable Execution powers a whole new set of interactions with long-running tools.\nThese tools can be used by any agentic system that functions as an MCP host and client, so you can switch from Claude to Goose to pick-your-tool.\nCheck out the sample: Temporal Invoice MCP.\nIf you have questions and want to learn more, feel free to reach out:\n\n  Join the Temporal Community Slack (channel #topic-ai).\n  Or email sales@temporal.io and mention AI blog in the subject line.\n  You can even take a whirl yourself with a free trial of Temporal Cloud with $1,000 in credits.\n\nSpecial thanks to Kevin Martin for the great Invoice Sample, and the Goose Team for creating such a useful app.",featureImage:{title:"blog-image-to-be-2",description:"blog-image-to-be-2",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5zhMxz2jLMc7zR6jDWfLqJ/a7edd6a6c3e0d3c93da257c65d54be30/blog-image-to-be-2.png"},publishDate:"2025-08-21",metaDescription:"Learn how to interact with a long-running tool workflow using MCP from one of our Solutions Architects, Josh Smith.",metaTitle:"Building long-running interactive MCP tools with Temporal",socialCard:{title:"Building long-running interactive MCP tools with Temporal",description:"Building long-running interactive MCP tools with Temporal",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2A3cDYkM8oio4RcgEPtUyJ/fb2eca816cd8c416044151331409e4a6/Building_long-running_interactive_MCP_tools_with_Temporal.png"},tags:"AI/ML,Python",slug:"building-long-running-interactive-mcp-tools-temporal",contentType:"blogPost",entityId:"49nijOmmexTUPf35SyMdak",authors:[{id:"6SCT7ktnc7C7malyJV3UsQ",name:"Joshua Smith",slug:"joshua-smith",jobTitle:"Staff Solutions Architect",photograph:{title:"Josh Smith photo",description:"Josh Smith photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2DHNWCAITAPlTgzovWEEyW/1e105a12a16a24ca6db7f3c7ae0ef44b/1678726677795.jpeg"},contentType:"person"}],authorsString:"Joshua Smith",category:"How-To",readingTime:6},{title:"The fallacy of the graph: Why your next agentic workflow should be code, not a diagram",content:"Im going to start with a bold statement: if youre building complex, procedural logic, especially for the new wave of agentic applications, you should stop using graphs.\nI say this after spending over two decades building orchestration solutions. Ive seen the patterns, Ive tried the different approaches, and Ive watched the industry rediscover the same lessons over and over. As AI agents become more sophisticated, I see teams reaching for graph-based frameworks to orchestrate their logic  essentially trying to rediscover the lessons of workflow engines from the beginning. Im writing this to help you skip a painful, expensive, and ultimately flawed phase of development.\nFirst, lets be clear what were building. An AI application is a workflow  a series of steps with branching, looping, and dependencies, that must execute reliably. Some, like a RAG pipeline, might follow a predictable path. Others, often called agents, are highly dynamic, using an LLMs reasoning to decide the next steps at runtime. These agents behave like distributed systems where each tool is a remote hop, and a single network hiccup can cause an agent to lose context.\nFrom an implementation standpoint, both require an engine that can handle this dynamic, data-driven execution. A static graph struggles with both, but it especially struggles with the dynamic nature of agents.\nThe core promise  and the core problem\nThe core idea of a workflow engine or orchestrator is simple: it guarantees that your code will execute to completion, even in the presence of failures like process crashes or network timeouts. This is not usually a property of normal application code. For a long time, representing your logic as a graph or an abstract syntax tree (AST), and augmenting that with persistence operations, was the only way to get this guarantee.\nBut that is no longer the case. A newer, more powerful abstraction we call Durable Execution  which I initially introduced while building the AWS Simple Workflow Service  now allows you to write normal, procedural code with these same crashless guarantees. It provides incremental execution, state persistence, and fault tolerance  tracking your applications progress so it can pick up right where it left off after a failure, like having the ultimate autosave.\nThe paradigm is robust enough that multiple modern frameworks are built on it, including Temporal, Restate, and DBOS. There is no practical need to force procedural code into an unnatural graph-based representation. This post breaks down the severe limitations of the graph-based approach and shows why plain code is not only sufficient but vastly superior.\nWhat is a programming language, anyway?\nWhether its Python, a state machine, or a graph of nodes and edges, any system for expressing logic must provide a few key things:\n\n  Control flow: The logic for sequencing, branching, and looping (if/else, for, while).\n  State (memory): A way to store, access, and manipulate data during execution.\n  Error handling: A way to manage failures, timeouts, and exceptions. While a subset of control flow, its so critical and complex it deserves its own discussion.\n\nLets examine how graph-based systems handle each of these and see where they fall short.\n1. Control flow: The illusion of simplicity\nThe most immediate problem with using a graph to represent control flow is that the flow itself almost always depends on data.\nA conditional branch requires an if statement that evaluates an expression to true or false. A loop needs a for or while construct that iterates over a collection or checks a condition. This means that a graph is never enough on its own. You always have to mix the diagram with snippets of code or expressions that are evaluated separately. This creates a disconnect where the true logic is hidden away from the visual representation.\nBut the real breaking point for graphs is dynamic control flow.\nConsider a common pattern in agentic applications: an LLM returns a list of tools to call based on a users prompt. The set of tools and their order isnt known when you design the graph. Its determined at runtime.\nHow do you represent this in a graph? A node that dynamically generates other nodes to execute? This concept of a mutable, dynamic graph is something that virtually no graph-based language supports well. Some graph frameworks try to paper over this with runtime-generated subgraphs, router nodes, or APIs that mutate the graph/state during execution. In practice, this still pushes real control logic into code blocks inside nodes and leaves the diagram as a thin wrapper around that code.\nAt this point, the graph is just linking a few big chunks of code together. So I ask: why do you need a graph to link pieces of code when you can just have code link pieces of code in a much cleaner way?\nLook how simple this is with code:\ndef run_agentic_workflow(prompt: str) -> list[str]:\n    \"\"\"\n    Dynamically executes tools recommended by an LLM.\n    This logic is impossible to represent in a static graph.\n    \"\"\"\n    # 1. First step is always to call the LLM\n    recommended_tools = llm.get_tools_to_call(prompt)\n    # recommended_tools could be ['search_api', 'calculate_results']\n\n    results = []\n    # 2. Dynamically iterate and execute the tools\n    for tool_name in recommended_tools:\n        if tool_name == \"search_api\":\n            result = apis.search(query=\"some query\")\n            results.append(result)\n        elif tool_name == \"calculate_results\":\n            result = apis.calculate(data=results) # Uses data from a previous step\n            results.append(result)\n        # ... and so on for other tools\n\n    return results\nDurable Execution orchestrators let you use normal language constructs (conditionals, loops, exception handling) to schedule tasks dynamically  the natural fit for agent behavior.\n2. Data management: A world of hurt\nBecause the control flow logic is often separated from the graph structure, data management becomes a challenge. Graph-based systems typically fall back on two poor patterns:\n\n  A global key-value store: A single, untyped dictionary (or map) where every node reads and writes data. This is equivalent to using only global variables. Its impossible to reason about data scope, and a simple typo in a key name ('user_id' vs 'userId') leads to a runtime error that static analysis cant catch.\n    \n      For example, one node might push a value: state['query_result'] = call_vector_db(). A subsequent node must know the exact string 'query_result' to retrieve it. If the first node changes the key, or the second node misspells it, the workflow fails at runtime.\n    \n  \n  Node-to-node data passing: Data is explicitly passed along the edges of the graph. While slightly better, it often devolves into passing massive JSON blobs between nodes. To access nested data, you have to use string-based query languages like JSONPath ($.results[0].id).\n\nThis is fragile, hard to debug, and troubleshooting such a program is really hard. Some graph frameworks try to mitigate this by letting you attach schemas to state (for example, Pydantic models). That can catch misspelled keys at the boundaries and is an improvement. But in the end, it doesnt solve the deeper issues: unclear scope, brittle string selectors across edges, weak refactoring support, and limited compile-time checks when control flow rewires which node produces which fields.\nCompare these two styles:\n1. Graph-based (YAML/JSON with JSONPath):\n- id: step_2\n  type: process_data\n  # Fragile, untyped, easy to misspell\n  input: data.user.credentials.token\n2. Code-based (Python):\n# Clean, strongly-typed, and your IDE can catch errors\nprocess_data(user.credentials.token)\nWhen your entire program relies on untyped, string-based expressions to access memory, you are setting yourself up for a world of runtime failures. Durable Execution abstracts away persistence of intermediate results  theres no need for a global key-value store.\n3. Error handling and compensations: Where graphs completely break down\nError handling massively complicates control flow, and this is where graphs struggle most. Complex applications require compensations  running actions to undo steps that have already succeeded when a subsequent step fails.\nThis pattern, often called the saga pattern in distributed systems, is an inherently dynamic control-flow problem.\nImagine you have three conditional steps: A, B, and C.\n\n  Sometimes you run A, B, and C.\n  Sometimes you just run A.\n  Sometimes you run A and C.\n\nIf C fails, you need to compensate for whichever of A or B actually ran. The set of compensations is not static; it depends on the execution path. With just three functions, this is already complex to draw. With 100 nodes, many of which can run in parallel, a graph representing all possible compensation paths becomes an unmanageable monstrosity.\nSome engines expose compensation handlers as first-class nodes or edges. They help for simple paths, but once compensations are data-dependent and path-dependent, authors are back to encoding the real logic in code anyway.\nIn code, compensations are straightforward.\ndef book_travel_workflow(details: TravelDetails):\n    \"\"\"\n    Books a flight and hotel, ensuring compensation if any step fails.\n    This dynamic compensation is nearly impossible to model in a graph.\n    \"\"\"\n    compensations = []\n    try:\n        if details.needs_flight:\n            flight_booking = book_flight(details.flight_info)\n            # Add the inverse operation to our list\n            compensations.append(lambda: cancel_flight(flight_booking.id))\n\n        if details.needs_hotel:\n            hotel_booking = book_hotel(details.hotel_info)\n            # Add the inverse operation to our list\n            compensations.append(lambda: cancel_hotel(hotel_booking.id))\n\n        # ... more steps\n        print(\"Workflow completed successfully!\")\n\n    except Exception as e:\n        print(f\"Workflow failed: {e}. Running compensations...\")\n        # Run all registered compensations in reverse order\n        for compensate in reversed(compensations):\n            compensate()\nWith Durable Execution, try/except/finally and idempotent activities give you natural, testable compensations.\nNow, try to represent this in a graph. If the car rental fails (step C), you must run compensations for hotel (B) and flight (A). If the hotel fails (step B), you must only compensate for flight (A). You would need to draw a complex web of conditional failure edges from every node to every previous nodes compensation. While some workflow engines provide compensation constructs, they still require designers to draw explicit compensation paths. The real issue is that modeling dynamic error paths in a static DAG becomes unwieldy and error-prone. With code, this logic is about 20 lines.\n4. Parallelism, reusability, and other woes\nThe problems dont stop there:\n\n  Parallelism: While fanning out to parallel branches is easy to draw, coordinating work between them is not. Coordination between parallel branches requires shared state, and such coordination in the graph world happens through data, which is usually just a bunch of key-value pairs. As weve seen, data management in graphs is already a weak point. When multiple parallel branches need to synchronize or share intermediate results to achieve a common goal, the graph notation provides no help  youre back to managing global variables with all their associated problems.\n  Asynchronous events: How does your workflow handle a user sending a new chat message to cancel a long-running task? This becomes even more complex when events can come out of order and require special handling based on their data. This requires dynamic logic that can interrupt the current flow, something graphs are ill-equipped to model. The common solution (a dedicated wait for event node) is clumsy and only works for the simplest cases. Durable Execution supports waiting for external events and user input as native operations.\n  Reusability: Graph-based logic is almost impossible to reuse. Because a node often relies on a loosely defined, ambient state, you cant just pick it up and use it in another workflow. In real programming, we have functions, classes, and libraries  units with explicit inputs/outputs. Graphs have no mature equivalent.\n\n5. Code brings modern development practices for free\nThe infrastructure-as-code movement won for a reason, and the same principles apply here. Graph-based systems force you to abandon the mature ecosystem of tools that makes software development efficient and reliable. When your workflow is code, you get the entire ecosystem of modern software engineering for free.\n\n  Source control: Use Git to track history, create branches, and collaborate. Reviewing a pull request for a YAML graph is painful; reviewing Python is a solved problem.\n  Testing: Write unit and integration tests for your logic using familiar frameworks like Pytest or JUnit. You can sometimes unit-test a node in a DAG, but its rarely ergonomic; teams end up building simulators or wrappers before they can test anything meaningful.\n  CI/CD: Integrate your workflow logic into existing automated build, test, and deployment pipelines.\n  Developer tooling: Leverage IDEs for autocompletion, static analysis, refactoring, and debugging  tools that barely exist for graph-based systems.\n  Observability: Durable Execution engines like Temporal integrate with distributed tracing (OpenTelemetry), enabling automatic generation of accurate execution traces for debugging.\n\nWhen building AI agents, developers need to experiment rapidly with prompts, tool order, and control logic. Representing this in a static graph slows iteration, whereas code can be changed and tested quickly using standard dev tools.\nThe But I can see it! fallacy\nThe single most cited benefit of a graph is that you can create a visual picture of it. But this is a sirens song. The picture is a lie.\n\n  It doesnt show the real control flow, which is hidden in data-dependent expressions.\n  It doesnt show data manipulation, which happens through untyped global maps or brittle selectors.\n  It cannot represent dynamic steps or complex error handling, which is where the most critical logic often resides.\n\nYou pay a big price in complexity, verbosity, runtime errors, and an inability to implement non-trivial scenarios, all for a picture that isnt even accurate.\nAnd heres the kicker: if you truly need a visual representation of your execution, code can produce a far better one. By instrumenting your code with standard tracing (like OpenTelemetry), you can generate a precise, hierarchical trace of what actually happened, not just a static ideal of what might happen.\nConclusion: Choose code\nThe next generation of AI applications demands a better approach. Durable Execution doesnt render graph-based orchestration entirely obsolete (there might be valid use cases when porting legacy systems), but it massively broadens the set of problems we can handle reliably. Match the tool to the job: static graphs for simple pipelines; durable code for dynamic, data-driven agents.\nDont assume that because others are using graphs, its the right or only way to write durable applications. The industry doesnt need to repeat the painful lessons we learned building workflow engines over the past two decades. A graph is one of the worst ways to represent procedural code. Its perceived simplicity is an illusion that shatters the moment you encounter the dynamic, data-driven, and error-prone reality of building sophisticated systems.\nThe next time someone tells you that you must use a graph to achieve durability and resiliency, tell them about Durable Execution. Its a proven paradigm that lets you write your business logic in plain, testable, reusable code. Pick up a modern framework that supports it, and see how much simpler, cleaner, and more robust your system becomes.\nYou absolutely can implement a graph-based engine on top of a Durable Execution system. The system makes any code durable. But that is a clunky, unnecessary, and leaky abstraction you simply dont need.",featureImage:{title:"social-card-temporalite-blog",description:"social-card-temporalite-blog",url:"https://images.ctfassets.net/0uuz8ydxyd9p/43c3wR1aXhf2oLpXy8WReZ/b280baada058cdc1d0dc9a4b2aaff37a/social-card-temporalite-blog.jpg"},publishDate:"2025-08-20",metaDescription:"Graphs break for dynamic AI agents. Durable Execution lets you build resilient, stateful workflows in plain code  with real error handling, retries, and tracing.",metaTitle:"The fallacy of the graph: Why your next agentic workflow should be code, not a diagram",socialCard:{title:"Blog (35)",description:"Blog (35)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/ggAgISA4FLL0OnzgaPwig/d568f8df6adaa45d387907de79a4b561/Blog__35_.png"},tags:"Durable Execution,Architecture,AI/ML,Python",slug:"the-fallacy-of-the-graph-why-your-next-workflow-should-be-code-not-a-diagram",contentType:"blogPost",entityId:"2xPQlA90qqR2qBqvIQJO1w",authors:[{id:"1X8y9RWlP8D5TPrughvFd2",name:"Maxim Fateev",slug:"maxim-fateev",jobTitle:"CTO and Co-Founder",photograph:{title:"Maxim Fateev",description:"Maxim Fateev",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7EdtHMKPMc4iH2gcwIzp8U/1909c8a7ab0fb81b122afe6810bb58c1/861A2412.jpg"},biography:"Max is CTO and co-founder of Temporal. He is a 20-year veteran of AWS, Google, and Uber, engineering leadership, having led the development of the SQS replicated message store and the Simple Workflow service at AWS, and then co-creating Cadence (Temporals predecessor) at Uber. Today, millions of Temporal workflows are run daily for high reliability and high scalability workloads from Stripe to Datadog to Snapchat.",twitterUrl:"https://twitter.com/mfateev",company:"Temporal",contentType:"person"}],authorsString:"Maxim Fateev",category:"Temporal Voices",readingTime:13},{title:"The unbreakable web: From fragile scripts to bulletproof Workflows",content:"The promise of AI agents is captivating. They are hailed as the next frontier in automation, capable of autonomously navigating websites, filling out forms, scraping data, and completing complex, multi-step processes without human involvement. The demos are slick and the conference talks are inspiring, but the reality for anyone building them in production is a daily battle against a single hard truth:\nThe web was built for humans, not for machines.\nThe answer is bulletproof browser automation, not merely smarter scripts.\nIts about building a system that always completes its mission, survives the chaos of the web, adapts when things change, and picks up exactly where it left off after something breaks. Thats what happens when you combine Browserbase, a platform for AI-powered browser automation, with Temporal, the industry standard for Durable Execution.\nThe brittle reality of web automation\n\n  Meet an engineer tasked with building a web automation workflow. Her goal: complete a complex, multi-page job application on an HR portal. This is a perfect use case for web automation because the portal doesnt have a public API, and the process involves filling out multiple forms, handling pop-ups, and navigating a multi-step user flow, all of which require a real browser.\n  \n  \n  She starts with a traditional automation script. It relies on a brittle selector to click the Submit button.\n\nawait page.locator('.submit-btn').click();\nThe script works until the next week, when the HR portals developers change the buttons class name from \"submit-btn\" to \"btn-primary\". Her automation script grinds to a halt, forcing her to spend a frustrating afternoon debugging and fixing broken scripts rather than moving on to higher-value work.\nEven worse, on a different attempt, a network blip occurs during a crucial data extraction step, causing the entire workflow to crash. All progress is lost, forcing her to start over from the beginning, wasting both time and compute resources. This cycle of fixing broken scripts and handling unexpected failures is the reality of traditional web automation.\nAn unbreakable foundation: Browserbase and Temporal\nThis is where Browserbase and Temporal come to the rescue. Instead of building fragile scripts, she uses Browserbase and its open-source AI browser automation SDK, Stagehand, to create an intelligent, self-healing automation. Stagehand uses large language models to understand and interact with web elements semantically, so she can write:\nawait stagehand.page.act(\"click the submit button\");\nStagehand understands her intent and finds the correct button, even if the underlying HTML or CSS changes. This makes her script resilient to website changes, significantly reducing maintenance overhead.\nBut what about the network failures and browser crashes? This is where Temporal provides the durability layer. Temporal is a Durable Execution platform that guarantees her code will run to completion, no matter what failures occur. It works by:\n\n  Persisting state: Temporal automatically saves the state of her Workflow after every step, so if a failure occurs, it can resume from the exact point where it left off. This is critical for long-running processes that would otherwise lose all progress across network interruptions, service restarts, or deployments.\n  Intelligent retries: She can declaratively define Retry Policies for the various steps in the automation Workflow, and Temporal will automatically manage retries for transient failures like network issues or timeouts.\n  Ensuring completion: Temporal ensures the entire multi-step process completes successfully, even if individual browser sessions crash.\n\nShe achieves this by wrapping the failure-prone portions of the Workflow in Temporal Activities. This simple but powerful pattern ensures that every single browser interaction, whether its filling out a form on page one or clicking Submit on page six of the job application, is durable and retryable. If the browser session dies or the website hangs, the Activity will simply retry that specific step, picking up right where it left off and reusing the existing Browserbase session thanks to the idempotent design. This transforms a fragile, manual-fix process into a reliable, self-healing automation.\nFrom basic code to bulletproof production\nIn our Browserbase Integrations GitHub repository, youll find a simple getting-started code sample that demonstrates this powerful combination: a resilient search workflow. Its a foundational example that shows how to encapsulate each step of a multi-step browser task in a durable Temporal Activity with automatic retry logic. This showcases the core principles of the partnership:\n\n  \n    Atomic Activities: Each step performs a single, well-defined task. For example,\n    initializeBrowser creates a browser session, and executeSearch types a query and submits the search. If one fails, only that specific step needs to be retried, not the entire Workflow, making Workflows efficient, easier to debug, and more flexible.\n  \n  Idempotent design: For safe automatic retries, Activities must be idempotent, meaning they can be called multiple times without causing unintended side effects. For instance, a cleanupBrowser Activity should be able to close open browser sessions and gracefully handle sessions that may already be closed.\n\nThe Temporal Workflow orchestrates these atomic Activities, defining the sequence of operations and applying tailored Retry Policies to each one. For example, the extractSearchResults Activity, which is most susceptible to website changes or network issues, is configured with more aggressive retries. This gives the developer granular control over how the system handles different types of failures.\nBelow you will see two steps of the Workflow, navigateToSearchPage and executeSearch, in both the Temporal UI and the Browserbase console.\nTemporal UI with Timeline View and Event History\n\nBrowserbase UI navigating to the Brave Search page\n\nTemporal UI with Timeline View and Event History\n\nExecuting the actual search in the Browserbase UI\nOnce the Workflow completes, you will see the top three search results for our initial question, How would you classify a Liger?\n\n  \n\nWhile the code sample focuses on a simple Brave search, you can scale the same architectural pattern to solve more ambitious use cases like:\n\n  Large-scale data collection: Extracting structured data from thousands to millions of dynamic websites with high success rates, automatically adapting to layout changes.\n  Complex fintech automation: Automating multi-page form submissions for critical tasks such as KYC (Know Your Customer) checks or loan applications on banking websites.\n  AI-agent workflow orchestration: Building multi-step AI agents that perform tasks across different platforms. For example: an agent that researches market trends, logs into a CMS to draft a blog post, and then schedules it on a social media platform.\n\nThe future of bulletproof web automation is here thanks to Browserbase and Temporal. Engineering teams can finally move beyond fixing fragile scripts and focus on building long-running, critical Workflows that truly drive business value. When your automation adapts to website changes automatically, you can monitor more sources with greater confidence.\nReady to build web automations that never fail? Dive into the full, runnable code example weve discussed by visiting the Temporal Code Exchange, or review the integration documentation. Youll find detailed instructions on setting up your environment, configuring API keys, and running the resilient search Workflow to see Temporal and Browserbase in action.\n\n\n  Get started: Learn more about building your first durable Workflow with the Temporal Platform Documentation and the Browserbase quick-start guide.\n  Dive into the code: Review the integration documentation and runnable code example on GitHub.\n  Need help? Join the Temporal Community Slack and the Browserbase Slack to connect with thousands of other developers.\n",featureImage:{title:"social-card-dark-waves (1) ",description:"social-card-dark-waves (1) ",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7fqbHM7iWOHKJo0GNha3Ou/ca1d6b6c63ab327d9e872eefa5a33627/social-card-dark-waves__1__1.png"},publishDate:"2025-08-20",metaDescription:"Build bulletproof browser automation and AI agents with Browserbase and Temporal. Stagehand and Durable Execution turn fragile scripts into resilient Workflows.",metaTitle:"The unbreakable web: From fragile scripts to bulletproof Workflows",tags:"Code Samples,Durable Execution,Retries,Timeouts,Typescript",slug:"the-unbreakable-web-from-fragile-scripts-to-bulletproof-workflows",contentType:"blogPost",entityId:"4ISCEqE6Z16cvVad1jRLSz",authors:[{id:"byguhZCaFwYjgF3brsTBH",name:"Dallas Young",slug:"dallas-young",jobTitle:"Commercial Solutions Architecture Manager",photograph:{title:"Dallas-Young",description:"Dallas-Young",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1BMR30dTfyI8fMODjB5kce/359f9e9d9be6987637613d450e3dcc73/TT31S6VK5-U067HQFKX28-90d388abcaa4-512.png"},linkedInUrl:"https://www.linkedin.com/in/dallas-young/",company:"Temporal",contentType:"person"},{id:"32iLw9CgOMKaTNCH077XIy",name:"Kyle Jeong",slug:"kyle-jeong",jobTitle:"Engineering and Growth",photograph:{title:"1753254639911",description:"1753254639911",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5RaobUdaZEFbYbfYqnBBWU/23e7caf75263388c856799b3bd717d34/1753254639911.jpeg"},linkedInUrl:"https://www.linkedin.com/in/kyle-jeong/",company:"Browserbase",contentType:"person"}],authorsString:"Dallas Young, Kyle Jeong",category:"Announcements",readingTime:7},{title:"Enabling platform engineering with Temporal: Five practical use cases",content:"Platform engineering teams are the force multipliers behind scalable infrastructure and streamlined developer experiences. Their mission? Build the internal platforms that let product engineers ship faster without sacrificing reliability or operational efficiency.\nThese days, apps are complex, spread out, and always crashing. Managing that complexity while providing reliable golden paths is no easy feat.\nThats where Temporal comes in. Temporal fortifies platform teams. With Temporal, your team can manage operations as fault-tolerant, reliable workflows.\nIn this post, well explore five real use cases where Temporal helps teams just like yours move from fragile scripts and makeshift processes to scalable infrastructure automation thats reliable. Always.\n1. Incident response and runbook automation\nFor platform teams, responding to incidents often relies on playbooks or inherent knowledge within an organization. Actions like restarting services, collecting logs, starting or stopping an operation within a Kubernetes cluster can be difficult to implement. Even if your team is using standalone tools or APIs to manage these actions, they often require oversight to ensure proper execution.\nHow Temporal helps:\nTemporal Workflows encode incident response logic as code:\n\n  Workflows can restart services, send alerts, or collect system data immediately when an incident occurs. These actions happen without manual intervention, reducing delays.\n  Some responses require human input, such as an approval or verification. Temporal lets Workflows pause and wait for those inputs before continuing.\n  Workflows can remain idle for hours or days until the next step is ready to run, allowing handoffs between teams or regions without losing progress.\n  All automated and manual steps are recorded in the Workflow history. This provides a clear record for audits and post-incident analysis.\n\nDatadog, for example, used Temporal to move their manual workbooks over to automated and highly available workflows for large migration operations and versioning. By turning runbooks into executable Workflows, they were able to gain consistency, speed, and insight during incidents.\n2. Certificate rotation\nExpired TLS certificates and stale credentials can silently disrupt critical services and introduce significant security vulnerabilities. Normally, certification rotation is handled through cron jobs or ephemeral scripts, which operate silently in the background.\nThese approaches are brittle: they can fail silently without triggering alerts, leaving administrators unaware of issues until service outages or security incidents occur. Its also tricky to track these operations throughout the rotation process and ensure visibility into their completion.\nHow Temporal helps:\nTemporal enables fault-tolerant Workflows that can help with certificate rotation in the following ways:\n\n  Certificate rotation process is done through resilient and stateful Workflows, surviving crashes and restarts with persistent state throughout.\n  Automated exponential backoff, retries, and long-running workflows (whether they run for less than a second or many years) ensure reliable, timely certificate renewal and propagation.\n  A visual UI offers real-time insight into certificate rotation progress, failures, and audit history.\n  Orchestration lives in Workflows, while rotation logic  like calling certificate authorities or updating secrets  runs in Workers for clarity and maintainability.\n\nTemporal Cloud supports certificate rotation with mTLS and API keys, and even provides guidance on how to do so. This approach provides platform teams with resilience, compliance visibility, and assurance that sensitive credentials are never left unmanaged.\n3. Infrastructure management\nOne of the most common challenges in infrastructure management is ensuring reliability across a complex ecosystem of components, each with its own potential points of failure. Whether it's hardware availability, network disruptions or service misconfigurations, platform teams must ensure that multi-step processes complete successfully even when issues arise. Otherwise, your infrastructure can end up in an inconsistent state with orphaned resources.\nWith Temporal, teams can build long-running, fault-tolerant workflows that guarantee each step executes reliably and consistently  regardless of underlying failures.\nHow Temporal helps:\nTemporal can support infrastructure management in a few different ways:\n\n  Automate the entire resource lifecycle by orchestrating provisioning, monitoring, updates, and teardown through resilient workflows that handle retries, timeouts, and state tracking  all without manual intervention.\n  If something fails, Temporal automatically retries. During that time, you can go and fix the issue without losing all the Workflows progress, and when youre done the Workflow will complete.\n  Teams can observe exactly where a resource is in its lifecycle with live status and history.\n\nTemporals powerful platform can be adapted as a powerful engine for managing the full lifecycle of infrastructure with built-in reliability, traceability and safety.\n4. CI/CD pipeline orchestration\nCI/CD pipelines often span multiple stages  unit tests, integration checks, approvals, canary deploys, metrics validation, and rollback conditions. Given the number of required steps, conventional tools can potentially fail hours into a job, resulting in the whole process needing to be started from scratch. Platform teams are often responsible for managing fast delivery without sacrificing reliability.\nHow Temporal helps:\nTemporal allows teams to:\n\n  Build CI/CD functions as stateful workflows with branching logic, retries, and pause-resume control, and dynamic rollback that resumes from the failure point instead of starting over\n  Release gates, canary deployments, and automated long-haul tests (e.g., 72-hour runs) can be managed as part of a CI/CD workflow, with customizable branching logic and dynamic pausing or halting when issues are detected\n  Every action taken in a pipeline  build, test, deploy, rollback  is logged and visible through Temporals history, supporting postmortems and compliance requirements.\n\nNetflix re-platformed Spinnaker to use Temporal as the backend for orchestrating continuous delivery (CD) pipelines. Temporal executes and tracks multi-step deployment workflows, ensuring resilience, state management, and reliable execution even if failures occur during a deployment. These features have provided Netflix with resilient, traceable software delivery.\n5. Internal Developer Platform (IDP) automation\nOperating in a cloud-native, microservice-based environment often adds difficulty, and teams must manage failures, data durability, and distributed consistency. As such, platform teams want to provide their developers with golden paths that shield them from complexity while also providing context.\nTemporal allows platform teams to use built-in primitives such as Workflows, Activities, Callers, and more to define specific actions that developers can take within their environments.\nHow Temporal helps:\nTemporal Workflows can form the backbone of IDP automation by doing the following:\n\n  Encapsulate complex tasks such as provisioning, CI/CD, or infrastructure management behind simple workflow triggers. Developers dont need to know the APIs, approval chains, or operational details.\n  Coordinate across multiple systems (e.g., GitHub, Terraform, Vault, DNS) to deliver end-to-end workflows.\n  Enable secure delegation with built-in role-based access control, namespace isolation, and API key management, allowing teams to self-serve operations within safe boundaries.\n  Integrate manual approvals or signals where needed, for example, for security or cost validation.\n  Provide a consistent, observable, and retryable developer experience, making platform workflows dependable and transparent.\n\nCompanies like Humana leverage Temporal as an abstraction layer that simplifies the development of resilient cloud applications. Now, their engineers can focus on business logic rather than navigating infrastructure complexity, and spend their time accelerating the delivery of their cloud-native applications.\nHow you can get started\nFrom automating incident response and securing certificate management to managing infrastructure, orchestrating CI/CD pipelines, and enabling golden paths through IDP automation, Temporal inspires platform engineering teams to tame complexity head-on. By turning operations into resilient, stateful workflows, Temporal gives teams the tools to build scalable, developer-friendly platforms.\nReady to see how Temporal can elevate your platform engineering strategy?\n\n  Talk to an expert about your platform challenges\n  Connect on the Temporal Community Slack\n  Sign up for Temporal Cloud and get $1,000 in free credits to explore what Temporal can do for your team\n",featureImage:{title:"social-card-purple",description:"social-card-purple",url:"https://images.ctfassets.net/0uuz8ydxyd9p/UbL8tEOAIBjMrI6OCSeNN/62aecca8ce16e11e288c1fd7ef4e346d/social-card-purple.jpg"},publishDate:"2025-08-13",metaDescription:"Learn how platform engineering teams automate incident response, certificate rotation, infrastructure management, CI/CD, and IDP workflows with Temporal.",metaTitle:"Enabling platform engineering with Temporal: 5 practical use cases",socialCard:{title:"Blog (33)",description:"Blog (33)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/BNpGgTDVkoygaFGhDDXEB/24296cc589bb7bd1f2a8f5cfe77c9c76/Blog__33_.png"},tags:"Code Samples",slug:"enabling-platform-engineering-with-temporal-five-practical-use-cases",contentType:"blogPost",entityId:"43w26bfXZ3qn0vqiMNmMnU",authors:[{id:"1yrw1pOcC2diZQ4Eh34TIG",name:"Cubby Sivasithamparam",slug:"cubby-sivasithamparam",jobTitle:"Product Marketing Manager, Platform Operations",photograph:{title:"TT31S6VK5-U08R85TH125-f6bfe8629b58-192",description:"TT31S6VK5-U08R85TH125-f6bfe8629b58-192",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5SX3woxXVYFZUsZBlZnbpf/d54322791501d0d22b2ac95f4e462037/TT31S6VK5-U08R85TH125-f6bfe8629b58-192.jpeg"},company:"Temporal",contentType:"person"},{id:"5UNwygCxwqYCdaa27gAYNS",name:"Cornelia Davis",slug:"cornelia-davis",jobTitle:"Senior Staff Developer Advocate",photograph:{title:"Cornelia Davis Headshot",description:"Cornelia Davis Headshot",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6TDAN3Pi1qvx8m6HBdC4Kk/24be44497f96b4236b4e61b054e8568f/image.png"},company:"Temporal",contentType:"person"}],authorsString:"Cubby Sivasithamparam, Cornelia Davis",category:"How-To",readingTime:7},{title:"Running GitHub Actions through Temporal: A complete guide",content:"For those who arent aware, Temporal is made up of an open-source project as well as a hosted Cloud offering. Our engineers work hard to maintain 100% feature parity between these two. This means that any release of the Cloud product requires, at a minimum, communication across two repositories. As Temporal has grown, and our CI/CD pipelines grew with it, we ran into a familiar set of problems: GitHub Actions can do the tasks, but their orchestration doesnt scale to complex release pipelines.\nWe needed more control over how actions run and the reliability to match.\nThats what inspired me to write this guide. Throughout, Ill walk through how we used Temporal to build a durable orchestration layer for GitHub Actions. It covers the full stack: GitHub App authentication, dispatch ID tracking, Temporal Workflows and Activities, retry logic, long-polling with heartbeats, and even helpful production test tips. Basically, breaking down everything I wish I knew when facing this problem myself.\nIf youve ever wanted to treat CI/CD like a proper system, something observable, debuggable, and recoverable, then join me as we walk through building this system from the ground up.\nWhy add orchestration to GitHub Actions?\nGitHub Actions do a great job running CI/CD tasks (e.g. testing, building, deploying, etc.) but once you need more coordination or visibility, things start to deteriorate. Dispatching across multiple repos, handling long-running jobs, or recovering gracefully from failure aren't built in.\nThat's why you need orchestration. Its a way to trigger, track, and manage actions as part of a bigger, more reliable system.\nBy combining GitHub Actions and Temporal, we created a CI/CD system that scales with our needs and survives failure without slapdash efforts to patch things up.\nArchitecture overview\nTo start, heres a high-level look at the system we built. This setup calls GitHub's Actions API through Temporal's Workflow orchestration to create reliable, observable CI/CD pipelines.\nNaming conventions\nBefore we get too deep into things, lets clarify some overlapping terminology that can be confusing:\n\n  Temporal: Has \"Workflows\" (orchestration logic) and \"Activities\" (individual tasks)\n  GitHub: Has \"actions\" (YAML workflow files) and \"workflows\" (individual runs of those actions)\n\nThroughout this guide, we'll use these naming conventions:\n\n  Action\" refers to GitHub concepts (the YAML files and their runs).\n  \"Temporal Workflow\" and \"Temporal Activity\" when referring to Temporal concepts.\n  \"GitHub Action\" when we need to be explicit about GitHub's side.\n\nFor example: \"Our Temporal Workflow triggers a GitHub Action, then uses Temporal Activities to monitor the action run's status.\"\nHigh-level components\nWith that naming cleared up, lets walk through the building blocks. To run GitHub Actions through Temporal, you need four main components:\n\n  GitHub API Client: Handles authentication via GitHub Apps and provides methods to trigger actions, search for action runs, and monitor their status\n  Temporal Workflow: Orchestrates the three-phase process of triggering and monitoring actions with proper error handling and retry logic\n  Temporal Activities: Execute the actual GitHub API calls with appropriate timeout and retry configurations for each operation type\n  \n    Worker/Client Infrastructure: Runs the Temporal workers and provides a client interface for triggering workflows\n    \n    \n  \n\nGitHub app authentication model\nThe system uses GitHub Apps for secure, installation-scoped authentication. Unlike personal access tokens, GitHub Apps provide:\n\n  Fine-grained permissions per repository\n  Installation-level access control\n  Audit trails for all API operations\n  Automatic token rotation\n\n\n  The app authenticates itself within your GitHub organization using a JSON Web Token (JWT).\n  The app will then generate an installation access token with specific repository access.\n\nYou can go here if you want to learn more about authentication with GitHub Apps.\nThe dispatch ID challenge\nNow that we've discussed authentication, its time to move to orchestration. One critical challenge when dispatching actions through GitHub's API is that it doesn't provide the ID of the dispatched action run. This creates a coordination problem: how do you track an action you just triggered when you don't know its ID?\nOur solution uses the community-accepted workaround of injecting our own unique identifier into the Action as an input parameter. Later in the process, we can search the step names of action runs to identify our specific run.\nname: wait-then-echo\non:\n  workflow_dispatch:\n    inputs:\n      dispatch_id:\n        description: An ID used to identify the workflow run\n        required: true\n        type: string\njobs:\n  dispatch:\n    runs-on: ubuntu-latest\n    steps:\n      # Put the dispatch ID in the step name so we can find it later\n      - name: Dispatch ${{ inputs.dispatch_id }}\n        run: echo \"Dispatch ${{ inputs.dispatch_id }}\"\nTemporal Workflow vs GitHub Actions relationship\nThe integration creates a clear separation of concerns:\n\n  GitHub Actions: Handle the actual CI/CD work (e.g. testing, building, deploying).\n  Temporal Workflows: Orchestrate when and how actions run, with reliable execution guarantees.\n\nThis relationship enables:\n\n  Complex coordination: Chain multiple actions across repositories.\n  Reliable execution: Automatic retries and failure handling.\n  Observability: Complete audit trail of all orchestration decisions.\n  Long-running processes: Wait for actions that take hours without timeouts.\n\nSetting up GitHub app authentication\nWith our architecture mapped out, lets look at the code. To trigger actions programmatically, we need to authenticate as a GitHub App. This provides secure, scoped access to repositories and their workflows.\nWe can use the ghinstallation library by bradleyfalzon to handle app and repository authentication. Once authenticated, we can use the go-github library to create a client for interacting with the GitHub API.\nThe authentication setup uses a two-step process. First, authenticate as the app using a credential obtained from an external source. Then, generate credentials specific to the repository you want to run the action in.\nimport (\n\t\"github.com/bradleyfalzon/ghinstallation/v2\"\n\t\"github.com/google/go-github/v68/github\"\n)\n\ntype GitHubApp struct {\n\tOrg        string\n\tID         int64\n\tPrivateKey string\n}\n\ntype Client struct {\n\t*github.Client\n}\n\nfunc NewClient(ctx context.Context, app GitHubApp, repo string) (*Client, error) {\n\t// Create app-level transport\n\tappTransport, err := ghinstallation.NewAppsTransport(\n\t\thttp.DefaultTransport,\n\t\tapp.ID,\n\t\t[]byte(app.PrivateKey),\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Find the installation for this repository\n\tappClient := github.NewClient(&http.Client{Transport: appTransport})\n\tinstallation, _, err := appClient.Apps.FindRepositoryInstallation(ctx, app.Org, repo)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Create installation-specific client\n\tinstallationTransport, err := ghinstallation.New(\n\t\thttp.DefaultTransport,\n\t\tapp.ID,\n\t\tinstallation.GetID(),\n\t\t[]byte(app.PrivateKey),\n\t)\n\n\treturn &Client{Client: github.NewClient(&http.Client{Transport: installationTransport})}, nil\n}\nCore GitHub API Operations\nOnce authenticated, we need three core operations: triggering actions, finding their IDs, and monitoring status.\nTriggering an action:\nfunc (client *Client) TriggerAction(ctx context.Context, org, repo, workflowFile, ref string, inputs map[string]any) error {\n\t_, err := client.Actions.CreateWorkflowDispatchEventByFileName(\n\t\tctx, org, repo, workflowFile,\n\t\tgithub.CreateWorkflowDispatchEventRequest{\n\t\t\tRef:    ref,\n\t\t\tInputs: inputs,\n\t\t},\n\t)\n\treturn err\n}\nFinding the action ID:\nSince GitHub doesnt return the run ID when triggering an action, we search for it by looking for our unique dispatch ID in the jobs step names.\nfunc (client *Client) GetActionID(ctx context.Context, org, repo, workflowFile, ref, dispatchID string) (int64, error) {\n\tfor runItem := range client.iterateActionRuns(ctx, org, repo, workflowFile) {\n\t\tfor jobItem := range client.iterateRunJobs(ctx, org, repo, runItem.value.GetID()) {\n\t\t\tfor _, step := range jobItem.value.Steps {\n\t\t\t\tif strings.Contains(step.GetName(), dispatchID) {\n\t\t\t\t\treturn runItem.value.GetID(), nil\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn -1, errors.New(\"Action ID not found\")\n}\nGetting the Action status:\ntype Action struct {\n\tStatus     string\n\tConclusion string\n\tURL        string\n}\n\nfunc (client *Client) GetActionStatus(ctx context.Context, org, repo string, actionID int64) (*Action, error) {\n\trun, _, err := client.Actions.GetWorkflowRunByID(ctx, org, repo, actionID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &Action{\n\t\tStatus:     run.GetStatus(),\n\t\tConclusion: run.GetConclusion(),\n\t\tURL:        run.GetURL(),\n\t}, nil\n}\nDesigning the Temporal Workflow\nAt the center of the system is our main Workflow. This Temporal Workflow orchestrates the three-step process: trigger, discover, and monitor.\ntype GitHubActionRequest struct {\n\tOrg          string // GitHub organization name\n\tRepo         string // Repository name\n\tRef          string // Git reference (branch, tag, or commit SHA. Most of the time this will be main)\n\tWorkflowFile string // Action file name (e.g. deploy.yml)\n\tInputs       []struct {\n\t\tKey   string // Input parameter name\n\t\tValue string // Input parameter value\n\t}\n}\n\ntype GitHubActionResponse struct {\n\tStatus     string // Action status: \"queued\", \"in_progress\", \"completed\"\n\tConclusion string // Final result: \"success\", \"failure\", \"cancelled\", etc.\n\tURL        string // GitHub URL to view the action run\n}\n\nfunc RunGitHubAction(ctx workflow.Context, request GitHubActionRequest) (*GitHubActionResponse, error) {\n\t// Create a dispatch ID to track the GH action we are running\n\tdispatchID, err := uuidSideEffect(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Start the GH action\n\tif err = triggerGitHubAction(ctx, request, dispatchID); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Use the dispatch ID we added to get the action's ID\n\tactionID, err := getActionID(ctx, request, dispatchID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Wait for the action to finish and return its final status\n\treturn awaitActionCompletion(ctx, request, actionID)\n}\nIts worth pointing out that the Workflow uses a SideEffect to generate a UUID that will remain consistent across Workflow Replays. This is so that our Activities can freely retry using a consistent dispatchID for the entire Workflow execution.\nfunc uuidSideEffect(ctx workflow.Context) (string, error) {\n\tsideEffect := workflow.SideEffect(ctx, func(ctx workflow.Context) any {\n\t\treturn uuid.New().String()\n\t})\n\tvar uuid string\n\treturn uuid, sideEffect.Get(&uuid)\n}\nImplementing Temporal Activities\nNow, lets zoom in on the activities themselves. In Temporal, Activities handle any code that can fail. For us, that means the GitHub API calls. Each Activity has specific timeout and retry configuration based on its expected behavior.\nTriggering the action\nYou may have noticed that were passing a slice for a variable representing a map. This is because Gos map type is non-deterministic and Temporal Activities require deterministic inputs so that they can be Replayed. We can handle this simply by converting the slice to a map before making the client call.\nfunc (a *Activities) TriggerGitHubActionActivity(ctx context.Context,request GitHubActionRequest, dispatchID string) error {\n\tinputs := mapFromSlice(request.Inputs)\n\n\t// Check if the user is using the dispatch_id input key\n\tif _, ok := inputs[\"dispatch_id\"]; ok {\n\t\terr := ReservedInputKeyError{}\n\t\treturn temporal.NewNonRetryableApplicationError(err.Error(), err.Name(), nil)\n\t}\n\n\t// Add the dispatch ID to the inputs\n\tinputs[\"dispatch_id\"] = dispatchID\n\n\tclient, err := github.NewClient(ctx, a.App, request.Repo)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn client.TriggerAction(ctx, request.Org, request.Repo, request.WorkflowFile, request.Ref, inputs)\n}\nFinding the action ID\nfunc (a *Activities) GetActionIDActivity(ctx context.Context, request GitHubActionRequest, dispatchID string) (int64, error) {\n\tclient, err := github.NewClient(ctx, a.App, request.Repo)\n\tif err != nil {\n\t\treturn -1, err\n\t}\n\n\treturn client.GetActionID(ctx, request.Org, request.Repo, request.WorkflowFile, request.Ref, dispatchID)\n}\nWaiting for action completion\nThis Activity implements a polling pattern with heartbeats to keep the Activity alive while monitoring long-running actions.\nThe key here is using activity.RecordHeartbeat() to prevent timeouts and provide status updates to the workflow execution history. Additionally, adding the status as a detail in the heartbeat call greatly improves developer visibility of the action's status during execution.\nThis Activity implements a polling pattern with heartbeats to keep the Activity alive while monitoring long-running actions.\nThe key here is using activity.RecordHeartbeat() to prevent timeouts and provide status updates to the workflow execution history. Additionally, adding the current status of the running Action as a detail in the heartbeat call greatly improves developer visibility of the action's status during execution.\nfunc (a *Activities) AwaitActionCompletionActivity(ctx context.Context, request GitHubActionRequest, actionID int64, pollRate time.Duration) (*GitHubActionResponse, error) {\n\tclient, err := github.NewClient(ctx, a.App, request.Repo)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor {\n\t\tstatus, err := client.GetActionStatus(ctx, request.Org, request.Repo, actionID)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tif status.IsRunning() {\n\t\t\tselect {\n\t\t\t// The ctx timed out or was cancelled before the action completed\n\t\t\tcase \u003C-ctx.Done():\n\t\t\t\treturn nil, ctx.Err()\n\t\t\t// Wait for the specified poll rate before checking again\n\t\t\tcase \u003C-time.After(pollRate):\n\t\t\t\tactivity.RecordHeartbeat(ctx, status)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tresp := &GitHubActionResponse{\n\t\t\tStatus:     status.Status,\n\t\t\tConclusion: status.Conclusion,\n\t\t\tURL:        status.URL,\n\t\t}\n\n\t\t// Return a non-retryable error if the action failed since this activity cannot retry the action\n    if status.IsFailure() {\n\t\t\terr := GithubActionConclusionError{}\n\t\t\treturn resp, temporal.NewNonRetryableApplicationError(err.Error(), err.Name(), nil, status.Conclusion)\n\t\t}\n\n\t\t// The action completed successfully\n\t\treturn resp, nil\n\t}\n}\n\nfunc (action Action) IsRunning() bool {\n\tterminalStates := []string{\"completed\", \"cancelled\", \"failure\", \"neutral\", \"skipped\", \"success\", \"timed_out\"}\n\treturn !slices.Contains(terminalStates, action.Status)\n}\n\nfunc (action Action) IsFailure() bool {\n  var failureStates = []string{\"failure\", \"timed_out\"}\n\treturn slices.Contains(failureStates, action.Conclusion)\n}\nError Handling\nAt Temporal, we always stress reliability so proper error handling is essential. This means we must differentiate between transient errors (typically network issues) which should be retried and errors which should not be retried (an invalid request, for example).\nTransient Errors:\nTransient errors within Temporal Activities can be treated exactly like normal Go errors. If your activity returns an error, the activity will be retried according to its RetryPolicy.\nNon-Retryable Errors:\nErrors which should not be retried can be created with temporal.NewNonRetryableApplicationError(). For organization we create custom error types and configure the activity with its possible errors.\ntype ReservedInputKeyError struct{}\n\nfunc (e ReservedInputKeyError) Error() string {\n  return \"dispatch_id input is a reserved input key\"\n}\n\nfunc (e ReservedInputKeyError) Name() string {\n\treturn \"ReservedInputKeyError\"\n}\n\nfunc triggerGitHubAction(ctx workflow.Context, request GitHubActionRequest, dispatchID string) error {\n\t...\n\n\tctx = workflow.WithActivityOptions(ctx, workflow.ActivityOptions{\n\t\tRetryPolicy: &temporal.RetryPolicy{\n\t\t\t...\n\t\t\t// Errors that will prevent the activity from being retried.\n\t\t\tNonRetryableErrorTypes: []string{\n\t\t\t\tReservedInputKeyError{}.Name(),\n\t\t\t},\n\t\t},\n\t})\n\n\tactivity := (*Activities).TriggerGitHubActionActivity\n\tfuture := workflow.ExecuteActivity(ctx, activity, request, dispatchID)\n\tif err := future.Get(ctx, nil); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\nHandling action retries:\nNow were handling API errors and invalid requests, but what if the action itself fails?\nIf our activities had a one-to-one correspondence with an Action run, we could return an error and let Temporal automatically handle the retries. But that's not our case. Since we interact with our actions through multiple Activities, we must retry at the workflow level. By default, Temporal does not retry Workflows when they fail, but we can add a retry policy to the Workflow in the exact same way we would add one to an Activity.\nfunc runWorkflow(ctx context.Context, temporalClient client.Client) error {\n  opts := client.StartWorkflowOptions{\n    TaskQueue: \"my-gh-actions-task-queue\",\n    RetryPolicy: &temporal.RetryPolicy{\n      // 0 means unlimited attempts\n      MaximumAttempts: 0,\n    },\n  }\n  ...\n\n  future, err := temporalClient.ExecuteWorkflow(ctx, opts, wf, args)\n  ...\n}\nWorker and client implementation\nThe final step is setting up the worker to execute activities and a client to trigger workflows.\nWorker setup:\nfunc main() {\n\t// GitHub App configuration\n\tapp := github.GitHubApp{\n\t\tOrg:        \"my-org\",\n\t\tID:         1234567,\n\t\tPrivateKey: \"my-private-key\",\n\t}\n\n\t// Create a Temporal client\n\ttemporalClient, err := client.Dial(client.Options{})\n\tif err != nil {\n\t\tfmt.Println(\"Failed to create Temporal client:\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Create a Temporal worker\n\ttaskQueue := \"my-task-queue\"\n\ttemporalWorker := worker.New(temporalClient, taskQueue, worker.Options{})\n\n\t// Register workflows and activities\n\ttemporalWorker.RegisterWorkflow(workflows.RunGitHubAction)\n\n\tactivities := workflows.Activities{App: app}\n\ttemporalWorker.RegisterActivity(activities)\n\n\t// Run the worker\n\tif err = temporalWorker.Run(worker.InterruptCh()); err != nil {\n\t\tfmt.Println(\"Worker failure:\", err)\n\t\tos.Exit(1)\n\t}\n}\nClient usage:\nfunc main() {\n\ttemporalClient, err := client.Dial(client.Options{})\n\tif err != nil {\n\t\tfmt.Println(\"Failed to create Temporal client:\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Execute the workflow\n\topts := client.StartWorkflowOptions{TaskQueue: \"my-task-queue\"}\n\trequest := workflows.GitHubActionRequest{\n\t\tOrg:          \"my-org\",\n\t\tRepo:         \"my-repo\",\n\t\tRef:          \"main\",\n\t\tWorkflowFile: \"wait-and-echo.yaml\",\n\t\tInputs: []struct {\n\t\t\tKey   string\n\t\t\tValue string\n\t\t}{\n\t\t\t{Key: \"wait_time\", Value: \"100\"},\n\t\t\t{Key: \"message\", Value: \"my custom message\"},\n\t\t},\n\t}\n\n\tfuture, err := temporalClient.ExecuteWorkflow(ctx, opts, workflows.RunGitHubAction, request)\n\tif err != nil {\n\t\tfmt.Println(\"Failed to execute workflow:\", err)\n\t\tos.Exit(1)\n\t}\n\n\tvar result workflows.GitHubActionResponse\n\tif err = future.Get(ctx, &result); err != nil {\n\t\tfmt.Println(\"Failed to get workflow result:\", err)\n\t\tos.Exit(1)\n\t}\n\n\tfmt.Printf(\"Action completed with status: %s\\n\", result.Status)\n}\nRunning it:\nAfter you have set everything up, you can run the Temporal Server, the Worker, and the client.\n# Start a Temporal server in the background\ntemporal server start-dev &\n\n# Start the worker in the background\ngo run ./cmd/worker/main.go &\n\n# Run the client to trigger an action\ngo run ./cmd/client/main.go\n\n  Go to http://localhost:7233 to see the Temporal Web UI and monitor the Workflow.\n  \n  \n\n\n  Go to your repository's Actions tab to see the action run.\n  \n  \n\nAs you can see, we successfully ran our action, with custom inputs, completely through our Temporal Workflow.\nTesting strategies\nNow we can orchestrate the running of any action we want, but we still need a way to test our CI/CD pipelines.\nBy default, actions don't have any form of dry run. This makes developing actions with side effects (creating artifacts, cutting branches, etc.) potentially dangerous. One wrong change can destroy a release branch. To combat this possibility, we've set up \"mirror\" repositories that are synced against the contents of our real repositories. With this, we can freely run integration tests of the entire CI/CD process.\nname: Mirror Respostory\non:\n  workflow_dispatch:\npermissions:\n  contents: read\n  id-token: write\njobs:\n  synchronize:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/create-github-app-token@v2\n        id: app-token\n        with:\n          app-id: ${{ secrets.MY_APP_ID }}\n          private-key: ${{ secrets.MY_PRIVATE_KEY }}\n          owner: ${{ github.repository_owner }}\n          repositories: my-repo\n      - uses: actions/checkout@v4\n        with:\n          repository: my-org/mirror-my-repo\n          ref: main\n          token: ${{ steps.app-token.outputs.token }}\n      - name: Hard reset mirror-my-repo to match my-repo\n        run: |\n          git config --unset-all http.https://github.com/.extraheader\n          git remote set-url origin https://token:${{ steps.app-token.outputs.token }}@github.com/my-org/mirror-my-repo\n          git remote add upstream https://token:${{ steps.app-token.outputs.token }}@github.com/my-org/my-repo\n          git remote set-url --push upstream NO_PUSH\n          git fetch upstream main\n          git reset --hard upstream/main\n          git push --force origin main\nThis strategy does require careful consideration when the repositories youre mirroring have actions that trigger on events like branch creation, or release creation.\nOne way of dealing with this problem is to use a repository level variable that defines when these side effects should be executed. Since this variable is not present in the mirror repository, we can safely interact with the mirror repositories without fear of triggering unexpected side effects.\nProduction considerations\nAt this point, you can orchestrate the running of actions and you can safely test them, but there are a few additional tips that go a long way in production.\nAction idempotency\nTemporal recommends that all activities performed by a workflow be idempotent. Since Temporal cannot validate the tasks performed by the GitHub Actions you choose to run, it is up to you to write your actions with this in mind.\nRunning Actions from the marketplace\nThe GitHub API only allows you to trigger actions defined in your own repositories. If you specifically want to run actions from the marketplace, you can write a simple wrapper that just calls the marketplace action.\nDebugging\nDebugging failing actions often involves a slow iteration loop, since you have to navigate many pages and buttons to find the information you need. To help with this, we recommend outputting the action URL when heartbeating, or returning from an error. The developer can then check for action inputs, status, and logs all in one place through the Temporal Workflow UI.\nConclusion\nWith Temporal and GitHub Actions, we got exactly what we needed: dependable CI, total transparency, predictable failures, and reliable scaling.\nOur system reflects how we approach developer productivity at Temporal  as more than just running tasks  leading to inherently resilient designs. If youre looking to make your CI workflows more predictable and debuggable, I hope this guide helps you get started faster.\nYou can view the complete source code for this blog here.\nIf youre a person who is curious like I am, you can always join our Community Slack and chat with devs or even members of Temporal about topics like this. If you want to get your hands dirty, then you can start with a free trial of Temporal Cloud with $1,000 in free credits.",featureImage:{title:"rick-rothenberg-JP-d0V5UBxs-unsplash 1",description:"rick-rothenberg-JP-d0V5UBxs-unsplash 1",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Q3MJsvD1ujCkIoEbicDUD/91e1dc92fa47018f97057873b03ff3c6/rick-rothenberg-JP-d0V5UBxs-unsplash_1.png"},publishDate:"2025-08-06",metaDescription:"If you're trying to figure out how to run GitHub Actions through Temporal, our software engineers will walk you through it.",metaTitle:"Running GitHub Actions through Temporal: A complete guide",socialCard:{title:"Running-GitHub-Actions-through-Temporal-a-complete-guide",description:"Running-GitHub-Actions-through-Temporal-a-complete-guide",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Hs0zvJF8zJ7DuAAo6h68w/0952f60e1179dcb67fc74061e0f0d1c5/Running-GitHub-Actions-through-Temporal-a-complete-guide.png"},tags:"Observability,CI/CD,Go,Batch Processing,Code Samples",slug:"running-github-actions-temporal-guide",contentType:"blogPost",entityId:"5bT3tFrBoVNZNSeOvvZUen",authors:[{id:"34UeziXP9UYcP6hb4HVsLJ",name:"Lily Baginski Doar",slug:"lily-baginski-doar",jobTitle:"Software Engineer II. Developer Productivity",photograph:{title:"lily-baginski-doar-headshot",description:"lily-baginski-doar-headshot",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4wUfkDKN3Z1AkqvpADtdQg/a832e13380b12272f6d81c60a6eec42f/lily-baginski-doar-headshot.jpeg"},contentType:"person"}],authorsString:"Lily Baginski Doar",category:"How-To",readingTime:17},{title:"Production-ready agents with the OpenAI Agents SDK + Temporal",content:"AI agents have become the dominant approach to building applications that leverage LLMs. They are AI-powered applications that dont just respond to input, but actively pursue objectives using LLMs, memory, and tools. While I dont believe there will ever be a single way to build these agents, some patterns are proving to be broadly applicable, and they are starting to show up as primitives in AI-centric programming frameworks, like the OpenAI Agents SDK.\nI worked with the TypeScript version of OpenAIs SDK a couple of months ago, but as of late have had a reason to dig deeper into the original Python one, and its pretty darn slick. I personally love anything where one of the stated goals is to keep the model as simple as possible, but only when it also stays the heck out of the way of the developer (nod to my friend and former boss Tom). These are the two stated goals of the OpenAI Agents SDK.\nBut the reason I come to you today is to share the news that things just got even better.\nOpenAI and Temporal have teamed up to add Durable Execution to agents built using OpenAIs Agents SDK, and today we released the new integration in Public Preview.\nThis means that AI agents you build with the OpenAI Agents SDK will stand up to any manner of challenges thrown at them in production. Rate-limited LLMs? Your apps will hang on and automatically progress when there is once again sufficient capacity. Sporadic network connectivity? Your app will retry downstream requests until they get through. Your app crashes when its just about done with a long-running task? Restart it, and Temporal will see to it that it picks up where it left off, saving you compute and token costs! That crash was due to a bug you hadnt caught yet? Yup, you can even fix that bug and continue execution of running apps.\n  \n  \n\nThats what Durable Execution gives you  crash-proof execution. Once the app starts running, Temporal will keep it running even in the face of all of these types of problems.\nBut heres the thing. You get all of this without an increase in code complexity. In fact, if you are new to Temporal, let me share with you one of the core Temporal values: With Temporal, you get to code the happy path, and Temporal does the error handling for you.\nThats right. Both OpenAI and Temporal share the foundational tenet of making the developer productive, yet both also give the developer the agency to do any manner of complex things. This is an integration thats making this developers heart sing!\nAnd let me draw your attention to the title of this post  it carries the word production-ready. While there are a fair number of frameworks out there that can help you build AI agent proof-of-concepts with relative ease, solutions that allow you to carry those experiments forward to production with comparable ease are few and far between.\nIn this post, I want to tell you about the new integration that does exactly that  allows you to get started quickly, and helps you achieve the durability you need for deploying this in the real world. Ill cover how it works, what you can do with it, and the value it brings. Ill start with a super quick intro to the most relevant parts of the Agents SDK and of Temporal  just enough to understand the magic that the integration brings. (Feel free to skip those parts if you are already aficionados thereof.) Then Ill jump into the details of the magic. Ill also share a set of steps you can follow to take your existing Agent SDK apps and add the Temporal integration.\nOpenAI Agents SDK: Easy-to-use agent primitives\nWith the goal of simplicity, the OpenAI Agents SDK defines only four primitives:\n\n  Agents\n  Handoffs\n  Guardrails\n  Sessions\n\nFor today, well focus on only the first two, but for a bit of context, guardrails are about putting some bumpers around user input (prompts), and sessions are about managing your applications memory.\nAn agent is, if you will, the core compute abstraction for your agentic apps. It starts with an LLM (and yes, each agent you define can point to a different model) and attaches to it:\n\n  Instructions that focus the LLM on very specific goals (e.g., you are a research assistant),\n  Tools that the LLM can decide to execute in pursuit of that goal,\n  A list of other agents that it may handoff control to,\n  And a bit of other configuration.\n\nHeres a definition of a triage agent that will take in user input and decide whether it should hand off to a weather reporting agent or a local businesses agent:\nfrom agents import Agent\nagent = Agent(name=\"Triage Agent\", \n              model=\"gpt-4o-mini\",\n              instructions=\"You are to decide whether the user is asking about \" +\n                           \"weather or information about local businesses. You \" + \n                           \"will handoff to the appropriate agent.\",\n              handoffs=[weather_agent, local_biz_agent],\n)\nA handoff is just what you think  it passes application control from one agent to another.\nIn order to understand how the Temporal/OpenAI Agents SDK integration works, its important for you to think of these agents as independent units, and your application will orchestrate a bunch of these units  agents  to get a job done. Handoffs are one way to orchestrate agents (well come to the other momentarily).\nTo run an agent, you will use another entity supplied by the Agents SDK  a Runner. A Runner establishes a context and then runs the agent in that context. To run the above agent, for example, you would execute the following:\nresult = Runner.run_sync(agent, \"How late is Costco open?\")\nOf course, you can write application logic that runs an agent, takes the output and uses that as input to the next agent, and so on. This is the second way that you can orchestrate the agents that make up your application. The triage agent could, for example, have been written as follows:\nfrom agents import Agent\ntriage_agent = Agent(name=\"Triage Agent\", \n              model=\"gpt-4o-mini\",\n              instructions=\"You are to decide ...\",\n)\nweather_agent = Agent(...)\nlocal_biz_agent = Agent(...)\nquery=\"How late is Costco open?\"\nresult = Runner.run_sync(triage_agent, query)\nif \"weather\" in result:\n    Runner.run_sync(weather_agent, query, ...)\nelif \"business\" in result:\n    Runner.run_sync(local_biz_agent, query. ...)\nelse:\n    \u003Cthrow an exception>\nThe difference between handoffs and orchestrations written in native Python code is an interesting discussion for another time. For today, just know that whether an agent is invoked with a Runner.run or via agent-to-agent handoffs, each agent runs as its own independent unit of execution (I promise the relevance of this will become clear very shortly).\nWith the OpenAI Agents SDK model, you will find yourself building a set of smaller agents that do one thing and do one thing well (Any Unix fans out there? Yeah, this makes me really happy too!), and then stitching them together to form your agentic applications.\nOkay, I think thats enough Agents SDK context for us to carry on.\nTemporal: Guaranteed reliable execution of your agents\nTemporal has a similarly minimalistic (yet extremely powerful) set of core primitives:\n\n  Workflows\n  Activities\n  Updates\n  Queries\n\nAgain, we will focus on the first two today, but for context, Updates are a way to inject control and data into a running Workflow, and Queries are a way to get data out.\nA Temporal Workflow holds the orchestration logic of your application, and its just native code. Today well be looking at Python examples, but know that Temporal also supports TypeScript, Java, Golang, .Net, Ruby and PHP. Dont let the name Workflow fool you  this isnt the BPM (Business Process Management) of the 90s. Its not some obscure representation of your business logic. Its just code (with some fairy dust sprinkled on it ). Really, just think of the Workflow as your applications main.\nWhat a Temporal Workflow primarily orchestrates are Temporal Activities. Where Workflows house the boring control flow things  loops, branching, parallelism, etc., Activities are where the most unpredictable parts of your application are implemented. A downstream call to an API (that might be unavailable due to a network hiccup). A call to an LLM (that might be rate-limited, or most certainly gives back a different response even when the same question is repeatedly asked). These are the things that Activities are expressly designed for (and yes, I am foreshadowing a bit here  check out this video for a good, quick overview.)\nBut Temporal Activities have some special properties. Whenever Activities are run, Temporal steps in and oversees progress. Temporal doesnt get into the details of what is happening inside of an Activity, but it does keep track of when an Activity is invoked, what the arguments were, whether the Activity has completed, and if so, it also keeps track of the return values.\nAnd the Workflow, which is orchestrating a bunch of Activity calls, keeps track of how all of those Activity calls have come together. If you follow up an LLM invocation with a tool execution and then a handoff to another agent, Temporal keeps track of all of that progress, and if something goes wrong, Temporal will compensate. Remember what I said earlier about Temporal picking up where it left off in the event of a crash? This is how you get that Durable Execution: Temporal keeps track of application progress and stores all Activity results, and thats how it can simply keep going when latent troubles have been resolved.\nThe following shows how you might implement an agentic loop in Temporal. Implemented in the Workflow, its just a simple Python loop in which a couple of activities are called:\nwhile True:\n   # Call the first activity: invoke model\n   result_one = await client.execute_activity(\n       \"invoke_model\",\n       agent_memory,\n       task_queue=\"openai-agents-task-queue\",\n       schedule_to_close_timeout=10,\n   )\n\n   if result_one.next_step == \"done\"\n       break\n\n   # Call the second activity: invoke tool\n   result_two = await client.execute_activity(\n       \"invoke_tool\",\n       result_one,\n       task_queue=\"openai-agents-task-queue\",\n       schedule_to_close_timeout=10,\n   )\nIn short, Temporal is a Durable Execution framework that makes distributed systems more resilient, even as the development thereof gets easier.\nAnd AI agents are distributed systems.\nLets put them together: Durable, scalable agents\nAt this point, I bet youre getting a sense of how these two technologies can come together to deliver more than the sum of their parts. The OpenAI Agents SDK provides a framework specially designed to enable developers to rapidly build AI agents. And Temporal provides a framework specially designed to enable developers to rapidly build production-ready distributed systems. Production-ready AI agents? That sounds good.\nWhen using these two products together, you will:\n\n  Define your AI agents exactly as you normally would using the OpenAI agents SDK. You will designate an LLM, provide it instructions, supply it with a list of tools it may leverage, and designate a set of agents this one may hand off to.\n  Orchestrate your agents in Temporal Workflows. This is not much of a departure from what you were already doing, as Temporal Workflows are Python code, just as your agent orchestrations were before. Using the Temporal Python SDK, you will define a class and annotate it as a Temporal Workflow definition, and within that class you will define a method and designate it as the entrypoint for that Workflow.\n  In the Workflow, you will define your agents (as shown above) and run them with the appropriate call to the OpenAI Agents SDK Runner class (as shown above).\n  Handoffs designated as a part of an agent definition operate exactly as they did before.\n\nSo the programming model is largely the same as it would be if you were using the Agents SDK alone, but under the covers, weve done things to make the agents and your agentic application durable. Specifically, and here are the key insights:\n every agent invocation is executed through a Temporal Activity,\n and because the orchestration is now running as a Workflow, Temporal automatically delivers all of the reliability we talked about above.\nThe following is a very simple agent built using the OpenAI Agents SDK and Temporal integration:\nfrom agents import Agent, Runner\nfrom temporalio import workflow\n\n@workflow.defn\nclass HelloWorldAgent:\n   @workflow.run\n   async def run(self, prompt: str) -> str:\n       agent = Agent(\n           name=\"Assistant\",\n           instructions=\"You only respond in haikus.\",\n       )\n\n       result = await Runner.run(agent, input=prompt)\n       return result.final_output\nHow this is all done is at once simple and clever. Around a month or two ago, OpenAI made the Runner an abstract base class, which allowed Temporal to provide an implementation of that class that would create an Activity for each agent invocation. The integration goes one step further and also emits data that integrates the execution running in these activities into the Open AI tracing system.\nThe behavior I am describing is most easily seen by viewing the dashboards of both Temporal and OpenAI. Lets run the very simple Haiku agent defined above:\n$ uv run openai_agents/run_hello_world_workflow.py \"Tell me about quantum computing\"\nResult: Bits dance in twilight,\nQuantum whispers unfold dreams,\nNew worlds in a chip.\nId like to draw your attention to the fact that the above code has nary a mention of a Temporal Activity. An agent is defined and run, with the await Runner.run(agent, input=prompt) call, yet in the following screenshot from the Temporal GUI, you can clearly see that an Activity was invoked.\n\n  \n\nOkay, so the first time I saw this  implicit Temporal Activities  I thought, Oh. Now, oh. Thats so cool.\n\n  To show you the power of the integrated tracing, let me show you the dashboards for a more involved application. My colleague Steve has also been working with this integrated offering and built a version of deep research  an extension of the research bot example that was inspired by the deep research API cookbook. This agent takes in a user prompt, uses a triage agent to decide whether more input is needed from the user, if so, it leverages a clarification agent to guide that engagement, uses instruction, planning, and search agents to conduct research and a writing agent to produce a final report.\n  \n  \n  In the Temporal GUI, this Workflow execution looks like this:\n  \n  \n  You can see that every agent execution was done with a separate Activity invocation, whether invoked via handoff  as done when the triage agent handed off to the instruction agent, or whether invoked from the Temporal Workflow  as done when the numerous (not predetermined) search agents were invoked in parallel. The corresponding trace is shown in the OpenAI dashboard:\n  \n  \n  You saw a short version of this demo in the video at the top of this post. Steve also put together a more comprehensive one  I assure you its worth a view. Youll find this sample and a few others in this repo. Do also have a look at the README here for some guidelines on how to configure your Workflows with the integration.\n\n\nSo heres the tl;dr: you can build durable, reliable, production-ready AI agents using the OpenAI Agents SDK, along with Temporal. And all of that reliability comes without adding any extra complexity to your implementation. \nBut wait, thats not all! You also get horizontal scale\nI try my best not to bury the lede in these types of blogs, yet perhaps today Ive done just that. In my defense, I do think that all of the above context is needed to get to the following point.\nIn addition to delivering retries, state management and implicit checkpoint-like recovery in the case of an agent crash, this integration brings another very important production-ready feature: scalability!\nWithout Temporal, your Agents SDK applications effectively run in a single process. If you want to scale the app, you are going to have to figure out how to manage a bunch of instances of your app and how to distribute work among them (plus many other challenges). And what happens when you need different capacity for different (micro)agents? For example, in the deep research example above, you might not need a lot more triage capacity, but you need a whole lot more search agent capacity. Hmm, this sounds eerily reminiscent of microservice scaling challenges, and its just as tricky.\nWhen you integrate Temporal with the Agents SDK, each (micro)agent is run in its own process or thread. Thats right  as soon as you use this approach, your agents are loosely coupled from an operational perspective. Need more capacity? Just add more workload (Workflow and Activity/agent) capacity. That added capacity will be used for whatever work shows up. If your search agents are doing more work than your triage agents, Temporal simply uses the capacity for that work. The details of how this works are beyond what we can cover here, but if you're thinking this sounds like an event-driven system, you are absolutely right. I do hope Ive convinced you that its worth a deeper look.\nGet started building production-ready agents\nYou want to build some experimental agents and see potential before investing too much effort in prod-readiness. At the same time, youd love to avoid throwing away proof-of-concept code when your ideas are ready for prime time.\nWith the integration weve announced here today, you get it all: the ability to get started quickly, all while being on the track for production deployment. You can either take your existing Agent SDK applications and make them production-ready using the steps weve outlined above, or you can build your orchestrations as Temporal Workflows from the get-go. The programming model is intuitive, and we offer a local dev instance to start prototyping with zero friction. To learn more and get started:\n\n  Watch the demo video.\n  Check out the Temporal Python SDK GitHub repo and be sure to follow the configuration steps found here.\n  Sign up for our webinar on September 23rd to learn exactly how the integration works and how you can achieve production-readiness.\n    \n      The first 100 registrants get a limited-edition t-shirt!\n      Presented by my colleague Steve, Dominik Kundel from OpenAI, and yours truly.\n    \n  \n\nAs always, wed love to hear from you. The integration is open-source and in Public Preview  we welcome feedback and contributions from the community. Or, let us know what youre building and what we can do to help. Come join us in the Temporal community, in #topic-ai!",featureImage:{title:"Temporal + OpenAI Public Preview Launch",description:"Temporal + OpenAI Public Preview Launch",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4zie1jYnopUq4BAtw0VKuQ/b89692d1e07622c64f853e4a4104b25a/temporal-openai-blog-card.png"},publishDate:"2025-07-30",metaDescription:"OpenAI and Temporal have teamed up to add Durable Execution to agents built using OpenAIs Agents SDK, and today we released the new integration in Public Preview.",metaTitle:"Production-ready agents with the OpenAI Agents SDK + Temporal",socialCard:{title:"OpenAI + Temporal Public Preview Social Card",description:"OpenAI + Temporal Public Preview Social Card",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4b9n7F0ikt5dtdaA2MHEHi/d2a23f345ec1aa2daa280a02501d3bdd/cornelia-post-social.png"},tags:"AI/ML,Industry Events",slug:"announcing-openai-agents-sdk-integration",contentType:"blogPost",entityId:"7DEbdxvgChlxGT4y9SyA4z",authors:[{id:"5UNwygCxwqYCdaa27gAYNS",name:"Cornelia Davis",slug:"cornelia-davis",jobTitle:"Senior Staff Developer Advocate",photograph:{title:"Cornelia Davis Headshot",description:"Cornelia Davis Headshot",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6TDAN3Pi1qvx8m6HBdC4Kk/24be44497f96b4236b4e61b054e8568f/image.png"},company:"Temporal",contentType:"person"}],authorsString:"Cornelia Davis",category:"Announcements",promoCard:{title:"Open AI Promo Card",eyebrow:"Dive Deeper",heading:"Learn more & get started",content:"Check out the [demo video](https://www.youtube.com/watch?v=fFBZqzT4DD8) and GitHub repository",callsToAction:[{text:"View the Repo",href:"https://github.com/temporalio/sdk-python/tree/main/temporalio/contrib/openai_agents",variant:"primary",leadingIcon:"github",trailingIcon:null,entityId:"1ZCaVANdznrqvrIWWcnFLu",large:false,theme:"ultraviolet"}],entityId:"10k3IXxOGVfwSlLJLD6LuO",contentType:"noise"},readingTime:16},{title:"Durable Digest: July 2025",content:"This blog post is a public copy of our monthly newsletter. If youd like to receive upcoming updates by email, you can subscribe to our newsletter here.\nWelcome to your July 2025 update! Catch up on new product updates, SDK releases, tutorials, community highlights, and upcoming events.\nFor more information on these updates and other things weve been working on, just keep reading! And as always, wed love to hear from you  feel free to share feedback in our Community Slack, or on X (@temporalio).\nProduct updates\n\n  Nexus updates galore! You can now have multiple callers starting operations backed by a single Workflow, associate Nexus links with their callbacks, and use new operation cancellation types.\n  Update-With-Start is generally available! This allows you to easily send updates to a Workflow whether or not it even exists yet, and create the workflow if not.\n  Worker Versioning is now in public preview. Confidently deploy changes to Workflows running on your Workers without breaking anything. Includes Workflow Pinning  pinned Workflows will run entirely on the Worker Deployment Version where it started.\n  Task Queue Priority is in pre-release. Simple Priority allows you to control the execution order for Workflows, Activities, and Child Workflows based on custom priority values in a single Task Queue.\n\nSDK updates\n\n  Go SDK v1.35.0: Adds Nexus operation cancellation types + updates to Dynamic Workflows and Activities.\n  Java SDK v1.30.0: Springboot integration (pre-release), Automatic Poller Scaling (pre-release).\n  Typescript SDK v1.12.0: Adds support for experimental Worker Deployment Versioning, Typed Search Attributes, Update-With-Start, and more.\n  PHP SDK v2.15.0: Task Queue Priority (pre-release), Activity Pause, and new User Metadata features.\n  Ruby SDK v0.5.0: Experimental support for Task Queue Priority, Worker Versioning, and Activity Pause.\n\nResources\n\n  We released a new tutorial, How to Build a Durable AI Agent with Temporal and Python.\n  The Temporal Ruby SDK is currently in public preview. To support this, we have released the Ruby Developer Guide.\n  We have also released 3 Getting Started Ruby tutorials!\n  Worker Versioning is also out in public preview, and we have added documentation to support it.\n\nBlog highlights\n\n  How Grepsr uses Temporal to deliver scalable and reliable web data\n  Building production-ready generative AI: How Temporal supercharges Google's Gemini and Veo\n  Durable MCP: How to give agentic systems superpowers\n  Durable Execution meets AI: Why Temporal is the perfect foundation for AI agent and generative AI applications\n\nCommunity highlights\nNew Code Exchange projects:\n\n  Temporal Cloud Terraform Starter by Ka Wo Fong: A practical example of using Terraform to configure Temporal Cloud, including with Google Cloud and Azure.\n  Local Reinforcement Learning Example by Sam Ingbar: This project demonstrates how to orchestrate a reinforcement learning (RL) training pipeline using Temporal and Ray RLlib.\n\nCommunity content:\n\n  System Design Series: A Step-by-Step Breakdown of Temporals Internal Architecture by Sanil Khurana: A step-by-step deep dive into Temporals architecture  covering Workflows, Tasks, shards, partitions, and how Temporal scales.\n  Transforming Network Automation with Temporal by Naveen Achyuta: This presentation introduces Temporal to the networking industry, outlines its architecture, showcases successful implementations in other sectors, and demonstrates various network automation use cases.\n  Rebecca Powell created a three-part blog series on combining .NET Aspire with Temporal: Part 1, Part 2, Part 3.\n\nWebinars\nDurable MCP: Bringing Resilience to the Agent Toolbox\nWe dove right into MCP servers in our monthly AI webinar and had a great time! We covered how to bring resilience to the agent toolbox and worked through building a durable MCP server that worked reliably, even in the face of a host of distributed systems challenges.\nSpace Camp\nAugust 14, 2025  St. Louis Java Users Group\nThis hybrid event features Temporals own Tom Wheeler, discussing how Temporal came to be and how you can make the most of Temporals features. In-person attendees will get astronaut ice cream, and everyone (virtual or in-person) can get a limited edition Space Camp sticker.\nEvents\nSeptember 810, 2025  Finovate FallNew York City, NY\nStop by our booth for interactive, live demos that showcase:\n\n  Reliable workflow orchestration for mission-critical financial operations\n  Fault-tolerant microservices that handle failures gracefully  no more lost transactions\n  Stateful application development at scale, without the operational burden\n\nWant to dive deeper? Schedule a meeting with a Temporal expert to explore how we can streamline your architecture and help future-proof your fintech stack.\nSeptember 810, 2025  Disney Data & Analytics ConferenceOrlando, FL\nJoin us at Booth319 to explore how were advancing data-driven innovation  come see live demos, connect with our team, and discover the Temporal difference.",featureImage:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},publishDate:"2025-07-29",metaDescription:"Explore Temporals latest developer updates: questions from the field, new releases, builder spotlights, learning resources, and ways to connect with our team.",metaTitle:"Durable Digest: July 2025",socialCard:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},tags:"",slug:"durable-digest-july-2025",contentType:"blogPost",entityId:"18w9LN81O8NXhhf3PChPNb",authors:[{id:"17hGmNrCwtXdBh7fhsLUnZ",name:"Temporal Technologies",slug:"temporal-technologies",photograph:{title:"temporal technologies logo",description:"temporal technologies logo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3g56zRXtFQYMeJxBBkVBIZ/7771670e5fc7da59f555837b086c35d6/temporal_technologies_logo.avif"},company:"Temporal Technologies",contentType:"person"}],authorsString:"Temporal Technologies",category:"Announcements",readingTime:4},{title:"How Grepsr uses Temporal to deliver scalable and reliable web data",content:"\n  \n    \n      \n        This is a guest post from our friends at Grepsr, a leading web data extraction platform that processes over 600 million records daily. In this post, the Grepsr team shares their journey of adopting Temporal to orchestrate their complex data workflows at scale, achieving 99% delivery reliability while significantly improving their engineering efficiency.\n      \n    \n  \n\nThe digital economy thrives on data. To gain a competitive edge, businesses require a continuous influx of fresh, structured data from diverse web sources, enabling insights into everything from real-time market trends to competitive pricing strategies. However, reliably extracting this data at scale and transforming it into a usable format presents a significant challenge.\nThis is precisely where Grepsr excels.\nGrepsr empowers companies to collect, structure, and deliver web data from thousands of sources, automating the entire data lifecycle. Our platform is leveraged by businesses across various sectors, including e-commerce, AI/ML, real estate, travel, and retail, to fuel more intelligent decision-making.\nThe maturity of data extraction / web scraping industry\nWeb data extraction or web scraping has transitioned from a niche technical task  once managed by engineers using custom scripts and cron jobs  into a mission-critical function and a thriving industry. Today, it encompasses a sophisticated ecosystem of platforms, tools, APIs, and specialized service providers.\nBusinesses increasingly depend on external data for a multitude of strategic purposes.\nAt Grepsr, we've witnessed this escalating demand firsthand. We currently process over 600 million records daily from more than 10,000 sources, serving hundreds of customers through both a self-serve platform and comprehensive fully managed services. However, managing this immense scale and ensuring reliability extends beyond crawlers; it demands robust orchestration  and thats where Temporal plays a pivotal role in our operations.\nThe challenge: Scaling without sacrificing reliability\nAt the heart of Grepsr is a microservices-based, event-driven architecture. Each component  from crawling to data delivery  operates independently. In our early stages, these services were interconnected using a combination of cron jobs, bespoke scripts, and message queues.\nHowever, as the complexity of our data extraction workflows rapidly increased, we encountered three significant and recurring challenges:\n\n  Failures were hard to trace: When a component failed, it often required deep log dives to understand what went wrong.\n  Workflow state was lost: If a job crashed halfway through, we had to restart the entire process from scratch.\n  Parallel execution was brittle: Running multiple jobs concurrently led to inconsistencies without proper orchestration.\n  Cron jobs lacked visibility: Scheduling was done via cron, with no built-in monitoring, history, or retry logic.\n\nTo meet growing demand while maintaining quality, we needed stronger orchestration, reliability, and observability.\nEnter Temporal: A game-changer in resilience & visibility\nAfter evaluating several options, we chose Temporal to orchestrate our workflows. The decision came down to a few key factors:\n\n  Code-first Workflows: Engineers write Workflows as regular code using Temporal SDKs, improving velocity and reducing custom orchestration logic.\n  Built-in fault tolerance: Temporal maintains Workflow state even during failures, allowing us to resume processing from where it left off.\n  Native parallelism: Handling thousands of concurrent workflows is straightforward with Temporal, helping us scale with demand.\n  Observability: With Temporals Web UI and Event History, our teams can debug, monitor, and track every data job from start to finish.\n\nBusiness impact: Reliability meets scale\nTemporal has become a critical part of Grepsrs backend infrastructure  and the impact is tangible:\n\n  99% delivery reliability, even with distributed failures\n  60% reduction in incident resolution time, thanks to complete observability\n  Faster time to market, as new Workflows can be built and deployed quickly\n  Higher throughput, with confident parallel execution across services\n\nTemporal has also provided unexpected but important benefits for team management. By encapsulating logic and behavior within well-defined Workflows, Temporal has helped Grepsr manage team transitions and turnover safely. New engineers can onboard faster, understand the system through declarative Workflows, and make changes without breaking critical processes.\nPerhaps more importantly, Temporal has created a shared language across the organization. Today, everyone from engineers and testers to project managers speaks in terms of Workflows  making collaboration, planning, and debugging significantly more efficient.\nOur engineers no longer have to worry about orchestrating retries or tracking job state. They focus on what matters  building better data experiences for our customers.\nFinal thoughts\nGrepsrs mission is to simplify access to web data  and Temporal helps us deliver on that promise at scale. With robust orchestration, resilient Workflows, and complete visibility, were not only building a more reliable system  were building a better customer experience, and a more collaborative, resilient engineering culture.",featureImage:{title:"buddha-elemental-3d-br5JFHhkoIA-unsplash (1)",description:"buddha-elemental-3d-br5JFHhkoIA-unsplash (1)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6KZNZOYRsAXONUbNuA5V7f/2f1ec7f2dd615ca6d4bb766d98271bff/buddha-elemental-3d-br5JFHhkoIA-unsplash__1_.jpg"},publishDate:"2025-07-24",metaDescription:"Grepsr scaled to 600 M web-data records a day with 99% delivery reliability by orchestrating its micro-services on Temporal  see how code-first Workflows made it happen.",metaTitle:"How Grepsr uses Temporal to deliver scalable and reliable web data",socialCard:{title:"Blog (32)",description:"Blog (32)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/55AbIfVr1FHRuCErnBg4WC/32da531da3f3c3a3e941c3bd06f0520c/Blog__32_.png"},tags:"Cloud",slug:"how-grepsr-uses-temporal-to-deliver-scalable-and-reliable-web-data",contentType:"blogPost",entityId:"5aJ2TLJG8nVEWqDgTtn0uQ",authors:[{id:"a6162yksfIbitTBFBtUsK",name:"Subrat Basnet",slug:"subrat-basnet",jobTitle:"Co-Founder at Grepsr",photograph:{title:"1747890353818",description:"1747890353818",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6R22YFi8TVEUY1V5aOE21S/2b8bedd13eedfdd15d16ede490b3b944/1747890353818.jpeg"},company:"Grepsr",contentType:"person"}],authorsString:"Subrat Basnet",category:"Community",readingTime:4},{title:"Building production-ready generative AI: How Temporal supercharges Google's Gemini and Veo",content:"Googles recent release of the Gemini 2.5 Flash and 2.5 Pro and the powerful Veo 2 video generation model has supercharged the AI community. These models allow developers to build sophisticated, agentic systems that can reason, plan, and create in new and exciting ways.\nHowever, moving from a mind-blowing demo to a reliable, production-ready agentic system introduces a host of engineering challenges. These systems are inherently complex, long-running, and distributed. They are susceptible to transient failures, from network hiccups and API rate limits to server crashes. How do you ensure a multi-step, hour-long process doesn't fail because of a momentary glitch?\nThis is where Temporal comes in. As a Durable Execution platform, Temporal provides the resiliency and reliability necessary to orchestrate these complex AI workflows.\nIn this blog, we'll explore the common failure points of agentic systems and demonstrate how Temporal's architecture offers a powerful solution. We will illustrate this using an open-source video generation system that uses Gemini 2.5 Flash to script scenes, Veo 2 to generate video clips, and Google Cloud Storage to stage the final video.\nVideo 1. An AI generated video using the prompt: \"Mermaids, dolphins, and octopuses performing for a circus performance.\"\nThe Achilles' heel of agentic systems in production\nGenerative AI agents are powerful, but the workflows they execute are often long-running and stateful, making them fragile in a production environment. Let's break down the key challenges.\n\n  Stateful, long-running processes: A typical agentic system consists of a sequence of generative tasks. For a video generation system, the sequence may include prompt analysis, script generation, video generation, and post-processing. This entire process could take minutes or even hours. If the server running this logic crashes mid-way, how do you resume from where you left off without losing all the intermediate work?\n  Transient failures: Behind the curtain, agentic systems are a form of distributed systems. The reality of distributed systems is that things fail. A call to the Gemini or Veo API might fail due to a temporary network blip, a 429 error from a rate limiter, or a brief service interruption. How will the system handle temporary issues like a network blip, a rate-limiter error from an API, or a brief service interruption?\n  Costly re-runs: Generative AI tasks are resource-intensive and can be costly. If a video generation workflow fails during the final step, re-running the entire process from scratch is inefficient and costly. If a resource-intensive workflow fails during the final step, how can you avoid rerunning the entire job from scratch?\n  Visibility and debugging: Agentic systems will inevitably fail due to transient issues like network hiccups, API rate limits, or server crashes. When a workflow does fail, how can you get a clear, auditable history of every step to identify the root cause of the failure?\n\nTemporal: The foundation for your durable agents\nTemporal is designed to solve precisely these challenges. By providing an observable Durable Execution platform, Temporal allows you to focus on building powerful AI features, not on the plumbing for failure handling.\nAt the heart of Temporal is the Workflow, a durable and resumable function. You write your multi-step AI process as a single piece of code, and Temporal ensures it executes to completion, even in the face of transient failures. Your Workflow's state is automatically persisted, so if a server crashes, your agent can resume from its last known good state. This ensures your hour-long video generation Workflow runs to completion exactly once, avoiding costly reruns.\nInteractions with external services, like calling the Gemini or Veo APIs, are performed within Activities. Temporal manages the execution of these Activities with built-in, configurable retries, timeouts, and error handling. That transient network blip? Temporal's default automatic retry policy, which uses exponential backoff with jitter, handles it for you.\nFor debugging, Temporal provides a detailed event history for every Workflow execution via its Web UI. You get a complete, auditable log of every Activity, including its inputs, outputs, and any errors, making it trivial to pinpoint the exact point of failure.\nMost importantly, Temporal Workflow is just code, so you can use popular tooling like Pydantic and Google Cloud SDK directly. There's no need to learn a new DSL or use complex YAML configurations; your workflow is defined in the languages you already know.\n\n  \n  Figure 1. A visual representation of a Temporal Workflow Execution through Temporal Cloud Web UI.\n\nArchitecture of a resilient video generation system\nLet's look at a high-level architecture of the open-source video generation system built with Temporal and Google's AI services.\n\n  \n  Figure 2. A flow chart of activities in the sample video generation system.\n\n\n  User prompt: The process begins when a user passes a video description prompt to start the video generation Workflow.\n  Scene generation with Gemini: An Activity calls the Gemini 2.5 Flash API. Leveraging Gemini's structured output capabilities, the user's prompt is transformed into a set of distinct scenes with descriptions and camera directions.\n  Parallel video generation with Veo 2.0: The Workflow then executes multiple Activities in parallel. For each scene, Gemini 2.5 Flash is used to generate a prompt, optimized for video generation tasks. Then, the prompt is used to generate a video clip for its corresponding scene using Veo 2.0.\n  Final compilation and completion: Once all the parallel video generations are complete, the final step is to combine the clips into a single video file. The finalized video is uploaded to Google Cloud Storage and its URI is returned to the user.\n\nA look at the code: Temporal and Gemini in action\nLet's examine some code snippets from the video generation system to see how this is built.\nThe main logic resides in the VideoGenerationWorkflow Workflow Definition below. It outlines the exact steps of our business logic.\n@workflow.defn\nclass VideoGenerationWorkflow:\n    @workflow.run\n    async def run(self, arg: VideoGenerationWorkflowInput) -> VideoGenerationWorkflowOutput:\n        workflow_start_time = workflow.now()\n        gcs_staging_directory = (\n            f\"videos/{workflow_start_time.strftime('%Y%m%d_%H%M%S')}\"\n        )\n\n        # Expand user prompt into movie scenes.\n        scenes = await workflow.execute_activity_method(\n            VideoGenerationActivities.create_scenes,\n            CreateScenesInput(prompt=arg.user_prompt),\n            start_to_close_timeout=timedelta(seconds=30),\n        )\n\n\t # For each scene, generate video\n        scene_gcs_paths: list[tuple[int, str]] = []\n        scene_gcs_paths = await asyncio.gather(\n            *[self._process_scene(scene, gcs_staging_directory) for scene in scenes]\n        )\n\n        # Combine the video scenes into a single video.\n        scene_gcs_paths.sort(key=lambda x: x[0])\n        full_video_gcs_name: str = await workflow.execute_activity(\n            VideoGenerationActivities.merge_videos,\n            MergeVideosInput(\n                gcs_video_paths=[x[1] for x in scene_gcs_paths],\n                gcs_staging_directory=gcs_staging_directory,\n            ),\n            start_to_close_timeout=timedelta(seconds=30),\n        )\n\n        return VideoGenerationWorkflowOutput(\n            gcs_uri=f\"gs://{video_gen_settings.GCS_BUCKET_NAME}/{full_video_gcs_name}\",\n        )\n\n    async def _process_scene(self, scene: Scene, gcs_staging_directory: str) -> tuple[int, str]:\n        vgm_prompt: str = await workflow.start_activity_method(\n            VideoGenerationActivities.generate_vgm_prompt,\n            scene,\n            start_to_close_timeout=timedelta(seconds=30),\n        )\n        scene.vgm_prompt = vgm_prompt\n        gcs_path = await workflow.start_activity_method(\n            VideoGenerationActivities.generate_video_for_scene,\n            GenerateVideoForSceneInput(\n                current_scene=scene,\n                gcs_staging_directory=gcs_staging_directory,\n            ),\n            start_to_close_timeout=timedelta(minutes=2),\n        )\n        return (scene.sequence_number, gcs_path)\nNotice how the Workflow code reads like a simple script. It calls the create_scenes Activity, then fans out to run the generate_vgm_prompt and generate_video_for_scene Activities for each scene in parallel using Python's native asyncio.gather. The best part is that Temporal handles all the complexity of retries, state persistence, and parallel execution.\nThe create_scenes Activity is where we interact with Gemini Flash 2.5. The real power here comes from combining Temporal's reliability with Gemini's ability to provide structured output.\n# workflows/videogen/schema.py\n\nclass Scene(BaseModel):\n    sequence_number: int\n    description: str\n    duration_estimate: int\n    camera_angle: str\n    lighting: str\n    vgm_prompt: str | None\n\n# workflows/videogen/activities.py\n\nclass VideoGenerationActivities:\n    def __init__(self):\n        self._google_api_key = video_gen_settings.GOOGLE_API_KEY\n        self._llm = GoogleGemini(api_key=self._google_api_key)\n\n    @activity.defn\n    async def create_scenes(self, arg: CreateScenesInput) -> list[Scene]:\n        llm_prompt = f\"\"\"\nYou are a creative AI agent that transforms user input into cinematic movie scenes. Your task is to take any concept, story, or idea and convert it into a compelling visual narrative with dramatic flair and artistic vision.\n.\n.\n.\nTransform the user's input into something unexpectedly cinematic, whether it's mundane or fantastical. Make every second count and every frame visually stunning.\n\nUser Input: {arg.prompt}\n\"\"\"\n        response: list[Scene] = await self._llm.generate_content(\n            prompt=llm_prompt,\n            response_schema=list[Scene],\n        )\n        return response\nBy specifying a response_schema that maps to our Pydantic Scene model, we instruct Gemini to return a well-formed JSON array, not just unstructured text. This eliminates the need for brittle parsing logic and makes the entire system stronger. If the Gemini API call fails for any reason (e.g., a network issue), Temporal automatically retries the activity based on the policy defined in the Workflow, ensuring the scene generation eventually succeeds.\nThe generate_video_for_scene activity is responsible for the heavy lifting: calling the Veo API. This can be a long-running and resource-intensive operation.\n# workflows/videogen/activities.py\n\n   @activity.defn\n    async def generate_video_for_scene(self, arg: GenerateVideoForSceneInput) -> str:\n        \"\"\"\n        Generate a video for a scene and store it in Google Cloud Storage.\n        \"\"\"\n        activity.logger.info(\"Generating a video for the scene. arg=%s\", arg)\n        vgm_prompt = arg.current_scene.vgm_prompt\n        video_name = f\"scene_{arg.current_scene.sequence_number}.mp4\"\n        gcs_destination_path = f\"{arg.gcs_staging_directory}/{video_name}\"\n        # Generate the video in a local temporary directory, then upload it to Google Cloud Storage.\n        with tempfile.TemporaryDirectory() as temp_dir:\n            output_path = Path(temp_dir) / video_name\n            output_path = await self._vgm.generate_video(\n                prompt=vgm_prompt,\n                output_path=output_path,\n            )\n            GoogleCloudStorage.upload_file(\n                bucket_name=video_gen_settings.GCS_BUCKET_NAME,\n                file_path=output_path,\n                destination_path=gcs_destination_path,\n            )\n\n        return gcs_destination_path\nThis is where Temporal's durability shines. For even longer rendering tasks, we could use instrument Activity Heartbeat to let Temporal know the process is still alive and making progress. If the Worker running this Activity crashes, Temporal will automatically re-run it on another available Worker, resuming from the beginning of the Activity. This combination of timeouts, retries, and heartbeating makes building reliable, long-running AI agents possible.\nConclusion: Build fearlessly with Temporal and Google\nGoogle's Gemini and Veo models provide immense power to developers. However, harnessing this power in production requires more than just calling an API. It requires a new way of thinking about agentic architecture, one that embraces the reality of distributed systems and their potential for failure.\nTemporal provides the missing piece of this puzzle by offloading the complexity of state management, failure recovery, and resilience engineering. This allows developers like you to focus your energy on creating high-value AI features, while Temporal provides the abstractions required for a production-ready agentic system.\nReady to get started?\n\n  Explore the code of the open-source video generation system on GitHub.\n  You can create a Gemini API key for free with a few clicks in Google AI Studio.\n  Learn more about Temporal.\n  Read more about Google AI for Developers and Google Gemini models.\n",featureImage:{title:"li-zhang-ZvVydsVkyTI-unsplash",description:"li-zhang-ZvVydsVkyTI-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3WwtmBoVCX8MFqaV2ZTQUq/fc4fc75dd2e1d75a6a36d292827b8d80/li-zhang-ZvVydsVkyTI-unsplash.jpg"},publishDate:"2025-07-17",metaDescription:"Learn how to navigate the pitfalls of producing agentic AI for prod with Temporal and Google's Gemini and Veo. ",metaTitle:"Building production-ready generative AI: How Temporal supercharges Google's Gemini and Veo",socialCard:{title:"Temporal-google-gemini 1200x628",description:"Temporal-google-gemini 1200x628",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5dhDPKYAU8qEHkw7sXtlho/df6b55b5af39719c1b5787d3f3d2873f/Temporal-google-gemini_1200x628.png"},tags:"AI/ML,Durable Execution,Code Samples",slug:"build-prod-ready-gen-ai-temporal-gemini-veo",contentType:"blogPost",entityId:"24Z3SWUkVJTJJftXNDtctQ",authors:[{id:"2fosBnOvCBjzr9Q0YJeHzf",name:"Ka Wo Fong",slug:"ka-wo-fong",jobTitle:"Staff Solutions Architect",photograph:{title:"Ka-Wo-Professional-PFP-2",description:"Ka-Wo-Professional-PFP-2",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6tx7QFUNCji7Pq3Grmrt0L/71d0399372a6321f14266ac285263da7/Ka-Wo-Professional-PFP.jpeg"},linkedInUrl:"https://www.linkedin.com/in/kawofong/",company:"Temporal",contentType:"person"}],authorsString:"Ka Wo Fong",category:"How-To",readingTime:9},{title:"Durable Execution meets AI: Why Temporal is the perfect foundation for AI agent and generative AI applications",content:"Simple question: Is Temporal an AI product/technology?\nMore nuanced answer: Yes! What we built is perfectly suited for AI applications, even if it was originally built for other use cases.\nTemporal is built to bring resilience  or as we like to call it, Durable Execution  to distributed systems. For example, it makes all of these things more resilient:\n\n  Your website, powered by dozens or hundreds of microservices.\n  Your order processing application that communicates with everything from payment processors to shipping and inventory management systems.\n  The system you use to reliably generate credit card statements for your millions of card members.\n\nThese, and many others, are the use cases that Temporal was originally built for, well before generative AI burst onto the scene in 2022. And now that the industry is to the point where AI agents are moving from the experimentation phase into production, it turns out Temporal is the perfect technology to implement your LLM-powered AI applications and agents.\nI've already spoken about the fact that AI applications and agents are distributed systems. I even suggest they are distributed systems on steroids because your app may end up making an order of magnitude more remote requests to fulfill a user experience. Just like the cloud-native applications of the last couple of decades, AI apps need to operate more reliably even though transient failures in the underlying infrastructure are common. I also captured my mental model for agents, which helped set a foundation for what I do in this piece.\nBut its time for more detail. How exactly does Temporal satisfy the needs of this class of applications? As it happens, Temporal has an answer for every one of the key elements of an AI application or agent.\nThe key elements of a generative AIpowered application\nAt the most basic level, Gen-AI powered applications are those that leverage an LLM to fulfill part of their functionality. The LLM alone does not make up the app. Even ChatGPT (which is an app, not an LLM), while simple, is an app that invokes an LLM, displays its response to the user, accepts input from that user, adds that input to the running history of the chat, and then invokes the LLM again.\nOf course, applications come in many shapes and sizes (its not even the case that every UX for a generative AIpowered application includes a chat interface), but at their core, they combine LLMs with actions to deliver some experience.\nFor example, you might use an LLM to process a Slack message sent to your #it-support channel, have it file an appropriate ticket in ServiceNow, wait for human approval, and then provision some infrastructure. That might look something like this:Chain workflow\nwhere a series of LLM calls, actions, and user interactions are strung together.\nOr it may look something like this:Loop workflow\nwhere the exact trajectory through the business logic is not known at design time but is determined by the system itself, specifically with the LLM being used to drive the flow.\nIn both cases, the primary elements of the solution are the same and are well-addressed by Temporal. This table offers an overview  a bit of a cheatsheet. On the left, weve bolded the terms most commonly used to describe a key element of AI applications. On the right, we briefly describe how Temporal satisfies the need. Think of this as a description of Temporal in todays AI lingua franca. In the section that follows, well cover each concept in more detail.\n\n  \n    \n      Key element in AI\n      How Temporal addresses it\n    \n  \n  \n    \n      We stitch together a bunch of steps into chains, graphs or agentic loops.\n      This is a Temporal Workflow. Workflows are equally well-suited to designs that structure steps at design time (first diagram) as those that are dynamic (second diagram).\n    \n    \n      We use Large Language Models (LLMs).\n      You invoke these through Temporal Activities, delivering resilience out of the box.\n    \n    \n      We invoke tools, craft prompts, and access resources.We also invoke MCP servers via MCP clients.\n      You invoke these through Temporal Activities, delivering resilience out of the box.When tools are MCP servers, the MCP client is implemented within an Activity.\n    \n    \n      We implement MCP servers.\n      These are implemented as Temporal Workflows and Activities.\n    \n    \n      AI applications, especially AI agents, are responsible for providing memory.\n      You just manage your application state in variables in your Workflow. As an added bonus, with Temporal, that state is durable.\n    \n    \n      We use checkpointing to keep from having to rerun steps if a process crashes.\n      Temporal delivers this implicitly through its event sourcing and state management architecture. You never have to think about checkpointing.\n    \n    \n      We must allow for humans in the loop.\n      This is achieved through Temporal Signals & Updates, and Temporal Queries.\n    \n    \n      AI applications are often long-running.\n      In addition to its event sourcing and state management foundation, Temporal handles long-running processes through its Worker architecture.\n    \n  \n\nLets take a closer look\nNow, with this very high-level overview showing the alignment of Temporal with the needs of an AI application or agent, lets dive deeper into each element. Understanding these building blocks  and how Temporal handles them  will not only deepen your understanding, but I also hope it will help you get started quickly.\n\n  Chain, graph or agentic loop: These are all terms used to describe how the boxes in the diagrams above are composed.\n    \n      Chaining of steps was a term popularized by LangChain through their first offering, one that allowed various steps in an application to be chained together, with outputs from one step flowing as inputs to the next. As depicted in the first diagram, a chain is used to define a predetermined, linear flow.\n      Agentic loop is the term used to describe the cycle shown in the second diagram. In this model, the LLM is used to drive the actions that happen on every cycle, and the LLM is also used to determine when a goal has been reached and the cycle is exited.\n      Clearly, you can model either of these approaches as a graph. Graphs are also sometimes used to model more complex, yet still predetermined, flows  think chains with added branches and loops.\n    \n  \n\nWhen using Temporal to build your AI application, the predetermined flow (simple or complex), or the agentic loop is implemented as a Temporal Workflow. Its just regular code, providing the most powerful and familiar model for orchestrating components  LLMs, Actions, and UX  into a business application. You can program in your favorite language1, so there is no new language or DSL to learn. Since its a general-purpose programming language, there are no abstractions to get in your way. AI application patterns will, without question, continue to evolve in the coming months and years, and we are confident that these general-purpose programming languages will be as well-suited to implement new patterns as they are suited to satisfy the current ones.\n\n  Large (or Small) Language Model (LLM/SLM): While the applications we speak of here obviously include the use of an LLM, it is still worth calling it out explicitly, not only for completeness but also because your application is responsible for interfacing with the LLM:\n    \n      The LLMs your application utilizes could be in the cloud, within your own corporate network, or even locally on your machine (these would be the smaller models I hinted at above). In virtually all cases, they are running in processes outside of your applications main orchestration.\n      While at the high level, all LLMs operate by taking in tokens and outputting tokens, their models differ, and the way that the input tokens are structured can impact their qualitative performance. The application you are writing is responsible for interfacing with the LLM, possibly structuring the input for the best performance.\n    \n  \n\nWhen using Temporal to build your AI application, the Workflow will interact with an LLM via a Temporal Activity. A Temporal Activity is code (again, written in your favorite language) that implicitly delivers resilience for distributed systems, and it gives you full control over any logic needed around the LLM invocation.\nFor example, when a network glitch renders the LLM unavailable or when the LLM is rate-limiting requests, the Activity automatically retries those requests until conditions allow for completion. As the developer, you dont write the retry logic; that behavior is handled by Temporal. And because Temporal is optimized for distributed systems, retries (and other resilience patterns) are designed to address a wide range of failure scenarios.\nAnd because an Activity effectively brokers the LLM invocation, you can structure it as a gateway of sorts, adding logic that, for example, redacts any Personally Identifying Information (PII) before sending it on to a third-party LLM.\n\n  Actions or Tools: This term represents the actions that the AI application or agent will take, sometimes at the direction of the LLM and sometimes as a step in a predetermined flow. Very often, this will result in the invocation of a downstream API or the access of external data stores. Tool was the first term popularized, albeit with a rather vague definition, but the emergence of the Model Context Protocol (MCP) has brought more specificity. MCP defines protocols for interfacing with the following types of entities:\n    \n      Tool: Invoking an API, calling a function, or otherwise interfacing with outside systems.\n      Data Source or Resource: Read/write access to data, either locally or in a remote location.\n      Prompt: Prompt templates that are used to provide direction to the LLM in the next invocation.\n    \n  \n  MCP servers: These are services that implement the functionality of a tool or access to a resource.\n\nWhen using Temporal to build your AI application, tools and resources are accessed via a Temporal Activity. The Workflow  which orchestrates the operations of your applications operations by calling LLMs, invoking tools, and allowing for user interaction  is all running within a single process and is therefore not subject to the challenges posed when calls are made to external systems. But Temporal Activities are explicitly designed to make external calls resilient.\nJust like Workflows, you build your Activity as code that invokes the downstream API or accesses external data sources. Temporal Activities implement a host of durability features so that when, for example, a network outage temporarily renders an API inaccessible, the Activity will automatically retry it without the developer having to handle the case explicitly.\nActivities may be written for specific downstream APIs: for example, you may create a FetchWeather activity that makes a REST call to the national weather service. Alternatively, Temporal supports dynamic Activities where the details of the invocation are supplied as arguments to the Activity. This latter approach is particularly useful when your AI agent is built in the form of the second diagram above. If your Workflow calls an MCP server, the Activity is the place where the MCP client is implemented.\nFinally, MCP servers themselves implement logic that also very often includes calls to external systems. Temporal Workflows and Activities are an ideal implementation for MCP servers.\n\n  Memory: LLMs are forgetful  that is, they are stateless. Each time they are invoked, they receive entirely fresh input as a sequence of tokens and generate entirely new output. It is the job of the AI application to remember; to manage the state of the application by keeping track of inputs to and outputs from previous steps, and any relevant resources and prompts, so that it may properly assemble them for every LLM invocation.\n\nWhen using Temporal to build your AI application, you simply use variables in your Workflow code to store the needed state. You have full control over what data to store, how to store it, and how it is assembled for input to the LLM. This works for flows that are fully specified at design time, as well as for the agentic loops that are driven by the LLM at runtime. There is nothing new to learn, and the approach is sure to work for the yet-to-be-invented, popular AI application patterns.\n\n  Checkpointing: AI applications beyond the simplest of demos make many calls to LLMs and tools, and they are increasingly leveraging other agents. In the event that the application stops before completion (due to both foreseen and unforeseen causes), checkpointing keeps the application from having to start from the beginning and rerun previous steps in the workflow.\n\nWhile Temporal is already showing well against the key elements weve covered so far, when it comes to checkpointing, Temporal really shines!! (And wait until you see whats in store in the long-running section below)\nYou see, when Temporal executes a Workflow, it records a full Event History  every single time code in the Workflow is run, every single time an Activity is called or returned, and more. Plus, it records the values returned by every single Activity call, which means the memory we just spoke about is completely visible and debuggable through Temporal tooling. The outcome that checkpointing delivers in other frameworks is realized through the event sourcing and state management features that form the foundation of Temporal. As the developer, you are not responsible for implementing any part of this protocol. By structuring your apps as Temporal Workflows and Activities, you get this behavior for free.\nIf the application instance were to shut down (crash, be proactively cycled, or because you wanted to fix a bug even while the app was running), as soon as the application starts again, the state will be recreated and processing will pick up where it left off. When building Temporal applications, you never have to think about checkpoints. Your mental model is simply that if the application goes down, it will pick up where it left off when it is brought back up. We call this Durable Execution.\n\n  Human-in-the-loop: While some AI applications may operate entirely autonomously, many (if not most) will have humans that interact with them. They may provide input on launch and at various points throughout the execution, including within an agentic loop.\n\nWhen using Temporal to build your AI application, you use Signals and Updates to supply input and Queries to extract state to show the user. These are primary abstractions in the Temporal programming model, and just as with Workflows and activities, you implement these in your programming language of choice. (Insert usual refrain on general-purpose programming languages giving you full flexibility to implement any logic you require. ) The protocols that invoke these methods, which are programmed idiomatically in each of the programming languages Temporal supports, are delivered in the Temporal SDK.\n\n  Long-running: Long-running apps are not unique to those leveraging LLMs, yet because AI is allowing more and more functionality to be handled autonomously, the amount of work done in one application session is only increasing. That is, long-running applications are becoming ever more commonplace. Checkpointing is certainly part of delivering a good user experience over timelines that may last hours, days, weeks, or even months and years. But beyond maintaining stability for long periods, applications also need to make efficient use of computing resources.\n\nWe already covered how Temporal delivers on checkpointing, so lets turn to the question of efficient resource utilization. When using Temporal to build your long-running AI application, efficient resource utilization is delivered through the Worker architecture that is at the core of Temporal.\nA Temporal Worker is the process within which your Workflow and Activity code runs. It looks after many concurrently running Workflows, and  key to the questions around long-running Workflows  it manages which are currently in active memory and which are not active but in cache. For those that have been evicted from the cache, it replays the Event History to reconstitute the application state for further processing (see checkpointing explanation above). So solid is the implementation that Workers can be tuned to efficiently look after hundreds or thousands of Workflows at once. Workers may also be sized and tuned for particular workload types.\nAs a developer, you can simply write Workflows as if they stayed active in memory at all times. Gone are the days when you had to fragment your business logic into separate pieces purely because of temporal constraints (pun definitely intended! )\nBuilding for whats next\nI didnt set out to write a blog about distributed systems patterns, but here we are. The thing is, once you start building real AI applications and agents, you quickly realize youre not just wrangling LLMs  youre orchestrating complex, multi-step, failure-prone distributed systems, PLUS youve got humans engaged throughout the workings of that complex system.\nThese distributed systems are powering the experiences you are delivering to your users, and the fact that they are delivered through a totally new paradigm (AI) doesnt lessen the users expectation that they just work.\nThe AI landscape is moving fast, and new patterns are emerging every month. But heres my bet: whatever comes next  whether its multi-agent orchestration, hybrid human-AI workflows, or something we havent even thought of yet  its going to need rock-solid distributed systems underneath. And thats exactly what Temporal gives you: real code, in real programming languages, handling real complexity.\nAs AI applications continue to evolve, the need for resilient, scalable execution becomes even more critical. Curious to see how Temporal can streamline your generative AI workflows in production? Sign up for Temporal Cloud today and get $1,000 in free credits to start building with confidence.\n\n  Footnotes\n  \n    \n      Python, Java, Go, Typescript, .NET, Ruby, PHP \n    \n  \n",featureImage:{title:"social-card-purple",description:"social-card-purple",url:"https://images.ctfassets.net/0uuz8ydxyd9p/UbL8tEOAIBjMrI6OCSeNN/62aecca8ce16e11e288c1fd7ef4e346d/social-card-purple.jpg"},publishDate:"2025-07-10",metaDescription:"Explore why Temporals Durable Execution makes it the ideal foundation for building resilient, reliable AI agents and generative AI applications. Discover how Temporal meets every core requirement of AI-driven workflows.",metaTitle:"Durable Execution meets AI: Why Temporal is ideal for AI agents & Generative AI Apps",socialCard:{title:"Blog (30)",description:"Blog (30)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Z6CwHPOuGrxlKa2uteem0/74501217477aa65c207218096ef927e9/Blog__30_.png"},tags:"Durable Execution,AI/ML",slug:"durable-execution-meets-ai-why-temporal-is-the-perfect-foundation-for-ai",contentType:"blogPost",entityId:"36mirWrzPGqxFsU9CiSFXJ",authors:[{id:"5UNwygCxwqYCdaa27gAYNS",name:"Cornelia Davis",slug:"cornelia-davis",jobTitle:"Senior Staff Developer Advocate",photograph:{title:"Cornelia Davis Headshot",description:"Cornelia Davis Headshot",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6TDAN3Pi1qvx8m6HBdC4Kk/24be44497f96b4236b4e61b054e8568f/image.png"},company:"Temporal",contentType:"person"}],authorsString:"Cornelia Davis",category:"Temporal Voices",readingTime:15},{title:"Durable MCP: How to give agentic systems superpowers",content:"Its been said by punnier people than me that there are three problems in computer science: naming things and off-by-one errors.\nI think thats dryly hilarious. But I also think the two hardest problems in computer science are configuration and integration:\n\n  Configuration: making the computer solve your problems the way you want them solved\n  Integration: making the computers talk together to cooperate and solve your problems\n\nNo matter how well you build or buy software, modern applications always come down to these two challenges. You have to make the computers solve your particular problem and talk to the other computers.Me and all my software engineering friends for my entire IT career. Source: ChatGPT enabled by Temporal\nOver the years, weve tried many different ways to manage configuration: modular, object-oriented, functional, domain-driven, several other kinds of -oriented, BRM, BPM. Despite all these approaches, its still a complex problem. Why? Because computers arent like people: they do exactly what we tell them, but we humans are imperfect translators of our own intentions.\nIntegration has seen similar evolution. Weve moved through mainframe multi-user systems, client-server, monolith, peer-to-peer, SOAP, REST, microservices, event-driven, event-sourced, choreography, and orchestration. Each approach has been useful and made things incrementally easier. Yet integration remains hard and prone to troubles because the integration code is made by people, all these systems are run by people, were all imperfect, and integration error rates stack.\nIn this piece, I will discuss how these core problems may have a new solution on the horizon, opening up new ways to simplify configuration and integration. Ill also talk about how making MCP durable with Temporal enables durable tool execution, opening up possibilities for tools and enabling people to build agentic tools that are durable, scalable, and enterprise-grade.\nEnter agentic\nBut what if we could change the game entirely? What if, instead of humans translating problems and solutions into computer instructions, the computers could just talk to you directly? This is possible with agents! Configuration suddenly becomes easy when you can just tell an AI what you want to do in plain language.\nGoals\nAgentic systems solve problems for you and on your behalf. They act as your agents, getting things done the way you need them done. One way to define what you want done (configuration) is to define goals for the agent to do.\nAt Temporal, weve demonstrated systems with pre-defined goals that can focus on specific tasks, and weve also built more flexibility into these agentic systems that can handle multiple goals and switch between them as needed.\nAt their core, goals are about getting things done, and agents accomplish their work through tools. Goals provide the context that helps an agentic system understand how to complete multi-step processes.\nGoals can be defined with human language:\n# sample goal definition \n description=\"The user wants to schedule paid time off (PTO) after today's date. To assist with that goal, help the user gather args for these tools in order: \"\n    \"1. CurrentPTO: Tell the user how much PTO they currently have \"\n    \"2. FuturePTOCalc: Tell the user how much PTO they will have as of the prospective future date \"\n    \"3. BookPTO: Book PTO after user types 'yes'\",\n\n\"Welcome me, give me a description of what you can do, then ask me for the details you need to do your job.\"\nTools\nWhile goals define what needs to be done, tools are how things actually get done. Tools can be local processes (read this local file and give me its output) or remote calls (read this database with these input keys because I need specific results).\nTools can be combined and sequenced  something we might have called microservices orchestration in a non-agentic system. But heres where it gets interesting: tools can be defined as part of an agentic system, with human language context being provided by the system as configuration. Even better, tools can be implemented by other agents with their own defined goals and tools.\nThis framework of goals, intelligence, and tools achieves something fascinating. Configuration  that eternal challenge of making systems solve your specific problems with your data and APIs  becomes a matter of human language:\n# sample goal definition\ngoal_hr_schedule_pto = AgentGoal(\n    id=\"goal_hr_schedule_pto\",\n    agent_name=\"Schedule PTO\",\n    agent_friendly_description=\"Schedule PTO based on your available PTO.\",\n    tools=[\n        tool_registry.current_pto_tool,\n        tool_registry.future_pto_calc_tool,\n        tool_registry.book_pto_tool,\n    ],\n    description=\"The user wants to schedule paid time off (PTO) after today's date. To assist with that goal, help the user gather args for these tools in order: \"\n    \"1. CurrentPTO: Tell the user how much PTO they currently have \"\n    \"2. FuturePTOCalc: Tell the user how much PTO they will have as of the prospective future date \"\n    \"3. BookPTO: Book PTO after confirms the proposal with 'yes'\",\n)\n\n# sample tool definition\nbook_pto_tool = ToolDefinition(\n    name=\"BookPTO\",\n    description=\"Book PTO start and end date. Either 1) makes calendar item, or 2) sends calendar invite to self and boss? \"\n    \"Returns a success indicator. \",\n    arguments=[\n        # \u003Csnip arguments definition for brevity>\n    ],\n)\n\n  This is a powerful way to make configuration easier. You define how to solve your problems in simple, human-readable terms, and the agentic AI works with you using the available tools.\n\nBut youve probably noticed a limitation: the system is constrained by its pre-defined tools. What if you wanted to use tools without pre-defining them in your application? What if we could make integration easy too?\nModel Context Protocol (MCP)\nMCP is automatic, AI-powered integration. MCP transforms agentic tools into something pluggable, discoverable, and dynamically composable.\nThe magic of MCP is that tools can describe themselves. Their capabilities and APIs are provided right in the server definition:\n// MCP tool definition from https://github.com/modelcontextprotocol/servers/blob/main/src/filesystem/index.ts\n      {\n        name: \"read_file\",\n        description:\n          \"Read the complete contents of a file from the file system. \" +\n          \"Handles various text encodings and provides detailed error messages \" +\n          \"if the file cannot be read. Use this tool when you need to examine \" +\n          \"the contents of a single file. Only works within allowed directories.\",\n        inputSchema: zodToJsonSchema(ReadFileArgsSchema) as ToolInput,\n      },\nWith MCP, tools can present their capabilities to an agentic system and allow for dynamic goal solutions. Combining tools and building agentic capabilities becomes much easier.\nNow, Ill be honest  adding tools can still be a bit complicated for some agentic MCP clients. But Im writing this blog with the assumption that this will become much easier soon. Great work is being done to simplify the process, and I foresee a future where entire agentic applications are composed simply by plugging different MCP tools into dynamic agent systems.\nDurable MCP: Give agents superpowers\nAs of the time of writing, MCP is both super powerful and really new. Agentic systems can call local MCP servers and remote MCP servers, but the current implementation uses simple JSON RPC without much durability built in. Visibility, security, reliability, and long-running capability are all still being figured out. MCP has tons of potential, but also much to deliver on.\n\n  MCP can do great things, but the protocol doesnt provide durability. Users want their tools to work every time, and in a business context, we want the important tools we call to do their important work successfully, every time.\n  \n  At Temporal, were admittedly a bit obsessive about durability. Our mission is making all systems fault-tolerant and reliable. MCP tools have tremendous potential, but we think these tools should be ready for the scale and durability requirements of the enterprise. We want these tools to have durability and fault-tolerance built in. So when we look at MCP, we see a huge opportunity: what if we could add robust durability to these systems by implementing MCP tools with a Durable Execution framework like Temporal?\n\nMCP tools as workflows\nHeres a simple model to add a lot of desirable architectural qualities to MCP tools quickly: implement MCP tools as workflows.\nHeres an example of a tool that executes a Temporal Workflow and returns the result:\n@mcp.tool()\nasync def get_forecast(latitude: float, longitude: float) -> str:\n    client = await get_temporal_client()\n    handle = await client.start_workflow(\n        workflow=\"GetForecastWorkflow\",\n        args=[latitude, longitude],\n        id=f\"forecast-{latitude}-{longitude}\",\n        task_queue=\"weather-task-queue\",\n    )\n\n    return await handle.result()\nThis tool then calls a Workflow that looks like this:\n @workflow.run\n    async def run(self, latitude: float, longitude: float) -> str:\n        points_url = f\"{NWS_API_BASE}/points/{latitude},{longitude}\"\n        points_data = await workflow.execute_activity(\n            \"make_nws_request\",\n            points_url,\n            schedule_to_close_timeout=timedelta(seconds=40),\n            retry_policy=retry_policy,\n        )\n\t #\u003Csnip>\nThat Activity call is guaranteed to execute durably and retry until it successfully retrieves weather data from the Weather Service.\nThis approach delivers some fascinating architectural benefits:\n\n  Tools automatically gain remote capabilities\n  Durable Execution comes baked in, bringing visibility, reliability, and scalability out of the box\n    \n      Every downstream call is automatically retried until it succeeds\n    \n  \n  Tools continue progressing even if the MCP client or server crashes\n  Tools can be built in any language Temporal supports, meaning a developer can build agentic capabilities in Go, Java, .NET, or several other languages\n  Existing Workflows become reusable  if you already have a workflow that does what your tool needs, youve got a great head start\n    \n      Maybe this isnt useful for everybody, but for Temporal users reading this blog, its real nice\n    \n  \n  Tools can run for any duration without timing out\n  Tools can maintain a lifecycle independent of the agent session\n    \n      Weve been exploring that capability here, wherein a long-lived Workflow backs several tools and the agentic system can interact with the Workflow over its lifetime\n    \n  \n  It creates an easy path for agents-as-tools (but thats a topic for another post)\n\nPutting it together: A simple application defined by a user and some tools\n\n  Let me show you what this means in practice. Say I want to figure out when the weather will be good to mow my lawn, and I need two hours of free time to do the mowing. With the durable weather tool above, I can check forecasts reliably. Add a calendar tool, and suddenly I can have an intelligent conversation with an agentic system that combines these tools  all without writing a line of integration code or configuring how the data meshes together. Heres how that conversation might look in Claude:\n  \n  \n  Building a weather-plus-scheduler application traditionally would require significant developer time, but the combination of agentic systems and MCP tools makes it trivial. Temporal makes these tools durable.\n\nThe possibilities become even more exciting when you imagine dynamically putting together all kinds of APIs and data sources across different contexts. As long as the tools exist, you can compose them in endless ways:\n\n  As a developer, I could use MCP-powered monitoring tools to hunt for production problems, then leverage other tools to repair those problems, with me as a human in the loop, directing and approving changes along the way.\n  As a product owner, I could connect tools that pull feature requests from customer feedback systems, analyze and refine them, write them into my teams project backlog, and update the sprint planning documents in my teams wiki  all through natural conversation with an agent.\n  As a foodie, I could have tools that connect my home grocery inventory system, a recipe system, and a food delivery system like Uber Eats. A simple conversation like I feel like eating sushi. Do I have the ingredients to make it? If not, can you recommend some restaurants in the area to deliver it to me? becomes a complete application.\n\nToday, theres still a bit of work to set up MCP tools, and if an MCP server doesnt exist, setting one up for an existing API or data source is a bit of work. This space will continue to mature and get easier, and I expect soon people will be building many kinds of data interactions powered by agentic AI and MCP tools.\nConclusion\nThe combination of agentic systems and MCP enables the creation of powerful, flexible systems defined in simple terms. Human interaction, configuration, and integration can all be driven by human language. When you add Temporals Durable Execution to this architecture, these systems become highly reliable (our customers sometimes say bulletproof)  something required to run in production in an enterprise.\nTemporal provides a rock-solid foundation for building these powerful distributed systems. Kevin Martin, myself, and others at Temporal are convinced that a new generation of applications will emerge  built quickly and durably using these technologies. I expect a new architecture to form, with agents, MCP, and Durable Execution combining to enable simple-to-build applications that are configured by end users to dynamically solve problems in ways traditional architectures never could.\nWe suggest you explore implementing your MCP tools as Temporal Workflows. Youll find these systems not only reliable but genuinely enjoyable to build.\nCheck out our demo repository, or even better, check out this course. And feel free to:\n\n  Join the Temporal Community Slack (channel #topic-ai).\n  Talk to an expert.\n  Sign up for Temporal Cloud and get $1,000 in free credits.\n",featureImage:{title:"Amazon Bedrock with Temporal: Rock Solid",description:"Amazon Bedrock with Temporal: Rock Solid",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6vkAcFvdvpPI8GBeiNonrO/48c2d48998507594a0591ae6759f1e0e/bed_rock.jpeg"},publishDate:"2025-07-09",metaDescription:"Explore how combining Model Context Protocol (MCP) with Temporal's Durable Execution can solve the core challenges of configuration and integration, creating reliable, enterprise-grade agentic systems.",metaTitle:"Durable MCP: Using Temporal to give agentic systems superpowers",socialCard:{title:"Blog (29)",description:"Blog (29)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/Tjdg0tVfeIXLv1vWp27fO/c99790c4b7d1cdaa5e7cfec99c3fcf58/Blog__29_.png"},tags:"AI/ML",slug:"durable-mcp-how-to-give-agentic-systems-superpowers",contentType:"blogPost",entityId:"2zT7ddn4UkmzW4Rcev7tvq",authors:[{id:"6SCT7ktnc7C7malyJV3UsQ",name:"Joshua Smith",slug:"joshua-smith",jobTitle:"Staff Solutions Architect",photograph:{title:"Josh Smith photo",description:"Josh Smith photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2DHNWCAITAPlTgzovWEEyW/1e105a12a16a24ca6db7f3c7ae0ef44b/1678726677795.jpeg"},contentType:"person"}],authorsString:"Joshua Smith",category:"Temporal Voices",readingTime:11},{title:"Durable Digest: June 2025",content:"This blog post is a public copy of our monthly newsletter. If youd like to receive upcoming updates by email, you can subscribe to our newsletter here.\nWelcome to your June 2025 update! Catch up on new SDK releases, upcoming events, and dont miss our upcoming webinar to explore the basic building blocks of Temporal: Workflows and Activities.\nFor more information on these updates and other things weve been working on, just keep reading! And as always, wed love to hear from youfeel free to share feedback in our Community Slack, or on X (@temporalio).\nSDK Updates\n\n  .NET SDK v1.7.0 includes pre-release access to workflow and activity priority keys, a preview of new APIs for worker deployment versioning, and automatic poller scaling configuration.\n  Python SDK v1.12.0 includes memos, activity pauses, and application failure categorization for logging and metrics tracking.\n\nOther Updates\nWith the launch of Temporal CLI 1.0 in August last year, its time to start End of Support for tctl. Starting September 30th, 2025, Temporal will no longer support tctl and its repo will be archived on GitHub. Users will still be able to access the repo, but there will be no further updates. Temporal CLI offers a great developer experience and makes it even easier to create apps with Temporal.\nLearn more about how to get started with Temporal CLI in the docs and on GitHub.\nSpace Camp\nTriviaTemporal Trivia continues on LinkedIn, X, and Instagram. There are prizes. Follow us to play along.\nSpace Camp RadioJust for funwere spinning up a space-and-Temporal-themed playlist battle in the Temporal Community slack. Join us in #watercooler and share your favorite tunes. The winner gets limited edition Camp Temporal swag. (Spotify account required.)\nEvents\nJuly 911, 2025, WeAreDevelopers World Congress 2025Berlin, Germany\nJoin Temporal at the world's largest developer conference, WeAreDevelopers World Congress 2025. Visit our booth to experience live demos, engage with our experts, and discover how Temporal simplifies building resilient, scalable applications. Don't miss this opportunity to connect with the global developer community and explore the future of software development.\nJuly 17, 2025, Temporal Community Meetup: MelbourneMelbourne, Australia\nTemporal and Airwallex are co-hosting an evening of technical talks and networking in Melbourne. Hear from industry experts on topics like large-scale customer migrations, handling Temporal's complexities, and implementing agentic AI in production. Enjoy refreshments, connect with fellow developers, and deepen your understanding of distributed systems.\nWebinars\nJuly 10 - Building Reliable Distributed Systems with Temporal: Error handling and workflow management\nExplore the basic building blocks of Temporal: Workflows and Activities. Youll use these building blocks along with Temporal's TypeScript SDK to develop a small application that communicates with an external service.\nWell review how Temporal helps you recover from failures and explore Temporal's execution model and event history while exploring the Temporal Web UI and command-line tools to explore and interact with your Workflows.\nCant make it? Register now, and well send you the recording.\nCommunity Highlights\nCommunity Events:\n\n  July 10: Community Live: On-machine AI agents with goose and Temporal Join this session to hear directly from the team of the open source project goose about their on-machine AI agent to assist with development tasks, and how it uses Temporal under the hood! \n  July 16: Virtual Temporal Meetup: Microservices Across Time In this session, happening at an EMEA-friendly time, well talk all about long-running workflows and the challenges and rewards therein.\n\nNew Code Exchange projects:\n\n  One-Time Schedule-Based Workflow Triggering by Akshat Jain\n  Temporal Invoice Processor (MCP + Claude + Human-In-The-Loop) by Kevin Martin and Joshua Smith\n  Temporal Minesweeper by Xinyi Chen\n  User Metadata Demo by Taylor Khan\n  CustomDataStore for Yugabyte YCQL by Greg Haskins\n  Slack ReminderBot (Clojure) by Greg Haskins\n\nCommunity Content:\n\n  Cecil Phillip hosted Cornelia Davis and Steve Androulakis for Building AI agents with Temporal and Stripes Agent Toolkit.\n  The Florida JUG Meetup Tour starring Tihomir Surdilovic, hosted by Ammar Yusuf (Tampa), Eyal Wirsansky (Jacksonville), and Eugenio Alvarez (Miami)\n  Pretty, Pretty, Presets by Brave Hager discusses using Temporal to make QA, E2E testing, and the overall product development lifecycle easier.\n  High leverage engineering in an early startup by Sam Waterbury How Unify uses Temporal by Noah Czelusta cover using Temporal for an outbound sales use case.\n  Temporal Cloud won two categories from The Cloud Awards: Best Cloud Automation Solution and Best Open Source Cloud Solution.\n\nBlog\n\n  Building an agentic system thats actually production-ready\n  Error handling in distributed systems: A guide to resilience patterns\n  From AI Hype to Durable Reality  Why Agentic Flows Need Distributed-Systems Discipline\n  Making Friends with Agents: A Mental Model for Agentic AI Applications\n",featureImage:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},publishDate:"2025-06-30",metaDescription:"Explore Temporals latest developer updates: questions from the field, new releases, builder spotlights, learning resources, and ways to connect with our team.",metaTitle:"Durable Digest: June 2025",socialCard:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},tags:"",slug:"durable-digest-june-2025",contentType:"blogPost",entityId:"3ZRpojVOwv3LHyR3ciTLm5",authors:[{id:"17hGmNrCwtXdBh7fhsLUnZ",name:"Temporal Technologies",slug:"temporal-technologies",photograph:{title:"temporal technologies logo",description:"temporal technologies logo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3g56zRXtFQYMeJxBBkVBIZ/7771670e5fc7da59f555837b086c35d6/temporal_technologies_logo.avif"},company:"Temporal Technologies",contentType:"person"}],authorsString:"Temporal Technologies",category:"Announcements",readingTime:4},{title:"Building an agentic system thats actually production-ready",content:"Youre in the industry and your hands are on the keyboard. I know you know that every company is clamoring to ship an AI assistant and that many fall flat on their faces before they even reach the finish line.\nRight now, Ive noticed theres a massive gap between the exciting potential of agentic AI (conversation, proactive, and helpful) and the reality of building something durable enough to survive production. Everyones flaunting their GPT-powered demos, but few have something that still works even two days later.\nIf youve already read this post on why agentic systems are just distributed systems in disguise, this is the follow up. Not the why, but the how.\nThats what inspired me to write this article. Not to further hype the trend, but to strip things down to the foundation (definitions, architecture, and flows) to make sure youre building on solid ground.\nIf youre an engineer, architect, or technical lead thinking about how to scale agent workflows, Im talking to you!\nSince agentic AI is a hot topic now, and there are a lot of terms, ideas, and technologies being discussed, along with the questions:\n\n  Why is this space so interesting? Whats so exciting (and fun!) about it?\n  What do all of these terms mean? Is there a consistent definition?\n  What does an Agentic System actually do?\n  How does Temporal (the technology) help in this space?\n  How is Temporal (the company) helping out companies implement these kinds of systems?\n\nThis blog aims to define some terms, share example architecture and code samples, and offer some helpful opinions on where this is all headed.\nIf youre especially curious about how we as a company are helping, check out these awesome stories and posts:\n\n  Gorgias Uses AI Agents to Improve Customer Service\n  Temporal Use Case Round-Up: Generative AI\n  How Dust Is Building the Future of Work With Agentic AI and Why it Runs on Temporal\n  Building, launching, and scaling ChatGPT Images\n\nAgentic systems: Potential\nAgentic systems have the potential to redefine application architecture because of their amazing capabilities. Agentic Systems can give you an army of qualified assistants that can analyze, execute, and recommend at a massive scale. They can replace a complex UI presenting hundreds of data points with a simple conversation, highlighting points of interest and massively reducing cognitive load. They can make recommendations and take action in context, dramatically reducing the burden of creation. They can validate and make judgements, reducing risk and building confidence.\nIn terms of the future of agentic AI, I (and my colleagues here at Temporal across Engineering, Solutions Architecture and GTM, Product, and Developer Relations) expect these systems may replace entire applications, in the same way the smart phone replaced CDs players, paper calendars, desk phones, personal computers, VCRs, and calling people on the phone to get food delivered. I expect agentic systems will also enable entirely new kinds of applications, just like other technology revolutions did.\nIf these systems can deliver on their promises, being a human connected to the internet is about to get a lot easier.\nAgentic systems: Definitions\nThere are lots of terms floating around in AI. Heres how I define the foundational elements of agentic AI Systems.\n\n  AI: In agentic systems, a Large Language Model (LLM) that simulates intelligence. It can recommend how to pursue goals, make decisions, and recommend or decide on actions to take.\n  Goal: Something the AI and user both want to finish. Often executed by one or more tools with the steps determined by the AI.\n  Tool: A capability of an agentic system.\n    \n      It performs Actions to be taken to accomplish goals with context to guide the AI about how and when to use the tool.\n      Often implemented as a simple function making an API call.\n      Sometimes tools have multiple steps or their own intelligence (see Agents as Tools, below).\n      Can interact with public and private data sources or APIs.\n      Can be built for a specific agentic system.\n      Can be MCP tools.\n        \n          MCP tools provide their own context that the AI can use to evaluate their usage for the users goals.\n        \n      \n    \n  \n  User: A person who wants something done.\n  Agent: Someone or something that acts on behalf and for the benefit of someone or something else.\n  Agentic: An attribute of a system, in which an AI acts on behalf of a user, completing tasks, making decisions, and recommendations for next steps.\n  \n    Agentic system: An application that interacts with a user and behaves in an agentic way, using AI and tools to accomplish goals.\n    Here is a simple model putting all of these concepts together:\n    \n    \n  \n\nAdvanced agentic systems\nThe following concepts are an expansion of those above. We are seeing systems being built that have more complex agentic capabilities:\n\n  Multi-Agent: An attribute of a system that uses multiple agents. Agents could have different capabilities and roles. Agents could be selected via agent routing or tasks could be delegated to agents, for example by implementing an agent as a tool.\n  Agents as tools: in a multi-agent system, Agents can be implemented as tools  a capability of the system. Agents can be tasked with implementing something as part of the users goal. This can be used to delegate a multi-step process that has its own agentic capabilities  deciding how best to implement the process and what tools to use.\n\n\n  \n\nWhat does an agentic system actually do? The agentic flow:\n\n  Agentic systems operate through three interconnected phases: Interaction (with users/events), Decision (via LLMs), and Action (tools, APIs, sub-agents).\n  In Temporal, these are orchestrated together in a single durable workflow:\n\n\n  Interactions: Agent responds to user prompts (e.g. chat) or external events (e.g. new data) and responds to the user.\n  Decisions: Agent uses an LLM API to determine what actions to take. The agent may decide it requires additional user input.\n  Actions: Agent executes specific activities, interfaces with external APIs, runs sub-agents, and uses knowledge bases as needed.\n\n\n  Here is a diagram of these three interactions working together as an agentic system, with Temporal orchestrating each:\n  \n  \n  If you want to see an example of this system in action, check it out on GitHub: Temporal Agentic Workflow Example.\n\nTogether, these make a system that is dynamic, reacting to inputs from users, the LLM, and tool results.\nAgentic challenges\nSo why isnt the hype real yet? We have all of the ingredients  tools, LLMs, humans who would love assistance getting their tasks done. Whats missing?\nWell, at Temporal, weve observed that there are some significant challenges to getting to production AI at scale.\n\n  Humans can be unreliable, inaccurate, or non-responsive.\n  Tool APIs and databases can go down.\n  AI is inherently non-deterministic.\n  Everything in this space is new (and changing constantly).\n  Agentic systems are complex and hard to debug and test.\n  Security is a problem that isnt completely figured out yet.\n\nAgentic systems often struggle to:\n\n  Orchestrate complex multi-step interactions across distributed data stores and tools.\n  Tolerate tool failure.\n  Orchestrate multi-level processes.\n  Hold state, potentially over long periods of time.\n  Be durable: self-heal and retry until the LLM returns valid data.\n  Have simple, generic implementations for human intervention such as approvals and input gathering.\n  Provide insight into the agents performance.\n  Tolerate human error and correction.\n  Securely handle data and access on behalf of users.\n  Ramp to production enterprise scale.\n\nAs we work with so many companies building AI systems, we hear these challenges every day.\nThe reasons the hype isnt real can generally be summarized as: building complex distributed systems is hard and agentic systems are extremely complex distributed systems.\nFor more on this topic, check out this video on how AI agents are distributed systems in their own right.\nAgentic systems must be well-engineered distributed systems\nAgentic systems wont work in production unless theyre well-engineered distributed systems.\nThat means they need to be stateful, fault-tolerant, observable, and able to coordinate both machines and humans over time. Which also means they are best built with reliable orchestration.\nOur position at Temporal is straightforward: If you want your agent to survive the real world, it needs Durable Execution. Durable Execution helps you easily solve the hard parts of distributed systems so you can get a reliable system by default, and you can focus on making something fun and useful for your users using this powerful technology.\nThats what we do and have done, and why were so invested in helping teams move from breakable demos to scalable, reliable systems.\nBuilding an agentic workflow framework\nHere is a simplified version of the agentic framework. Key elements of the Agentic Workflow:\n\n  User interaction is enabled via Signals and self.add_message()  to send messages to the user\n  A Tool Planner activity which uses the LLM to plan tools\n  Activities are used to execute Tools\n  The interaction waits for user confirmation before running Tools\n\n# Simplified version of https://github.com/temporal-community/temporal-ai-agent\n\n@workflow.defn\nclass AgentGoalWorkflow:\n\n    def __init__(self): \n\n    @workflow.run\n    async def run(self):\n        while True:\n            await workflow.wait_condition(  # prompt OR confirm\n                lambda: self.prompt_queue\n                or (self.waiting_for_confirm and self.confirm)\n            )\n\n            #  handle prompt outcome: question/confirm/done\n            tool_data = await workflow.execute_activity(\n                ToolActivities.agent_toolPlanner,\n                {\"prompt\": prompt, \"history\": self.conversation_history},\n            )\n            self.add_message(\"plan\", tool_data)\n\n            # The planner thinks all arguments are ready and a tool should run\n            # Ask the user to confirm\n            if tool_data[\"next\"] == \"confirm\":  # agent is ready to run tool\n                self.add_message(\"agent\", tool_data[\"response\"]) \n\n            elif tool_data[\"next\"] == \"question\":  # ask user for more info\n                self.add_message(\"agent\", tool_data[\"response\"])\n\n            elif tool_data[\"next\"] == \"done\":  # end chat\n                return json.dumps(self.conversation_history)\n\n            #  run tool if outcome is confirm and user confirms\n            elif self.waiting_for_confirm and self.confirm:\n                result = await workflow.execute_activity(\n                self.add_message(\"tool_result\", result)\n                self.waiting_for_confirm = self.confirm = False  # reset flags\n\n    @workflow.signal\n    async def user_prompt(self, prompt: str): \n\n    @workflow.signal\n    async def confirm(self):\n        self.confirm = True\nAs a Temporal Worker, this application can be deployed just like any other Python application. Workers are stateless  all state is stored in the Temporal Service. Since they are stateless, any worker application crashes can be recovered from seamlessly, and I can scale this up to thousands of instances, each able to handle many many conversations concurrently.What the agentic framework looks like\nI can see the entire conversation and flow using the Temporal Workflow History, which I can also use for analyzing Agent success. We can add any Goals or Tools (even MCP tools!) to this framework, enabling the building of many different Agents. These goals and tool definitions are just passed as input to the workflow.\n\n  The workflow is dynamic, flowing and adapting to the conversation, with the agent planning tools based on user input:\n  \n  \n  To try it for yourself, check out the Temporal Agent Framework and explore. Keep in mind, since its just a Temporal application, it will scale and be durable as you need it to. Im excited about this, since it delivers on the needs of agentic applications mentioned above. Plus, its a lot of fun to work with.\n\nProduction agentic AI at scale  powered by Temporal\nFortunately, Temporal was designed to solve the pain of building complex distributed systems. Durable Execution with Temporal makes orchestration of agentic processes simple.\nAgents implemented as Workflows can run for as long as you need them to. Failures are easy to retry, human interaction is simple and flexible, and scale is trivial. It really is that simple.\nWant to see what I mean? Check out this webinar, in which we walk through our agentic AI framework, how we built it, and we try to make it break  but Temporal keeps it bulletproof. Ive talked to so many people whove taken the framework for a spin and built cool agents with it  some are in production now. Building with this framework is fun  I hope you enjoy working with it as so many others have.\nIf youre like me, then Im sure you want to dive deeper into how Temporal makes systems of all kinds durable, scalable, flexible, flexible, and simple to build. If so, you can check out these resources:\n\n  Why Temporal Replaces Traditional State Machines for Distributed Applications\n  Building Reliable Distributed Systems with Temporal: Error Handling & Workflow Management (on the AWS Developers Youtube channel)\n  A Better Way To Build Modern Applications\n  Events are the wrong abstraction\n\nIf you have questions and want to learn more, feel free to reach out:\n\n  Join the Temporal Community Slack (channel #topic-ai). Im there and always willing to chat!\n  Talk to an expert and discuss your specific use case.\n  Take us for a whirl for yourself: sign up for Temporal Cloud and get $1,000 in free credits.\n",featureImage:{title:"buddha-elemental-3d-br5JFHhkoIA-unsplash (1)",description:"buddha-elemental-3d-br5JFHhkoIA-unsplash (1)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6KZNZOYRsAXONUbNuA5V7f/2f1ec7f2dd615ca6d4bb766d98271bff/buddha-elemental-3d-br5JFHhkoIA-unsplash__1_.jpg"},publishDate:"2025-06-26",metaDescription:"Learn to build production-ready, scalable agentic AI systems. This guide for engineers and architects covers foundational concepts, architecture, and a durable framework using Temporal to overcome common development and reliability challenges.",metaTitle:"Building an agentic system thats actually production-ready ",socialCard:{title:"Blog (27)",description:"Blog (27)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3wCvBCq3sUB7uEBPJDQuy2/46b8120930e101662dd12051ec01da78/Blog__27_.png"},tags:"AI/ML",slug:"building-an-agentic-system-thats-actually-production-ready",contentType:"blogPost",entityId:"XxCCyAY903HtJhAarv783",authors:[{id:"6SCT7ktnc7C7malyJV3UsQ",name:"Joshua Smith",slug:"joshua-smith",jobTitle:"Staff Solutions Architect",photograph:{title:"Josh Smith photo",description:"Josh Smith photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2DHNWCAITAPlTgzovWEEyW/1e105a12a16a24ca6db7f3c7ae0ef44b/1678726677795.jpeg"},contentType:"person"}],authorsString:"Joshua Smith",category:"Temporal Voices",readingTime:11},{title:"Error handling in distributed systems: A guide to resilience patterns",content:"Lets face it: distributed systems are tough. Just when you think youve got everything working perfectly, bam, a network interruption or a mysteriously slow service reminds you that while failures are not desirable features of your application, they are unavoidable characteristics of the distributed computing landscape you build on.\nThe good news is that with the right patterns and mindset, you can build systems that dont just survive these failures but thrive despite them.\nWhy distributed systems are different (and why you should care)\nMoving from monolithic to distributed architectures fundamentally changes how we think about errors. Heres what makes them special (and occasionally maddening):\nPartial failures: Your new normal\nIn a monolith, when something breaks, everything breaks. Simple, if painful. In distributed systems? Service A might be having a great day while Service B is on fire. Your e-commerce site could be processing orders perfectly while the recommendation engine is temporarily unavailable.\nThis partial failure mode creates a fascinating challenge. Instead of dealing with binary states, youre managing a spectrum of degradation. Maybe your system is 87% healthy  what does that even mean for your users? Can they still check out? Will they see personalized recommendations or generic ones?\nThe mantra here is design for failure. You dont merely want to handle errors, you want to expect them and prepare for them. Build your architecture to isolate failures, prevent cascades, and enable autonomous recovery wherever possible. When you assume things will break, you build systems that gracefully degrade rather than dramatically collapse.\nThe network: Your unreliable friend\nHeres a truth that seasoned distributed systems engineers know in their bones: the network will betray you.\n\n  Networks introduce latency that varies wildly based on everything from physical distance to how many people are streaming the latest Netflix series. They drop packets like a clumsy waiter drops plates. And sometimes, they partition, creating isolated islands where parts of your system cant talk to each other.\n  When a service doesnt respond, youre stuck with a mystery.\n\n\n  Did your request never arrive?\n  Did the service receive it but crash?\n  Did it process successfully but the response got lost?\n  Is it just slow today?\n\nThis ambiguity is why patterns like retries (with idempotency!) and well-tuned timeouts are essential. Such uncertainty has led to approaches like Durable Execution, where the platform tracks every step of your workflow execution, eliminating the guesswork about what succeeded and what failed.\nAsynchronous chaos\nAsync communication is great for decoupling and scaling. It lets your services work independently, processing messages at their own pace without blocking each other. But it turns error handling into a puzzle.\nWhen an error occurs three services deep in an async flow, tracing it back to the source is like following breadcrumbs through a hurricane. By the time Service C fails to process a message, Service A has long since moved on, not realizing that its original request has gone sideways. While you can still get stack traces from individual service logs, the problem is correlating them across the correct host and transaction for that particular flow. You need new tools and patterns to maintain visibility.\n\n  At-most-once: A message will be delivered once or not at all. This is fast but risks data loss.\n  At-least-once: A message will be delivered one or more times. This prevents data loss, but your system must be able to handle duplicate messages.\n  Exactly-once: A message will be delivered exactly one time. This is the ideal state, but it's arguably impossible to guarantee in any distributed system framework due to physics (e.g., a crash occurring at the exact moment a response is being sent). The goal is to get as close as possible through careful, stateful coordination.\n\nThis complexity multiplies when you have long-running processes that span hours or days (and sometimes weeks or more). A payment reconciliation that runs overnight, a document processing pipeline that waits for human approval, or a subscription renewal that triggers monthly  these patterns demand that level of stateful coordination. This is where Temporals Durable Execution shines. It can provide an effectively exactly-once guarantee for an entire business process. It achieves this by ensuring your Workflow logic is executed to completion once, even if it requires multiple replays behind the scenes. Its Activities (the functions that do the work) are executed at least once, and you use idempotency patterns to ensure there are no unintended side effects from retries.\nA key advantage of Temporal is that it allows you to write code that looks and feels like simple, synchronous, local code, while the platform executes it as durable, asynchronous code. This gives you the benefits of scalable, event-driven systems without you having to build and manage the underlying complexity.\nData (in)consistency\nIn distributed systems, youre constantly trading off between consistency, availability, and performance. Strong consistency simplifies your life but can tank availability during network partitions. Eventual consistency keeps things running but forces you to handle stale or conflicting data.\nWhen operations span multiple services and traditional distributed transactions arent feasible, the saga pattern becomes your friend, using compensating transactions to handle failures. Imagine an account opening process: user created, address added, client profile... failed. Now what?\nYou cant leave the user with a partially created account. The saga lets you roll back the journey, deleting the address and user to restore logical consistency. Its not as clean as an ACID transaction, but its often the best you can do in a distributed world.\nHeres how a saga might look in a Temporal Workflow:\n// workflow implementations as sequential executions\nexport async function openAccount(params: OpenAccount): Promise\u003Cvoid> {\n  // This array holds the compensating transactions for our saga.\n  const compensations: Compensation[] = [];\n\n  try {\n    // Step 1: Create the account.\n    // This is a critical first step. If it fails, the saga doesn't even start.\n    await createAccount({ accountId: params.accountId });\n  } catch (err) {\n    log.error('Fatal error: creating account failed. Stopping workflow.', { err });\n    // No compensations are needed because nothing has been done yet.\n    throw err;\n  }\n\n  try {\n    // The saga begins now. From this point on, any failure will trigger a rollback.\n\n    // Step 2: Add the user's address.\n    await addAddress({\n      accountId: params.accountId,\n      address: params.address,\n    });\n    // If successful, add its compensating transaction to the stack.\n    compensations.unshift({\n      message: prettyErrorMessage('reversing add address'),\n      fn: () => clearPostalAddresses({ accountId: params.accountId }),\n    });\n\n    // Step 3: Add the user as a client.\n    await addClient({\n      accountId: params.accountId,\n      clientEmail: params.clientEmail,\n    });\n    // If successful, add its compensating transaction to the stack.\n    compensations.unshift({\n      message: prettyErrorMessage('reversing add client'),\n      fn: () => removeClient({ accountId: params.accountId }),\n    });\n\n  } catch (err) {\n    // A step in the saga has failed. We must now roll back.\n    log.error('A downstream step failed. Starting saga rollback.', { err });\n\n    // Execute all compensating transactions in the reverse order they were added.\n    for (const compensation of compensations) {\n      log.info(`Executing compensation: ${compensation.message}`);\n      try {\n        await compensation.fn();\n      } catch (compensationErr) {\n        log.error('Compensation function failed.', { compensationErr });\n        // Depending on requirements, you might want to handle this failure,\n        // e.g., by logging for manual intervention.\n      }\n    }\n    // After rolling back, re-throw the original error to fail the workflow.\n    throw err;\n  }\n}\nThe beauty is that the Temporal platform durably executes your Workflow code. This ensures that your catch block and all the compensation logic within it are guaranteed to run, even if your worker process crashes mid-rollback. You write standard-looking try...catch logic, and the platform makes it fault-tolerant.\nEssential resilience patterns that actually work\nNow for the fun part: the patterns thatll save your bacon when things go wrong.\nTimeouts: Your first line of defense\nWithout timeouts, a single slow service can bring down your entire system through resource exhaustion. But setting them is an art:\nTwo types to configure:\n\n  Connection timeout: How long to wait to establish a connection.\n  Request timeout: How long to wait for a response after connecting.\n\nSmart timeout strategies:\n\n  Percentile-based: Set timeouts based on your p99 or p99.9 latency. If 99% of requests complete in 100ms, maybe timeout at 150ms.\n  Deadline propagation: If your user request has 2 seconds total, and youve already used 500ms, tell the next service it only has 1.5 seconds. No point processing requests thatll timeout anyway.\n\nThe Goldilocks problem:\n\n  Too short? Youll timeout healthy services and trigger unnecessary retries.\n  \n    Too long? Youll exhaust resources waiting for dead services.\n    Remember: timeouts trigger other patterns. Theyre often the canary that tells your circuit breaker to start counting failures (more on that further down!).\n  \n\nRetries: Second chances for transient failures\nRetries help you recover from temporary glitches, but theyre a double-edged sword.\nStrategies that work:\n\n  \n    \n      Strategy\n      Description\n      When to use\n    \n  \n  \n    \n      Immediate retry\n      Try again instantly\n      Almost never (seriously)\n    \n    \n      Fixed interval\n      Wait a constant time between retries\n      When you know recovery time\n    \n    \n      Exponential backoff\n      Double wait time each retry (1s, 2s, 4s)\n      Most network calls\n    \n    \n      Exponential backoff + jitter\n      Add randomness to prevent thundering herds\n      The gold standard\n    \n  \n\nThe golden rule of retries: Idempotency\nNever, ever retry non-idempotent operations. Charging a credit card twice because of a timeout isnt a transient error, its a lawsuit waiting to happen.\nKnow when to quit:\n\n  Dont retry client errors (400s)  they wont magically fix themselves.\n  Dont retry an already overloaded service  youll make things worse.\n  Watch for retry amplification in deep call chains (one failure times 3 retries per layer equals exponential pain)\n\nHeres how retry policy configuration looks in practice with Temporals Python SDK:\nfrom temporalio.common import RetryPolicy\n# ...\n        activity_result = await workflow.execute_activity(\n            your_activity,\n            YourParams(greeting, \"Retry Policy options\"),\n            start_to_close_timeout=timedelta(seconds=10),\n            # Retry Policy\n            retry_policy=RetryPolicy(\n                backoff_coefficient=2.0,\n                maximum_attempts=5,\n                initial_interval=timedelta(seconds=1),\n                maximum_interval=timedelta(seconds=2),\n                # Don't retry on application errors like ValueError\n                non_retryable_error_types=[\"ValueError\"],\n            ),\n        )\nThis declarative approach means you configure once and let the platform handle retry timing and backoff calculations.\nCircuit breakers: Stop hitting yourself\nCircuit breakers are your systems self-preservation instinct. When a downstream service is clearly struggling, the circuit breaker says enough is enough and stops calling it entirely. This prevents your system from wasting resources on doomed requests and gives the struggling service breathing room to recover.\nThe pattern takes its name from electrical circuit breakers, and the analogy is apt. Just as an electrical breaker prevents your house from burning down when theres a short circuit, a software circuit breaker prevents cascading failures from taking down your entire system.\nThree states:\n\n  Closed: Everythings fine, requests flow normally.\n  Open: Service is dead to us, fail fast without calling.\n  Half-open: Lets cautiously check if its recovered.\n\nKey settings to tune:\n\n  Future threshold (e.g., 50% errors in 10 seconds).\n  Reset timeout (how long to wait before checking again).\n  Request volume threshold (dont trip on just 2 failure requests).\n\nCircuit breakers and retries can work together beautifully. Retries handle transient blips, while circuit breakers handle persistent problems. When the circuit is open, smart retry logic knows not to bother  theres no point retrying when the circuit breaker has already declared the service unavailable.\nSome platforms achieve circuit breaker behavior through retry policies. In Temporal, you can configure maximum retry attempts with specific error types that immediately stop retries. You can also build advanced monitoring and control.\nFallbacks: Plan B (and C)\nWhen things fail despite retries and circuit breakers, you need alternatives:\n\n  Cache it: Serve stale data rather than no data.\n  Simplify it: Show generic recommendations when personalization fails.\n  Disable it: Turn off non-essential features.\n  Fail fast: Sometimes a quick, graceful error is better than a long wait.\n\nWhats key here is that fallback logic must be simpler and more reliable than what its replacing. A fallback that queries three other services and performs complex calculations defeats the purpose. The best fallbacks often involve static data, simple caches, or straightforward business rules that can execute without external dependencies.\nDead Letter Queues: Where messages go to think about what theyve done\nIn async systems, some messages are destined to fail. Maybe theyre malformed, maybe theyre trying to process an order for a product that no longer exists, or maybe theyre perfectly fine but arrived during a service outage. Dead Letter Queues (DLQs) give these problematic messages a place to go instead of clogging up your main processing pipeline. While its easy to think of them like error bins, theyre actually diagnostic goldmines.\nBest practices:\n\n  Monitor DLQ depth and arrival rate.\n  Analyze patterns (same message type failing? Same error?).\n  Implement automated or manual reprocessing.\n  Set retention policies  dont hoard failures forever.\n\nModern workflow engines like Temporal take a different approach that removes the need for DLQs entirely. Instead of moving a failed task to a separate queue where it loses its context, Temporal keeps the stuck Workflow in a failed state, but its full execution history remains visible and queryable.\nThis is a huge advantage. It means you can handle these stuck events with far more powerful patterns:\n\n  Alerting: Set up monitoring to alert you when a Workflow has a high failure count or has been running for an unusually long time.\n  Debugging: Inspect the live, failed Workflow's state and complete history to understand exactly what went wrong.\n  Hotfixing: Fix the underlying bug in your worker code.\n  Resume/replay: Once the fix is deployed, you can use Temporals tooling to replay the failed Workflow. It will then re-execute on the fixed code, often continuing from the point of failure without losing any progress.\n\nThis turns a potential data loss scenario (a message in a DLQ) into a recoverable operational flow.\nThe Bulkhead pattern: Compartmentalize your failures\nThe Bulkhead pattern recognizes a simple truth: shared resources create shared fate. When all your services share the same thread pool, one slow service can exhaust all the threads, starving every other operation.\nBy isolating resources into separate pools, you contain the blast radius of failures. Service A gets 50 threads, Service B gets 30, Service C gets 20. Now when Service A decides to have a bad day, it can only exhaust its own threads. Services B and C continue operating normally, blissfully unaware of As struggles.\nThis principle of isolation is fundamental to how Temporal designs resilient systems. While traditional bulkheads operate at the resource level (like thread pools), Temporal applies the pattern at an architectural level using Task Queues. By assigning different types of activities to different Task Queues, each served by a dedicated pool of Workers, you create a robust bulkhead. If activities on one queue become slow or start failing, they only consume the resources of their dedicated Worker pool, leaving other critical business functions completely unimpaired.\nThis approach is fundamentally more resilient than simple resource pooling because of Durable Execution. The work itself (the workflow state) is not tied to a specific worker or thread; its durably persisted by the Temporal cluster. This means even if an entire worker pool crashes and needs to be restarted, the work is never lost.\nIdempotency: The unsung hero\nMaking operations idempotent is the foundation of reliable retries and at-least-once delivery. As we discussed, Temporal Activities provide an at-least-once execution guarantee, and your idempotent Activity implementation provides the no-more-than-once business effect. Together, they allow you to achieve an effective exactly-once execution of your business logic.\nImplementation approach:\n\n  Client generates a unique idempotency key.\n  Server checks if the key was seen before.\n  If new: process and store result with key.\n  If duplicate: return stored result without reprocessing.\n\nPro tips:\n\n  Use UUIDs or meaningful keys (e.g., order-create-{orderId})\n  Store keys with TTL  dont keep them forever.\n  Make the key capture the operations intent precisely.\n\nIn Temporal Workflows, idempotency is particularly elegant. Since the platform tracks every step of execution, you can implement this pattern reliably.\nimport uuid\nfrom datetime import timedelta\nfrom temporalio.common import RetryPolicy\nfrom temporalio import workflow\n\n# Define your activity, e.g., process_payment\n@activity.defn\nasync def process_payment(data: PaymentRequest) -> str:\n    # This activity would connect to a payment provider like Stripe,\n    # passing the idempotency_key with the API request.\n    # The payment provider handles step 2 (checking the key).\n    ...\n    return \"payment_processed_ok\"\n\n@workflow.defn\nclass PaymentWorkflow:\n    @workflow.run\n    async def run(self, data: PaymentRequest) -> str:\n        # NOTE: Generating random data directly in a Workflow is a non-deterministic \n        # operation and will break replay. A unique key must be generated in a \n        # deterministic way. A best practice is to have the client that starts \n        # the Workflow generates the key, or use workflow.side_effect. \n        # Here, we assume it's passed in via the `data` object. \n        # The Workflow calls the activity, passing the key. \n        # If the Workflow process were to crash and resume here, the *same* # idempotency_key would be used on the next attempt, # preventing a duplicate charge.\n\n        # The Workflow calls the activity, passing the key.\n        # If the Workflow process were to crash and resume here, the *same*\n        # idempotency_key would be used on the next attempt,\n        # preventing a duplicate charge.\n        return await workflow.execute_activity(\n            process_payment,\n            data,\n            idempotency_key=idempotency_key,\n            start_to_close_timeout=timedelta(seconds=30),\n            retry_policy=RetryPolicy(maximum_attempts=3),\n        )\nObservability: Seeing through the chaos\nYou cant fix what you cant see. Three pillars light your way:\nStructured logging + correlation IDs\nEvery request gets a unique ID that follows it everywhere. Combined with structured (JSON/YAML) logs, you can trace a requests entire journey with a simple query.\n{\n  \"timestamp\": \"2024-01-10T10:30:45Z\",\n  \"level\": \"ERROR\",\n  \"service\": \"payment-service\",\n  \"correlationId\": \"abc-123-def\",\n  \"message\": \"Payment processing failed\",\n  \"userId\": \"user-789\",\n  \"error\": \"Gateway timeout\"\n}\nDistributed tracing\nWhile logs show what happened in each service, traces show the big picture  how services called each other, where time was spent, and where failures occurred.\nA trace might reveal that your API call took 5 seconds not because your service was slow, but because it spent 4.8 seconds waiting for a database query that normally takes 50ms. Without tracing, youd be optimizing the wrong thing.\nOpenTelemetry is becoming the standard here, letting you instrument and choose your backend (Jaeger, Zipkin, etc.) later. But Temporal can make your life easier: it provides built-in visibility into execution history, making it easy to debug failures without instrumenting every service call.\nMetrics that matter\nMonitor your resilience patterns to know if theyre helping or hurting:\n\n  \n    \n      Pattern\n      Key metrics\n      Alert when\n    \n  \n  \n    \n      Timeouts\n      Timeout rate, p99 latency\n      Rate > X% or latency approaching timeout\n    \n    \n      Retries\n      Retry rate, max retries hit\n      High retry rate or many hitting max\n    \n    \n      Circuit breaker\n      State changes, rejected calls\n      Stuck open or flapping\n    \n    \n      DLQ\n      Queue depth, message age\n      Growing depth or old messages\n    \n    \n      Fallbacks\n      Invocation rate, success rate\n      High usage or fallback failures\n    \n  \n\nWhile these three pillars are essential for any distributed system, a platform like Temporal bakes observability in as a first-class feature. Temporal automatically injects correlation IDs like WorkflowId and RunId into logs and traces, making it trivial to track a single executions journey. The SDKs emit the very metrics mentioned above (retries, latencies, timeouts) out-of-the-box and integrate with OpenTelemetry for distributed tracing.\nBut Temporals greatest contribution to observability is its fourth pillar: the Event History. Every Workflow execution provides a complete, queryable, and replayable audit trail of every event (WorkflowExecutionStarted, ActivityTaskScheduled, ActivityTaskCompleted, TimerFired, etc.). This provides an infallible source of truth for debugging that makes stitching together disparate logs and traces unnecessary, allowing you to see exactly what happened, step-by-step, long after the execution is complete.\nPerformance: The cost of resilience\nEvery resilience pattern has overhead. The trick is making smart trade-offs:\n\n  Retries increase load  use backoff and jitter.\n  Idempotency adds lookup latency  optimize your key storage.\n  Circuit breakers can have false positives  tune thresholds carefully.\n  Tracing adds overhead  use sampling in production.\n\nThe question isnt whether these patterns have costs, but whether those costs are worth paying. In almost every case, they are. A system that takes 50ms longer to process requests but stays up during failures beats a system thats 50ms faster but falls over when you sneeze at it. Your users wont thank you for those saved milliseconds if they cant complete their transactions.\nTesting your resilience\nDont wait for production to test your error handling. Use:\n\n  Load testing with failure injection.\n  Chaos engineering to break things on purpose.\n  Game days to practice incident response.\n\nThe Durable Execution alternative\nWhile the patterns weve discussed are essential knowledge for any distributed systems engineer, theres a new approach that fundamentally changes how we handle failures: Durable Execution. Temporal embeds these resilience patterns directly into the execution model.\nWith Durable Execution, your workflow state is automatically persisted, retries happen without your intervention, and the platform handles the complexity of coordinating distributed transactions. Instead of writing defensive code full of error handling, you write business logic that looks almost sequential:\nasync function processOrder(orderId: string) {\n  // Each step is automatically retried on failure\n  const items = await checkInventory(orderId);\n  const payment = await processPayment(orderId);\n  await shipOrder(orderId, items);\n  await sendConfirmationEmail(orderId);\n}\nBehind the scenes, the platform handles retries, maintains state across failures, and ensures exactly-once execution for Workflows and at-least-once execution for Activities. Companies like Netflix, Stripe, and Snap have adopted this model for critical workflows, reporting dramatic reductions in error-handling code and faster development cycles.\nConclusion: Embracing the chaos\nDistributed systems will fail. And thats not dooming, its physics. Networks have latency. Servers crash. Bugs happen. But with the right patterns, observability, and mindset, you can build systems that bend without breaking.\nStart simple. Add timeouts to your external calls. Make your critical operations idempotent. Implement retries with exponential backoff and jitter. As you gain confidence, layer in circuit breakers and bulkheads. Invest heavily in observability. Or try Temporal: we bake these resilience patterns directly into our platform, so you can focus on your business logic.\nRemember: the goal isnt to prevent all failures, but to handle them so gracefully that your users never notice. Thats the art of distributed systems.\nNow go forth and build something resilient with Temporal Cloud. Start your free trial today and get $1000 in free credits. Your future on-call self will thank you.",featureImage:{title:"social-card-brandon",description:"social-card-brandon",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1oX4jNjimgeS45r7uoaMha/d54d7043f6f959dc26a493a2e74d98c7/social-card-brandon.jpg"},publishDate:"2025-06-20",metaDescription:"Failures in distributed systems are unavoidable. Learn essential error handling patterns like retries, sagas, and circuit breakers to build resilient applications and see how Durable Execution simplifies it all.",metaTitle:"Error handling in distributed systems: A guide to resilience patterns",socialCard:{title:"Blog (26)",description:"Blog (26)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1YaVeYQXraqgEEkvLnJsX/cb8b9249654fe6e35a943e3c3ea76ee4/Blog__26_.png"},tags:"Retries,Timeouts",slug:"error-handling-in-distributed-systems",contentType:"blogPost",entityId:"ukdiNjcThZV1mkLmlQd27",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"How-To",readingTime:19},{title:"From AI hype to durable reality  why agentic flows need distributed-systems discipline",content:"I remember when I became a technophile. It was 1995, and my dad, Paul, lugged a spotted-cow Gateway 2000 box into the house. He booted Windows 95, opened Microsoft Paint, and let me explore. The moment I learned that I could clean up with a quick Ctrl+N, a world of infinite possibilities opened up in front of me, and I was hooked.\nFast-forward to a month ago. I asked my colleague Steve Androulakis how Temporal fits into the world of AI agents and Model Context Protocol (MCP). Steve sent me the Getting Started with MCP for Claude Desktop guide and reminded me that the best way to learn is to roll up your sleeves (Thanks Steve!). I started with Anthropics National Weather Service-API example, wrapped the tools in Temporal Workflows, and turned the HTTP call into a Temporal Activity. I realized that MCP empowers LLMs to seamlessly interact with external or internal services and APIs, while Temporal fortifies these interactions with robust Durable Execution. Together, Durable Tools transform AI from passive responders into resilient, action-taking agents. As I watched my weather agent come to life, the same spark of excitement around infinite possibilities I felt in 1995 returned.\n# weather.py (MCP Server)\n\nfrom temporalio.client import Client\nfrom mcp.server.fastmcp import FastMCP\n\nmcp = FastMCP(\"weather\")\n\n# Temporal client setup (do this once, then reuse)\ntemporal_client = None\n\nasync def get_temporal_client():\n    global temporal_client\n    if not temporal_client:\n        temporal_client = await Client.connect(\"localhost:7233\")\n    return temporal_client\n\n@mcp.tool() # Durable Tool: Get Alerts\nasync def get_alerts(state: str) -> str:\n    client = await get_temporal_client()\n    # By starting the workflow as the first operation, we're capturing the intent in Temporal, thereby making it durable and resistent to network / process / server failures\n    handle = await client.start_workflow(\n        \"GetAlertsWorkflow\",\n        state,\n        id=f\"alerts-{state.lower()}\",\n        task_queue=\"weather-task-queue\"\n    )\n    return await handle.result()\n\n#######################################################################################\n\n# workflows.py\n\n# Temporal's retry policies remove the need for endless try/catch blocks \nretry_policy = RetryPolicy(\n    maximum_attempts=0,  # Infinite retries\n    initial_interval=timedelta(seconds=2),\n    maximum_interval=timedelta(minutes=1),\n    backoff_coefficient=2.0,\n)\n\nNWS_API_BASE = \"https://api.weather.gov\"\n\n@workflow.defn # Workflow for Getting Alerts from the NWS, called from the Durable Tool above\nclass GetAlertsWorkflow:\n    @workflow.run\n    async def run(self, state: str) -> str:\n        url = f\"{NWS_API_BASE}/alerts/active/area/{state}\"\n        data = await workflow.execute_activity(\n            \"make_nws_request\",  # Name of the registered activity, retries based on the retry_policy above, with a 40 second timeout\n            url,\n            schedule_to_close_timeout=timedelta(seconds=40),\n            retry_policy=retry_policy,\n        )\n\n        if not data or \"features\" not in data:\n            return \"Unable to fetch alerts or no alerts found.\"\n        if not data[\"features\"]:\n            return \"No active alerts for this state.\"\n        alerts = [format_alert(feature) for feature in data[\"features\"]]\n        return \"\\n---\\n\".join(alerts)\nWho I Am:\nIm Kevin Paul Martin, a Senior Strategic Account Executive at Temporal who still keeps a terminal open. For the last two-and-a-half years Ive guided global enterprises through their Temporal journeys, translating business goals into durable workflows. Before stepping into the AE role, I was a Sr. Solution Architect at Redis, helping Fortune-100 teams master everything real-time. And long before that shift to solutioning, I was a full-stack engineer at ZEFR, where I built BrandID Store  a customer-facing data-visualization web-app that armed our sales team with the insights they needed to sell targeted advertising packages. That mix of builders curiosity and customer focus is exactly what pulled me into todays agentic-AI frontier.\nWhy This Post:\nThe past month of building stateful agentic flows and MCP servers taught me that the glamorous part of AI ends quickly; operationalizing for production is where projects live or die. Below are the lessons I learned while building these flows with Temporal  and why Temporal keeps showing up in the answers.\nLearning #1  AI Systems Are Distributed Systems In Disguise\n\n  \n  Once an AI system grows beyond a single machine, and even more importantly when you start preparing for production, its real challenges stop being AI and start being distributed-systems problems on steroids:\n  \n  \n\n\n  Scale & Parallelism  Training or serving a large model means sharding parameters and data across GPUs, nodes, or regions  just like any other high-throughput service.\n  Data Pipelines  ETL, feature stores, vector databases, and streaming updates must guarantee consistency, ordering, and fault tolerance.\n  Orchestration & Coordination  Agentic, Retrieval Augmented Generation (RAG), & MCP pipelines, chain tokenizers, retrievers, LLMs, and post-processors that need idempotent retries, safe versioning, and back-pressure handling.\n  Reliability & Observability  Health checks, retries, circuit breakers, metrics, and tracing remain mandatory; GPU kernels do not repeal the fallacies of distributed computing.\n\n\n  So while the logic is AI-specific, the plumbing is pure distributed systems. Temporal removes that plumbing pain: its workflow engine handles state, retries, timeouts, back-pressure, and event replay out of the box, while its built-in tracing and metrics give you instant observability  enabling teams to ship agentic flows without reinventing distributed-systems discipline.\n  \n  \n\nLearning #2  Durable Execution Drives Resilience\nPackets drop, links flap, and dependencies misbehave: the network can vanish mid-call, a downstream database might choke, a third-party SaaS endpoint may rate-limit or 500, and that stable vendor API you dont control will inevitably get flaky at 2 a.m. Temporal absorbs all of it.\n\n  Automatic retries & back-off wrap every Activity call  whether its an internal microservice or an external AI APIso transient failures dont page the on-call.\n  Timeouts stop hung tasks from cascading through the system.\n  Event-sourced history lets a crashed worker replay state on restart: no lost progress, no double charges.\n  Schedules trigger recurring or delayed actions  say, firing off a quarterly-renewal workflow; Signals let an external system inject events into that workflow  picture the CFO clicking Approve (human-in-the-loop) in your finance portal, whose backend persists the approval to Temporal before it returns 200 OK; and Queries let downstream dashboards read the live state without mutating it. Because the approval signal is durably stored first, even if the payment-gateway API times out or the partner ERP goes offline, Temporal simply replays the workflow and keeps retrying the charge until it clears  no lost sign-offs, no duplicate invoices.\n\nWith Durable Execution, resilience isnt an after-thought  its the default.\nLearning #3  Polyglot Freedom Enables Flexibility\nEach service keeps its favorite language  Python, Java, Go, TypeScript, .NET, Ruby, even PHP  while Temporal handles the cross-language coordination. A Python MCP implementation can kick off a RAG workflow, and a Java worker can perform the retrieval step; signals and queries flow seamlessly between them. This polyglot model lets AI specialists stay productive in Python while platform teams reuse existing services, making cross-functional collaboration frictionless.\nLearning #4  Nexus Bridges AI & Business Workflows With End-to-End Observability\nNexus lets an agentic workflow invoke an existing microservice  also implemented in Temporal  through a single, durable control plane. Every hop  agent call, business logic, external API  lands in the same Workflow History and the same metrics dashboards. One system finally gives engineers, SREs, and data scientists the unified view theyve wanted for years, eliminating the need for separate schedulers, sidecars, or observability silos. AI and non-AI paths share durability, tracing, and alerting in one place  and platform complexity shrinks accordingly.\nLearning #5  Crash-Proof Conversations: Signals, Queries & MCP In Action\nSteves demo is my favorite proof-point: using Signals and Queries, a chat workflow stays fully stateful even if the user slams the laptop lid. When they reopen it, Temporal replays the entire event history and the conversation picks up exactly where it left off  no Sorry, I forgot what we were talking about.\nI saw the same durability in my own MCP demo. The MCP server acts as a Temporal client, and every tool invocation is a StartWorkflow call. If the process hosting the agent crashes mid-dialog, the Workflow History simply rehydrates on the next Worker, the Signal channel reconnects, and the agent finishes the request without losing context or duplicating work.\nBottom line: whether its Steves multi-turn chat or my MCP toolchain, Temporal turns fragile conversational loops into crash-proof, replayable workflows.\nLearning #6  Developer Velocity Through Code Simplicity\n\n  Durable Execution, implicit retries, and built-in state management slash boilerplate. Teams often report double-digit reductions in lines of code and a dramatic drop in custom glue logic. Fewer moving parts mean faster prototypes, quicker reviews, and easier audits.\n  \n  \n  (Diagram is conceptual and not based on real-world data)\n\n\n  Without Temporal, we would be lagging behind significantly from where we are. Because of the productivity it provides, we are able to move much, much faster than where we were previously. I dont think that the product I work on would be successful at all if Temporal were not part of the solution.  Rob Zienert, Sr. Software Engineer, Infra Management, Netflix\n\nLearning #7  Durable Tools Means Free Scalability\nWhen each MCP tool is implemented as a Temporal Workflow, instead of running inside the MCP server process, every invocation is picked up by the global worker fleet  the same pool that already scales your non-AI workloads. That architecture delivers horizontal elasticity without extra infrastructure:\n\n  A burst of agent requests simply fans out across additional workers (or k8s autoscaled pods) with no changes to the MCP server code.\n  Hot spots are isolated: slow or compute-heavy tools dont block lightweight steps, because workers pull tasks independently.\n  \n    Back-pressure is automatic: the Temporal Server queues pending tasks, so the MCP server never collapses under peak load.\n    In practice, this Durable Tools pattern lets a single MCP server stay thin and stateless while Temporal handles the heavy lifting of concurrency, throughput, and resource isolation  scaling right alongside the rest of your platform.\n  \n\nSocial Proof\n\n  Temporal is used for asynchronous workflows and operations inside OpenAI. Temporal is a neat workflow solution that makes multi-step workflows reliable even when individual steps crash, without much effort by developers. Its particularly useful for longer-running workflows like image generation at scale.  Gergely Orosz\n\nThe quote above comes from OpenAIs post on The Pragmatic Engineer blog, which states that Temporal was employed to manage asynchronous operations and ensure reliability during the launch of ChatGPT's image generation feature. Temporal's workflow orchestration capabilities were particularly beneficial in handling the high demand and complexity associated with large-scale image generation tasks. TPE is one of my favorite industry blogs, and I highly recommend subscribing if you havent. Additionally Temporal powers OpenAIs Codex product, a powerful agentic tool for coding quickly.\nTakeaways & How to Turn Hype into Durable Reality\nAgentic AI is exhilarating, but durability, scalability, observability, and developer velocity decide who reaches production. Temporal lets you focus on prompts and models while it handles the distributed-systems discipline underneath.\nIf youre experimenting with MCP reliability or agent orchestration, lets connect.\n\n  Join the Temporal Community Slack (channel #topic-ai).\n  Find me on LinkedIn & GitHub.\n  Sample Code: temporal-invoice-mcp, temporal-durable-mcp-weather-sample.\n  Or email sales@temporal.io and mention AI blog in the subject line.\n\nWe can help you turn the AI hype into durable reality  by giving every agentic flow the distributed-systems discipline it deserves. Try your hand at improving your agentic AI production with a free trial of Temporal Cloud with $1,000 in credits.",featureImage:{title:"image-3D-waves",description:"image-3D-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/62stYfm7wc5gZJaaldJ4jy/4f585ec2bd98307d1b4593c6c5f6ca92/Screenshot_2024-11-13_at_12.44.34_PM.png"},publishDate:"2025-06-11",metaDescription:"Move AI agents from hype to production. Learn why agentic flows demand distributed-systems discipline and how Temporal provides the Durable Execution, resilience, and scalability to build truly robust AI applications that won't fail.",metaTitle:"From AI hype to durable reality  why agentic flows need distributed-systems discipline",tags:"AI/ML,Code Samples",slug:"from-ai-hype-to-durable-reality-why-agentic-flows-need-distributed-systems",contentType:"blogPost",entityId:"3aS3fncRjUrdKVdrh9ZhSg",authors:[{id:"6o3jzEvdJJ2BGf8hYHFlPH",name:"Kevin Martin",slug:"kevin-martin",jobTitle:"Sr. Strategic Account Executive",photograph:{title:"kevin-martin-headshot",description:"kevin-martin-headshot",url:"https://images.ctfassets.net/0uuz8ydxyd9p/zgFcGzBwVwP7Vk6Qoujc6/e5eca529c6261ddb28daaad3a0072412/TT31S6VK5-U04HVHG9D6W-31cb48b66c24-512.jpeg"},company:"Temporal",contentType:"person"}],authorsString:"Kevin Martin",category:"Temporal Voices",readingTime:10},{title:"Making friends with agents: A mental model for Agentic AI applications",content:"When I told a colleague that I was working on a post that would present a mental model for AI agents, he asked, What will make it different from the dozens of others out there already?\nA great question that I noodled on for a bit and heres what it came down to: I read a whole bunch of pieces, yet still didnt feel like I had a working model in my head. They were either very high-level, or down in the weeds. I couldnt see how it all fit together: goals, tools, loops, LLMs.\nSo I kept studying. I played with LangGraph. I vibe coded with Cursor (coding agents are a great example of AI agents). I created a new agent using a sample that my colleague Steve created. I drew some pictures (that I will share here), and I socialized with a bunch of people who are well ahead of me on the learning curve, as well as some who were also learning. And now, I get it. Dont get me wrong, I still have a ton to learn, but I now have a framing around which I can extend that learning.\nThis post is the mental model I wish Id had when I started. Its for my fellow devs who want to understand how agentic AI applications actually work: what you need to build, how the pieces fit together, and why its not as magical (or as mysterious) as it might seem initially.\nIm Talking about LLMs and Tools Here\nFirst, let me be clear about the flavor of agent Im talking about: the kind that leverages an LLM to drive the flow of an application; that is, the LLM is determining the next steps that the application will take, and the agents job is to execute tools at the LLMs direction. (Not to worry, Ill talk more clearly about tools in just a moment).\nIm not going to talk about whether we should use the term agent to describe apps that invoke LLMs and downstream services through code that has a predetermined flow. Its an interesting debate, for sure, but this is something that is quite adequately covered in some of the aforementioned pieces (I particularly like this one from LangChain).\nFrom here on out, when I use the term AI agent, or just agent, Im talking about an application that operates roughly like this:\n\n  \n\n\n  The agent is generally implemented as an event loop that is kicked off with an expression of some goal.\n  In the loop, it:\n    \n      Asks the LLM to determine the next steps in the flow, and then\n      Invokes one or more tools to perform those actions.\n    \n  \n  It keeps looping until the LLM hits its goal or the user stops it.\n\n\n  An agent has a fixed set of tools available to it; for now, think of a tool as just an API (more to come in a moment). Each time the LLM responds with some instruction, it is the job of the agent to take that response and make preparations for tool execution. The agent may ask the user for confirmation before executing the tool. And after a tool is executed, it is the job of the agent to update the content that is fed to the LLM for the next turn.\n  \n  \n  These are effectively the pieces that you, the AI agent developer, are responsible for building:\n\n\n  A prompt that will bootstrap the LLM to kick off the work of the agent.\n  A library of tools that may be invoked by the agent.\n  A mechanism for turning LLM decisions into a concrete tool execution.\n  A mechanism for updating the input to the LLM on each turn through the loop.\n\nAnd then you have to put all of these pieces together, so you will need:\n\n  An application that durably implements the event loop. A durable event loop is one that can recover from a crash, picking up where it left off in the event of failure.\n  And finally, a way to durably invoke LLMs and tools. Durable invocations are ones that will survive intermittent network and service outages, rate-limited LLMs, and more.\n\nThis, right here, is my mental model for an AI agent.\nIn the rest of this post, I will cover each of the things on this list in a bit more detail.\nThe Language of LLMs and Tools\nBy now, you likely know the basics of how an LLM works: it takes in some content as a sequence of tokens, and it outputs content, usually as a sequence of tokens. The output tokens are determined from the large amounts of content that the models have been trained on (say, the content of the entire internet). The training of these models isnt germane to our conversation here, but the language of the input and output is.\nJust a few scenarios:\n\n  Natural language as input, natural language as output  for example, getting a summary of a meeting transcript.\n  Natural language as input, an image as output  for example, the generation of your latest cat meme \n  Natural language plus code as input, code as output  for example, asking Claude code, Github Copilot, Codex or Cursor to make updates to a code base.\n\nThat is, the interface to an LLM is the language for the input and the language for the output. As the AI agent developer, you get to decide what that interface is. Most often, the input will include at least some natural language that expresses the goal that the agent is to fulfill  remember this for a moment.\nNow lets turn to the interface for tools.\nUltimately, a tool turns into an invocation of a service that has rigorously defined inputs and outputs that might be described through specifications like OpenAPI, GraphQL SDL, or Protobuf for gRPC. But earlier I suggested there was a bit more to it than this  and that is all about language.\nIn order for an LLM to determine which tools must be executed, and in which order, it must have a way to associate the words that make up the goal with the right tools. This is done by associating a set of words with each of the tools  namely, each tool will have natural language descriptions of:\n\n  The overall function of the tool  for example, a service that will search for flights with available seats.\n  The meaning of each of the input parameters  for example, the departure and arrival locations, and date of travel.\n  The meaning of each of the output parameters  for example, a flight number and cost.\n\n\n  The Model Context Protocol (MCP) has become the de facto standard for tool specifications.\n  \n  \n  The goal should be quite detailed, and must be expressed with language that makes it easy for the LLM to associate it with the set of available tools. While LLMs are quite adept at navigating synonyms and alternate phrasing  and indeed, this is one of the major advantages of agentic systems over the rigid, form-based experiences that have dominated our digital experiences in the past  the more closely aligned the language of your goal is to the descriptions of the tools, the better the outcome is likely to be.\n\nTo bootstrap the agentic loop, the goal, the tool descriptions, and some additional context (which I will go into more detail on in just a bit) are fed to the LLM, which will return output indicating which tool is to be invoked.\nLets now talk about taking that output and readying it for tool invocation.\nPreparing for Tool Invocation\nLets walk though a concrete example. Say the goal is to search for flights, book one, and then charge the user. With a properly crafted goal, upon invocation, the LLM will decide that the first thing the agent will do is search for relevant flights, using the flight search tool. That tool takes in arguments including departure and destination cities, and a travel date. So before running the tool, the agent must collect those arguments and structure them in such a way that the tool can be invoked with the right values. The agent handles the preparation for invoking the tool.\n\n  How the agent does this preparation can vary. If necessary, such as in the above example, it could present the user a form that allows them to provide the necessary information, or it may engage in a chat with the user to get that data; the latter is depicted in the following diagram.\n  \n  \n  The lower left depicts the main event loop, but then you can see another loop that is used to prepare for tool execution. In this second loop, the LLM on the left is used to generate prompts to the user, guiding them toward the needed inputs, and the LLM on the right (hmm, that kind of looks like the tool Im using is an LLM!! ) is used to validate the response from the user. To be clear, this agent structure is not prescriptive  you will decide the structure of your agents  but Im finding the mental model of the primary event loop helpful in keeping my agents well structured.\n\nOnce all the inputs are gathered, an API will be invoked, and for that, the data must be structured. But what better way to transform unstructured data (Id like to go from LAX to Toronto on April 16th) into structured form ({ departure : LAX, destination : YYZ, date : 2025-04-16 }) than an LLM? You achieve this by supplying additional instructions to the LLM.\nFor example, the loop at the upper right would include instructions that might say something like once you have gathered all the inputs needed for the current tool, structure it as JSON, using the parameter names you find in the tool description. Remember the breadcrumb I left earlier that suggested the LLM would take in context beyond the goal and tool descriptions? This is a perfect example. As an agent developer, it behooves you to get LLMs to do a lot of work for you, and the more instruction and context you provide, the better.\nAnd speaking of supplying data to the LLM, lets now turn our attention to the lower part of the event loop where we will take stock of where things sit after the tool execution, and craft the input to the next turn with the LLM.\nUpdating the LLM Input\nYou might have noticed that the further we got into this post, the more I spoke about prompts. And indeed, prompt engineering is one of the main jobs of the AI agent developer. I have found it helpful to think about the LLM input as containing the following chunks of data:\n\n  The goal  this provides an overall description of the function of the agent; this should be quite detailed and expressed in such a way that the LLM can make decisions in the context of the available tools.\n  The tools  the APIs that will be executed in achieving a goal, along with natural language descriptions of the function, inputs, and outputs.\n  Example conversation  which demonstrates what an ideal interaction looks like.\n  Context instructions  additional instructions that guide the LLMs output, for example providing output formats, or input validation instructions.\n  Conversation history  which records the dialog between the user and the agent; it is up to the agent to keep track of the conversation as LLMs do not preserve any state over multiple invocations.\n\nI already talked about bootstrapping the event loop with the goal and tools, and while Ive called it out in this list separately, the example conversation can be thought of as a detailed part of the goal; these pieces should be included during bootstrapping and remains throughout all the iterations of the event loop.\nWhen you are updating the input to the LLM on subsequent turns, you will primarily be working with the context instructions and the conversation history. The latter is quite straightforward  you will append both the question asked of the user (which was, of course, generated by the LLM), and the users response to the conversation history.\n\n  The context instructions will be updated with the results of the tool execution and perhaps some additional instructions, allowing the LLM to assess the progress against the goal and choose the next step. One of my favorite examples here is that when coding agents have made some changes to source code, the context instructions must be updated to reflect the new state of those source files. Pretty cool to think about it that way, huh?\n  \n  \n  Okay, weve covered all of the pieces and parts, lets now put it all together.\n\nPutting It All Together\nAs a reminder, here are those pieces and parts:\n\n  Goals and tools, expressed using language that allows the LLM to leverage the right tool at the right time.\n  Mechanisms for preparing for tool invocation, following direction from the LLM.\n  Mechanisms for updating the LLM input with the new state of the world following tool invocation.\n\nOf course, we also need the agent to invoke the LLM and the tools.\n\n  This sounds like an orchestration problem to me, captured in the following diagram:\n  \n  \n\nIts just an app that you can write in whatever programming language you fancy. Python? TypeScript? Java? Golang? .NET? Ruby? Even PHP? Take your pick!\nI will draw your attention to two things that need special attention.\nFirst, notice that the invocation of the LLM and the tools are external calls, and of course you know that all sorts of things can go wrong. Rate limiting on the LLM might cause that call to fail, even if only intermittently. Networks can be flakey. Even tool APIs could fail. But in the cloud-native era we are all living in, your application is expected to be resilient to these types of failures. You need to ensure you have durability for these external calls.\nAnd second, the AI agent app  that which is depicted in the above flowchart  could itself go down, yet you will want your application to pick up where it left off after something like Kubernetes resurrects it. In other words, you need to ensure durability for the AI agent itself. This means we must preserve the agent state as well as an understanding of where, exactly, the agent was when the crash occurred.\nAnd there you have it, the details of my mental model for AI agents.\nTakeaways\nAs I hinted, Im building some agents, both to explore a variety of ideas and to demo some Temporal capabilities in an AI context. This work not only led to the formation of the mental model Ive just presented, but also a deeper appreciation for three elements of AI agent development.\nFirst, is prompt engineering. Prompt engineering was one of the first AI programming techniques that emerged after the release of ChatGPT. Remember all of the talk about one-shot and few-shot? (And can you believe that was only 45 years ago?!) While this area of development has continued to evolve to include concepts like chain-of-thought, and tree-of-thoughts, now that robots are doing the prompting, not just humans, the science of prompt engineering has become even more important. Prompts are at the heart of how agents work, and we are seeing standards like MCP emerge around them.\nSecond, I know where I stand on the question of what the best language for agent construction is. Answer: whatever programming language you like! Even while a significant portion of the agent implementation is contained within the prompts (goals, tools, context instructions, etc.), you still need an engine that drives things. While I am suggesting that the mental model I present here is a good framing to use when designing your agents, the details of what happens in the various parts of the event loop will vary. For example, you may need to include security and compliance checks before you invoke a tool. You need to have complete control over that logic and there is no better way to do this than with a general-purpose programming language. Simply put, you need flexibility.\nAnd finally, ensuring durability for these agentic systems is absolutely critical. The distributed, cloud-native applications that have come to dominate the landscape over the last 1015 years have already proven that a host of patterns (like retries and externalized state) were needed to deliver reliable applications over an inherently unreliable infrastructure. Agentic AI applications take that challenge to the next level, easily increasing the number of downstream calls to LLMs and tools by an order of magnitude. Check out this short video for more details.\nWith that I invite you to have a look at the sample AI agent that I mentioned at the start. And here is a short video of Steve demoing it.\nId also love to hear from you. One of the best ways you can do this is by finding me on the Temporal Community Slack  Im the only Cornelia Davis there! ",featureImage:{title:"social-card-image",description:"social-card-image",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1NfzbiO64uLGYOtl5hBwnw/8e88e819b8ef01edc766b2fb0f0b35fe/social-card-image.jpg"},publishDate:"2025-06-04",metaDescription:"Demystify agentic AI: Cornelia Davis offers a clear mental model for developers on how AI agents work, integrating LLMs, tools, prompts, and durable loops.",metaTitle:"Making friends with agents: A mental model for Agentic AI applications",socialCard:{title:"Blog (24)",description:"Blog (24)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1w6aQREJbAXgFx0ueHtpcW/2ffcb41d266ef6919da5afdc6ad81955/Blog__25_.png"},tags:"AI/ML,Code Samples",slug:"a-mental-model-for-agentic-ai-applications",contentType:"blogPost",entityId:"38dqO8G3H61O91ofv3crDb",authors:[{id:"5UNwygCxwqYCdaa27gAYNS",name:"Cornelia Davis",slug:"cornelia-davis",jobTitle:"Senior Staff Developer Advocate",photograph:{title:"Cornelia Davis Headshot",description:"Cornelia Davis Headshot",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6TDAN3Pi1qvx8m6HBdC4Kk/24be44497f96b4236b4e61b054e8568f/image.png"},company:"Temporal",contentType:"person"}],authorsString:"Cornelia Davis",category:"Temporal Voices",relatedPosts:[{title:"Build resilient Agentic AI with Temporal",content:"The current generation of Agentic AI frameworks was designed for short-lived chains of tools. While effective for simple tasks, they fall short when used for more complex, long-running workflows. Developers trying to push these frameworks beyond their limits run into fundamental problems: lack of durability, limited scalability, and rigid integration options.\n\nTemporal provides a more robust approach. It was built for reliability and scale, making it an ideal foundation for Agentic AI workflows that need to persist, interact with humans, and evolve with the fast-changing AI landscape.\n\nHeres how Temporal differentiates itself:\n## Developer Velocity\nTemporal is designed to feel natural and idiomatic for developers. With the [Python SDK](https://docs.temporal.io/develop/python) and other language support, you dont have to think about state machines or complex orchestration  it just works, letting you focus on building rather than managing infrastructure.\n## Insights and Observability\nStep-debugging workflows, tracking execution with detailed UI metrics, and leveraging Temporals visibility features make it easy to troubleshoot and optimize. Developers can quickly identify bottlenecks and ensure their agents run efficiently.\n## Scheduled Execution\nTemporal supports [running workflows on a schedule](https://docs.temporal.io/evaluate/development-production-features/schedules), enabling AI agents to periodically poll for new data and act accordingly. This makes it an ideal choice for use cases requiring continuous updates and real-time responsiveness.\n## Durable and Resilient\nLLMs are probabilistic by nature and can sometimes return incorrect or inconsistent responses. Temporals retry capability helps mitigate these issues, ensuring that workflows can recover from bad outputs and continue progressing reliably.\n\nIn addition, Temporal ensures workflows can survive real-world failures: process crashes, bad data, and network timeouts. Unlike single-process frameworks, Temporal retains state and automatically retries failed steps, ensuring that agents recover and continue without losing progress.\n\nIn many other frameworks, a crash means the whole process stops, forcing developers to rebuild context from scratch. With Temporal, thats never a concern.\n![agentic-AI-workflow-temporal](//images.ctfassets.net/0uuz8ydxyd9p/6jyQ1T1q4xue44shH38D5E/9de368d4bacd7d5c7a85f7c675d13d48/agentorchestrator-b.png)\nHeres how a typical [Temporal agent orchestrator workflow](https://www.youtube.com/watch?v=GEXllEH2XiQ) operates:\n1. The user initiates a request (signal).\n2. The agents (activities) determine the next step.\n   - If needed, the workflow queries an LLM with workflow text as context.\n4. Possible agent responses:\n   - Ask the user for more information.\n   - Request permission to run a tool.\n7. The user confirms the tool run (signal).\n8. The tool runs (API call), and the response is parsed by an LLM and sent back to the user.\n9. Steps repeat until the agent reaches its goal.\n## Long-Running and Stateful\nMost frameworks handle short-lived sequences. Temporal is built for workflows that last hours, days, or even months. It maintains state across the entire lifecycle, so your agent never loses track of its goal or context  no matter how complex or prolonged the interaction.\n## Human-in-the-Loop Support\nSome decisions require human oversight. Temporal makes it easy to involve people at critical moments:\n- Pause workflows for approval or input.\n- Provide updates and notifications for human intervention when necessary.\nThis makes Temporal well-suited for enterprise applications where accountability and control matter.\n## Flexible and Extensible\nIn a constantly evolving AI ecosystem, flexibility is key. Many existing frameworks are tied to specific LLMs or databases, limiting adaptability. Temporal offers:\n- Support for multiple languages (Go, Python, Java, TypeScript, .NET, Ruby).\n- Easy integration with any LLM, vector database, or external service.\nYoure not locked into a single vendor or toolchain  new AI models and services can be added as they emerge.\n## Centralized Orchestration\nTemporal functions as a brain for coordinating API calls, services, and data sources. It is architected to be fault-tolerant and horizontally scalable, ensuring high availability and resilience even in large, distributed environments. It scales far beyond the single-process limitations of other frameworks, allowing developers to create distributed workflows without worrying about state management or fault tolerance.\n## The Future of Agentic AI\nAgentic AI is evolving quickly. Building agents that can persist, collaborate with humans, and adapt requires a solid foundation. Temporal offers the durability, flexibility, and scale needed to meet these demands without being boxed in by the constraints of traditional frameworks. Learn more about using Temporal for Agentic AI [here](https://temporal.io/ai/agentic-ai).\n\nReady to build resilient, scalable AI agents? New Temporal Cloud users get $1,000 in free credits to get started. [Sign up now](https://temporal.io/get-cloud) and start building today.",featureImage:{title:"social card - green waves",description:"social card - green waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4GBHZR0vUnoRSbPtSTCH4s/daf7308a10e469059827e2169065d7ea/social_card_-_green_waves.jpg"},publishDate:"2025-02-25",metaDescription:"Learn how Temporal powers durable, scalable Agentic AI workflows with reliable state management, human-in-the-loop, and seamless orchestration.",metaTitle:"What are Agentic AI Workflows? Scalable & Durable Workflows",socialCard:{title:"agentic-ai-social-card",description:"agentic-ai-social-card",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3pmVeP1SxxfU9GSZYP1bej/df3de388b5865b5b00e768d05950bd40/Blog__11_.png"},tags:"AI/ML",slug:"build-resilient-agentic-ai-with-temporal",contentType:"blogPost",entityId:"1koM9i3HL18LEeOMAFrJI9",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"Temporal Concepts",readingTime:4},{title:"How Dust is building the future of work with agentic AI and why it runs on Temporal",content:"In the early days of AI agents, the pitch was slick: tools that would take work off your plate, understand what you need, and magically get it done.\n\nWhat we actually got? [Clippy](https://www.seattlemet.com/news-and-city-life/2022/08/origin-story-of-clippy-the-microsoft-office-assistant) with a language model.\n\nBots that couldnt remember what you just said. Smart agents that needed you to paste the entire project brief into a text box just to get started. Like asking for help moving a couch and being told to list all the furniture in the house first. Helpful but only if your definition of helpful was vague summaries and a shrug.\n\nDust is flipping the script.\n\nTheyre building teammates  AI agents that live in your stack, follow your processes, and actually ship work. These agents dont just live in a sidebar. They integrate directly into your tools, your workflows, and your teams habits.\n\nMaking that magic happen takes more than a good prompt. It requires a product-driven engineering team, a serious perspective on scale, and an orchestration backbone to keep it all running. Thats where Temporal comes in.\n\n## Building a Platform Around Context\nDusts AI understands. Their agents arent sitting outside your workflows waiting for input. Theyre embedded in the systems you already use: Slack, Notion, GitHub, Confluence, Salesforce, and more.\n\nThis gives Dust agents a superpower: context.\n\nWhen a pull request opens, an agent can comment based on the design doc that led to it. If a bug comes up in Slack, the agent can create a ticket: assigned, categorized, and formatted to match internal standards.\n\nThese arent stateless bots. Theyre live, real-time Workflows built with company data and triggered by actual events.\n\n> We aim to be both horizontal and flexible by design, Stan Polu, co-founder and CTO, notes. We understand that the one-size-fits-all approach will never work for enterprise.\n\nThats why Dusts platform spreads organically across organizations. Anyone can build their own agent but this kind of adoption happens bottom-up, driven by real use cases, not forced rollouts.\n\nHowever, to support that kind of speed and autonomy, you need orchestration that doesnt fall over. Dust needed to keep everything in sync, without sacrificing reliability or scale.\n\n## How Engineering Culture Shapes Product\nDusts product reflects how the team works internally. The engineering culture is fast-moving, product-led, and deeply focused on ownership. Engineers drive initiatives end to end  discovery, user feedback, scoping, building, shipping, and even external communication.\n\nTheres no separate track for just building features. Every engineer operates like a full-stack product team. This model isnt just efficient, it shapes the kinds of systems Dust needs to build.\n\nEngineers are the Directly Responsible Individuals (DRIs) for product initiatives, says Stan. They dont do everything alone, but they are responsible for it moving forward. That creates a sense of momentum and clarity that top-down prioritization cant match.\n\nBecause of this structure, Dusts platform must be both powerful and adaptable. New ideas come from within, and the tooling has to support fast iteration, safe changes, and the ability to move quickly without compromising core infrastructure.\n\nThe team moves fast, but never recklessly. Security is non-negotiable. With a strong foundation, they focus on maintaining momentum by shipping quickly and cleaning things up as they go. Temporal gives them the confidence to build at this pace without sacrificing stability. \n\nTemporal fits into a broader pattern in how Dust builds: autonomous teams using reliable systems to deliver real results, quickly.\n\n## How Dust Uses Temporal to Keep Everything in Sync\nFrom the beginning, Dust has relied on Temporal as the orchestration engine powering its agent platform.\n\nWhenever a Slack message is posted, a Notion doc is updated, or a pull request is created, a Temporal Workflow is triggered. That Workflow might pull data, transform it, run AI processing, and update internal indexes. It might respond back to the platform or kick off a follow-up action. Some Workflows last seconds; others span hours.\n\nTemporal also powers Dusts Tracker product, which monitors for stale documents based on internal activity and triggers agent-led updates to things like coding guidelines or internal processes. These are complex Workflows. They may involve polling APIs, running AI tasks, and proposing structured changes; all of which require persistence, retry logic, and state.\n\nTracker does so much more than keeping documentation fresh. It also acts as a kind of agent-for-agents. It monitors conversations, code, and processes to suggest updates to AI agents prompts, coding rules, and internal guidance. In doing so, Dust closes the loop between learning and doing.\n\n> Ingesting company data requires complex orchestration with Actions that can be retried that depend on each other in complex ways, Stan explains. Temporal felt like a perfect fit.\n\nTrying to build this orchestration layer on top of a traditional queue system would have meant custom logic for retries, timeout handling, state recovery, and failure coordination across dozens of async steps. Temporal replaces all of that with a built-in, durable Workflow model.\n\nAnd if youre thinking, Okay, but what about observability? its not an afterthought. Temporal gives you a real-time view into every Workflow, so when something does go wrong, you dont dig through scattered logs. You just look it up.\n\nDust runs over 10 million Temporal Activities per day on [Temporal Cloud](https://temporal.io/cloud). Theres no custom infrastructure for scale. When the load increases, they just run more workers. The rest of the system is built on PostgreSQL, GCS, and Kubernetes.\n\nWorkflows are deeply instrumented with Datadog, giving engineers real-time visibility into every retry, error, and completion event without log-diving.\n\n> Its Temporal all the way down for orchestration, Stan expounds. Scaling just means running more Workers.\n\nTemporals native support for long-running Workflows via [continueAsNew] and built-in visibility features allow Dust to focus on product-building rather than writing glue code for orchestration and recovery. Beyond a framework choice, its part of Dusts design philosophy.\n\nTemporal has changed how the team thinks about building reliable systems. Instead of stitching together ad hoc retries and error handling, Dust treats Workflows as durable, inspectable units of business logic.\n\n## The Architecture Behind Workflows\nThe diagram below shows how Dust uses Temporal as the backbone of its orchestration system.\n\n![dust-architecture-diagram-stylized-dust-branding](//images.ctfassets.net/0uuz8ydxyd9p/7fp9cGUhKLWGc03CoCkJfs/069a16ee20945ee640240d5ea31f0316/dust-architecture-diagram-stylized-dust-branding.png)\n\nAt the center is the connectors service, which manages real-time data ingestion from tools like Slack, Notion, Confluence, and GitHub. Each incoming event (new message, document edit, or pull request) triggers a Temporal Workflow that handles ingestion, enrichment, and indexing.\n\nLong-running or resource-intensive tasks, like document chunking and embedding, are managed asynchronously as Temporal Activities, ensuring responsiveness without blocking other parts of the system.\n\nThe architecture is designed to scale horizontally. Workers can be added dynamically to meet demand, and Temporal Cloud handles the state, retries, and execution flow. Observability is instrumented in the Temporal stack with Datadog, providing deep visibility into Workflows across the entire system.\n\nThis approach lets Dust maintain near real-time data synchronization with minimal operational overhead.\n\n## A Look Inside: Real-Time Ingestion with Temporal\nOne example of this architecture in action is Dusts GitHub connector. When a repository is connected, a Temporal Workflow is triggered to ingest, filter, and index its contents. The following code snippet, adapted from Dusts open-source repo, illustrates how they filter files during repository extraction before sending them downstream for indexing:\n\n    const EXTENSION_WHITELIST = [\".ts\", \".js\", \".py\", \".md\", \".yaml\"];\n\n    await extract({\n      file: tarPath,\n      cwd: tempDir,\n      filter: (path, stat) => {\n        if (path.endsWith(\"/\")) return true;\n        const ext = extname(path).toLowerCase();\n        const isUnderLimit = stat.size \u003C 1024 * 1024;\n        const isWhitelisted = EXTENSION_WHITELIST.includes(ext);\n        return isUnderLimit && isWhitelisted;\n      },\n      onentry: onEntry,\n    });\n\nThis logic runs inside a Temporal Activity, managed as part of a broader Workflow that handles repo syncing across the platform. If a failure occurs, say, during a download or parsing step, Temporal automatically retries the Activity and resumes execution precisely from the point of failure. No lost work, no dangling jobs.\n\nIts a clean example of the kind of stateful, retry enabled, and observable orchestration that underpins Dusts platform  and showcases exactly why Temporal is such an essential component of that foundation.\n\n## Whats Next?\nDust is focused on deepening agent capabilities and expanding integrations with more enterprise platforms. As new products like Doc Tracker mature, orchestration demands will only grow, but with Temporal at the foundation, the team wont have to worry about reliability or retry logic. Theyre free to move swiftly and build confidently.\n\nThe long-term goal is to make AI agents not just useful, but foundational to how teams operate: handling real Workflows, surfacing genuine insights, and evolving alongside the business. Temporal makes that possible, serving as the reliable execution engine behind every interaction.\n\nWant to see how Dust builds AI infrastructure in the open? Check out their [GitHub](https://github.com/dust-tt/dust), follow them on [Twitter/X](https://x.com/DustHQ) or [LinkedIn](https://www.linkedin.com/company/dust-tt/), and explore more at [dust.tt](https://dust.tt). \n\nGet started today building something great, just like Dust, with a free trial and $1,000 in credits with [Temporal Cloud](https://temporal.io/cloud).\n",featureImage:{title:"hazel-z-45AHiklPJH4-unsplash",description:"hazel-z-45AHiklPJH4-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Potp6G9LHoZ780AhLw3vs/861da43ba6e469417a7a9084b708e71f/hazel-z-45AHiklPJH4-unsplash.jpg"},publishDate:"2025-05-29",metaDescription:"Dust uses Temporal to power real-time AI agents that work inside Slack, GitHub, Notion, and more; scaling to 10M+ Activities/day with ease.",metaTitle:"How Dust Builds Agentic AI with Temporal Workflows",socialCard:{title:"How Dust Is Building the Future of Work With Agentic AI and Why it Runs on Temporal",description:"How Dust Is Building the Future of Work With Agentic AI and Why it Runs on Temporal",url:"https://images.ctfassets.net/0uuz8ydxyd9p/77iESpruExpDgWjTpBxwAV/aa89c3d94c3ab7eeb70bd242bc99681e/How_Dust_Is_Building_the_Future_of_Work_With_Agentic_AI_and_Why_it_Runs_on_Temporal.png"},tags:"AI/ML,Cloud",slug:"how-dust-builds-agentic-ai-temporal",contentType:"blogPost",entityId:"3KUig71A2DBSU0qzAujFUB",authors:[{id:"780p8MZSlKh9AuMzW5FrA0",name:"Clair Byrd",slug:"clair-byrd",jobTitle:"CMO",photograph:{title:"Clair Byrd",description:"Clair Byrd",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2ENA9j4df6EfXCLgoWmt46/bb029b33e3f92fb2a7973348c8ccce88/861A2507.jpg"},biography:"Clair Byrd is the Chief Marketing Officer at Temporal, the company defining durable execution in software engineering. Before joining Temporal, Clair held senior marketing and leadership roles at Twilio, InVision, and Sauce Labs, and co-founded the front end builder platform Mason. Her work centers on elevating developer experience, connecting open-source ecosystems, and building brands that inspire technical creativity and trust. Clair is passionate about storytelling that helps engineers build faster, smarter, and with lasting impact.",company:"Temporal",contentType:"person"}],authorsString:"Clair Byrd",category:"Community",readingTime:8}],readingTime:15},{title:"How Dust is building the future of work with agentic AI and why it runs on Temporal",content:"In the early days of AI agents, the pitch was slick: tools that would take work off your plate, understand what you need, and magically get it done.\nWhat we actually got? Clippy with a language model.\nBots that couldnt remember what you just said. Smart agents that needed you to paste the entire project brief into a text box just to get started. Like asking for help moving a couch and being told to list all the furniture in the house first. Helpful but only if your definition of helpful was vague summaries and a shrug.\nDust is flipping the script.\nTheyre building teammates  AI agents that live in your stack, follow your processes, and actually ship work. These agents dont just live in a sidebar. They integrate directly into your tools, your workflows, and your teams habits.\nMaking that magic happen takes more than a good prompt. It requires a product-driven engineering team, a serious perspective on scale, and an orchestration backbone to keep it all running. Thats where Temporal comes in.\nBuilding a Platform Around Context\nDusts AI understands. Their agents arent sitting outside your workflows waiting for input. Theyre embedded in the systems you already use: Slack, Notion, GitHub, Confluence, Salesforce, and more.\nThis gives Dust agents a superpower: context.\nWhen a pull request opens, an agent can comment based on the design doc that led to it. If a bug comes up in Slack, the agent can create a ticket: assigned, categorized, and formatted to match internal standards.\nThese arent stateless bots. Theyre live, real-time Workflows built with company data and triggered by actual events.\n\n  We aim to be both horizontal and flexible by design, Stan Polu, co-founder and CTO, notes. We understand that the one-size-fits-all approach will never work for enterprise.\n\nThats why Dusts platform spreads organically across organizations. Anyone can build their own agent but this kind of adoption happens bottom-up, driven by real use cases, not forced rollouts.\nHowever, to support that kind of speed and autonomy, you need orchestration that doesnt fall over. Dust needed to keep everything in sync, without sacrificing reliability or scale.\nHow Engineering Culture Shapes Product\nDusts product reflects how the team works internally. The engineering culture is fast-moving, product-led, and deeply focused on ownership. Engineers drive initiatives end to end  discovery, user feedback, scoping, building, shipping, and even external communication.\nTheres no separate track for just building features. Every engineer operates like a full-stack product team. This model isnt just efficient, it shapes the kinds of systems Dust needs to build.\nEngineers are the Directly Responsible Individuals (DRIs) for product initiatives, says Stan. They dont do everything alone, but they are responsible for it moving forward. That creates a sense of momentum and clarity that top-down prioritization cant match.\nBecause of this structure, Dusts platform must be both powerful and adaptable. New ideas come from within, and the tooling has to support fast iteration, safe changes, and the ability to move quickly without compromising core infrastructure.\nThe team moves fast, but never recklessly. Security is non-negotiable. With a strong foundation, they focus on maintaining momentum by shipping quickly and cleaning things up as they go. Temporal gives them the confidence to build at this pace without sacrificing stability.\nTemporal fits into a broader pattern in how Dust builds: autonomous teams using reliable systems to deliver real results, quickly.\nHow Dust Uses Temporal to Keep Everything in Sync\nFrom the beginning, Dust has relied on Temporal as the orchestration engine powering its agent platform.\nWhenever a Slack message is posted, a Notion doc is updated, or a pull request is created, a Temporal Workflow is triggered. That Workflow might pull data, transform it, run AI processing, and update internal indexes. It might respond back to the platform or kick off a follow-up action. Some Workflows last seconds; others span hours.\nTemporal also powers Dusts Tracker product, which monitors for stale documents based on internal activity and triggers agent-led updates to things like coding guidelines or internal processes. These are complex Workflows. They may involve polling APIs, running AI tasks, and proposing structured changes; all of which require persistence, retry logic, and state.\nTracker does so much more than keeping documentation fresh. It also acts as a kind of agent-for-agents. It monitors conversations, code, and processes to suggest updates to AI agents prompts, coding rules, and internal guidance. In doing so, Dust closes the loop between learning and doing.\n\n  Ingesting company data requires complex orchestration with Actions that can be retried that depend on each other in complex ways, Stan explains. Temporal felt like a perfect fit.\n\nTrying to build this orchestration layer on top of a traditional queue system would have meant custom logic for retries, timeout handling, state recovery, and failure coordination across dozens of async steps. Temporal replaces all of that with a built-in, durable Workflow model.\nAnd if youre thinking, Okay, but what about observability? its not an afterthought. Temporal gives you a real-time view into every Workflow, so when something does go wrong, you dont dig through scattered logs. You just look it up.\nDust runs over 10 million Temporal Activities per day on Temporal Cloud. Theres no custom infrastructure for scale. When the load increases, they just run more workers. The rest of the system is built on PostgreSQL, GCS, and Kubernetes.\nWorkflows are deeply instrumented with Datadog, giving engineers real-time visibility into every retry, error, and completion event without log-diving.\n\n  Its Temporal all the way down for orchestration, Stan expounds. Scaling just means running more Workers.\n\nTemporals native support for long-running Workflows via [continueAsNew] and built-in visibility features allow Dust to focus on product-building rather than writing glue code for orchestration and recovery. Beyond a framework choice, its part of Dusts design philosophy.\nTemporal has changed how the team thinks about building reliable systems. Instead of stitching together ad hoc retries and error handling, Dust treats Workflows as durable, inspectable units of business logic.\nThe Architecture Behind Workflows\nThe diagram below shows how Dust uses Temporal as the backbone of its orchestration system.\n\n  \n\nAt the center is the connectors service, which manages real-time data ingestion from tools like Slack, Notion, Confluence, and GitHub. Each incoming event (new message, document edit, or pull request) triggers a Temporal Workflow that handles ingestion, enrichment, and indexing.\nLong-running or resource-intensive tasks, like document chunking and embedding, are managed asynchronously as Temporal Activities, ensuring responsiveness without blocking other parts of the system.\nThe architecture is designed to scale horizontally. Workers can be added dynamically to meet demand, and Temporal Cloud handles the state, retries, and execution flow. Observability is instrumented in the Temporal stack with Datadog, providing deep visibility into Workflows across the entire system.\nThis approach lets Dust maintain near real-time data synchronization with minimal operational overhead.\nA Look Inside: Real-Time Ingestion with Temporal\nOne example of this architecture in action is Dusts GitHub connector. When a repository is connected, a Temporal Workflow is triggered to ingest, filter, and index its contents. The following code snippet, adapted from Dusts open-source repo, illustrates how they filter files during repository extraction before sending them downstream for indexing:\nconst EXTENSION_WHITELIST = [\".ts\", \".js\", \".py\", \".md\", \".yaml\"];\n\nawait extract({\n  file: tarPath,\n  cwd: tempDir,\n  filter: (path, stat) => {\n    if (path.endsWith(\"/\")) return true;\n    const ext = extname(path).toLowerCase();\n    const isUnderLimit = stat.size \u003C 1024 * 1024;\n    const isWhitelisted = EXTENSION_WHITELIST.includes(ext);\n    return isUnderLimit && isWhitelisted;\n  },\n  onentry: onEntry,\n});\n\nThis logic runs inside a Temporal Activity, managed as part of a broader Workflow that handles repo syncing across the platform. If a failure occurs, say, during a download or parsing step, Temporal automatically retries the Activity and resumes execution precisely from the point of failure. No lost work, no dangling jobs.\nIts a clean example of the kind of stateful, retry enabled, and observable orchestration that underpins Dusts platform  and showcases exactly why Temporal is such an essential component of that foundation.\nWhats Next?\nDust is focused on deepening agent capabilities and expanding integrations with more enterprise platforms. As new products like Doc Tracker mature, orchestration demands will only grow, but with Temporal at the foundation, the team wont have to worry about reliability or retry logic. Theyre free to move swiftly and build confidently.\nThe long-term goal is to make AI agents not just useful, but foundational to how teams operate: handling real Workflows, surfacing genuine insights, and evolving alongside the business. Temporal makes that possible, serving as the reliable execution engine behind every interaction.\nWant to see how Dust builds AI infrastructure in the open? Check out their GitHub, follow them on Twitter/X or LinkedIn, and explore more at dust.tt.\nGet started today building something great, just like Dust, with a free trial and $1,000 in credits with Temporal Cloud.",featureImage:{title:"hazel-z-45AHiklPJH4-unsplash",description:"hazel-z-45AHiklPJH4-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Potp6G9LHoZ780AhLw3vs/861da43ba6e469417a7a9084b708e71f/hazel-z-45AHiklPJH4-unsplash.jpg"},publishDate:"2025-05-29",metaDescription:"Dust uses Temporal to power real-time AI agents that work inside Slack, GitHub, Notion, and more; scaling to 10M+ Activities/day with ease.",metaTitle:"How Dust Builds Agentic AI with Temporal Workflows",socialCard:{title:"How Dust Is Building the Future of Work With Agentic AI and Why it Runs on Temporal",description:"How Dust Is Building the Future of Work With Agentic AI and Why it Runs on Temporal",url:"https://images.ctfassets.net/0uuz8ydxyd9p/77iESpruExpDgWjTpBxwAV/aa89c3d94c3ab7eeb70bd242bc99681e/How_Dust_Is_Building_the_Future_of_Work_With_Agentic_AI_and_Why_it_Runs_on_Temporal.png"},tags:"AI/ML,Cloud",slug:"how-dust-builds-agentic-ai-temporal",contentType:"blogPost",entityId:"3KUig71A2DBSU0qzAujFUB",authors:[{id:"780p8MZSlKh9AuMzW5FrA0",name:"Clair Byrd",slug:"clair-byrd",jobTitle:"CMO",photograph:{title:"Clair Byrd",description:"Clair Byrd",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2ENA9j4df6EfXCLgoWmt46/bb029b33e3f92fb2a7973348c8ccce88/861A2507.jpg"},biography:"Clair Byrd is the Chief Marketing Officer at Temporal, the company defining durable execution in software engineering. Before joining Temporal, Clair held senior marketing and leadership roles at Twilio, InVision, and Sauce Labs, and co-founded the front end builder platform Mason. Her work centers on elevating developer experience, connecting open-source ecosystems, and building brands that inspire technical creativity and trust. Clair is passionate about storytelling that helps engineers build faster, smarter, and with lasting impact.",company:"Temporal",contentType:"person"}],authorsString:"Clair Byrd",category:"Community",readingTime:8},{title:"Forrester study confirms: Temporal Cloud delivers 201% ROI and transforms developer productivity",content:"Weve always believed in the power of Temporal to help developers build and operate resilient applications with greater ease and efficiency. Today, were excited to share compelling, independent validation of Temporal Clouds significant business impact.\nTemporal commissioned Forrester Consulting to conduct a Total Economic Impact (TEI) study on Temporal Cloud. The results are in, and they are impressive: the study found that Temporal Cloud can deliver a 201% return on investment (ROI) over three years for a composite organization.\nThis comprehensive study, based on interviews with four Temporal Cloud customers, quantifies how organizations can achieve substantial benefits and cost savings.\nKey Findings from the Forrester TEI Report\nThe numbers speak for themselves. Heres a snapshot of the value Temporal Cloud can bring:\n\n  201% Return on Investment: A clear indicator of the strong financial benefits.\n  $2.8 Million Net Present Value (NPV): Demonstrating significant value creation over three years.\n  Enhanced Developer Productivity by 15%: Freeing up developers to focus on innovation rather than managing complex infrastructure.\n  50% Faster Time-to-Market for Features: Accelerating innovation and enabling businesses to respond more quickly to market needs.\n  Up to Two Avoided Outages Per Year: Improving system reliability, leading to better customer experiences and avoided revenue loss.\n  14-Month Payback Period: Organizations can realize the value of their investment quickly.\n\nHelping Developers and Businesses Succeed\nUltimately, the Forrester study delves into how Temporal Cloud empowers development teams and contributes to broader business objectives. By simplifying the complexities of Durable Execution, Temporal lets developers build reliable, scalable systems more efficiently.\nOne senior engineering manager in the transportation sector shared, [Temporal] gives us scalability, reliability, and dependability. It satisfies a peace-of-mind element for us, and it has improved the developer experience.\nThe study also highlights how Temporal Cloud enables teams to tackle challenging projects with more confidence. An engineering manager in financial services remarked, Temporal makes it easy to do hard things. It empowers engineers to write complex code without having to be an expert in distributed systems engineering.  It empowers engineers to do elegant solutions without getting scared of having to maintain it in perpetuity.\nFurthermore, the report notes the ability to accelerate feature delivery. A vice president of engineering in food services stated, Weve extended and built business capabilities very quickly with Temporal. [One feature] was going to be a several-month effort. When we built it into our existing Temporal Workflow, it was twelve lines of code, and we spent longer testing it than we did coding it. It took us literally a day to build and then a few weeks to test.\nDiscover the Full Value\nThese findings underscore Temporals commitment to providing a platform that not only solves complex technical challenges but also delivers tangible business results. We believe this study provides a valuable framework for organizations evaluating how to enhance their application reliability and development velocity.\nWe invite you to explore the complete Forrester TEI study to understand the full scope of benefits and how Temporal Cloud can drive efficiency and cost savings for your organization.\nRead the full Forrester Total Economic Impact of Temporal Cloud report here.\nThe results of this study reinforce our dedication to empowering developers and organizations to build the future, confidently.\nWant to discuss these findings, ask questions, or connect with other Temporal users and our team? Join our Slack community today!\nYou can see savings like this is your own stack. Start a trial of Temporal Cloud with $1,000 in credits.",featureImage:{title:"Forrest Total Economic Impact ",description:"Forrest Total Economic Impact ",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2SwNdLrEGquYCv8BjrVPjD/7a7f16f9d2ce44ad8e8849e9cceb5ba7/TEI_Forrester_Report.png"},publishDate:"2025-05-29",metaDescription:"A Forrester TEI study confirms Temporal Cloud delivers a 201% ROI, $2.8M NPV, and 15% enhanced developer productivity. Learn how to achieve faster time-to-market and fewer outages.",metaTitle:"Temporal Cloud ROI: 201% According to Forrester TEI Study",socialCard:{title:"Forrester TEI Social Card",description:"Forrester TEI Social Card",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5BasYLsAWSDhvsIWGL1MZ6/58456cdfbc7a59dfe77c65a98e269cc2/TEI_Forrester_Report.png"},tags:"Industry Events",slug:"forrester-study-confirms-temporal-cloud-delivers-201-percent-roi",contentType:"blogPost",entityId:"4y1PIBrsZ5vtWazWK0chO3",authors:[{id:"4VItFICZ65R9CRGZQLE9un",name:"Allanah Hughes",slug:"allanah-hughes",jobTitle:"Communications Manager",photograph:{title:"Allanah-photo",description:"Allanah-photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4fukLvMAknnWvSkX9j9s4C/16176d8f1f1ffaeeb578a68e19ff05e7/240206-Temporal-DTLA-017-Allanah-Hughes-50NS.jpg"},contentType:"person"}],authorsString:"Allanah Hughes",category:"Announcements",readingTime:3},{title:"Durable Digest: May 2025",content:"This blog post is a public copy of our monthly newsletter. If youd like to receive upcoming updates by email, you can subscribe to our newsletter here.\nWelcome to your May 2025 update! This month, were bringing you key enhancements across our TypeScript, Python, and PHP SDKs. Were also excited to officially open registration for Camp Temporal, our unique summer program for developers.\nDiscover the latest Forrester Total Economic Impact report on Temporal Cloud, find out where to connect with us at upcoming global events, and celebrate the fantastic contributions from our community.\nSDK Updates\n\n  TypeScript SDK v1.11.8: Includes updates for the Core SDK and multiple vulnerable dependencies.\n  Python SDK v1.11.0: Includes pre-release access to Priority and Worker Versioning, and introduces new Automatic Poller Scaling for Workers.\n  PHP v2.14.0: Provides dedicated Workflow loggers, new methods to define dynamic handlers, and adds support for user metadata in the Client API.\n\nSpace Camp\nAre you ready for Camp Temporal? Its the galaxys most curious summer program for developers who build, fix, tinker, retry, and repeat.\nSign up today to join a crew of cadets, creators, and cosmic troubleshooters from across the Temporalverse. From June 5 through August 31, meet up with fellow cadets virtually and in-person to share knowledge, forge connections, explore new tools, and build systems more reliable than a quantum space toaster. And if were lucky, we might even save the galaxy from a mysterious disturbance!\nYoull earn badges, unlock secrets, help fellow cadets, and maybejust mayberise through the ranks to become a Temporal Creator. We can neither confirm nor deny the rumors of stellar swag.\nWell be adding lots of activities, events, and meetups throughout the summer, but the best way to stay up-to-date on all that Camp Temporal has to offer is to register today.\nEvents\nThe Temporal team is going global in June!\nJoin us at the events listed below to see how Temporal is transforming the way modern applications are built. Stop by our booths for live, interactive demos that showcase advanced Workflow orchestration, fault-tolerant microservices, and stateful application development at scale.\nWant to go deeper? Request a meeting with our experts:\n\n  AI Engineers Worlds Fair | San Francisco, CA | June 35\n  AWS Summit | Sydney, Australia | June 45\n  DASH by Datadog | New York, NY | June 1011\n  LDX3 by LeadDev | London, UK | June 1617\n  Open Source in Finance Forum | London, UK | June 24\n  PlatformCon | London, UK | June 25\n  PlatformCon | New York, NY | June 26\n\nResources\nReport: New Forrester Total Economic Impact Study\nTired of duct-taping your Workflows together? Forrester found Temporal Cloud delivers 201% ROI by cutting downtime, boosting productivity, and skipping the headaches of DIY infrastructure. Read the report to see how much smoother life gets with managed durability.\nWebinar: Inside Dusts AI-Powered Vision for the Future of Work\nJoin us on June 5 at 10am ET/4pm CET for a behind-the-scenes look at how Dust is building the future of work with AI and why Temporal is at the heart of their platform. In this 45-minute session, well explore how Dust is transforming those everyday tasks with intelligent agents that are deeply contextual, resilient, and production-ready. Cant make the live session? No worries! Register now to get the recording sent to your inbox.\nCommunity Shout-Outs\n\n  In The Pragmatic Engineer Newsletter, Gergely Orosz interviewed two engineering leaders deeply involved in the release of ChatGPT ImagesSulman Choudhry (Head of Engineering, ChatGPT) and Srinivas Narayanan (VP of Engineering, OpenAI)about whats happening under the hood, including Temporal! \n  While at Stripe Sessions, Steve Androulakisand Tom Wheeler joined Cecil Phillip for a livestream on Integrating Temporal to manage your payment workflows.\n    \n      You can find their Stripe Ridesharing Demo in Code Exchange! It showcases Stripes usage-based billing with only the most cutting-edge 8-bit graphics. ;)\n    \n  \n  In a collaboration between Jason Lengstorf and Alex Garnett, the Build a web-based game in 4 hours Web Dev Challenge gave participants 30 minutes to plan and four hours to build a game thats played on at least two devices with Temporal.\n    \n      Catch their follow-up session on May 29! Build invincible apps with Durable Workflows\n    \n  \n  The recording from our Community Live session Event-driven Architectures for Full-Stack Devs with Temporal and React is now available. Big shout-out to J.D. Nicholls for leading this, his first time presenting in English! \n  In other event news, members of Temporals team including Brandon Moorer, Cornelia Davis, and Mason Egger presided over the MCP and A2A HackathonAWS Edition. Over 300 were in attendance, and the winning project by Anup Ghatage (Quantum Branches: Play a new game every time, generated by AI) used Temporal to orchestrate a dynamic Workflow which calls multiple agents in a sequential manner to generate all the elements of the game. I guess you could say winners choose Temporal. \n  Also AI-related, Alex Garnett gave a talk at the Write the Docs conference, about how Temporal is using AI to augment our documentation: Docs AI Tooling is Better (and Better for Us) than You Think\n  And hey, speaking of AI: it was a BIG month for AI in our Code Exchange, with tons of AI-oriented examples submitted:\n    \n      Temporal MCP Server (by Gonzalo (Glo) Maldonado)Temporal MCP Server is a bridge connecting AI assistants like Claude with the powerful Temporal Workflow engine. By implementing the Model Context Protocol (MCP), it allows AI assistants to discover, execute, and monitor complex Workflow orchestrationsall through natural language conversations.\n      Temporal Based Zendesk Add-on for Ticket and Organization Summary (by Tao Guo)An AI-powered support ticket analysis system that integrates with Zendesk to provide enhanced ticket management capabilities.\n      Temporal + Spring AI RAG Example(by Carson McDonald)This is a demo application showcasing the use of Spring AI with Temporal for Retrieval-Augmented Generation (RAG).\n      Temporal Trivia (by Keith Tenzer, Ci-Ci Thomson, and Anthony Wong)A multi-user trivia game built durably on Temporal. It uses GenAI and Workflows to maintain and control the state of the trivia game.\n      AI IDE Rules (by Mason Egger and Drew Gorton)Community collection of AI-powered IDE coding rules for generating Temporal applications. Contribute your rules today!\n      Using Temporal with Anthropics Message Batches API (by Steve Kinney)Leveraging Temporal to take advantage of Anthropics Message Batches API for bulk processing prompts. Comes with a great tutorial about it as well!\n    \n  \n  Other Code Exchange entries over the past month:\n    \n      Temporal Symfony Examples (by Thierry Feuzeu)Our very first PHP project, these examples leverage the Symfony framework features to automatically register the Temporal Workflow and Activity classes, together with their respective options.\n      Temporal Flow (by Itai Soudry)Temporal Flow is a lightweight UI overlay for Temporal that renders your Workflows and Activities as an interactive flow diagram, streamlines navigation between parent and child Workflows, and provides an easy search.\n    \n  \n",featureImage:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},publishDate:"2025-05-29",metaDescription:"Explore Temporals latest developer updates: questions from the field, new releases, builder spotlights, learning resources, and ways to connect with our team.",metaTitle:"Durable Digest: May 2025",socialCard:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},tags:"",slug:"durable-digest-may-2025",contentType:"blogPost",entityId:"74wnAdWJhblJZLBAZop40h",authors:[{id:"17hGmNrCwtXdBh7fhsLUnZ",name:"Temporal Technologies",slug:"temporal-technologies",photograph:{title:"temporal technologies logo",description:"temporal technologies logo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3g56zRXtFQYMeJxBBkVBIZ/7771670e5fc7da59f555837b086c35d6/temporal_technologies_logo.avif"},company:"Temporal Technologies",contentType:"person"}],authorsString:"Temporal Technologies",category:"Announcements",readingTime:6},{title:"Improving our Java SDK with Codex by OpenAI",content:"We were recently invited to test and provide feedback on Codex, a new cloud-based software engineering agent from OpenAI that can work on many tasks in parallel. Turns out, Codex gave us a surprisingly effective way to level up our Temporal SDKs.\nInitially, we started out with the goal of simply providing some usability feedback and moving on, but Codex had other plans. It quickly found its place in our toolchain, and folks across Temporal started getting value in meaningful ways.\nWhat Codex Helped Us Build\nCodex was able to find and fix bugs, implement features, and perform some surprising refactoring operations. Codex complemented existing tools by providing a new way of performing work in the background while local development continued in IDEs and editors.\nFor the Java SDK, Codex was able to help us tackle some longstanding issues that we hadnt been able to find time for yet. Tasks like improving code coverage, adding documentation, or implementing features that the Java SDK was missing that our other SDKs already had.\nFor example, our other SDKs already had an API to count workflow executions using search attributes (something the Java SDK was missing). After giving Codex the Github issue and a brief summary of the requirements, it was able to implement the API, including adding an end-to-end test. Codexs change still needed some minor work to rename some classes and clean up the test, but it was able to do a majority of the work unsupervised.\nA common pattern among engineers was to go through the backlog before lunch or at the end of the day and identify a few open issues, then kickoff multiple Codex tasks. Then after lunch or at the start of the next day come back and iterate from there.\nCheck out a sampling of PRs made with Codex in our open source repos:\n\n  https://github.com/temporalio/sdk-java/pull/2516\n  https://github.com/temporalio/sdk-java/pull/2517\n  https://github.com/temporalio/sdk-java/pull/2518\n  https://github.com/temporalio/sdk-java/pull/2519\n  https://github.com/temporalio/temporal/pull/7762\n  https://github.com/temporalio/temporal/pull/7766\n  https://github.com/temporalio/sdk-core/pull/913\n\nThis exploration also provided us an opportunity to ready our projects for agentic contributions. An AGENTS.md is a plain text markdown file that can be added to the top level of a repo or any subdirectory within it. The goal of the file is to provide guidance to Codex that will help it better comprehend the overall codebase and how to best interact with it.\nHere is a sample from our sdk-java repo:\n#Contributor Quickstart Guide\n\n##Repository Layout\n- `temporal-sdk`: core SDK implementation.\n- `temporal-testing`: utilities to help write workflow and activity tests.\n- `temporal-test-server`: in-memory Temporal server for fast tests.\n- `temporal-serviceclient`: gRPC client for communicating with the service.\n- `temporal-shaded`: prepackaged version of the SDK with shaded dependencies.\n- `temporal-spring-boot-autoconfigure`: Spring Boot auto configuration.\n- `temporal-kotlin`: Kotlin DSL for the SDK.\n- `temporal-opentracing`: OpenTracing interceptor integration.\n\n##General Guidance\n- Avoid changing public API signatures. Anything under an `internal` directory\n  is not part of the public API and may change freely.\n- The SDK code is written for Java 8.\n\n##Building and Testing\n1. Format the code before committing:\n   ```bash\n   ./gradlew --offline spotlessApply\n   ```\n2. Run the tests. A full build requires a local Temporal Server instance.\n   ```bash\n   ./gradlew test\n   ```\n   To run only the core SDK tests or a single test:\n   ```bash\n   ./gradlew :temporal-sdk:test --offline --tests \"io.temporal.workflow.*\"\n   ./gradlew :temporal-sdk:test --offline --tests \"\u003Cpackage.ClassName>\"\n   ```\n3. Build the project:\n   ```bash\n   ./gradlew clean build\n   ```\n##Tests\n- Tests use JUnit4 and are located under\n  `temporal-sdk/src/test/java/io/temporal`.\n- Workflow API tests should rely on `SDKTestWorkflowRule` to create a worker and\n  register workflows, activities, and nexus services.\n\n##Commit Messages and Pull Requests\n- Follow the [Chris Beams](http://chris.beams.io/posts/git-commit/) style for\n  commit messages.\n- Every pull request should answer:\n  - **What changed?**\n  - **Why?**\n  - **Breaking changes?**\n  - **Server PR** (if the change requires a coordinated server update)\n- Comments should be complete sentences and end with a period.\n\n##Review Checklist\n- `./gradlew spotlessCheck` must pass.\n- All tests from `./gradlew test` must succeed.\n- Add new tests for any new feature or bug fix.\n- Update documentation for user facing changes.\n\nFor more details see `CONTRIBUTING.md` in the repository root.\n\nAGENTS.md files can be written from scratch or Codex can help bootstrap the process by prompting it to create a draft based on other instructions in the repo. Since Codex can run multiple jobs in parallel, you could even ask it to generate a file multiple times and compare the results of multiple tasks.\nWe will continue to work across our open source projects in the coming months to make them better suited for agentic contributions.\nWere looking forward to seeings how Codex evolves in the future!\nPowered by Temporal\nThis new, awesome product just so happens to run on Temporal. While we were busy putting Codex to work on our SDKs, it was quietly relying on Temporal to power its own reliability and scalability.\nWe asked the OpenAI team what role Temporal played behind the scenes., heres what they had to say:\n\n  \n    Temporal is a critical part of the infrastructure powering Codex, responsible for executing our core control flows. It allows us to easily reason about concurrency, correctness, and fault tolerance, enabling us to move quickly to implement and scale a complicated distributed system required to build a product like Codex.\n     Will Wang, SWE, Codex by OpenAI.\n  \n\nAre you curious how Codex and other AI systems achieve reliable execution at scale? Temporal Cloud makes that kind of reliability easier to build than you might think.\nGive it a try with your first $1,000 in usage on us.",featureImage:{title:"li-zhang-ZvVydsVkyTI-unsplash",description:"li-zhang-ZvVydsVkyTI-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3WwtmBoVCX8MFqaV2ZTQUq/fc4fc75dd2e1d75a6a36d292827b8d80/li-zhang-ZvVydsVkyTI-unsplash.jpg"},publishDate:"2025-05-17",metaDescription:"Learn all about how the Temporal engineers used OpenAIs Codex to improve our Java SDK, automate bug fixes, and prepare for agentic contributions, plus, how part of Codex itself runs on Temporal.",metaTitle:"Improving our Java SDK with Codex by OpenAI",socialCard:{title:"Improving our Java SDK with Codex by OpenAI",description:"Improving our Java SDK with Codex by OpenAI",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4KQ3Erfo5PsPlHQMAwnxTo/93a43b7a1cf47df391a680abeee183d5/Improving-our-Java-SDK-with-Codex-by-OpenAI.png"},tags:"Java,Architecture",slug:"improving-java-sdk-codex-openai",contentType:"blogPost",entityId:"2zn13pL0XtIuDahLGEnuxi",authors:[{id:"ajQhbAcyfwZWX0QYds1wu",name:"Ryan Cox",slug:"ryan-cox",jobTitle:"Senior Director of Infrastructure and Security",photograph:{title:"Ryan-Cox-headshot",description:"Ryan-Cox-headshot",url:"https://images.ctfassets.net/0uuz8ydxyd9p/8pSb695JPTbxEZKrNCKib/834dc7b5ec09ac9288d4579e8ea18686/Ryan-Cox-headshot.jpeg"},company:"Temporal",contentType:"person"}],authorsString:"Ryan Cox",category:"Announcements",readingTime:5},{title:"The definitive guide to Durable Execution",content:"When I joined Temporal three years ago, hardly anyone I met at conferences had heard of us. Explaining what we did was challenging because there wasnt much they could compare it to. People often learn new things by connecting them to what they already know. Someone familiar with PostgreSQL, for example, will quickly understand the role of some other relational database, such as IBM DB2 or Microsoft SQL Server.\nIt felt a bit like trying to describe an iPhone to someone from 1975. You could say its both a phone and a camera, but that doesnt really capture how transformative it is. These days, everyone knows what a smartphone isno explanation needed.\nTemporal is typically categorized as a Durable Execution Platform, but this often raises the question, What is Durable Execution? Ive heard many definitions, both inside and outside the company, and given several myself. Most are either overly complex or blur the line between what Durable Execution is and how its implemented or supported by various platforms.\nAfter thinking about this for months, I delivered a talk at our Replay 25 conference in London. This blog post summarizes the key points from my talk, starting with a clear definition of Durable Execution and continuing with why it fundamentally changes how developers build reliable applications.\nWhat is Durable Execution?\nDurable Execution is crash-proof execution.\nIt enables developers to write reliable software with less effort. It lets them focus on what the application should achieve instead of anticipating and trying to handle everything that might go wrong along the way.\nWhy is Durable Execution important?\nDevelopers spend significant time writing code to detect and handle failures. In fact, computer science Professor Flaviu Cristian observed in Reliable Computer Systems that this type of code often accounts for more than two-thirds of all code in a production systemfar more than whats dedicated to the happy path where no failures occur.\nThe world has changed since that book was published. Cloud computing, microservices, and event-driven architectures have transformed software development. Modern applications are distributed systems, with many more potential points of failure, yet the expectations of reliability have never been higher.\n\n  \n    Failures are inevitable.\n    Durable Execution makes them inconsequential.\n  \n\nDurable Execution offers three key benefits:\n\n  It improves application reliability by providing fault tolerance.\n  It simplifies code by allowing it to focus on the goal instead of potential problems.\n  It accelerates development by eliminating the need to write complex error-handling logic.\n\nWhat is a Durable Execution platform?\nDurable Execution is made possible by an abstraction that insulates code from crashes and enables applications to continue running despite them. A Durable Execution platform is the system that provides this abstraction.\nMost Durable Execution platforms refer to the abstraction as a workflow, although this term is not universal. Adding to the confusion, relatively few of the systems typically referred to as workflow engines actually provide Durable Execution.\nAlthough the terminology may vary from one Durable Execution platform to the next, what they all have in common is the ability to deliver crash-proof execution.\nFour key characteristics of Durable Execution\nThere are important differences between Durable Execution platforms, including how they work and the additional capabilities they offer. However, the concept of Durable Execution and what it means for developers is universal. The four key characteristics that follow apply to all Durable Execution platforms.\n1. Durable Execution virtualizes execution\nTo describe Durable Execution as crash-proof does not suggest that a crash cannot happen. It means that a crash will have no consequence. To make an analogy, wearing a waterproof watch doesnt prevent you from falling into a swimming pool. Instead, it guarantees that the watch will continue running despite it.\nExecution normally takes place within a single process, running on a single machine, and will immediately end if that process crashes for any reason. Why might an application crash? There are countless reasons. It could result from a bug in the application code, a bug in a library used by that code, a bug in the operating system, a power outage, or a hardware failure. Regardless of the cause, the outcome is the same. The values of the variables updated while the application was running are lost, along with the notion of which statements already ran and which one should run next.\nDurable Execution is crash-proof because it virtualizes execution, enabling it to take place across a series of processes, each of which can potentially run on a different machine than the one before. If the current process happens to crash, Durable Execution ensures that work transparently resumes in a new process. The application state is recreated in that new process, after which execution will continue as if the failure never happened at all.\nAn example will help to illustrate this concept. Consider an application that requires five steps to achieve its goal. Lets say that it successfully completes steps A and B, but crashes before completing step C. Without Durable Execution, execution would come to an end, and there would be no further progress.\n\n  \n\nWith Durable Execution, however, the work resumes in a subsequent process. Since the state is fully reconstructed in this new process, all variables have the same values as they did at the time of the crash, including the results from the previously completed steps.\nLets say that step C now completes, but a hardware failure causes this second process to terminate during step D. Once again, the execution will resume in a subsequent processthis time on a new machineand will continue making progress until the application achieves its goal.\n\n  \n\nIn this case, execution happened to span three different processes across two different machines. Practically speaking, these details dont matter because this is how it looks from the developers perspective:\n\n  \n\n2. Durable Execution is not limited by time\nBecause Durable Execution enables applications to withstand crashes, it enables them to run for as long as needed to reach their goal. An execution that processes a payment may complete in a fraction of a second, but one that manages a loan may need to run for several years.\nSome applications naturally involve long periods of inactivity. For example, an application for customer onboarding might need to send emails at certain intervals during the first year. Without Durable Execution, you might implement this with a scheduler system and an application database, since you cant expect a program started today to still be running six months from now. That complexity isnt necessary with Durable Execution, since you can reliably achieve the same result with nothing more than a for-loop and a sleep statement. The example below illustrates this, using pseudocode to avoid the implementation details of a specific platform or programming language:\nfunction Notifier(String username) {\n    // notify customer at each defined interval\n    for interval in [1, 7, 30, 60, 90, 180] {\n        sleep(Time.days(interval))\n        sendNotification(username)\n    }\n}\n\nThe sleep call in the example above illustrates another important point. Durable Execution enables an individual API call to await a result for as long as necessary, regardless of whether that takes a few seconds or several months.\n3. Durable Execution automatically preserves application state\nWithout the benefit of Durable Execution, a crash causes the values of variables within the running application to suddenly disappear, resulting in the loss of its state.\nOne way to guard against this is to use an application database, since it provides a place for those values to live when the application that generated them stops running. Developers who employ this approach must write tedious code to copy values from the application and store them into the database, only to later load them from the database and update the variables within the application. In such cases, using a database isnt the actual goalit might not be mentioned in the requirements at allits just a defensive mechanism intended to protect the application from a crash.\nWith Durable Execution, you dont need an application database nor all the code necessary to interact with it to guard against a crash. Durable Execution is crash-proof execution, which means that all of the variables in your application, including local variables, are durable. They will have the same values after a crash as they did before it.\nThere are often good reasons to use an application database, even with Durable Execution. You might use one for reporting purposes, for example, but you wont need one to protect your application from a crash.\n4. Durable Execution is hardware agnostic\nFor many years, reliable systems emphasized fault tolerance through hardware, in some cases favoring very expensive machines with exotic features such as hot-swappable CPUs and memory. This makes sense for certain applications where the cost of downtime is exceptionally high. Fault-tolerant hardware may reduce the likelihood of failure, but it can never eliminate it. Consequently, these systems cannot guarantee that execution will continue if that failure does occur. Furthermore, hardware-based fault tolerance offers no protection against crashes caused by software defects, such as a divide-by-zero error in the application or a kernel panic in the underlying operating system.\nConversely, Durable Execution builds reliability into the software. While Durable Execution platforms vary in terms of system requirements, Durable Execution itself does not depend on any specific hardware. In fact, applications that use Durable Execution can be deployed to virtual machines or containers. Unlike hardware-based solutions for fault tolerance, Durable Execution is not bound by physical proximity, does not require specialized networking equipment, and works natively in both local data centers and cloud environments.\nThrough its ability to span multiple processes and systems over time, Durable Execution can overcome crashes, regardless of whether they result from software failure or hardware failure. This is welcome news for any developer tasked with designing and building mission-critical applications.\nDurable Execution elevates development\nPlatforms provide powerful abstractions that decouple how we view the system from how it exists in reality. For example, the filesystem abstraction provided by UNIX allows us to think about storage in terms of files instead of sectors on a disk. Databases build on this to further elevate our thinking. By delegating to the database, developers gain the ability to think in terms of fields, records, and tables instead of being concerned with file structures and serialization formats.\nDurable Execution similarly elevates application development. Think about all of the complexity involved with mitigating failures, from implementing retry and timeout logic, to manually loading and saving application state, and even using external schedulers to overcome the practical limits of time. Now, imagine how much simpler your application would be if it just couldnt fail. What youre imagining is Durable Execution.\nIn addition to making the application more resilient, Durable Execution makes developers more productive by liberating them from the burden of writing, testing, and maintaining all of the code described above.\nIn conclusion\nBy increasing application reliability, reducing code complexity, and boosting developer productivity, Durable Execution offers significant value to application developers.\nWhile the platforms that provide Durable Execution vary according to their capabilities, advantages, and limitations, all of them enable a fundamental change in how developers build and run modern production applications.",featureImage:{title:"What is Durable Execution?",description:"What is Durable Execution?",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2ClmATJKsN9k0sfTt6Vkpn/30f273fe3b328021a682c1948317523a/Screenshot_2025-04-21_at_10.15.27_AM.png"},publishDate:"2025-05-06",metaDescription:"Learn what Durable Execution is and how it enables developers to quickly create reliable applications that can withstand crashes. ",metaTitle:"The definitive guide to Durable Execution",socialCard:{title:"What is Durable Execution?",description:"What is Durable Execution?",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2ClmATJKsN9k0sfTt6Vkpn/30f273fe3b328021a682c1948317523a/Screenshot_2025-04-21_at_10.15.27_AM.png"},tags:"Durable Execution",slug:"what-is-durable-execution",contentType:"blogPost",entityId:"7JgEnMBrFBz0gb1dvyIueY",authors:[{id:"6NFooJhrzJdVAxMRWhgeTl",name:"Tom Wheeler",slug:"tom-wheeler",jobTitle:"Principal Developer Advocate",photograph:{title:"Tom Wheeler",description:"Tom Wheeler",url:"https://images.ctfassets.net/0uuz8ydxyd9p/53ysX1Y47NqQaThXEVUny4/b1d9bbb620188ffc23a6a5098a80cfa5/tomwheeler-2024-headshot-800x800.webp"},biography:"Alternating between software engineering and technical education roles, Tom Wheeler's career spans more than 25 years in the financial, healthcare, defense, and tech industries. Prior to joining Temporal as the founding member of the Education team in 2022, he wrote training courses at Cloudera, developed aerospace engineering software at Object Computing, helped create a distributed system for high-volume data processing at WebMD, and built some of the earliest web applications at brokerage firm A.G. Edwards. When Tom manages to step away from the computer, you can probably find him cooking, traveling, or playing guitar.",company:"Temporal",contentType:"person"}],authorsString:"Tom Wheeler",category:"Temporal Concepts",readingTime:10},{title:"Durable Digest: April 2025",content:"This blog post is a public copy of our monthly newsletter. If youd like to receive upcoming updates by email, you can subscribe to our newsletter here.\nWere rolling out major observability boosts with new Datadog and New Relic integrations, simplifying scaling with the KEDA worker scaler, and giving you finer control with Task Queue Priority. Explore the latest SDK releases (Ruby hits Public Preview!), catch us at Stripe Sessions, and join our AI agent webinars. See whats new!\nFor more information on other things we've been working on, just keep reading! And as always, we'd love to hear from youfeel free to share feedback in our Community Slack, or on X (@temporalio).\nProduct Updates\n\n  The latest version of KEDA (Kubernetes-Based Event-Driven Autoscaling) now contains a Temporal Worker scaler! This solution empowers you to dynamically scale the number of Temporal workers based on the size of the Task Queue backlog, enabling efficient resource utilization in Kubernetes environments.\n  Task Queue Priority (launching in Pre-Release) gives you control over the execution order of workflows, activities, and child workflows using priority levels from 1 to 5.\n\nAnnouncements\nNew Observability Integrations for Temporal Cloud: Datadog and New Relic\nWere excited to announce two major new integrations! Temporal Cloud now integrates with both Datadog and New Relic, making it easier than ever to monitor your workflows alongside the rest of your infrastructure.\n\n  \n    Temporal Cloud + Datadog: Send key metrics and Workflow visibility data directly to Datadog for centralized monitoring, alerting, and analysis.\n  \n  \n    Temporal Cloud + New Relic: Gain powerful insights into your Workflows by integrating Temporals observability data into New Relics dashboards and alerts.\n  \n\nThese integrations give you deeper visibility into your applications, helping you build and scale with even greater confidence.\nSDK Updates\n\n  Go SDK v1.34.0 includes pre-release features Activity Pause and Task Queue Priority as well as multiple changes and updates\n  Java SDK v1.29.0 includes pre-release features Activity Pause, Task Queue Priority, and Versioning/Safe Deploys. Note the changes to the SlotSupplier interface if you are using it\n  .NET SDK v1.6.0 includes a new event loop algorithm, and there are also published Linux-musl builds for x64 on NuGet\n  PHP v2.13.x releases include various maintenance updates and fixes\n  Ruby SDK v0.4.0 moves Ruby to Public Preview status. Updates include Replayer support, Linux x64 musl builds, and Open Telemetry tracing support\n\nEvents\nStripe Sessions: May 68 | San Francisco, CA\nMeet the Temporal team at Stripe Sessions! Stop by Booth 402 in the Moscone West Convention Center and see how Temporal is redefining how you build modern applications. Dive into live, interactive demos to explore advanced Workflow orchestration, fault-tolerant microservices, and stateful application development at scale.\nWant to go deeper? Request a meeting with our founders or set up time with one of our Temporal experts.\nThis is your chance to get hands-on, connect with the creators of Temporal, and discover how it can transform your architecture. Well see you there!\nWebinars\nHow to Build AI Agents with Python & Temporal  On Demand\nDiscover how to build agentic AI workflows using Temporals Python SDK in this recorded session, featuring a hands-on demo. Watch it anytime, at your convenience. Watch the recording >\nAI Agent Code Walkthrough with Python & Temporal\nJoin us on May 2nd at 9am PST/12pm EST for a deep dive into Temporals Agentic AI use cases. Well begin with a live demo demonstrating how Temporal lets you recover from unexpected issues before transitioning to a live walkthrough with our Solution Architects. Save your spot >\nResources\nThe Education team is hosting a Temporal 101 in Go webinar on May 14 at 9:00 AM PST. Register here!\nWant to present Temporal to your local meetup? We have you covered! Check out our Meetup in a Box program, which provides prebuilt slides and code demonstrating Temporal. We have one presentation done, and available in Go, Java, TypeScript, Python, and .NET, with more presentations planned. Keep your eye on this page for the latest Meetups in a Box!\nCommunity Highlights\n\n  Temporal JS workshop in Colombia by J.D Nicholls\n  Anant Agarwal gave a talk Orchestrating at Scale: How Instacart Manages 20M+ Daily Workflows at the Data Council conference.\n  New Code Exchange entries:\n    \n      .NET/C# Logistics Process Manager Example (by Ivan Blazhko) - Simple example of a process manager dealing with the logistics domain. Implemented in .NET/C# and hosted in Docker Compose.\n      Temporal Diagram Generator (by Jonathan Muszkat) - Generate visual sequence diagrams from your Temporal workflowsautomatically! Useful for debugging, documentation, and onboarding.\n      Claim Mapper Authorization (by Matt Chaffe) Learn how to implement role-based authentication for self-hosted Temporal. Use custom claim mappers and authorizers to enhance security and access control for your workflows.\n    \n  \n",featureImage:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},publishDate:"2025-04-29",metaDescription:"Explore Temporals latest developer updates: questions from the field, new releases, builder spotlights, learning resources, and ways to connect with our team.",metaTitle:"Durable Digest: April 2025",socialCard:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},tags:"",slug:"durable-digest-april-2025",contentType:"blogPost",entityId:"6GNwLupNKaqTyDIbtnwQgZ",authors:[{id:"17hGmNrCwtXdBh7fhsLUnZ",name:"Temporal Technologies",slug:"temporal-technologies",photograph:{title:"temporal technologies logo",description:"temporal technologies logo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3g56zRXtFQYMeJxBBkVBIZ/7771670e5fc7da59f555837b086c35d6/temporal_technologies_logo.avif"},company:"Temporal Technologies",contentType:"person"}],authorsString:"Temporal Technologies",category:"Announcements",readingTime:4},{title:"Building resilient Workflows: from Azure to Cadence to Temporal",content:"Software engineering isnt just about solving technical challenges  its about removing ones that shouldnt exist in the first place. Few understand this better than Max Fateev and Samar Abbas, co-founders of Temporal. Their experiences span some of the most influential tech companies, including Amazon, Microsoft, and Uber, shaping their vision of what workflow orchestration should be. Theyve seen firsthand how orchestration can either empower developers or drag them down. Their careers have shaped a daring vision: letting developers write clean business logic without worrying about failure recovery, state, or time.\nAmazon and the Birth of Orchestration\nIn 2002, Max, now CTO of Temporal, joined Amazon amid a pivotal transition from monolithic applications to a service-oriented architecture (now known as microservices). At that time, the entire Amazon website ran as a single binary  a massive Apache module taking an excruciating 45 minutes to link after each minor code change. This inefficiency sparked Amazons transition into service-oriented architectures.\nMaxs team developed Amazons foundational pub/sub architecture, ultimately evolving into Amazons Simple Queue Service (SQS). During this period, Max realized queues alone werent sufficient for reliable communication between distributed services. This insight prompted him to lead development on Amazons Simple Workflow Service (SWF), an innovative orchestration tool designed to bring order to asynchronous communication.\nHowever, SWF struggled with widespread adoption, largely due to its challenging developer experience. Although conceptually advanced, developers found it complex and cumbersome, highlighting an essential lesson: powerful technology must also be accessible.\nSamar Abbas and Azures Durable Task Framework\nSamar, CEO of Temporal, who had worked alongside Max at Amazon, carried these lessons to Microsoft. At Azure, Samar faced internal competition  Azure already offered multiple orchestration services. Nevertheless, Samar built the open-source Durable Task Framework, driven by a belief in simplifying orchestration for developers. Durable Task Framework is an orchestration library simplifying the creation and management of long-running, stateful workflows. It gained grassroots traction within Microsoft and Azures developer community, eventually becoming a key dependency for Azure Functions.\nUber and the Open-Source Era With Cadence\nMax and Samar reunited at Uber, creating Cadence  an orchestration framework designed from the outset as fully open source. This decision was critical: Max observed firsthand at Amazon how powerful technologies stagnated if kept proprietary. Ubers openness fostered broader adoption, innovation, and community-driven improvement.\nCadence aimed squarely at solving distributed workflow challenges. However, Max and Samar again realized they could do better by enhancing the developer experience and simplifying fault tolerance even further.\nTemporal: Durable Execution and Redefining Orchestration\nTemporal was born as a direct answer to the challenges Max and Samar encountered at Amazon, Microsoft, and Uber. At its core lies the concept of Durable Execution, a groundbreaking abstraction that automatically preserves the full state of a Workflow  even across failures, crashes, or data center outages.\nMax emphasizes the radical simplicity Temporal brings to developers: You practically end up writing pure business logic without thinking about other things  no event handlers, callbacks, or explicit database interactions. For a financial Workflow, its as simple as writing: withdraw, deposit, and if something goes wrong, automatically compensate.\nThis might sound too good to be true, a common reaction Max notes when first explaining Temporal. Yet, real-world results at mission-critical enterprises, including major financial institutions, confirm Temporals promise. It substantially reduces code complexity, increases fault tolerance, and boosts developer productivity  often cutting the necessary code by a factor of five.\nWhy Banks and FinServ Companies Are Choosing Temporal\nFinancial services rely heavily on resilience, precision, and guaranteed transactions  exactly where Temporal excels. Banks, Max notes, typically manage long, complex workflows involving manual approvals, numerous API calls, and critical compensations. Temporal makes managing such complex scenarios straightforward, with built-in resiliency and guaranteed outcomes.\nFor instance, an Australian bank, ANZ, fully automated its electronic mortgage process using Temporal. Payments, approvals, and compensations  which previously required extensive code  are now simple, reliable Workflows.\nSecurity by Design\nAddressing concerns around open-source security, Max emphasizes Temporals secure-by-design approach. Temporal separates its backend orchestration cluster from user applications. Users retain full control, encrypting their data client-side. Even if the orchestration backend were compromised, sensitive data remains inaccessible.\nA competitive Advantage, Built on Openness\nUnlike open-core solutions, Temporal is fully open-source under an MIT license. Max highlights this strategic choice: We believe the best way to ensure our technologys longevity and constant improvement is complete openness. If customers ever doubt us, they can always run Temporal themselves. Temporal also offers a cloud-hosted service, managing backend infrastructure while developers maintain complete control over their applications and data.\nMax and Samars journey through Amazon, Microsoft, and Uber was about continually refining how developers interact with technology. Temporal represents a culmination of these lessons, offering an orchestration tool where developers can finally focus exclusively on business logic, confident that their Workflows are resilient by design.\nSee for yourself  get started with Temporal Cloud today and claim $1000 in free credits.",featureImage:{title:"social-card-dark-waves (1) ",description:"social-card-dark-waves (1) ",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7fqbHM7iWOHKJo0GNha3Ou/ca1d6b6c63ab327d9e872eefa5a33627/social-card-dark-waves__1__1.png"},publishDate:"2025-04-25",metaDescription:"Discover how Temporal evolved from Amazon, Azure, and Uber to simplify workflow orchestration. Learn why top FinServ companies trust it for resilience, security, and scale.",metaTitle:"How Temporal Transformed Workflow Orchestration from Azure and Uber Roots",socialCard:{title:"Blog (22)",description:"Blog (22)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6xyyDh1ensU5QBmtcXi68k/904203b750766b25ae5ede449440fe8f/Blog__22_.png"},tags:"Industry Events",slug:"building-resilient-workflows-from-azure-to-cadence-to-temporal",contentType:"blogPost",entityId:"3fxrxcBGFoPbwirjPcRX8c",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"Temporal Voices",readingTime:5},{title:"Monitor your Temporal Workflows with the new Temporal Cloud integration for New Relic",content:"We're excited to announce the new integration between Temporal Cloud and New Relic, making it easier to monitor and observe the performance of your Temporal Workflows.\nTemporal applications power critical workflows across industries, from financial services and AI to healthcare and logistics. Observability is essential to keeping these systems healthy and scalable. With this new integration, engineering teams can now bring Temporal Cloud metrics directly into their New Relic dashboards, gaining real-time insight into Workflow execution, system behavior, and service performance.\nBuilt for Real-Time Observability\nWith the new New Relic Instant Observability quickstart integration for Temporal, teams can ingest Temporal Cloud metrics via the New Relic Flex integration, unlocking:\n\n  Live monitoring of Temporal namespaces and Workflows\n  Pre-built dashboards and charts\n  Support for alerts and anomaly detection\n  Insight into worker performance and system health\n\nThis helps teams detect bottlenecks, identify retry storms, track Workflow throughput, and ensure systems are running reliably at scale.\nWhat You Get\nThe integration includes:\n\n  Out-of-the-box New Relic dashboards for Temporal Cloud metrics\n  Easy set up and Flexible configuration through the all-in-one New Relic Flex integration\n  A direct connection between your Temporal workloads and your existing monitoring practices in New Relic\n\n\n  \n\nWhy It Matters\nBefore this integration, many users relied on custom tooling or limited visibility into Temporals metrics. Now, with native support through New Relic, teams get a reliable, production-ready monitoring experience with minimal setup.\nWhether you're running mission-critical financial systems, building AI Workflows, or managing complex microservices architectures, observability matters. And now, you can pair the power of Temporal Cloud with the insights of New Relic.\nGet Started\nYou can explore the integration now via New Relic Instant Observability: https://newrelic.com/instant-observability/temporal-cloud\nOr head to the Temporal documentation to learn how to get it set up in your environment.\nWere thrilled to make Temporal even more accessible, scalable, and observable through this integration with New Relic. Let us know what you build.",featureImage:{title:"Temporal Cloud New Relic integration",description:"Temporal Cloud New Relic integration",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4hkE2pLvASfT7o2tq7yHqq/acb2151ab3a9d7ad652253bf7fa2a702/image1.png"},publishDate:"2025-04-24",metaDescription:"We're excited to announce the new integration between Temporal Cloud and New Relic, making it easier to monitor and observe the performance of your Temporal Workflows.",metaTitle:"Monitor your Temporal Workflows with the new Temporal Cloud integration for New Relic",tags:"Cloud",slug:"monitor-your-temporal-workflows-temporal-cloud-integration-for-new-relic",contentType:"blogPost",entityId:"U4REcc0GlqddjROuaXqy4",authors:[{id:"16sAl0Xh8imRribCT59nCa",name:"Brandon Moorer",slug:"brandon-moorer",jobTitle:"Project Marketing Manager, Startups",photograph:{title:"Brandon Moorer",description:"Brandon Moorer",url:"https://images.ctfassets.net/0uuz8ydxyd9p/272lfKyej0ZUapzYWM5o17/da114ecb051ca065617d78c4349c8e53/image__1_.png"},company:"Temporal",contentType:"person"}],authorsString:"Brandon Moorer",category:"Product News",readingTime:2},{title:"How many Activities should I use in my Temporal Workflow?",content:"A common question when working with Temporal Cloud: Should I split this Activity into multiple Activities? Or put another way: How much can I cram into one Activity before its too much?\nFinding the right balance between too many Activities or too few involves weighing trade-offs.\nUsing more Activities means the Temporal service has to track more state changes, keep a larger Event History, and handle extra network requests. If you're self-hosting, this can put more strain on your systems computing power and storage. When using Temporal Cloud, these concerns are simplified into consuming additional actions.\nUsing fewer Activities might seem better at first, but it can actually make things harder down the road. Youll have fewer natural breakpoints to take advantage of Temporals built-in tools, which can make it trickier to configure Retry and Timeout Policies, keep your application state valid, debug issues, run tests, monitor performance, and refine your Workflow design over time.\nWhile increased usage is an important consideration, there are these considerations beyond cost, as Activities also provide value to your application. Ideally, you should consider the value the Activity provides in relation to its cost in order to make the best decisions for your use case.\nAs a rule of thumb, Activities should be fine-grained: one operation (aka transaction) per Activity. This is a best practice that will ensure your Workflows are simple, maintainable, observable, easily versioned, and reliable. However, there are times when you may want or need to combine different kinds of work inside of a single Activity and having clarity on the reasoning behind the best practices can be helpful in weighing the pros and cons of doing so.\nIn this blog post, Ill go over some of the main reasons you would split up the work going on inside of Activities which will help you uncover the rare exceptions to this best practice and help you to make wise decisions when you design your own Activities.\nThe TL;DR (Too Long; Didnt Read)\nThis post is full of details and examples, but just in case you are pressed for time and want to get straight into the guidelines heres a summary of the main reasons you should use more Activities instead of fewer:\nYou Must Use More Activities If\n\n  You need to run an Activity on a different Task Queuefor example, to route work to specialized hardware, enforce rate limits, or isolate network traffic.\n  You require a different Retry Policy for certain operations.\n  You need a distinct Timeout Policy for specific tasks.\n\nIts Practical to Use More Activities If\n\n  An Activity includes multiple database transactions that change state.\n  You make multiple calls to external services that modify state.\n  Theres a financial cost associated with certain remote service calls.\n  You need to dynamically execute individual units of work, like in a DSL or DAG-based Workflow.\n  Your business requires detailed observability into Workflow status.\n\nYou Might Prefer More Activities If\n\n  A more granular design makes development faster and maintenance easier by simplifying testing and debugging.\n  You plan to use Temporals saga pattern for compensating transactions.\n  \n    Your Workflow involves concurrent execution, and you prefer Temporals concurrency model over traditional approaches.\n    If youre interested in learning more about these categories or the specific examples for each, keep reading as they will be covered in detail.\n  \n\nShould You Use More Activities or Fewer?\nThere are three main categories where youll want to use more Activities instead of fewer:\n\n  Necessity  Some situations require multiple Activities.\n  Practicality  Using more Activities can be more financially efficient, or improve business value, even if its not strictly required.\n  Preference  Some choices make development easier and code more maintainable, but the decision to use more Activities in these scenarios come down to personal or team preference.\n\nNecessityWhen using Fewer Activities Wont Work\nSometimes, using multiple Activities is required because using fewer Activities is impossible. Youre forced to split the work into pieces. Here are some common cases where breaking an Activity into multiple parts isnt optional.\nUsing Separate Task Queues in your App\nSometimes you need to route work to specific Workers. For example, some Workers may have specialized hardware (they might be using high-end GPUs for AI/ML models) or they may be hosted within a different network. In these cases, where you want to make sure that work arrives at the right Worker, you need separate Task Queues, which means invoking an additional Activity. This logic also applies when enforcing rate limits on a Task Queue.\nConsider the following example: imagine youre building a payment processing system that needs to handle sensitive financial transactions. To stay compliant with security regulations like PCI-DSS, these transactions must be processed within a secure, isolated networkone that general-purpose application Workers cant access. By using a separate Task Queue, you ensure that only Workers inside this secure environment handle payment encryption and validation, keeping customer data safe while allowing the rest of your application to run in a regular-security environment.\n\n  \n  Fig 1.1: Using a separate task queue for high-security Activities ensures that only PCI-DSS compliant infrastructure can access the secure database, with outbound-only traffic to Temporal Cloud. While this setup requires an extra Activity in the Workflow, it keeps sensitive data protected and separates security concerns from the rest of your application.\n\nDifferent Retry or Timeout Policies for Different Real-World Processes\nWhen different parts of an Activity need separate Retry Policies, you must split them into multiple Activities. For example, if one step should retry only once while another allows unlimited retries, they require different configurations. This means separate Activities. The same applies to Timeout Policies.\nConsider an online checkout Workflow. One step captures a payment, while another sends a receipt via email. If payment capture fails, the Workflow should fail immediately and prompt the customer to enter new payment details. But sending the receipt is differentit can be retried multiple times without impacting the order. It wouldnt make sense to fail the entire Workflow just because an email didnt send on the first attempt.\n\n  To enforce these distinct Retry Policies, you need one Activity for payment capture and another for sending the email receipt.\n  \n  \n  Fig 1.2.1: This setup combines payment capture and sending of the email receipt into one Activity. The problem? If the email fails, the entire Workflow failseven if the payment already went through.\n  \n  Fig 1.2.2: A better approach, as shown in Fig 1.2.1, splits the monolithic Activity into two separate Activities: one for capturing payment and another for sending the email receipt. This allows each Activity to have its own Retry Policy, ensuring that a failure to send an email wont cause the entire Workflow to fail after a successful payment capture.\n\nPracticalityWhen Splitting Activities Pays Off\nNot every situation requires the use of additional Activities, but sometimes using more is the practical choice. Whether its about reducing costs, improving efficiency, or aligning with business needs, structuring your Activities can lead to smoother, more maintainable Workflows. Here are some cases where using more Activities is the best practical choice.\nNot Just All-or-Nothing\nImagine youre ordering takeout for your family. Everyone picks their meal, and you place a single orderbecause if one persons meal is missing, dinner isnt complete. This is an all-or-nothing situation: you either want all the meals or none, so your family can eat together.\nNow, lets say you order from multiple restaurants instead of one. Suddenly, coordination becomes a headache. Each restaurant is working independently, with no way to track the status of your full order. If one restaurant is late or forgets an item, theres no easy way to fix it across all restaurants. This level of coordination is complicated, and most restaurants simply arent designed to handle it.\nThis is exactly the kind of challenge Workflows solve. Inside a Workflow, you have the tools to handle complex coordination across servicesbut once you enter an Activity, you lose that orchestration ability. If an Activity tries to handle multiple all-or-nothing concerns (aka a transaction) at oncelike coordinating multiple restaurant orders in one stepit introduces risk. In these situations, you often end up needing the functionality that Temporal already provides at the Workflow level, but since you are combining the transactions into one Activity you have to build that kind of tooling yourself which is a huge time sink.\nIt is important to recognize that not all use of multiple services is an all-or-nothing situation. Going back to the restaurant metaphor: it is perfectly fine to make a phone call to four different restaurants and ask them what their hours and menu items are prior to ordering dinner. If one restaurant fails to pick up the phone it doesnt change much to call them or all the restaurants again. When you order food from multiple restaurants and expect them to all deliver dinner at the same time you are expecting a change in the state of the world, not just the delivery of information. If one restaurant fails, the other restaurants may have already prepared the food they are responsible for.\nIn the same way that calling multiple restaurants at the same time does not result in an all-or-nothing scenario, calling multiple services, or using multiple databases does not automatically mean you are facing a scenario where you ought to be using more Activities. Theres no issue with reading from several databases or fetching information from several different APIs in the same Activityand sometimes you may even need to! However, writing to multiple databases or using multiple APIs that change some remote state is a clear sign that you have an all-or-nothing situation on your hands.\nA good rule of thumb: If your Activitys work involves multiple database transactions or coordination of state changes across multiple remote services, you should be using multiple Activities to handle the orchestration of these transactions and remote service calls.\nBundling transactions in Activities can cause serious issues:\n\n  What if one transaction succeeds but the next one fails? Youre left in a halfway-done state.\n  How do you report errors back to the Workflow? Should you retry everything or just part of it?\n  \n    Debugging becomes much hardersince its unclear how far the Activity got before failing and this information cannot be deduced from the Workflows Event History.\n    By splitting these steps into separate Activities, each one runs independently, making failures easier to track, debug, and recover from without having to rebuild the functionality that is already available in a Temporal Workflow.\n  \n\nIsolating Retries\nWhile Activities have a small costfractions of a cent on Temporal Cloudretries can sometimes trigger much higher costs in unexpected ways. Theres a real financial cost whenever a retry involves a remote service call that is charged for based on usage. In these scenarios, using more Activities allows for a distinction between Retry Policies, which makes financial sense.\n\n  Consider the example of pairing an expensive API call, like pulling a credit report, with a cheaper one like sending a customer a notification. Failures in sending a notification should not result in a potential retry on the expensive operation of fetching a credit report. Activities do have costs associated with them but you should never lose sight of the costs and labor involved with the entire Activity execution. If you have to re-run expensive steps, its smarter to split those steps into separate Activities that dont have to repeat in lock-step with lower cost ones.\n  \n  \n  Fig 2.1.1: Pulling a credit report is costly and rate-limited, while updating a risk profile in your application database, and sending a notification are virtually free. But in this setup, all three tasks are bundled into one Activity, meaning a retry due to a failed notification or failure to update the database could unnecessarily trigger another credit pull. Even though these tasks seem related, theres no need to keep them tied together. A better design would eliminate the potential of the Workflow to make duplicate calls to the credit bureau because of failures in unrelated services.\n  \n  Fig 2.1.2: Compared to the design in Fig 2.1.1, this approach is much safer. By isolating the credit report fetch into its own Activity, retries for low-cost taskslike updating a risk profile or sending notificationswont accidentally trigger costly extra credit pulls.\n\nDiscrete Invocation\nSometimes, you need to invoke work dynamically as separate units. This is common in DSLs (Domain-Specific Languages) and DAG (Directed Acyclic Graph) orchestration, where dynamic inputs control the flow of execution.\nTemporal already supports dynamic invocation through Activities. Trying to replicate this functionality inside of an Activity would be far more complex and costly than simply structuring your Workflow with additional Activity calls.\nImproved Observability\nTemporal Workflows arent just for engineersstakeholders like support staff and product managers also rely on them for visibility. While you could build a separate observability system, its often unnecessary. If Temporals built-in observability meets your needs, using it saves time, effort, and cost. Instead of reinventing the wheel, take advantage of whats already there.\n\n  Stakeholders outside of your engineering team arent the only beneficiaries. Having excellent observability tools is a win for you and your team too. By using additional Activities you can make your application easier to debug and simpler to explain and understand.\n  \n  \n  Fig 2.3: Temporals built-in observability tools provide detailed insights into a workflows status. These visualizations make it easier to collaborate with non-technical stakeholders, keeping everyone on the same page.\n\nPreferenceImproving Software Quality and Developer Experience\nSome design choices arent strictly required or of objective financial benefit, but they can still provide long-term subjective benefits. Using additional Activities can improve code clarity, maintainability, and developer experience. Even if fewer Activities could handle all the work, breaking things up can make debugging easier, reduce cognitive load, and help teams collaborate more effectively.\nWhile theres always a cost to adding more Activities, the right balance depends on how your team works and what makes your system easier to maintain over time. Here are some cases where structuring Activities for qualitative benefits is the better choice.\nReduced Cognitive load\nSmaller Activities make Workflows easier to understand, debug, and modify. Breaking down work into clear, focused units reduces cognitive load, helping developers reason about each step without unnecessary complexity.\nSmaller Activities also improve flexibility. They make it easier to move components, write targeted unit tests, and work with simpler abstractions. Instead of managing a large, monolithic Activity, developers can focus on well-defined, modular pieces that are easier to maintain and adapt over time.\nSimpler Compensations\nTemporal makes the saga pattern easy to use, especially when each local transaction has its own Activity Definition. Keeping Activities small keeps compensations clear and manageable.\nLarger Activities, on the other hand, require more complex compensations, making them harder to maintain. By breaking work into smaller Activities, you create more granular, maintainable compensations that are easier to debug and reason about.\n@Override\npublic void bookVacation(BookingInfo info) {\n   Saga saga = new Saga(new Saga.Options.Builder().build());\n   try {\n       saga.addCompensation(activities::cancelHotel, info.getClientId());\n       activities.bookHotel(info);\n\n       saga.addCompensation(activities::cancelFlight, info.getClientId());\n       activities.bookFlight(info);\n\n       saga.addCompensation(activities::cancelExcursion, \n                            info.getClientId());\n       activities.bookExcursion(info);\n   } catch (TemporalFailure e) {\n       saga.compensate();\n       throw e;\n   }\n}\n\nFig 3.1: Example saga compensations in Java using Temporal Activities for each individual step.\nEasier Concurrency\nTemporal's idiomatic code makes it natural for developers to create highly concurrent and reliable workflows. This is because high-level primitives like Workflows allow applications to use Activities and Child Workflows to break up large processes into discrete units of work and durably execute them in a concurrent fashion. By splitting work into multiple Activities your applications can run them concurrently with little additional effort or hidden complexity.\nWithout Temporal, performing concurrent operations like fan-out/fan-in requires the use of traditional concepts such as threads or asynchronous libraries that abstract the difficulties involved with concurrent programming inside of a single process. If you do take this route then you will need to consider the complexities of handling potential race conditions, thread pool exhaustion, durability, and all the other challenges that come along with the language-native primitives. It is totally possible to combine the use of Temporal and the use of traditional concurrent programming methods inside of your Activitiesbut it is often a more complex solution which requires more diligence and maintenance on your part.\n  public static class MultiGreetingWorkflowImpl implements MultiGreetingWorkflow {\n\n    private final GreetingActivities activities =\n        Workflow.newActivityStub(\n           GreetingActivities.class,\n           ActivityOptions.newBuilder().setStartToCloseTimeout(\nDuration.ofSeconds(2)).build());\n\n    @Override\n    public List\u003CString> getGreetings(List\u003CString> names) {\n      List\u003CString> results = new ArrayList();\n\n      List\u003CPromise\u003CString>> promiseList = new ArrayList\u003C>();\n      if (names != null) {\n        for (String name : names) {\n          promiseList.add(Async.function(activities::composeGreeting, \"Hello\", name));\n        }\n\n        // Invoke all activities in parallel. Wait for all to complete\n        Promise.allOf(promiseList).get();\n\n        // Loop through promises and get results\n        for (Promise\u003CString> promise : promiseList) {\n          if (promise.getFailure() == null) {\n            results.add(promise.get());\n          }\n        }\n      }\n      return results;\n    }\n  }\n\nFig 3.2: Example of durably running Activities concurrently using Temporals Java SDK. Each point of concurrency is a separate Activity invocation.\nWrap-up\nUsing more Activities instead of fewer can improve your Workflows. When youre motivated by necessity (task queues, retry, or timeout policies), practicality (isolating retries, observability, discrete operations), or preference (reducing cognitive load, maintainability, or leveraging Temporals concurrency model), consider using more Activities as a possible means to improve your Workflow design.\nHave you found other reasons to use additional Activities or times when it is safe to combine Activities that arent mentioned in this post? Share your insights in the Community Slack!\nYou can also get started today with a free trial of Temporal Cloud and $1,000 in credits.",featureImage:{title:"buddha-elemental-3d-br5JFHhkoIA-unsplash (1)",description:"buddha-elemental-3d-br5JFHhkoIA-unsplash (1)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6KZNZOYRsAXONUbNuA5V7f/2f1ec7f2dd615ca6d4bb766d98271bff/buddha-elemental-3d-br5JFHhkoIA-unsplash__1_.jpg"},publishDate:"2025-04-16",metaDescription:"Learn how to strike the right balance with Temporal Activities. Taylor Khan covers when and why to split Activities, from practical trade-offs to best practices.",metaTitle:"How many Activities should I use in my Temporal Workflow?",socialCard:{title:"Blog (21)",description:"Blog (21)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/oCwa8YbCwLRx9d6BnJGLN/ac0c42484040e7feffef5ef646c568dd/Blog__21_.png"},tags:"Temporal Primitives",slug:"how-many-activities-should-i-use-in-my-temporal-workflow",contentType:"blogPost",entityId:"2Ee1wMUF4HhgZecFQEPF4p",authors:[{id:"5O8LII9rB3OXVVNL2GYVB6",name:"Taylor Khan",slug:"taylor-khan",jobTitle:"Senior Solutions Architect",photograph:{title:"taylor-khan",description:"taylor-khan",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6xb68SeDYnprcPAj7WyqdJ/d1cf413c380e3fdf5ef83f735081ec1e/TT31S6VK5-U057WKN0F60-23dbf4bf2c5f-512.jpeg"},company:"Temporal",contentType:"person"}],authorsString:"Taylor Khan",category:"Temporal Voices",readingTime:15},{title:"Temporal Cloud metrics in Datadog: Easy, out-of-the-box observability ",content:"Were excited to announce a new integration between Temporal Cloud and Datadog, designed to transform how developers monitor and optimize their Temporal Workflows.\nThis integration delivers out-of-the-box metrics dashboards, simplified setup, and cost-saving opportunities.\nUnlock observability with minimal effort\nWith this integration, joint customers can now access a pre-built Temporal Cloud metrics dashboard directly within Datadog. This dashboard provides insights into system health, performance, and Workflow efficiencyall with minimal setup. By leveraging Datadog, teams can monitor key Temporal Cloud metrics such as service latency, replication lag, Workflow success rates, and more without needing to build custom visualizations from scratch.\nSimplified metrics integration\nPreviously, integrating Temporal Cloud metrics with Datadog required a PromQL-to-Datadog scraper, adding complexity and maintenance overhead. With this integration, thats no longer necessary. The integration uses a crawler-based approach to fetch metrics directly from Temporal Clouds Prometheus endpoints via REST APIs.\nCost-efficient monitoring\nAn additional benefit of this integration is the potential to lower your Datadog costs. Unlike custom metrics ingestion, which incurs additional charges in Datadog, the Temporal Cloud metrics provided through this integration are classified as standard metrics. This means you can achieve comprehensive observability without worrying about escalating costs.\n\n  \n\nWhats included in the integration?\nThe Temporal CloudDatadog integration offers:\n\n  Out-of-the-Box Dashboards: Pre-configured dashboards for monitoring system health and Workflow efficiency.\n  Proactive Alerts: Built-in monitors for critical metrics like service latency (P99), Workflow failures, and replication lag.\n  Granular Insights: Metrics tagged with attributes like namespace, operation type, and task type for detailed analysis.\n\nGet started today\nSetting up the integration is straightforward. You simply need to configure your Temporal Cloud Prometheus endpoint URL within Datadog and upload the required certificates for secure authentication. Once configured, the crawler will automatically fetch metrics data periodically and populate the dashboards in real time.\nIf youre ready to get started, check out the detailed instructions in our documentation.",featureImage:{title:"social-card-temporalite-blog",description:"social-card-temporalite-blog",url:"https://images.ctfassets.net/0uuz8ydxyd9p/43c3wR1aXhf2oLpXy8WReZ/b280baada058cdc1d0dc9a4b2aaff37a/social-card-temporalite-blog.jpg"},publishDate:"2025-04-15",metaTitle:"Monitor and optimize your Workflows in Temporal Cloud with a new Datadog integration that provides metrics, insights, out-of-the-box dashboards, and proactive alerts",socialCard:{title:"social-card-temporalite-blog",description:"social-card-temporalite-blog",url:"https://images.ctfassets.net/0uuz8ydxyd9p/43c3wR1aXhf2oLpXy8WReZ/b280baada058cdc1d0dc9a4b2aaff37a/social-card-temporalite-blog.jpg"},tags:"Cloud,Observability",slug:"temporal-cloud-metrics-in-datadog",contentType:"blogPost",entityId:"5LRYn83PaUgM7lkJ9ACNSF",authors:[{id:"5rRXBv9YX2HZHsbvCIr7ts",name:"Nikitha Suryadevara",slug:"nikitha-suryadevara",jobTitle:"Staff Product Manager",photograph:{title:"headshot-nikitha",description:"headshot-nikitha",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4OACKtdVPmoAygYiRKZnHU/d4033aa0852aae010c69fe249c9e90c0/headshot-nikitha.png"},biography:"Nikitha is a Staff Product Manager at Temporal based in San Francisco. She oversees several areas of the product such as high availability, worker management, and observability. Before Temporal, she worked on Compute Infrastructure (Borg) in Google Cloud. Her introduction to compute and cloud was through being a Product Line Manager at VMware. Nikitha started her career as a software engineer and product manager at various SaaS startups. She got her bachelor's degree in electrical engineering from the Manipal Institute of Technology and an MBA from UCLA Anderson.",company:"Temporal",contentType:"person"}],authorsString:"Nikitha Suryadevara",category:"Announcements",readingTime:2},{title:"Announcing KEDA-based auto-scaling for Temporal Workers ",content:"Were thrilled to announce the availability of the Temporal Worker scaler in the latest version of KEDA (v2.17.0). KEDA is a Kubernetes-based Event-Driven Autoscaling component. It provides event-driven scaling for any container running in Kubernetes. This solution empowers developers to dynamically scale the number of Temporal workers based on the size of the Task Queue backlog, enabling efficient resource utilization in Kubernetes environments.\nThis integration would not have been possible without contributions from our own Temporal community, as well as the maintainers of KEDA  thank you to all who were involved!\nWhy it matters\nScaling Temporal workers dynamically has several key benefits:\n\n  Cost Efficiency: Scale workers down to zero when theres no workload, reducing infrastructure costs.\n  High Throughput: Automatically scale up during traffic spikes to meet demand and maintain SLAs.\n  Operational Simplicity: Eliminate the need for manual scaling by relying on event-driven automation.\n\nThis approach is ideal for use cases where workloads are unpredictable or seasonal, such as e-commerce platforms, financial systems, and IoT data processing pipelines.\nAuto-scaling demo\nWeve released a new demo that showcases KEDA-based auto-scaling for Temporal Workers. This demo highlights how you can use KEDA to automatically adjust the number of Temporal Worker pods in real time. By scaling Workers up or down based on Task Queue activity, you can ensure your workflows are processed efficiently, even during traffic spikes or periods of low activity.\nThe demo is built on Temporals Order Management System (OMS) reference application, which simulates a realistic e-commerce system with Workflows for order processing, payments, and shipments. With KEDA integration, this system can now handle variable workload demands without requiring manual intervention.\nHow the demo works\nThe demo uses KEDAs Temporal scaler to monitor Task Queue backlogs and trigger scaling events based on predefined thresholds. For example, when the backlog of orders or shipments increases beyond a certain point, KEDA automatically scales up the Worker pods to process tasks more quickly. Once the backlog is cleared, the system scales back down to conserve resources.\nThe OMS web application now includes a page that enables you to visualize application load in real timetracking order completion rates, Task Queue backlogs, and the number of active worker pods as scaling occurs.\n\n  \n\nTry it yourself\nWeve made it easy for you to explore this functionality with a preconfigured demo environment that includes all necessary components: Temporal Server, KEDA, and the OMS application itself. For detailed installation instructions, technical configurations, and source code, visit the GitHub repository.\nWhats next?\nWere excited to see how you leverage this pattern to build scalable and cost-effective Temporal applications. Whether youre orchestrating complex workflows or managing high-throughput systems, KEDAs auto-scaling capabilities can help you optimize performance while simplifying operations.\nWed love to hear your feedback! Try out the demo and share your thoughts on GitHub or in our Slack community.\nCommunity Shout-outs\nWe also want to take a moment to appreciate the following Community members who led the charge on this initiative over several attempts:\n\n  Prajith P. who re-invigorated a previous attempt at introducing a Temporal Scaler with a fresh approach (#6191) and worked tirelessly to address and respond to feedback. Prajith is a DevOps Engineer at ClearTax who hails from India and is passionate about open-source software and innovations. His motivation for contributing to the KEDA scaler for Temporal is to give back to the open-source community and help build scalable solutions that benefit everyone.\n  Ross P Smith, who spear-headed the initial attempt (#4724) at a Temporal KEDA scaler.\n  Rob Holland and Chad Retz who reviewed the PRs and collaborated with Prajith on addressing feedback. Rob also produced the demo.\n  Jan Hecking, who thoroughly tested the PR and gave detailed feedback on its performance.\n  Nikitha Suryadevara and Febin Sathar who helped shepherd the PR process along at various key points.\n\nFrom the KEDA side, we would also like to thank the following maintainers who reviewed and approved the PR that ultimately led to inclusion of Temporal support in KEDA:\n\n  Jorge Turrado Ferrero (who also tagged the KEDA v2.17.0 release)\n  Zbynek Roubalik\n",featureImage:{title:"KEDA logo",description:"KEDA logo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2fiVYKRQev3A3Ugpl7vjoX/130d46b211b8cb3bf1584c10a2e07bb0/Group_2__2_.png"},publishDate:"2025-04-12",metaDescription:"Were thrilled to announce the availability of the Temporal Worker scaler in the latest version of  KEDA (v2.17.0). KEDA is a Kubernetes-based Event-Driven Autoscaling component.",metaTitle:"Announcing KEDA-based auto-scaling for Temporal Workers ",tags:"Scaling,Temporal Primitives",slug:"announcing-keda-based-auto-scaling-for-temporal-workers",contentType:"blogPost",entityId:"5iCM2LLlWvDqzeG4cTlAAc",authors:[{id:"5rRXBv9YX2HZHsbvCIr7ts",name:"Nikitha Suryadevara",slug:"nikitha-suryadevara",jobTitle:"Staff Product Manager",photograph:{title:"headshot-nikitha",description:"headshot-nikitha",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4OACKtdVPmoAygYiRKZnHU/d4033aa0852aae010c69fe249c9e90c0/headshot-nikitha.png"},biography:"Nikitha is a Staff Product Manager at Temporal based in San Francisco. She oversees several areas of the product such as high availability, worker management, and observability. Before Temporal, she worked on Compute Infrastructure (Borg) in Google Cloud. Her introduction to compute and cloud was through being a Product Line Manager at VMware. Nikitha started her career as a software engineer and product manager at various SaaS startups. She got her bachelor's degree in electrical engineering from the Manipal Institute of Technology and an MBA from UCLA Anderson.",company:"Temporal",contentType:"person"}],authorsString:"Nikitha Suryadevara",category:"Product News",readingTime:4},{title:"Why Temporal replaces traditional state machines for distributed applications",content:"Modern backend and infrastructure developers frequently grapple with the challenges of orchestrating complex, multi-step processes in distributed systems. These workflows often span multiple services and can run for extended periods, introducing several technical problems: managing the state of long-running processes, ensuring reliability despite failures, coordinating asynchronous steps (workflow orchestration), and implementing robust retries and timeouts.\nMany cloud applications involve workflows that are multi-step, distributed across multiple services, and potentially arbitrarily long  bringing all the hard problems of distributed systems to the forefront. Traditional approaches using explicit state machines or ad-hoc orchestration code often become complex and error-prone as systems grow. In this writeup, well examine:\n\n  How state machines have traditionally tackled workflow issues\n  Why Temporals Durable Execution model provides a better solution\n  How Temporal lets developers write plain code and often avoid writing explicit state-machine logic while still getting all the benefits of state tracking, retries, and orchestration\n\nCommon Challenges in Distributed Applications\nBuilding reliable distributed application logic  like processing an e-commerce order or handling a user sign-up  involves several key challenges:\nOrchestration and State Management\nDevelopers need to coordinate multiple steps across distributed services (e.g., charge payment, reserve inventory, send confirmation email) and track progress. The system must remember what has been done and what should happen next, even if there are delays or crashes. In a distributed setting, state often must be stored externally so work can resume after failures or restarts.\nRetries and Timeouts\nRemote calls or tasks will inevitably fail intermittently due to network issues or downtime, so each step requires retry logic with backoff. Some steps might hang, requiring timeouts to avoid waiting indefinitely. Implementing retries and timeouts is non-trivial; developers must carefully avoid duplicating tasks or losing track of attempts..\nDistributed Reliability\nIn a distributed system, any service or machine can fail at any time. The workflow must be robust to partial failures  if a step fails or a service goes down, the overall process should eventually complete or compensate correctly, without ending up in an inconsistent state. This often requires additional logic for error handling, compensating transactions (rollback of previous steps in case of failure, as in the saga pattern), and ensuring exactly-once or at-least-once execution semantics for each step.\nVisibility & Debugging\nWith many moving parts, determining what went wrong when something fails becomes difficult. If a long-running process stops, developers need insight into which step it was executing, what succeeded, what failed, and possibly the ability to resume or replay the process. In home-grown solutions, this typically involves combing through logs or querying state in databases spread across services.\nTraditional Solution: State Machines for Workflow Orchestration\nA state machine (or finite state machine  FSM) is a well-known paradigm for modeling the process logic by defining all possible states and transitions. For backend workflows, a state machine might include states like order created, payment processed, inventory reserved, order shipped, etc., with transitions occurring based on events like payment confirmation, shipment failure, timeouts, and so on.\nThis approach makes the systems current state explicit and defines how the system should react to different events. State machines, often event-driven, have traditionally been used to impose structure on complex, dynamic workflows that would otherwise be hard to manage.\nHow State Machines Address the Problems\nBy breaking a process into discrete states and transitions, developers can handle each step in isolation and ensure prerequisites are met before moving to the next step. For example, if payment fails, the state machine can transition to a payment failed state and trigger a compensating action or retry, rather than proceeding forward.\nMany teams implement this by storing the workflow state in a database and writing code or using a framework to move between states based on events or timer triggers. This explicit state tracking helps with reliability: if the system crashes, it can reload the last known state from the database and resume from there. It also helps coordinate distributed steps  one microservice can publish an event that causes another to advance the state.\nExamples\nAWS Step Functions uses JSON-defined state machines to orchestrate AWS Lambda functions or other services. Similarly, many companies have built bespoke orchestration engines where workflows are represented as state machines in code or configuration. In a simpler form, a cron job plus a database flag can be seen as a two-state (pending/done) machine. The saga pattern for distributed transactions can also use state machines to drive the sequence of steps and compensations.\nLimitations and Complexity\nWhile state machines enforce structure, they can become very complex to build, test, and maintain as the number of states and transitions grows. Each new scenario or edge case often means introducing additional states or branches in the state diagram. State machine code grows in complexity and length with each new state, and maintaining or testing these sprawling state graphs becomes challenging.\nDevelopers often write extensive plumbing code: saving state transitions to databases, implementing switch/case logic for transitions, handling timeouts by scheduling future events, and so on. This distracts from core business logic.\nFurthermore, manually implemented state machines need careful failure handling. Developers must catch exceptions and decide how to update the state or retry, ensuring the system can recover if crashes occur during transitions. Missing corner cases can lead to stuck workflows or data inconsistencies.\nA real-world ad-hoc solution might involve multiple moving pieces  storing status in a database, a periodic job (cron) to check for tasks to do, queues to distribute work to workers, and separate handlers for different events like cancellations.\nA Temporal engineer described such a solution as a distributed asynchronous event-driven bespoke system with multiple durable stores and components. While functional, these solutions represent a radical departure from the original simple code in terms of complexity. All that infrastructure is essentially implementing a state machine and workflow engine from scratch, consuming a lot of developer effort, and yet failure scenarios are numerous and few implementations get it 100% right.\nIn summary, explicit state machines can solve workflow orchestration by making state explicit and recoverable, but at the cost of significant complexity. This is where Temporal comes in  to provide a better, more developer-friendly approach.\nTemporals Approach: Durable, Event-Sourced State Machines as Code\nTemporal is an open-source platform designed to abstract away the plumbing of distributed workflows, letting developers focus on straightforward business logic. At its core, Temporal is essentially a state machine engine  but one thats generalized, highly durable, and completely encapsulated behind a programming model that feels like writing simple synchronous code.\nDevelopers can write what looks like a normal function, and the platform ensures that function executes reliably to completion regardless of failures. This is achieved through Temporals Durable Execution model, built on concepts like event sourcing, durable state tracking, and automatic retries.\nDurable Execution and Event Sourcing\nDurable Execution means that application logic can run reliably despite failures or interruptions. Temporal accomplishes this through a simple but powerful approach: it automatically records each significant step of your application logic as it executes.\nThis creates an append-only log of events stored in Temporals persistence layer. Instead of developers having to manually track state in their own databases, Temporal handles this automatically, capturing everything needed to understand what has happened so far.\nBecause this event log is managed by the Temporal service rather than living on a single machine, your application becomes resilient to infrastructure failures. If the process or machine executing your code crashes, Temporal can seamlessly continue execution on entirely different infrastructure, picking up exactly where it left off.\nThe result is application logic that appears to run continuously even when the underlying infrastructure is unreliable  a critical feature for business processes that may take minutes, hours, or even days to complete.\nWriting Synchronous Code, Getting Asynchronous Benefits\nTemporal divides work between Workflow code and Activities. Workflow code is your orchestration code (which runs under Temporals control with automatic state persistence and can be replayed), and Activities are the actual tasks that might do things like call external services, perform calculation, send emails, etc.\nWhat makes this powerful is that developers write code that looks completely synchronous:\nasync function processOrder(orderId) { await activities.verifyPayment(orderId); \nawait activities.reserveInventory(orderId); \nawait activities.shipOrder(orderId); \nawait activities.sendConfirmation(orderId); }\n\nBut behind the scenes, Temporal is handling complex distributed messaging automatically. When a Workflow needs to run an Activity, Temporal:\n\n  Puts a task into a task queue\n  Worker processes pick up the task to execute the Activity\n  The Workflow waits until the activity completes\n\nThis architecture (clients start Workflows, Workflows queue tasks, Workers pull tasks) means developers dont have to build their own queuing or messaging systems. Temporal handles all the complex pub/sub infrastructure while your code remains clean and readable.\nEvery step is mediated by the Temporal Server, which ensures that only one Worker will execute a given task, and the result or failure of the task is recorded as an event. This eliminates the need to build locking mechanisms to coordinate distributed tasks. Moreover, every action in the Workflow is recorded durably, providing complete visibility into what happened and when, including retries and Workflow decisions.\nWhy Temporals Model Is Better\nTemporals model offloads the hardest parts of Workflow management to its distributed architecture of Server and SDKs working together. The complete state of your Workflow (local variables, progress, etc.) is autosaved by the platform, giving you all the benefits of a state machine without you having to manually maintain state persistence or transition logic.\nThis invisible checkpointing happens automatically at critical points like activity calls or timer waits. Your function could be interrupted mid-execution by a server crash, deployment, or even a planned maintenance window lasting days  and when it resumes (potentially on entirely different infrastructure), every local variable, every loop counter, every conditional branch taken is exactly as it was. Your code continues executing from precisely where it left off, with no special recovery logic required.\nThis eliminates entire categories of bugs and infrastructure that developers typically build: state tables in databases, status fields, manual checkpointing, and complex resume logic all disappear. Your business logic remains pure, focused only on what should happen, not on how to make it reliable.\nNo Manual State Tracking\nWith Temporal, there's no need to write code saving Workflow state to databases or checking if (state == X) then resume from here  the platform handles this automatically. The complete state of your function and workflow is captured, eliminating the need to track and validate state yourself. This drastically reduces boilerplate and potential bugs.\nThe Workflow code looks like a normal function that simply calls the next step, but if that function halts and later continues, all local variables and progress remain as if the function never stopped. The Workflow functions progress effectively becomes the state, dramatically simplifying the mental model.\nAdding a new step in the middle of a Workflow only requires adding an activity call in the code at the appropriate place, rather than modifying state definitions and transition logic in multiple locations.\nBuilt-in Retries and Timeouts\nTemporal provides native support for retry policies on Activities and built-in timeout handling. You can declaratively specify how an Activity should be retried (e.g., exponential backoff, maximum retry interval), and Temporal performs retries automatically if the Activity fails or times out.\nTheres no need to wrap every network call in custom retry loops or worry about transient failures derailing Workflows  Temporal treats retries as first-class concepts. Timeouts and long waits are also simple: you can call Workflow.sleep(30 days) or set a timer, and Temporal will reliably wake the workflow after that duration even if processes restart in the meantime. Implementing this with hand-rolled state machines would be extremely difficult, potentially requiring cron jobs or external schedulers.\nResilience to Failures\nDue to the durable event history and replay engine, Temporal Workflows are fault-tolerant by design. If your Workflow code or host machine crashes during execution, the Temporal Server detects the Workers failure to report completion, and the Workflow is rescheduled (on a new Worker or when the original Worker returns) by replaying its history. From the developers perspective, its as if your function is atomically persisted at each await point.\nTemporal ensures each step executes at least once and uses event history to avoid duplicating actions. The platform handles state management, queuing, resilience, deduplication, and other safety properties automatically, eliminating the need for complex recovery code. Temporal provides exactly-once execution semantics for Workflow logic and at-least-once for activities, with mechanisms to avoid duplicate side effects in most cases.\nSimplified Error Handling and Sagas\nTemporal transforms how developers implement patterns like sagas (distributed transactions with compensation). In traditional systems, implementing sagas requires maintaining complex state across services to track which steps completed and which compensations are needed.\nWith Temporal, this complexity disappears. Developers simply write straightforward try/catch blocks where both the happy path and compensation logic live together in the same function.\nFor example, in a money transfer scenario, the withdrawal, deposit, and potential refund (compensation) all exist in one cohesive piece of code. This natural coding style dramatically simplifies implementation. The compensation logic lives right alongside the happy path, making it immediately clear what happens in both success and failure scenarios. Developers no longer need to build complex state tracking systems or distributed coordination  they just write simple, readable code that handles both the ideal flow and all the potential error paths in one place.\nVisibility and Debugging\nTemporal provides tools (and a UI in Temporal Web) to inspect Workflow histories. You can see each event, each Activity call, and the current state of a Workflow at any time. You can even query Workflows or send signals to them (e.g., for human-in-the-loop scenarios). The platform lets you replay executions for debugging, or even rewind a running Workflow to a past point if you need to fix something and re-run part of it.\nThis kind of introspection is usually absent in home-grown state machine systems. Temporal allows you to inspect, replay, and rewind every Workflow execution, step by step, so you never have to guess whats going on. In contrast, with an ad-hoc distributed state machine spread across services, reproducing the sequence of events that led to a failure can be a nightmare. Temporal centralizes that history.\nAll these features mean that Temporal acts as a robust state machine engine under the hood  one that is generic and heavily tested  so you dont have to build your own. Instead of your team writing the 100th variation of a retry loop or state persistence mechanism, you can rely on Temporals battle-hardened infrastructure.\nWorkflow-as-code is much friendlier than trying to express logic in a JSON/YAML state machine definition, and even though systems like Step Functions+Lambda allow expressing some logic, the moment you need anything dynamic or non-trivial, the complexity of those DSL-based state machines grows quickly and becomes painful. Temporal avoids those pitfalls by letting you use a real programming language for your workflow logic, which is infinitely flexible and integrates with normal development workflows.\nOrchestration-as-Code: Eliminating the Need for Explicit State Machines\nTemporals key advantage is its developer experience. You write Workflows as straightforward code in your language of choice (Go, Java, Python, TypeScript, PHP, .NET, or Ruby), using normal control flow constructs and calling services via Activities. Unlike libraries such as Spring State Machine where you explicitly define states and transitions in code, with Temporal you write procedural code while the platform manages state persistence and transitions implicitly.\nConsider this money transfer example:\ntypescript\nasync function transfer(fromAccount, toAccount, amount) {\n  await activities.withdraw(fromAccount, amount);\n  try {\n    await activities.deposit(toAccount, amount);\n  } catch (err) {\n    await activities.deposit(fromAccount, amount); // compensate by refunding\n    throw err;\n  }\n}\n\nThis code functions as a state machine: after withdrawal, its waiting for deposit; if deposit fails, it compensates. Temporal ensures that if the process crashes after withdrawal, the Workflow resumes and attempts the deposit. The variables fromAccount, toAccount, amount and the execution state are all preserved automatically.\nTemporal captures the complete state of your functions (variables, threads, call stack) so you get the benefits of a state machine without maintaining complex state machine code. Developers no longer need to write code to update status fields in databases or create switch statements over states  the Workflow functions progress becomes the state. Adding a new step means adding an Activity call at the appropriate place, rather than modifying state definitions and transition logic in multiple locations.\nTemporals approach can make explicit state machines unnecessary in many cases. Instead of having a separate state machine module or service, the Temporal Workflow acts as the orchestrator. The platform handles making the state durable and trackable. As the Temporal documentation notes, because it captures the entire state and progress of your Workflow, you can often eliminate or avoid state machines altogether. In other words, Temporal itself is a state machine, general-purpose enough that you dont have to write one. Engineers at Netflix reported spending less time writing glue code for consistency and failure-handling because Temporal does it for them.\nAnother benefit is testability and maintainability. You can unit test Temporal workflow logic using the same tools you use for any other code. Temporal provides testing frameworks to run workflows in-memory to validate their logic deterministically. The Workflow-as-code concept feels natural to developers since its just code  theres no new proprietary language to learn for defining workflows.\nTemporal doesnt remove the inherent complexity of business processes, but it localizes that complexity in a single Workflow function and handles error-prone parts automatically. You write straightforward steps, not scattered event handlers or state transition rules. The code becomes easier to understand, with flow explicitly defined in a single place, while Temporal takes care of state management, queuing, and resilience.\nConclusion\nBackend developers building distributed systems have long struggled with coordinating complex processes  managing long-running operations, synchronizing services, implementing retries, and recovering from failures. Traditional solutions using explicit state machines can work, but they often become unwieldy and costly to maintain as requirements grow.\nTemporal offers a fundamentally better approach by providing a Durable Execution engine that transforms complex distributed processes into straightforward code with built-in state persistence, reliability, and observability. Its essentially a state machine-as-a-service: you write normal code, and Temporal ensures it executes reliably step by step, even across process restarts, failures, or long delays.\nThis results in more robust applications with much less boilerplate. Many engineering teams don't even realize a solution like this is possible; they are so used to the norm of manually handling failures that Temporals model is paradigm-shifting. By using Temporal, teams can deliver features faster (since they can focus on business logic rather than building infrastructure) and gain confidence that their complex operations will run correctly and resiliently in production.\nYou can forget you ever worried about building a state machine  you just write your logic in code, and let Temporal handle the rest. The end result is simpler code, fewer bugs from missed edge cases, and a more observable, fault-tolerant system.\nTry it out for yourself with a free trial of Temporal Cloud with $1,000 in credits.\nFAQ\nIs Temporal suitable for any kind of distributed workflow, or are there scenarios where explicit state machines still make sense?\nTemporal is versatile enough to handle most distributed workflow scenarios. However, explicit state machines may still be appropriate if your system is simple, static, or requires a strictly defined and enforced state structure. Temporal excels when workflows are dynamic, complex, long-running, or require robust failure handling and state recovery.\nCan Temporal Workflows handle extremely long durations, such as weeks or months?\nAbsolutely. Temporal Workflows are designed to handle very long-running processes effectively. They persist Workflow states across restarts or crashes, using event sourcing to resume workflows seamlessly even after extended periods, such as days, weeks, or months.\nWhats the overhead of using Temporal versus custom-built solutions or simpler state machines?\nTemporal introduces minimal overhead compared to the benefits it provides. While there is a slight learning curve and initial setup time, the long-term reduction in complexity, fewer bugs from edge cases, and improved maintainability and reliability significantly outweigh initial costs.\nHow does Temporal guarantee exactly-once execution semantics?\nTemporal uses durable event sourcing combined with idempotent execution. Workflow actions and decisions are logged durably, allowing Temporal to replay events to reach the exact state before failures. Activities (external tasks) are retried at least once, and Temporal provides mechanisms like activity IDs and idempotency tokens to ensure side effects are executed exactly once.\nWhat about debugging? How easy is it to debug Workflows running on Temporal?\nTemporal greatly simplifies debugging. Its durable event history lets you inspect, replay, or even rewind Workflows step by step. Temporal Web provides detailed visibility into Workflow execution, allowing developers to easily pinpoint failures, view exact states, and debug complex Workflows much more effectively than traditional methods.",featureImage:{title:"social-card-newsletter",description:"social-card-newsletter",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3k9UpZsjFZDXElTHI4BCLz/3a72dd7f1c60ada1f5bd28f46f684810/social-card-newsletter.jpg"},publishDate:"2025-04-11",metaDescription:"Discover how Temporals Durable Execution model simplifies distributed applications by replacing complex state machines with intuitive code while enhancing reliability and observability.",metaTitle:"Temporal: Beyond State Machines for Reliable Distributed Applications",socialCard:{title:"Blog (20)",description:"Blog (20)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2ODXUCoTkruW1Khi7OUXxP/80199d0ba2b543a422e4d56c83c995fe/Blog__20_.png"},tags:"Architecture",slug:"temporal-replaces-state-machines-for-distributed-applications",contentType:"blogPost",entityId:"443qmiETj3WFPK37JUvieZ",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"How-To",readingTime:18},{title:"Trading Airflow + EMR for Temporal + Bauplan: The Mediaset tale",content:"What do you get when you mix a legacy Airflow stack, a mountain of AWS services, and a news dashboard that takes an hour to refresh?\nFrustrated engineers, slow feedback loops, and a ton of missed opportunities.\n\n  This is how Mediasetone of Europes largest private broadcasterswent from it works, but dont touch it to a modern, Python-native data stack built with Temporal and Bauplan.\n  In just a few weeks, they shipped a near real-time dashboard that updates in minutes instead of hours.\n\nThe Setup: Video Views, Petabytes, and Plenty of Pain\nMediaset digital by the numbers (2024):\n\n  24 million registered users (nearly half of Italys population)\n  10 billion video views (roughly 25 million views per day)\n  76 petabytes of data processed\n\n\n  Their original data stack looked like a greatest-hits collection of AWS services: EMR, Glue, Athena, Redshift, plus Airflow duct-taped on top. Building just one internal dashboard for TGCOM24their flagship news propertytook three months, required a team of senior engineers and consultants, and still had a frustrating one-hour data lag.\n  \n  \n\nRebuilding from First Principles\nRather than another temporary fix, the Mediaset team decided to start fresh. Heres what changed:\n\n  Airflow  Temporal for orchestration\n  \n    EMR + Glue + Athena + Redshift  Bauplan serverless platform for data management and pipelines.\n    The goal wasnt just a tech upgrade. It was to build a simpler, more reliable system that could be developed and maintained by any competent engineering and data science team without needing deep infra expertise.\n    \n    \n  \n\nWhat Bauplan Does, and Why It Beats the Traditional AWS Stack\nBauplan is a serverless platform specifically built for data and AI workloads. Its designed for developers who want to ship fast without wrangling infra.\nHeres what it replaces:\n\n  EMR  no more cluster management\n  Glue  no more boilerplate job authoring\n  Athena/Redshift  no need for a data warehouse\n\nInstead, you write Python functions, chain them together to build pipelines and run them as serverless functions in the cloud and get nicely typed objects back (boto3, looking at you!):\nclient.create_branch(\"my_dev_branch\")\nclient.import_data(\"s3://my-bucket\")\nclient.run(\"quality_pipeline\")\nclient.merge(\"my_dev_branch\", \"main\")\n\nData remains securely in your S3 buckets, stored in open formats like Iceberg. Theres no lock-ins, no data copies, and no hidden compute bills. You treat your data like code: versioned, testable, and portable.\nWhat Temporal Does, and Why Its Better than Airflow\n\n  Temporal is a workflow engine built for reliability. It handles retries, failures, and orchestration state without losing state.\n  Why Mediaset picked it over Airflow:\n\n\n  Durable, replayable Workflows with automatic retries\n  Everything is codeno YAML, no flaky UI debugging\n  Built-in support for scheduling, signals, and complex flows\n\nAirflow is fine when it works. But when it breaks (and it will), debugging DAGs across multiple AWS services becomes a full-time job. Temporal just works.\nReal-world Results\nAfter switching to Temporal and Bauplan:\n\n  Data freshness improved from 1 hour  5 minutes\n  Dev cycles shrank from 3 months  6 weeks\n  Infrastructure complexity went from 6+ AWS services  2 tools\n\nThe new stack enabled fast iteration, clean interfaces, and resilient workflowswithout requiring a team of platform specialists or months of onboarding.\nWhy It Works\n\n  Temporal manages orchestration, and Bauplan handles the data. Together, they give you a full CI/CD workflow for your pipelines, minus the traditional complexity of big data stacks.\n  You write Python. You commit your changes. You ship.\n  The dashboard was just the beginning. Mediaset is now rolling out even more ambitious use cases:\n\n\n  AI pipelines with LLMs for content summarization\n  Real-time ad optimization\n  A full migration away from legacy tooling\n\nLearn even more about the Mediaset journey and try Temporal for yourself. Watch the talk, try Bauplan for free, and sign up for Temporal Cloud and get $1000 in free credits.",featureImage:{title:"social-card-dark-waves (1) ",description:"social-card-dark-waves (1) ",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7fqbHM7iWOHKJo0GNha3Ou/ca1d6b6c63ab327d9e872eefa5a33627/social-card-dark-waves__1__1.png"},publishDate:"2025-04-10",metaDescription:"This is how Mediasetone of Europes largest private broadcasterswent from it works, but dont touch it to a modern, Python-native data stack built with Temporal and Bauplan.",metaTitle:"Trading Airflow + EMR for Temporal + Bauplan: The Mediaset tale",tags:"Cloud",slug:"trading-airflow-emr-temporal-bauplan-mediaset",contentType:"blogPost",entityId:"2WyN3dgtSj5bTxDQthiq2l",authors:[{id:"5pCwTeJOWFQV3I8InRP4Pk",name:"Stu Kendall",slug:"stu-kendall",jobTitle:"Director of Product Marketing",photograph:{title:"Stu-Kendall-PFP",description:"Stu-Kendall-PFP",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6nkZSIFJ6i4dWzcP8TKv5J/399d49245fe8bf6e329ee602450a211d/Stu-Kendall-PFP.jpeg"},company:"Temporal Technologies",contentType:"person"}],authorsString:"Stu Kendall",category:"Community",readingTime:4},{title:"Partnering with Google Cloud for Startups to help startups scale with confidence",content:"Startups today face constant pressure to scale quickly while keeping infrastructure costs under control. Temporal Cloud for Startups is designed to help early-stage teams accelerate development without the complexity of managing backend systems. Weve seen the impact firsthandhundreds of startups have used Temporal to move faster and focus on what truly matters: building great products.\nNow, through our new partnership with Google Cloud for Startups, were making it even easier for founders to get started. This exclusive offer for members of the Google for Startups Cloud Program (GFSCP) provides $12,000 in free Temporal Cloud credits over 12 months, helping startups scale with confidence while optimizing for efficiency.\nWhats Included?\n\n  \n    Temporal Cloud Usage. Get fully managed Temporal Cloud with namespace-as-a-serviceno need to worry about server management, scaling, or uptime.\n  \n  \n    Business Plan. Startups on the Business Plan receive two-hour P0 response times, hands-on workflow troubleshooting, guidance on worker configuration, and advisory support for implementing Temporal SDKs.\n  \n\nWhos Eligible?\nTo redeem this offer, startups must:\n\n  Member of Google Cloud for Startups program\n  Have a Temporal Cloud account and run your first workflow\n  Have received funding\n\nWere excited to support more teams as they scale their businesses on Google Cloud Find the offer listed on Google Cloud Startup Perks page and start building today!",featureImage:{title:"Google Cloud for Startups",description:"Google Cloud for Startups",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4kDM5Ye01hmDyfV9zhLYRz/cdf0206256ee6709c688f35f465e225b/Screenshot_2025-04-08_at_4.17.46_PM.png"},publishDate:"2025-04-09",metaDescription:"Startups today face constant pressure to scale quickly while keeping infrastructure costs under control. Temporal Cloud for Startups is designed to help early-stage teams accelerate development without the complexity of managing backend systems.",metaTitle:"Partnering with Google Cloud for Startups to help startups scale with confidence",tags:"Cloud",slug:"partnering-with-google-cloud-for-startups-to-help-startups-scale",contentType:"blogPost",entityId:"59E262756XyDSMeDIkmlsg",authors:[{id:"16sAl0Xh8imRribCT59nCa",name:"Brandon Moorer",slug:"brandon-moorer",jobTitle:"Project Marketing Manager, Startups",photograph:{title:"Brandon Moorer",description:"Brandon Moorer",url:"https://images.ctfassets.net/0uuz8ydxyd9p/272lfKyej0ZUapzYWM5o17/da114ecb051ca065617d78c4349c8e53/image__1_.png"},company:"Temporal",contentType:"person"}],authorsString:"Brandon Moorer",category:"Announcements",readingTime:2},{title:"Build resilient distributed Workflows with the Temporal TypeScript SDK",content:"Building resilient distributed systems can feel daunting. Edge cases, unexpected errors, and sudden worker outages pose significant hurdles, making reliable applications seem difficult to achieve. Temporals Workflow management framework, coupled with AWS infrastructure, addresses these challenges by simplifying how developers build robust, fault-tolerant applications.\nIn a recent collaboration, Temporal and AWS showcased how developers can leverage Temporals TypeScript SDK to build and manage an e-commerce order fulfillment Workflow. The demo revealed how Temporal addresses common complexities through its capabilities: state management, error handling, signals, and Workflow monitoring.\nDefining Clear Workflows\nTemporal breaks down complex business processes  such as payment processing, inventory reservation, and order delivery  into clear, manageable steps. Each Workflow step is clearly visualized in Temporals web UI, including its input, output, and duration, making execution details transparent:\nimport { proxyActivities } from '@temporalio/workflow';\n\nimport type * as activities from '../src/activities';\nimport type { Order } from '../src/interfaces/order';\n\nconst { processPayment, reserveInventory, deliverOrder } = proxyActivities\u003Ctypeof activities>({\n  startToCloseTimeout: '5 seconds',\n  retry: {\n    nonRetryableErrorTypes: ['CreditCardExpiredException']\n  }\n});\n\nexport async function OrderFulfillWorkflow(order: Order): Promise\u003Cstring> {\n  const paymentResult = await processPayment(order);\n  const inventoryResult = await reserveInventory(order);\n  const deliveryResult = await deliverOrder(order);\n\n  return `Order fulfilled: ${paymentResult}, ${inventoryResult}, ${deliveryResult}`;\n}\n\n\n  \n\nEnsuring Continuity with Worker Failover\n\n  In distributed systems, workers can occasionally fail or become unavailable. Temporal seamlessly manages these situations by preserving Workflow state and ensuring continuous execution. If one worker stops unexpectedly, another automatically picks up exactly where the Workflow left off:\n  \n  \n\nSmart Error Handling and Retries\nTemporal efficiently handles common error scenarios, such as intermittent API failures. Built-in retry mechanisms allow Workflows to automatically retry failed steps until they succeed, significantly reducing manual intervention and improving reliability:\nexport async function reserveInventory(order: Order): Promise\u003Cstring> {\n  // Simulate inventory service downtime\n  // The activity will sleep the first 3 times it is called\n  // And throw an error to simulate API call timeout\n  const { attempt } = activity.Context.current().info;\n\n  if (attempt \u003C= 4) {\n    console.log(`Inventory service down, attempt ${attempt}`);\n    await new Promise((resolve) => setTimeout(resolve, 10000));\n    throw new Error(\"Inventory service down\");\n  }\n\n  // Simulate inventory reservation logic\n  console.log(\"Reserving inventory...\");\n  await reserveInventoryAPI(order.items);\n\n  await simulateDelay(1000);\n  return `Inventory reserved for ${order.items.length} items`;\n}\n\nNot every error warrants a retry, however. Temporal recognizes non-retriable errors  such as processing payments with expired credit cards  and immediately halts execution. This approach prevents wasted resources and clearly identifies the precise reason for the Workflow failure.\nIntegrating Signals\nMany real-world Workflows require human decisions, like order approvals. Temporal manages these scenarios through signal handlers. Workflows can pause, awaiting external input, and resume immediately once the required approval or other signal is received:\nimport {\n  proxyActivities,\n  defineSignal,\n  setHandler,\n  condition\n} from '@temporalio/workflow';\n\nimport type * as activities from '../src/activities';\nimport type { Order } from '../src/interfaces/order';\n\nconst {\n  requireApproval,\n  processPayment,\n  reserveInventory,\n  deliverOrder\n} = proxyActivities\u003Ctypeof activities>({\n  startToCloseTimeout: '5 seconds',\n  retry: {\n    nonRetryableErrorTypes: ['CreditCardExpiredException']\n  }\n});\n\nexport const approveOrder = defineSignal('approveOrder');\n\nexport async function OrderFulfillWorkflow(order: Order): Promise\u003Cstring> {\n  let isApproved = false;\n\n  setHandler(approveOrder, () => {\n    isApproved = true;\n  });\n\n  if (await requireApproval(order)) {\n    await condition(() => isApproved);\n  }\n\n  const paymentResult = await processPayment(order);\n  const inventoryResult = await reserveInventory(order);\n  const deliveryResult = await deliverOrder(order);\n\n  return `Order fulfilled: ${paymentResult}, ${inventoryResult}, ${deliveryResult}`;\n}\n\nTo avoid indefinite waits, Temporal Workflows can incorporate timeouts. If a manual intervention isnt received within a set timeframe, the Workflow gracefully times out, ensuring system resources arent wasted:\nimport {\n  proxyActivities,\n  defineSignal,\n  setHandler,\n  condition,\n  sleep,\n  ApplicationFailure\n} from '@temporalio/workflow';\n\nimport type * as activities from '../src/activities';\nimport type { Order } from '../src/interfaces/order';\n\nconst {\n  requireApproval,\n  processPayment,\n  reserveInventory,\n  deliverOrder\n} = proxyActivities\u003Ctypeof activities>({\n  startToCloseTimeout: '5 seconds',\n  retry: {\n    nonRetryableErrorTypes: ['CreditCardExpiredException']\n  }\n});\n\nexport const approveOrder = defineSignal('approveOrder');\n\nexport async function OrderFulfillWorkflow(order: Order): Promise\u003Cstring> {\n  let isApproved = false;\n\n  setHandler(approveOrder, () => {\n    isApproved = true;\n  });\n\n  if (await requireApproval(order)) {\n    const approvalOrTimeout = Promise.race([\n      condition(() => isApproved),\n      sleep(30_000).then(() => {\n        throw new ApplicationFailure('Approval timed out');\n      })\n    ]);\n\n    await approvalOrTimeout;\n  }\n\n  const paymentResult = await processPayment(order);\n  const inventoryResult = await reserveInventory(order);\n  const deliveryResult = await deliverOrder(order);\n\n  return `Order fulfilled: ${paymentResult}, ${inventoryResult}, ${deliveryResult}`;\n}\n\nFor a deeper look into the TypeScript SDK demo, check out the original source code on GitHub.\nMonitoring and Debugging Made Simple\nTemporal provides a comprehensive web UI that simplifies monitoring Workflow execution. Developers can quickly identify execution steps, diagnose issues, and see exactly where Workflows succeeded or encountered problems. This transparency significantly streamlines debugging and increases reliability.\nTemporal Cloud, hosted on AWS, equips developers with powerful tools to build resilient, distributed applications more easily and effectively. By simplifying state management, handling errors intelligently, managing manual interactions smoothly, and offering clear execution monitoring, Temporal reduces complexity and improves system reliability. Check out our extensive documentation to learn all about Temporal, and share your projects with our community via Code Exchange!\nWhether youre starting fresh or enhancing existing systems, Temporal offers a practical path to building reliable distributed applications. Get started today by claiming $1000 in Temporal Cloud credits.",featureImage:{title:"social-card-temporalite-blog",description:"social-card-temporalite-blog",url:"https://images.ctfassets.net/0uuz8ydxyd9p/43c3wR1aXhf2oLpXy8WReZ/b280baada058cdc1d0dc9a4b2aaff37a/social-card-temporalite-blog.jpg"},publishDate:"2025-04-01",metaDescription:"Build fault-tolerant systems with Temporals TypeScript SDK on AWS. See e-commerce Workflow demos, smart retries, signals, and monitoring tools.",metaTitle:"Develop resilient apps with Temporal TypeScript SDK",socialCard:{title:"Blog (19)",description:"Blog (19)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5DaCLh7lajxJDjO1bKIu4x/f8a73dff65bc36f821d7226f5c0fbbd3/Blog__19_.png"},tags:"Typescript",slug:"build-resilient-distributed-workflows-with-temporal-typescript-sdk-demo",contentType:"blogPost",entityId:"JJ6HxPsAw8CQmxQvakerE",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"How-To",readingTime:5},{title:"A letter from Samarone year as CEO",content:"One year ago, I stepped into the role of CEO at Temporal, a transition that was driven by our mission to best serve the developers and organizations relying on our technology. Co-founding this company with Max has been an incredible journey, one that has allowed us to create a platform where developers can build and scale their products with confidence. As we grew,  the best way to support our future was to align our leadership with our strengths. Maxs passion for innovation and product development continues to drive Temporal forward, while I wanted to tackle a new challenge of shaping our long-term vision and supporting the incredible team that makes it all happen.\nLooking Back: A Year of Achievements\nThis past year has reinforced my belief in the power of resilience and innovation.\nAt Temporal, our mission is to redefine backend software engineering, making complex distributed systems manageable and reliable.\nOur growth this year has been strategic and purposeful. Weve built a leadership team with talent from top developer-focused and hyper-growth companies. I brought on Jim Cyb as President, leveraging his proven track record of scaling SaaS companies through hyper-growth at Duo Security and Zendesk. Clair Byrd joined as our CMO, bringing marketing expertise from Twilio, Sauce Labs, and InVision. Dan Rosanova came on board as VP of Product, bringing deep experience from Confluent and Microsoft Azure.\nIn 2024, we released Temporal Nexus, which enables teams to connect Temporal applications across Namespaces. We also released our new Ruby SDK and features for improved Worker performance and versioning. For Temporal Cloud, we added Google Cloud availability, migration tooling, features for extra high availability, and HIPAA compliance. Our .NET courses and the Code Exchange, which compile community-contributed code and sample applications, make Temporal more accessible for developers.\nThese milestones reflect the dedication of our team and the trust our customers place in Temporal. With the reflection of this year, reaching Series C funding was inevitable. Today, I'm thrilled to announce our Series C financing, which marks a significant step forward in our journey.\nLooking Ahead: Continuing our Upward Climb\nAs Temporal marks its sixth year since our founding in 2019, Temporal has been adopted by more than 183,000 weekly active open source developers and has been deployed in over 7 million unique Temporal clusters, marking 600% growth in developer adoption in the last 18 months. Temporal Cloud, our hosted commercial offering, has been adopted by over 2,500 customers globally, with revenue growing 4.4x in the past 18 months and Net Dollar Retention of 184%. We've reached a remarkable inflection point in our growth journey.\nWith that said, I'm equally proud of the incredible adoption we've seen. Companies like Noon, Airwallex, and Verkada are now running thousands of critical workflows on our platform. This growth across both startups and global enterprises validates the approach of making distributed systems easier to build, operate, and scale.\nIm proud of what weve accomplished, and Im even more excited about whats ahead. We remain committed to making distributed systems easier to build, operate, and scale, so that developers can focus on creating the future, not managing complexity.\nTo Max, our customers, partners, and the Temporal team, thank you. Your belief in us fuels our ambition. Heres to another year of pushing boundaries, solving hard problems, and empowering developers to build the resilient systems that power our digital world.",featureImage:{title:"samar-letter",description:"samar-letter",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6FMXGyJIf213Uakgn72Bmo/d7f84287cb9b220036829b07db87ea68/samar-letter.png"},publishDate:"2025-03-31",metaDescription:"Samar shares reflections from their first year as CEO of Temporal  a year marked by growth, leadership hires, major product launches, and a Series C milestone. See whats ahead for the team and community.",metaTitle:"A letter from Samarone year as CEO of Temporal",socialCard:{title:"Blog (18)",description:"Blog (18)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2zWyyGBBjw1vkw38q5eMwN/0a947857f85ad6d4c0248b2b3630828c/Blog__18_.png"},tags:"Industry Events",slug:"a-letter-from-samar-one-year-as-ceo",contentType:"blogPost",entityId:"4jZZgREKWsJozBJ7O9krlf",authors:[{id:"1xCMA9tU4DFRKfBJgJaBRo",name:"Samar Abbas",slug:"samar-abbas",jobTitle:"CEO and Co-Founder",photograph:{title:"Samar Abbas",description:"Samar Abbas",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5ET9VSHfvnFpbBEmpfoBDN/f5bd4ea1eeb428c5f8f4bcf02246ec82/861A2427.jpg"},biography:"Samar is CEO and cofounder of Temporal. He is a 20-year veteran of AWS, Microsoft and Uber engineering leadership, having worked on Amazon Simple Workflow Service from inception and led development of the Durable Task Framework at Azure, and then co-creating Cadence (Temporals predecessor) at Uber. Today, millions of Temporal workflows are run daily for high reliability and high scalability workloads from Stripe to Datadog to Snapchat.",twitterUrl:"https://twitter.com/samarabbas77",company:"Temporal",contentType:"person"}],authorsString:"Samar Abbas",category:"Announcements",readingTime:3},{title:"Temporal raises $146M Series C to power the future of durable applications",content:"Since day one, weve believed that the best way to build Temporal was to start with an incredible product, make it freely available to developers, and let adoption drive us forward. Today's results validate our belief: the Temporal community is flourishing, adoption is accelerating, and we've hit a turning point.\nTemporals open-source and cloud ecosystem have never been stronger. More than 183,000 weekly active open-source developers adopted Temporal, and deployed it in over 7 million unique Temporal clusters, marking 600% growth in developer adoption during the last 18 months. Temporal Cloud, our companys hosted commercial offering, has been adopted by over 2,500 customers globally, with revenue growing 4.4x in the past 18 months.\nWere thrilled to announce a $146M Series C funding round at a $1.72B post-money valuation, led by Tiger Global, and joined by existing and new investors. This investment reflects a strong conviction in Temporals vision, our technology, and the future of Durable Execution.\nBuilding Whats Next, Together\nThe AI revolution is here, and with it comes the need for a new backend: one that is durable, reliable, and built for the demands of intelligent, high-scale applications. Temporal is at the heart of this shift. Our combination of open-source flexibility, polyglot support, and cloud scalability makes us the natural choice for developers looking to build AI-native systems that just work.\nIts less about the technology and more about the people. The developers who rely on Temporal every day, the open-source contributors who push the boundaries of whats possible, and the engineers building the next generation of resilient applications. This funding isnt about growth for growths sake; its an investment in the community that made Temporal what it is today.\nA Community-Led Future\nTemporal has always been driven by its community. From our first open-source release to todays global adoption, developers have shaped the way we build, ship, and develop the platform. We believe that when developers have the right tools; they build the future. Our job is to support them, amplify their impact, and remove the roadblocks standing in their way.\nWith this Series C, were doubling down on that mission. More learning resources, better SDKs, deeper integrations; everything we do is in service of making sure developers can build without limits.\nWere just getting started. Thank you to every developer and contributor who has been part of this journey. The future of Durable Execution is bright, and were excited to build it together.",featureImage:{title:"series c announcement",description:"series c announcement",url:"https://images.ctfassets.net/0uuz8ydxyd9p/MVBoG5892YKspGNeJMKCC/297e7798137da896fa52756c23468388/series_c_announcement.png"},publishDate:"2025-03-31",metaDescription:"Temporal announces a $146M Series C funding round led by Tiger Global, reaching a $1.72B valuation. Learn how our thriving open-source community, rapid growth, and AI-focused vision are shaping the future of Durable Execution.",metaTitle:"Temporal raises $146M Series C to power the future of durable applications",socialCard:{title:"series c announcement",description:"series c announcement",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1U8DyM2Yb7TMe0M93cEm0l/89a9c5f2199ab9380166a150b3399635/series_c_announcement.png"},tags:"Industry Events",slug:"temporal-series-c-announcement",contentType:"blogPost",entityId:"2tOml4Y0gYqM1rtknE5CH1",authors:[{id:"4VItFICZ65R9CRGZQLE9un",name:"Allanah Hughes",slug:"allanah-hughes",jobTitle:"Communications Manager",photograph:{title:"Allanah-photo",description:"Allanah-photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4fukLvMAknnWvSkX9j9s4C/16176d8f1f1ffaeeb578a68e19ff05e7/240206-Temporal-DTLA-017-Allanah-Hughes-50NS.jpg"},contentType:"person"}],authorsString:"Allanah Hughes",category:"Announcements",readingTime:3},{title:"Why Netflix and Snap trust Temporal for scalable, reliable systems",content:"Every so often, a technology emerges that doesnt just solve a problem, it redefines how an entire industry thinks about it.\nTemporal is one of those rare innovations. Its not just another tool in the developers stack; its a fundamental shift in how organizations like Snap, Noon, Airwallex, Verkada, and Netflix approach reliability, scalability, and orchestration.\nWhat started as a powerful idea has enabled a passionate developer community; one thats expanding exponentially as more teams experience firsthand what Temporal makes possible. But what drives this momentum? And why are some of the worlds most forward-thinking companies not just adopting Temporal, but actively championing it?\nProduct Market Fit\nTemporals strength comes from its community, which continues to quadruple year after year. They share an enthusiasm and a passion thats impossible to miss. From high-growth startups to some of the worlds largest enterprises  organizations are not just using Temporal, they cant stop raving about it. Stefan Petricia, Director of Engineering at Sinch, emphasizes that Temporals unique programming model, open source posture, and out-of-the-box reliability guarantees making choosing it our de facto genetic backend a no brainer.\nAs organizations realize the need for fast, durable, and reliable Workflows, the market for a platform like Temporal is expanding rapidly. The market forces at play, such as the rise of cloud-native architectures, increasing demand for artificial intelligence, and the push for better developer productivity tools, are accelerating adoption at an incredible rate. Temporal is not just keeping up with these changes; its shaping the future of how modern applications are built.\nWhy Temporal\nTechnology is evolving at an unprecedented pace, and the demand for greater reliability, scalability, and efficiency in software development has never been higher. Across industries, engineering teams are facing increasing complexity in orchestrating microservices, managing state, and ensuring long-term reliability.\nThat growing complexity has engineers searching for better solutions that dont just patch over challenges but fundamentally improve how applications are built and operated. Temporal is answering that call.\nAs more teams recognize the need for a durable, developer-friendly approach to workflow orchestration, adoption is surging. Temporals open-source and cloud ecosystem have never been stronger. More than 183,000 weekly active open-source developers adopted Temporal, and deployed it in over 7 million unique Temporal clusters, marking 600% growth in developer adoption during the last 18 months. Temporal Cloud, our companys hosted commercial offering, has been adopted by over 2,500 customers globally, with revenue growing 4.4x in the past 18 months.\nDespite the incredible traction Temporal has already gained, were just scratching the surface. The market for Durable Execution and workflow orchestration is massive, and were at an inflection point where the need for a solution like Temporal is only growing.\nTemporal has achieved product-market fit, built a thriving developer community, and earned the trust of top customers, but what truly sets it apart is the team. The energy, passion, and talent here are unmatched. From my very first conversations with Samar and Max, I knew this was where I wanted to be.\n\n  To everyone at Temporal, thank you for the warm welcome. Im looking forward to getting to know you, hearing your ideas, and working together to push boundaries.\n  To those in the Temporal community, I am excited to learn from you. Please dont hesitate to reach out via Temporals Community Slack channel.\n\nExciting times aheadI cant wait to build the future together.\nJim Cyb recently joined Temporals Executive Leadership Team as President.",featureImage:{title:"jimannouncement",description:"jimannouncement",url:"https://images.ctfassets.net/0uuz8ydxyd9p/23BC6Q6EKoxXKlTwd0nY1H/20d427b69ea69b8a90c5f238e0103268/jimannouncement.png"},publishDate:"2025-03-31",metaDescription:"Temporal is changing how companies like Netflix and Snap build reliable, scalable systems. Learn why adoption is growing and what's driving the momentum.",metaTitle:"How Temporal redefines reliability and orchestration",socialCard:{title:"jimannouncement",description:"jimannouncement",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4Ic6bSI7igSQEGlszeVsW6/108ee5ce685741330e584d1960b14318/jimannouncement.png"},tags:"Scaling",slug:"why-temporal-jim-cyb",contentType:"blogPost",entityId:"4oCaH2wwusEOA2tvgVpFVF",authors:[{id:"3LlQAdoyzz6CEmKHmL6ekV",name:"Jim Cyb",slug:"jim-cyb",jobTitle:"President",photograph:{title:"Jim Cyb",description:"Jim Cyb",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5Oy18SVGd25gTskaTnEwFc/b978f42f743c865261129432a2453dcb/861A2473.jpg"},biography:"More to come!",company:"Temporal",contentType:"person"}],authorsString:"Jim Cyb",category:"Temporal Voices",readingTime:3},{title:"Durable Digest: March 2025",content:"This blog post is a public copy of our monthly newsletter. If youd like to receive upcoming updates by email, you can subscribe to our newsletter here.\nReplay 2025 Was One for the Books! Were still energized from an incredible few days at Replay 2025 in London. It was amazing seeing our community come together for hands-on workshops, insightful keynotes, and real-world case studies on durable execution and workflow orchestration.\nCouldnt make it  or want another look? Weve got you covered. Head over to our website for session recordings, daily recaps, and all the product news announced during the event.\n\n  \n    Product Announcements: Weve rolled out some big updates  like our new Ruby SDK, the official launch of Nexus, a handy zero-downtime migration tool, and major improvements to Temporal Cloud. Read more here.\n  \n  \n    Session Videos & Daily Blogs: Revisit your favorite talks, check out our daily blog posts, and flip through photo galleries from the event. Access them here.\n  \n\nLooking ahead, were already planning Replay 2026 and cant wait to share more details with you soon. Stay tuned for updates as we continue to build upon the success of Replay 2025 and bring our community together for another unforgettable experience.\nProduct Updates\nIn case you missed it, we made some exciting product announcements at Replay 2025. Here are the top updates:\n\n  Nexus is Generally Available\n  New zero-downtime migration tooling for self-hosted users looking to adopt Temporal Cloud\n  Expanded high availability features in Temporal Cloud\n\nSDK Updates\n\n  Ruby SDK v0.3.0 marks the Ruby SDK as Pre-release. Submit feedback via GitHub or ask questions in Community Slack.\n  Go SDK 1.33.0 introduces new versioning APIs, fixes a known workflow reset issue, and adds Nexus support (note server version requirements).\n  Java SDK 1.28.0 (and up) multiple releases include Nexus support, API key usage updates, and enhanced API key support for Spring Boot integration.\n  Python SDK 1.10.0 adds official support for Pydantic, along with changes to Python version compatibility.\n  Temporal CLI v1.3.0 includes standard updates to the latest versions of UI Server and Temporal Server, plus 30+ feature requests, fixes, and new command exposures.\n\nCode Exchange\nWe just launched the Temporal Code Exchange: a curated library of community-driven code samples, example apps, and innovative projects showcasing creative ways to use Temporal.\nWere starting strong with 15 practical examples across Python, Go, TypeScript, .NET, and Java. Highlights include:\n\n  Multi-agent workflow orchestration library\n  eCommerce application with Stripe integration\n  Full-stack template for building apps quickly with Temporal and React\n  Workflow visualization toolkit for end-to-end monitoring\n  Insurance application workflow samples\n\nWell regularly refresh the collection with new community contributions.\nHow to ContributeWe welcome submissions! Visit the Community GitHub repository via the Code Exchange to share your own projects or team up with other Temporal developers. Lets see what we can build together.\nEvents\nAWS Summit Paris: April 9 | Paris, France\nWere excited to announce that Temporal will be at AWS Summit Paris on April 9th at the Palais des Congrs de Paris. Swing by our booth for live demos showcasing how Temporal can revolutionize your application development, particularly in AI-driven solutions. To schedule a personalized meeting with our team during the summit, please visit our event page.\nGoogle Cloud Next: April 911 | Las Vegas, NV\nMeet the Temporal team at Google Cloud Next! Stop by Booth 1801 in the Mandalay Bay Convention Center and see how Temporal is redefining how you build modern applications. Dive into live, interactive demos to explore advanced Workflow orchestration, fault-tolerant microservices, and stateful application development at scale.\nWant to go deeper? Request a meeting with our founders or set up time with one of our Temporal experts.\nThis is your chance to get hands-on, connect with the creators of Temporal, and discover how it can transform your architecture. Well see you there!\nPyTexas: April 1113 | Austin, TX\nSee how Temporal is revolutionizing application development with durable execution and Workflow orchestration. Stop by our table and learn how Temporal can simplify your architecture and supercharge your Python applications.\nAWS Summit Amsterdam: April 16 | Amsterdam, Netherlands\nExciting news! Temporal is heading to AWS Summit Amsterdam on April 16th at The RAI. Visit our booth for exclusive demos and engaging conversations about simplifying stateful application development with Temporal, including leveraging AI to enhance your workflows. To arrange a one-on-one meeting with our experts during the event, please visit our event page.\nBengaluru Meetup: April 15 | Bengaluru, IN\nWere excited to announce the Temporal Community Meetup in Bengaluru on April 15, 2025, from 6:30 PM to 9:30 PM, at the Courtyard by Marriott Bengaluru. Join us for an evening of technical talks, networking, and refreshments, featuring insights from Temporal experts and industry leaders. Dont miss this opportunity to connect with fellow developers and learn more about building reliable, scalable applications with Temporal. For more details and to RSVP, visit our event page.\nDevoxx France: April 1618 | Paris, France\nExciting news! Temporal will be at Devoxx France 2025, happening April 1618 at the Palais des Congrs in Paris. Our own Mal will be present at our partner Takimas booth (D06), ready to discuss how Temporal can enhance your development processes. Takima, a Diamond sponsor of the event, is known for their expertise in innovative and robust solutions. Swing by to connect with Mal and explore the future of application development together!\nWebinars\nHow to Build AI Agents with Python & Temporal\nJoin us on April 3 at 9 AM PST/12 PM EST to explore agentic AI workflow creation using Temporals Python SDK, including a live demo.\nResources\nThe Education team is hosting a Temporal 101 in .NET webinar on April 9 at 9:00 AM PST. Register here!\nCommunity Shout-Outs\n\n  Phil Calado continued his Building AI Products blog series (Part I, Part II) that uses Temporal on the backend to create an AI-powered Chief of Staff for engineering leaders.\n  Also on the AI train, Long Quanzheng wrote Build Reliable AI Agents with Indeed Workflow Framework on Temporal  check out the demo of an AI-powered email agent capable of composing, translating, and scheduling emails with auto-save drafting and cancellation features.\n  For all you Infrastructure as Code fans out there, you can now use the new Pulumi Temporal Cloud Provider as an alternative to the Terraform Temporal Cloud Provider.\n  This month, we received four new submissions to Code Exchange:\n    \n      Cross-Language Data Processing Service with Temporal (Bar Moshe) demonstrates how Temporal empowers teams to seamlessly orchestrate complex data processing workflows across multiple programming languages. Specifically, it showcases how Go, Python, and TypeScript can interoperate smoothly within a single, scalable workflow.\n      Go Code Generation with Temporal & Protobufs (Chris Ludden) generates code for Temporal workflows from Protobuf definitions, automating client and worker creation. It simplifies development by converting structured workflow definitions into runnable code, reducing manual effort and ensuring consistency.\n      kairos-cli (Sepehr Sobhani) is a snappy cli application that allows you to maintain your flow state while allowing you to open a workflow in the cloud for a richer experience and deeper analysis.\n      Indeed Workflow Framework (iWF) (Indeed Engineering Team) is a framework built on top of Temporal that simplifies the development, management, and orchestration of long-running, asynchronous workflows. It provides clear abstractions so you can focus on business logic.\n    \n  \n",featureImage:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},publishDate:"2025-03-27",metaDescription:"Explore Temporals latest developer updates: questions from the field, new releases, builder spotlights, learning resources, and ways to connect with our team.",metaTitle:"Durable Digest: March 2025",socialCard:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},tags:"",slug:"durable-digest-march-2025",contentType:"blogPost",entityId:"T2kEZfFRtOu0gfw17rGN7",authors:[{id:"17hGmNrCwtXdBh7fhsLUnZ",name:"Temporal Technologies",slug:"temporal-technologies",photograph:{title:"temporal technologies logo",description:"temporal technologies logo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3g56zRXtFQYMeJxBBkVBIZ/7771670e5fc7da59f555837b086c35d6/temporal_technologies_logo.avif"},company:"Temporal Technologies",contentType:"person"}],authorsString:"Temporal Technologies",category:"Announcements",readingTime:7},{title:"Join the Temporal Code Exchange!",content:"We've just launched something special for our global community of developers: Temporal's Code Exchange is now live!\nThe Temporal Code Exchange is your new hub for discovering and contributing to open-source projects, designed to make it easier and more enjoyable than ever to build with Temporal.\nWhat's the Code Exchange?\nThe Code Exchange is a curated collection of real-world examples, sample applications, and reusable libraries showcasing what's possible when you build with Temporal. To kick things off, we've launched with 12 fantastic examples covering five programming languages:\n\n  Python\n  Go\n  TypeScript\n  .NET\n  Java\n\nHere's a taste of what's available right now:\n\n  Orchestrate multi-agent workflows: Explore Jerron Lims powerful library designed to simplify and orchestrate complex multi-agent workflows. Perfect for AI-driven applications and automation at scale.\n  eCommerce app with Stripe integration: Dive into Cecil Phillips fully functional eCommerce sample app that integrates seamlessly with Stripe for payments. See firsthand how Temporal workflows streamline transaction reliability and customer experience.\n  Full-stack Temporal and React template: Quickly build powerful, scalable full-stack applications using J.D. Nicholls ready-to-go template, simplifying your development process and speeding up your time-to-launch.\n\nOur initial examples are just the beginning; our goal is to create a thriving collection of community-built projects that highlight your brilliance and the endless possibilities with Temporal across multiple languages and use cases.\nHow the Code Exchange Helps You\nWe know the Temporal community is packed with talent, creativity, and a willingness to collaborate. The Code Exchange was built with you in mind, designed to:\n\n  Get started easier: See real-world examples that make building your own Temporal project a breeze.\n  Find inspiration: Check out the clever, quirky, and downright genius projects your fellow developers are cooking up; you might just find your next big idea!\n  Collaborate and innovate: Team up with fellow developers, contribute to exciting projects, or throw your wildest ideas into the mix.\n\nWhether you're just starting out with Temporal or you're a seasoned developer looking to take your Workflows to up a notch, the Code Exchange has something for everyone.\nGet Involved\nThis is your chance to build something amazing, learn from others, or simply explore new ideas that can help elevate your Temporal projects. Our repository is always open, and we encourage ideas, suggestions, and collaboration.\nHeres how to get started:\n\n  Visit our Code Exchange page to explore available projects.\n  Head over to our GitHub repository for guidance.\n  Submit your own project, or share an idea to collaborate with other community members.\n\nWe're excited to see what the community creates together. Start exploring today, and let's build something incredible!",featureImage:{title:"hassaan-here-Ype8P9pAjXQ-unsplash (1)",description:"hassaan-here-Ype8P9pAjXQ-unsplash (1)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/KvEfARajfbO29cCpW6LFk/41429439f78f47be8e077b611fe16f23/hassaan-here-Ype8P9pAjXQ-unsplash__1_.jpg"},publishDate:"2025-03-21",metaDescription:"Explore the Temporal Code Exchangeyour hub for community-driven code, example apps, and reusable libraries across languages. Contribute and learn today!",metaTitle:"Introducing Temporal Code Exchange for collaboration",socialCard:{title:"Code-exchange-collaborate-build-innovate",description:"Code-exchange-collaborate-build-innovate",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6gEpFZkE377ZM63sDp1Itp/6b4d68a8e136d1393997d7e265874262/Code-exchange-collaborate-innovate.png"},tags:"Industry Events,Contributions",slug:"join-temporal-code-exchange",contentType:"blogPost",entityId:"6dhc21jIulwE9gD5HipdHd",authors:[{id:"1Rx1K2ufd9SesyVQyEp7tt",name:"Matt Pyle",slug:"matt-pyle",jobTitle:"Sr. Manager, Growth",photograph:{title:"Matt Pyle",description:"Matt Pyle",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1ncTM42YT5cQty0mu08Xuo/27fd5e72dfd42dc55a8dd485a3912bea/mattpyle.jpeg"},company:"Temporal",contentType:"person"},{id:"18qI9Klto8BBXF4qObF8ET",name:"Angie Byron",slug:"angie-byron",jobTitle:"Senior Manager, Developer Advocacy & Community",photograph:{title:"Angie Byron",description:"Angie Byron",url:"https://images.ctfassets.net/0uuz8ydxyd9p/lBQUFwdlhhE1sWJ6Hkkyy/f00ae0b4854ad0b750e0f01297cffcc7/IMG_6961.jpeg"},biography:"Angie has been herding open source cats for 20+ years and in her spare time enjoys videos games, doodling silly cartoons, and wakka wakka wakka!",twitterUrl:"https://x.com/webchick",linkedInUrl:"https://www.linkedin.com/in/webchick/",website:"https://webchick.tech/",company:"Temporal",contentType:"person"}],authorsString:"Matt Pyle, Angie Byron",category:"Announcements",readingTime:3},{title:"Designing high-performance financial ledgers with Temporal",content:"Financial systems live and die by their ledgers. Whether youre running a bank, a fintech startup, or a payment processor, getting the ledger right is fundamental  because getting it wrong means losing customer funds, eroding trust, and inviting regulatory scrutiny. Kris Hansen, CTO at investment management firm Sagard, has spent years working on this problem.\nIn his experience, a well-designed ledger is not just about recording transactions; its about handling scale, ensuring resilience, and maintaining trust. To help businesses navigate these challenges, Kris authored a comprehensive white paper on designing high-performance financial ledgers, which serves as a deep dive into the key considerations for building a robust ledger system.\nIn a recent discussion, Kris outlined the core principles of high-performance financial ledgers and explained why Temporal is uniquely positioned to solve many of the challenges associated with ledger design.\nThe Three Core Challenges of Ledger Design\nKris identifies three critical elements that define a robust financial ledger:\n\n  High-Performance Transaction Handling  A ledger must be capable of processing transactions at scale, responding quickly even when external partners experience downtime and flood the system with backlog transactions.\n  Double-Entry Bookkeeping and Internal Account Balances  The ledger should be built on well-established accounting principles to ensure financial integrity. Any discrepancy, even by a few cents, can indicate a deeper issue that needs to be traced and resolved.\n  Flexible Transaction Metadata  Financial transactions come with a variety of metadata requirements that evolve over time. If your system isnt flexible enough to handle new payment rails or reconciliation processes, youll be forced into painful rework.\n\nThe challenge is that these three principles often conflict. High-performance processing demands efficiency, but rich metadata introduces complexity. The key is designing an architecture that balances both.\nWhy Temporal Is a Game-Changer for Ledger Design\n\n  Ledgers involve multiple moving parts, often requiring coordination between high-speed transaction engines and robust metadata layers. This is where Temporal comes in.\n  Temporal provides durable execution, ensuring that complex workflows dont fail due to network issues, service downtime, or process crashes. It enables a ledger architecture that combines:\n\n\n  A high-speed transaction layer  Something like TigerBeetle, optimized for rapid transaction processing.\n  A metadata-rich accounting layer  A system like Formance to handle reconciliation, compliance, and reporting.\n  \n    A reliable transaction durability layer  Temporal acts as the glue between these components, guaranteeing that transactions complete successfully, even in the face of failures.\n    \n    \n    \n  \n\nHow Temporals Features Strengthen Financial Ledgers\nA well-designed ledger must not only process transactions but also ensure integrity, recoverability, and auditability. Temporals approach to durable execution offers several key advantages:\nStateful Workflows for Transaction Integrity\nEvery transaction is tracked as a long-running, stateful Workflow, ensuring that operations remain consistent even if parts of the system fail.\nAutomatic Retries and Failure Handling\nTraditional ledger systems require extensive error handling to deal with API failures, database issues, and network timeouts. Temporal eliminates the need for custom retry logic by handling failures natively.\nGuaranteed Execution for Reconciliation\nMany financial workflows require multi-step processing, such as reconciling accounts across different systems. Temporal ensures that these steps execute in order, with full visibility into their completion status.\nScalability for High-Volume Transaction Processing\nFinancial services need to handle millions of transactions per second. Temporals architecture allows Workflows to scale dynamically, ensuring that spikes in transaction volume dont lead to failures or delays.\nEnd-to-End Visibility for Auditing and Compliance\nTemporal provides an Event History of every Workflow, making it easier to audit transactions and meet regulatory requirements. This is crucial for financial institutions that need provable correctness in their ledgers.\nFlexible Workflow Orchestration\nUnlike rigid batch processing systems, Temporal enables event-driven workflow execution, allowing financial institutions to adapt to real-time changes in their transaction flows.\nReal-World Example: Handling Reconciliation at Scale\n\n  One of the toughest problems in financial services is reconciliation. Payments are messy  settlement can take days, amounts can change between authorization and finalization, and transactions can arrive out of order. A system that doesnt handle these nuances will break under real-world conditions.\n  With Temporal, each transaction can be tracked as a separate Workflow, ensuring that:\n\n\n  Payments dont get lost or duplicated.\n  Metadata stays intact, making troubleshooting and audits easier.\n  Suspense accounts and reconciliation logic are handled correctly, preventing financial imbalances.\n\nBuild vs. Buy: Should You Create Your Own Ledger?\n\n  Many fintech startups initially assume that a ledger is just a simple table in a database. But a transaction log is not the same as a ledger. A robust financial ledger requires transaction integrity, auditability, and real-time reconciliation  features that arent trivial to implement.\n  If your ledger is a core differentiator for your business, building it from scratch might make sense. But if youre looking for a reliable, scalable solution with built-in support for reconciliation, metadata management, and regulatory compliance, buying (or integrating with an existing ledger framework) could be the smarter choice.\n\nMoving Forward\n\n  If youre designing a financial ledger, consider the long-term challenges from day one. High-speed processing, compliance, reconciliation, and metadata management all need to be built into your architecture. By leveraging Temporals durable execution model, you can ensure that your ledger is not just functional, but future-proof.\n  Want to explore how Temporal can help streamline your ledger architecture? Check out our documentation and get started today.\n",featureImage:{title:"social-card-purple",description:"social-card-purple",url:"https://images.ctfassets.net/0uuz8ydxyd9p/UbL8tEOAIBjMrI6OCSeNN/62aecca8ce16e11e288c1fd7ef4e346d/social-card-purple.jpg"},publishDate:"2025-03-18",metaDescription:"Learn how Temporal's durable execution solves core challenges  scalability, reconciliation, and compliance  to create reliable, future-proof ledger systems.",metaTitle:"Designing Robust Financial Ledgers with Temporal",socialCard:{title:"Blog (15)",description:"Blog (15)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4m88IuPss9wKGIDbkFhllA/08f86025b1ad14825ab72f2cdc5f8672/Blog__15_.png"},tags:"Batch Processing,Cloud,Finance",slug:"designing-high-performance-financial-ledgers-with-temporal",contentType:"blogPost",entityId:"cCPF8X2ZgK5Qgw6obVonE",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"Temporal Concepts",readingTime:5},{title:"Replay 25, day three: Wrapping up in style",content:"The final day of Replay 25 delivered a mix of technical deep dives and real-world case studies before concluding with an unexpected twist. After two days packed with hands-on learning and insightful talks, attendees gathered for the last round of knowledge sharing focused on practical applications of Temporal.\nBuilding for reliability\n\n  Temporals Sergey Bykov kicked off the day with an engaging comparison between application reliability and the Three Little Pigs fairy tale. He traced the evolution of reliability requirements and explained how redundancy enhances resilience while introducing new coordination challenges.\n  \n  \n  This theme continued with Wise Payments approach to managing databases at scale. With 16 million customers worldwide and downtime tolerance measured in milliseconds, Samira El Aabidi and Yash Vanzara demonstrated how theyre using Temporal to enable self-service automation for critical database operations, integrating with AWS to handle issues with minimal human intervention.\n  \n  \n\nProduction patterns and enterprise adoption\n\n  Several sessions highlighted the journey from basic workflows to production-grade systems. Mercurys Ian Duncan shared insights from building financial infrastructure with Temporal, focusing on testing approaches, transactional safety, and performance optimizations in their Haskell SDK.\n  \n  \n  Following the previous days product announcements, Temporals Drew Hoskins and Shahab Tajik introduced Worker Versioning APIs, providing guidance on implementing these new capabilities to make deployments safer and more controllable.\n  \n  \n  Enterprise adoption stories came from companies like Nutanix, where Bharadwaj Embar shared three years of production experience using Temporal for platforms engineering. His examples ranged from simplified Kubernetes workload management to access control systems, demonstrating how Temporal solves problems at multiple layers of their stack.\n\nCritical systems and cross-boundary orchestration\n\n  Some of the most compelling stories came from organizations using Temporal for mission-critical applications. Verkadas Sai Teja Reddy Moolamalla explained how their cloud-based alarm system uses Temporal to build durable alarm responses for AI-powered security systems, where reliability is essential for monitoring and dispatch workflows.\n  \n  \n  One highlight was Miros presentation with Temporals Phil Prasek on Temporal Nexus. Pedro Albuquerque and Juan Agustn Moyano explained how they built a self-healing control plane for storage infrastructure, then leveraged Nexus to orchestrate cross-region data migrations without direct network connectivity.\n\nKOHOs Ali Waseem shared a particularly relatable crisis response story, detailing how they adopted Temporal mid-flight during a critical development cycle. Their team integrated Temporal to maintain service reliability during a vendor's severe outage, turning what could have been a major incident into a non-event for their users.\nTemporal Across Industries\n\n  The technical program concluded with Checks Sam Wilson explaining how they transformed payroll processing using Temporal. By combining microservices principles with durable execution, theyve achieved significant improvements in reliability and development speed while processing billions in wages.\n  \n  \n  Other industry applications spanned pharmaceutics (Eli Lilly), telecommunications (Telenor), retail (Trendyol Group), and global infrastructure (Equinix), each demonstrating how Temporal addresses unique challenges in their respective domains.\n\nEnding on a high note: The Tech Roast and afterparty\n\n  In a fun twist, Replay 25 closed with the Tech Roast Show making its London debut. This comedy troupe brought sharp tech satire to the stage, providing a light-hearted conclusion to three days of intensive learning.\n  \n  \n  \n  \n  The evening continued with an afterparty, where attendees had a final opportunity to network and continue discussions in a relaxed setting.\n\nReplay 25 is over, long ;ive Replay 26!\n\n  As Replay 25 concluded, the impact of Temporals flagship developer event was clear. With new tools like Ruby SDK, Nexus, and Worker Versioning now available, the community departed with fresh approaches to tackling their workflow orchestration challenges  until Replay 26. Thank you for joining us!\n  \n  \n  Want to relive the conference highlights? Check out our Google Photos album for a visual journey through all three days of Replay 25.\n",featureImage:{title:"ziggy-space-replay-25",description:"ziggy-space-replay-25",url:"https://images.ctfassets.net/0uuz8ydxyd9p/48JgGReZ8OoE4c2Uf6ut0h/afae7b0a094629e576fbb3fffae82861/DSC_1012.jpg"},publishDate:"2025-03-07",metaDescription:"The final day of Replay 25 delivered a mix of technical deep dives and real-world case studies before concluding with an unexpected twist.",metaTitle:"Replay 25, day three: Wrapping up in style",socialCard:{title:"Blog (13)",description:"Blog (13)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2cOhrMTSvIcGnJa8AxH8l6/7f2ead7a5dd0951a1fdbb6df44fa089b/Blog__14_.png"},tags:"Replay",slug:"replay-25-day-three",contentType:"blogPost",entityId:"5Lz6D56mI3Ec6WzbQoD4Ty",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"Community",readingTime:4},{title:"Replay 25, day two: Big announcements, real-world wins, and Durable Execution",content:"\n  \n  Day two of Replay 25 in London shifted from hands-on learning to real-world applications, with the Bishopsgate Forum packed for the mornings keynote.\n\nKeynote: Expanding the Temporal Ecosystem\nAngie Byron opened the keynote in memorable fashion, sporting full medieval gear (including actual chainmail!), to welcome attendees to the second day.\n\n  Following this unique introduction, Temporals leadership team  including co-founder and CTO Max Fateev, SVP of Engineering Preeti Somal, Engineering Manager Liang Mei, and Senior Staff Solutions Architect Steve Androulakis  took the stage to unveil a series of exciting announcements.\n  \n  \n  The keynote revealed several major product launches: the Pre-Release Ruby SDK with full feature parity, General Availability of Nexus for connecting workflows across teams, enhanced high availability through namespace replication, safer Worker versioning APIs, zero-downtime migration tooling, Temporal Cloud on Google Cloud, and new security and operations tools.\n  \n  \n  For full details on these announcements, check out the Replay 25 Product Announcements blog or watch the full keynote here.\n\nThe keynote set the context for a day focused on how companies are using Temporal in production environments.\nTemporal in the Wild: From Telecom to Finance\n\n  The morning and early afternoon featured case studies showing Temporals versatility:\n  Vodafones James Irwin shared how theyre using Temporal in their Customer Premise Equipment Management Platform. Their implementation supports USP, a standardized protocol that lets them add new services to connected devices dynamically.\n  \n  \n  Chandan Bhattad from noon described their journey from Airflow to Temporal for data pipeline orchestration. What started as a solution for specific data challenges expanded as other teams adopted Temporal.\n\n\n  Datadogs Hardy Ferentschik and Marcos Cela Lpez gave an unvarnished look at self-hosting Temporal at scale. They detailed the realities of managing dozens of clusters over four years, including handling compute outages, misconfigurations, and critical incidents.\n  \n  \n\nBuilding Better Applications\n\n  The technical sessions continued with Tihomir Surdilovics deep dive into the Temporal Spring Boot integration thats approaching GA status. His session covered configuration, observability, scaling, and testing  key information for Java developers working on production applications.\n  \n  \n  Tom Wheelers talk on Durable Execution posed a question: How would you code if your application could not fail? Tom compared how senior engineers and beginners approach projects, noting that experienced developers design for failure modes that beginners often overlook.\n\nTransforming Business Operations\n\n  The afternoon showcased companies using Temporal to modernize their systems:\n  Sonnya Dellarosa explained how Mollie transformed from a PHP monolith to Java-based microservices orchestrated by Temporal. Their customer onboarding process now uses multiple concurrent workflows, making complex financial processes more intuitive while improving efficiency for both development and operational teams.\n  \n  \n  Salesforces Trevor Grieger and Austin Deal tackled the challenge of migrating Marketing Cloud across substrates. Building on their presentation from last year about delivering Temporal at scale, they showed how they're coordinating this massive effort across dozens of teams and a codebase spanning over 1000 engineers.\n\nSolving Practical Problems\n\n  The final sessions brought practical solutions to common challenges:\n  Mitsufumi Kikyotani from Airwallex showed how they stabilized their global financial platform by wrapping legacy microservices with Temporal. This approach reduced incidents and increased developer productivity sixfold without requiring a complete rebuild.\n  \n  \n  Maersks Szymon Bohdanowicz and Andrey Dubnik demonstrated their internal developer platform that serves 4,500 engineers. Their platform automates application setup, repository creation, deployment workflows, and infrastructure provisioning.\n\n\n  Marco Reni from Mediaset and Jacopo Tagliabue from Bauplan outlined their switch from Airflow+EMR to Temporal+Bauplan. This change helped Mediaset, one of Europes largest broadcasters, process 150GB of data daily through a streamlined Python-native platform.\n  \n  \n  Gytis Ramanauskas concluded by showing how Vinted manages payment flows for Europes largest second-hand marketplace. Their integration of Temporal into a Ruby-based payments system handles millions of daily transactions with improved reliability.\n\nLooking Ahead\n\n  \n  Day two showed that Temporal serves as more than just a workflow engine  its becoming a fundamental part of resilient system design. The diverse implementations, from self-hosted deployments to cloud integrations, demonstrated Temporal's adaptability across technical environments and business domains.\n\nThe second day wrapped up with anticipation building for day three of Replay 25.",featureImage:{title:"replay-25-max-main",description:"replay-25-max-main",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2hK5QVcRD5AmpCOAUi9F3r/5ab114b7bad0cd6c5bb48ee72990ece9/DSC_8781__1_.jpg"},publishDate:"2025-03-06",metaDescription:"Catch up on day two of Replay 25 in London, featuring big announcements from Temporal, real-world success stories across telecom, finance, and technology sectors, and practical insights into durable system execution.",metaTitle:"Replay 25 day two recap: Major product announcements, customer stories, and Durable Execution",socialCard:{title:"Blog (12)",description:"Blog (12)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/46nYM591lAYzdg7dT51pOi/44b03096bab00a136cb9b089df6b31ca/Blog__12_.png"},tags:"Replay",slug:"replay-25-day-two",contentType:"blogPost",entityId:"7Ff6zk8Qk6rczFDs4ik2RG",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"Community",readingTime:4},{title:"Temporal Nexus is now generally available",content:"Today, were excited to announce that Temporal Nexus is now generally available! Nexus allows you to connect Temporal Applications within and across isolated Namespaces and provides all the benefits of Durable Execution with improved modularity, security, debugging, and fault isolation.\nUnlike other forms of inter-service communication, Nexus is built with Durable Execution in mind. It combines a familiar programming model with the resiliency of Temporal to provide reliable state-based execution, built-in observability, and multi-region connectivity in Temporal Cloud across AWS and GCP.\n\n  \n\nUsed in production by companies like Netflix and Miro\nTemporal Nexus is used by companies like Netflix and Miro to connect Temporal Applications across teams, Namespaces, and cloud regions.\n\n  Netflix aims to allow each team to own their own Namespace and call into each other to build abstractions on top of each others Workflows. When a Durable Execution spans teams, you often want to delegate a portion of the overall Workflow to another team with Workflows running in a different Namespace, but want a clean service contract that doesnt share too much.\n  Miro needed to enable cross-region data migration with a hierarchy of complex Workflows that took days or weeks to complete across isolated regions with no network connectivity or entry points for remote execution.\n\nPreviously, this required building custom API proxies and webhooks to facilitate cross-namespace collaboration. Teams had to handle complex tasks like setting up authentication and authorization (AuthZ), ensuring security, and managing cross-namespace failure scenarios. This was a lot of undifferentiated heavy lifting that could be simplified and even then you didnt get first-class observability and execution debugging.\nA fully integrated Temporal experience\nNexus GA provides a fully integrated Temporal experience where you can use the Temporal SDK to spin up Nexus Operation handlers in Temporal Workers that expose clean service contracts for others to use through a Nexus Endpoint, which is a reverse proxy for your Nexus Services. Nexus Operations are used to abstract underlying Temporal primitives, like Workflows, or execute arbitrary code. Nexus calls can be made from caller Workflows within and across Namespace boundaries, which solves the immediate problem of cross-namespace calls in Temporal.\nNexus GA is supported in both the Open Source and Temporal Cloud, and enables you to:\n\n  Build Nexus Services with the Go SDK & Java SDK - others coming soon!\n  Run Nexus Services with Temporals queue-based Worker architecture.\n  Use Nexus Operations through a Nexus Endpoint, a reverse proxy for Nexus Services.\n  Enhance reliability with at-least-once and exactly-once execution guarantees.\n  Secure sensitive Workflow state with isolated Namespaces for each team.\n  Debug cross-namespace calls with integrated observability.\n\nTemporal Cloud provides enhanced Nexus capabilities:\n\n  Connect Temporal Applications within and across regions in AWS and GCP.\n  Control access to Nexus Endpoints with built-in policy enforcement.\n  Audit changes to Nexus Endpoints and monitor Nexus metrics.\n\nSince the Nexus Public Preview was announced last year, Nexus GA has been focused on:\n\n  Enhanced stress testing and hardening.\n  SDK ergonomics: tracing, error rehydration, and metrics failure tagging.\n  Circuit breaker visibility and enhanced bi-directional links in the Temporal UI.\n  Multi-cloud Nexus connectivity across AWS and GCP in Temporal Cloud.\n  Support for multi-region Namespaces as Nexus Endpoint targets in Temporal Cloud.\n  Terraform support for managing Nexus Endpoints in Temporal Cloud.\n\nThe road ahead\nThe Nexus roadmap is currently focused on 3 key themes:\nConnect from more places:\n\n  Nexus calls from non-workflow callers (bash, service, app)\n  Non-namespace credentials to establish a Nexus caller identity\n  Connect OSS and Temporal Cloud\n\nDevelop in any language with a better developer experience:\n\n  All Temporal SDKs support Nexus\n  SDK ergonomics and richer semantics\n  Service contract IDL & code generation\n\nOperate shared services with enhanced visibility & control:\n\n  Multi-tenant visibility and rate limiting\n  Fine-grained authorization\n  Enhanced routing rules\n\nGet started with Nexus today!\nLearn how Nexus connects Temporal Applications and provides all the benefits of Durable Execution within and across Namespace boundaries with improved modularity, security, debugging, and fault isolation.\n\n  Watch the Nexus GA talk at Replay London 2025 with Miro and the Nexus team.\n  Watch the webinar featuring Netflix and the Nexus team.\n  Join the #nexus community channel in Temporal Slack.\n  Evaluate why you should use Nexus and watch the Nexus keynote and demo.\n  Learn key Nexus concepts and how Nexus works in the Nexus deep dive talk.\n  Build your first Nexus service using the Go SDK and Java SDK quick starts.\n  Explore additional resources to learn more about Nexus\n",featureImage:{title:"buddha-elemental-3d-br5JFHhkoIA-unsplash (1)",description:"buddha-elemental-3d-br5JFHhkoIA-unsplash (1)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6KZNZOYRsAXONUbNuA5V7f/2f1ec7f2dd615ca6d4bb766d98271bff/buddha-elemental-3d-br5JFHhkoIA-unsplash__1_.jpg"},publishDate:"2025-03-06",metaDescription:"Temporal Nexus is now generally available! Nexus allows you to connect your Temporal Applications across isolated Namespaces.",metaTitle:"Temporal Nexus is now generally available",socialCard:{title:"Temporal-Nexus-generally-available",description:"Temporal-Nexus-generally-available",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1ueL0rsuEl2QHtZHFo5vD5/74c68614df65991ebb025cf7d85fdca3/Temporal-Nexus-generally-available.png"},tags:"Temporal Primitives",slug:"temporal-nexus-now-available",contentType:"blogPost",entityId:"4EIjnhDkZq4dWoFbaY9oG",authors:[{id:"3Kphz7jmScrDXEXQXzv3Or",name:"Phil Prasek",slug:"phil-prasek",jobTitle:"Sr. Staff Product Manager",photograph:{title:"Phil Prasek Headshot",description:"Phil Prasek Headshot",url:"https://images.ctfassets.net/0uuz8ydxyd9p/25ix1Mi0zw7jnVTdMPJPzl/8bf86d92d6e4b23dc89924397d10a3cf/Phil_Prasek_Headshot.png"},biography:"Phil is a Sr. Staff Product Manager at Temporal where he is working on durable execution in multi-team environments. Phil previously led Product for the core platform at Apollo GraphQL including Apollo Federation and the Apollo Router, a high-performance supergraph runtime. Phils past roles at Upbound working on Crossplane, Chef, and HPE bring over two decades of experience with a mix of open source and enterprise in dev tooling, control planes, and infrastructure as a service. Phil also enjoys skiing and hiking in the Pacific Northwest.",company:"Temporal",contentType:"person"}],authorsString:"Phil Prasek",category:"Product News",readingTime:4},{title:"Expanding Temporal Clouds high availability offerings",content:"We are pleased to announce that Multi-region Replication (previously known as Multi-region Namespaces or MRN) is now Generally Available (GA) in Temporal Cloud. We are also launching a new capability, Same-region Replication, in Public Preview.\nThese advancements further enhance Temporal Clouds High Availability (HA) offerings, providing robust solutions for maintaining operational continuity and meeting stringent availability requirements.\nHigh Availability in Temporal Cloud\nTemporal Cloud is designed with reliability and availability built into its foundations. Temporal Cloud provides a contractual service level agreement (SLA) of 99.9% guarantee against service errors for all Namespaces, which meets the needs of many use cases.\nIn addition, for critical use cases, Temporal Cloud offers a suite of High Availability (HA) features that organizations can enable for 99.99% SLA. Temporal Clouds HA features ensure that your Workflows remain operational even during unexpected disruptions. When HA features are enabled, Temporal Cloud automatically synchronizes data between a primary and a replica, keeping them in sync. In the event of an incident or outage, the system seamlessly fails over to the replica, allowing Workflows to continue without interruption.\nWhy High Availability Matters\nTemporal Clouds HA features are designed to meet the needs of use cases where uptime is critical. Key benefits include:\n\n  Business Continuity: Protect applications from outages and service disruptions with seamless failover mechanisms for your Workflows.\n  Compliance and Reliability: Achieve a 99.99% contractual service level Agreement (SLA) for applications with strict availability requirements.\n  Flexible Deployment Options: Choose between single-region replication and multi-region replication based on your application architecture and business needs.\n\nKey Concepts\nReplication is the foundation of Temporal Clouds HA features, designed as an additional safeguard for your workflows against service disruptions.\nA standard namespace in Temporal uses database-level replication to distribute data across three availability zones (AZs). This ensures that any change in workflow state and generated history is first written to all three AZs. As a result, your Temporal namespace remains operational even if a single AZ goes down.\nHowever, Temporal deploys namespaces using a cell-based architecture, where each cellalong with its physical and software resourcesacts as a failure domain. If a shared dependency or common infrastructure component, such as the DB, or networking, fails within a cell, all namespaces within that cell can be affected. Temporal Clouds HA features protect against this failure mode by creating a Replica and initiating Failovers as necessary.\n\n  Replica: Workflow Executions are asynchronously replicated from an active Namespace to a replica. This can occur within the same region or across different regions, depending on your architecture and requirements.\n  Failover: In cases of network or performance issues in the active Namespace, Temporal Cloud automatically transitions control to the replica, ensuring continuity without manual intervention.\n\nMulti-region Replication: General Availability\nWith Multi-region Replication now Generally Available (GA), users can replicate Workflows across different regions for enhanced resilience and reliability. This capability is particularly beneficial for organizations with multi-regional architectures or those required to be highly available across regions for compliance purposes. You can also now enable Multi-region replication for your GCP Namespaces!\nFuture Pricing Update: To align with cloud provider network traffic pricing, we plan to introduce adjustments for multi-region replication in the future. Your plan will include a generous base allocation, with additional pay-per-use charges for any network usage beyond that threshold. Most multi-region customers will not be impacted by this change.\nSame-region Replication: Public Preview\nFor applications designed for single-region deployment, Same-region Replication is now available in Public Preview. This feature enables Workflows to be replicated within the same region, providing a reliable failover mechanism while maintaining simplicity in deployment.\nNext Steps\nTo enable High Availability features, you can configure your Namespace settings directly within Temporal Cloud. For detailed instructions, please refer to our updated documentation, which reflects these new capabilities. Note that enabling Same-region or Multi-region Replication incurs additional charges, see Pricing for more details.\nComing Soon!\nThe GA of Multi-region Replication and the launch of Same-region Replication mark an important milestone in our commitment to providing reliable, scalable solutions for business-critical workflows. These features empower organizations to maintain operational continuity and meet their availability goals with confidence.\nBe on the lookout for the next feature in our High Availability portfolio coming soon  Multi-cloud Replication, i.e. the ability to replicate workflows across cloud providers!",featureImage:{title:"social-card-image",description:"social-card-image",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1NfzbiO64uLGYOtl5hBwnw/8e88e819b8ef01edc766b2fb0f0b35fe/social-card-image.jpg"},publishDate:"2025-03-04",metaDescription:"Learn about Temporal Clouds expanded High Availability features, including Multi-region Replication (GA) and Same-region Replication (Public Preview), ensuring seamless failover and 99.99% SLA for business-critical workflows.",metaTitle:"Temporal Cloud Expands High Availability: Multi-Region & Same-Region Replication",tags:"Cloud",slug:"expanding-temporal-clouds-high-availability-offerings",contentType:"blogPost",entityId:"1TYxc9t8ZkYAIRc5WNdCVd",authors:[{id:"5rRXBv9YX2HZHsbvCIr7ts",name:"Nikitha Suryadevara",slug:"nikitha-suryadevara",jobTitle:"Staff Product Manager",photograph:{title:"headshot-nikitha",description:"headshot-nikitha",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4OACKtdVPmoAygYiRKZnHU/d4033aa0852aae010c69fe249c9e90c0/headshot-nikitha.png"},biography:"Nikitha is a Staff Product Manager at Temporal based in San Francisco. She oversees several areas of the product such as high availability, worker management, and observability. Before Temporal, she worked on Compute Infrastructure (Borg) in Google Cloud. Her introduction to compute and cloud was through being a Product Line Manager at VMware. Nikitha started her career as a software engineer and product manager at various SaaS startups. She got her bachelor's degree in electrical engineering from the Manipal Institute of Technology and an MBA from UCLA Anderson.",company:"Temporal",contentType:"person"}],authorsString:"Nikitha Suryadevara",category:"Product News",readingTime:4},{title:"Replay 25, day one: Hackathon & workshops",content:"\n  \n\nThe energy was palpable yesterday at Replay 25 in London. As developers huddled around tables, keyboards clicking and ideas flowing, you could feel that special buzz when creative minds come together. Day one of our event showcased what the Temporal community is all aboutbuilding, learning, and solving problems together.\nUnconference Hackathon: Community-Driven Innovation\nThe day kicked off with rapid-fire project pitches that set the tone for what would become a remarkable day of creation. Over 60 participantsranging from Temporal newcomers to battle-tested veteransvoted on ideas they were passionate about, naturally forming seven distinct teams.\n\n  \n\nWhat happened next was fascinating to watch. Each table became its own innovation hub, with participants often splitting into smaller groups to tackle different aspects of their projects. As the day progressed, these parallel efforts merged into impressive demonstrations of whats possible with Temporal.\nEight distinctive themes emerged: two AI-focused groups, Visualization, Finance, Gaming, Developer Experience, Batch Orchestra, and Microservice Orchestration.\n\n  \n\nAI was clearly a hot topic, but the range of projects showed the versatility of Temporal across different domains. From social media sentiment analyzers to auction systems, the creativity on display was impressive.\n\n  \n\nOne standout project was a GUI Workflow execution visualizer that generated flowcharts showing exactly where in your business logic a Temporal Workflow is running. Another team built a visual diff tool that highlights changes between Workflow runs. The Batch Orchestra team focused on creating an easy-to-use library for reliably performing many like operations such as database migrations and periodic batch jobs.\n\n  \n\nThroughout the day, participants swapped ideas, troubleshot together, and built connections that extended beyond the code they were writing.\n\n  \n\nDemo Time: Creativity on Display\nThe afternoon culminated in lightning demos that drew a packed house. Even workshop attendees and early happy hour arrivals crowded in to witness what had been built in just a few hours. Each presentation sparked questions and applause, highlighting just how much can be accomplished when passionate developers collaborate.\n\n  \n\nThe demos showcased an impressive range of completed projects: a Slack Support Bot, an Intelligent Agenda system, an AI Code Edit Loop, and a fully functional Temporal Auction System (backend, frontend) that managed bid submissions with signals, queries, and encryption.\nMake sure to check out each project by visiting our dedicated GitHub page!\n\n  \n\n\n  \n\nAngie capped the demos by distributing prizes from a local shop, along with the highly coveted Temporal swag  those Ziggy pins were especially popular!\n\n  \n\nWorkshops: Hands-On Learning Across Languages\n\n  \n\nWhile the hackathon teams worked their magic, an annual tradition since the very first Replay was continuing, the workshops. Every year, our Developer Educators deliver our workshops to new and experienced Temporal developers alike. This year the team delivered a new format for the workshops, combining the Temporal 102: Exploring Durable Execution course with the newly released Crafting an Error Handling Strategy course. The courses were in Go, Java, andfor the first time.NET.\n\n  \n\nAttendees rolled up their sleeves and worked through practical exercises, gaining real-world skills using Temporal's capabilities.Throughout the day, participants dove deep into the intricacies of building reliable distributed systems, getting hands-on experience that went well beyond theory. The interactive format meant people weren't just listeningthey were doing, which is the best way to truly learn any technology.\nFrom explaining how History Replay works to unpacking why determinism is crucial in Temporal applications, attendees explored everything from foundational principles to advanced design patterns. Participants learned not just how to use Temporal, but how to think about building robust, resilient systems.\n\n  \n\nOne of the workshop's highlights was the direct access to Temporal experts. Solutions architects and engineers were on hand throughout the day, answering questions and providing insights. This meant attendees could dig into nuanced topics like error handling, cloud deployments, and worker tuning.\nAttendees also spent significant time on practical debugging techniques, teaching participants how to interpret event history and effectively use Temporal's Web UI to interpret the Event History. These skills are invaluable for anyone building Temporal applications.\n\n  \n\nThe workshop raised fascinating questions about more advanced temporal features, signaling a deep hunger in the developer community to push the boundaries of what's possible with distributed systems design. Over 100 attendees attended the workshops, eager to learn about Temporal. And the workshops arent just for new attendees! Even those already familiar with Temporal found the workshop enrichingone attendee shared, More beneficial than expected! I feel I deepened my understanding and am much more confident.\nWhats Next at Replay 25: Building on the Momentum\nThe hackathon and workshops have set the stage perfectly for the rest of Replay '25. With keynotes and technical talks still to come, theres much more to look forward to. Day one was about building, learning, and sharingand this is just the beginning. Take a look at our recaps of day two and day three to learn more.\nMissed the Hackathon? You still have another chance to contribute to your fellow dev community. Make sure you check out our Code Exchange, take Temporal for a test drive, and stay tuned for more from day two and three of the conference.",featureImage:{title:"Hackathon-Replay-25-day-one",description:"Hackathon-Replay-25-day-one",url:"https://images.ctfassets.net/0uuz8ydxyd9p/15uh5G5GXZNaWshNR4vbnX/56b12884bf10f921e6c3e562719c9e22/DSC_7873.jpg"},publishDate:"2025-03-04",metaDescription:"Day one of Replay '25 was great! Attendees joined us to learn from our workshops and jam with their peers during the Hackathon.",metaTitle:"Replay 25, day one: Hackathon & workshops",socialCard:{title:"Replay-25-day-one-social-card",description:"Replay-25-day-one-social-card",url:"https://images.ctfassets.net/0uuz8ydxyd9p/npPPM7VYrx33ccsS2a2xN/ab0d61919ecd7cf5798150f755237b60/Replay-25-day-one-social-card.png"},tags:"Replay",slug:"replay-25-day-one-hackathon-workshops",contentType:"blogPost",entityId:"4Prtn9hw15f8PEXUtQ5rDG",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"Community",readingTime:5},{title:"Announcing automated, zero-downtime migrations to Temporal Cloud",content:"Were thrilled to announce the launch of our migration tooling that enables seamless transitions from self-hosted Temporal instances to Temporal Cloud, now in Pre-release. With this new tool, we aim to make the migration process as smooth and secure as possible while ensuring minimal disruption to your Workflows. This tooling will let you more easily take advantage of the scalability, performance, and simplified operations that Temporal Cloud offers.\nThe migration tooling has been designed with the following objectives in mind:\n\n  Zero-downtime migrations: Workflows, including long-running Workflows continue running during migration without downtime.\n  End-to-end automation: Temporal handles the migration process using internal Workflows.\n  No changes to application code: Your existing Workflows, signals, and queries will work without modification.\n  Minimal effort on your side: Setup and coordination requirements are reduced, provided your self-hosted Temporal instance supports migration.\n  Full control and customization: You decide when to initiate the migration, validate its success, and confirm or abort the process before completion.\n\nIts important to note that this tooling currently supports migrations from self-hosted Temporal to Temporal Cloud only. Reverse migrations (from Cloud back to self-hosted) are planned in our roadmap!\nHow It Works\n\n  \n\nMigration Server\nA Temporal Service (aka Server) facilitates secure connections between your self-hosted instance and Temporal Cloud. It acts as the backbone of the migration process.\nMigration Proxy\n\n  To enhance security, proxies are introduced between your self-hosted server and the migration server:\n  Customer-side proxy: Installed on your infrastructure for secure communication.\n  Cloud-side proxy: Managed by Temporal Cloud.\n\nA step-by-step guide to migration\nHeres how the migration process will work:\n\n  Preparation Phase\n\n\n  Temporal coordinates with you to set up a migration server, which may take several hours.\n  You install a migration proxy to establish secure connections between your self-hosted instance and the migration server.\n\n\n  Initiating Migration\n\n\n  Use the StartMigrationRequest API to specify namespaces for migration along with endpoint details.\n  A corresponding namespace is created in Temporal Cloud with a non-active status. You can configure permissions and access controls during this phase.\n\n\n  Monitoring Progress\n\n\n  The GetMigrationResponse API allows you to track replication progress, including workflows replicated, remaining workflows, and estimated time for completion.\n\n\n  Validation and Handover\n\n\n  Once replication is complete, you can use the HandoverNamespaceRequest API to switch traffic between your source namespace (self-hosted) and target namespace (cloud).\n  This gives you time to validate that everything is functioning correctly in Temporal Cloud by switching worker traffic and workflow starters incrementally.\n\n\n  Finalizing or Aborting Migration\n\n\n  After validation, use ConfirmMigrationRequest API to finalize the migration.\n  \n    If issues arise (e.g., incorrect namespace migrated or replication errors), you can abort using AbortMigrationRequest API. Aborting will roll back changes without impacting your workflows.\n    These APIs provide granular control over every step of the process, ensuring transparency and flexibility.\n  \n\nPre-requisites and limitations at Pre-release\nRefer to this document for pre-requisites and limitations of using this migration tool.\nConclusion\nWith this new migration tooling, migrating from self-hosted Temporal to Temporal Cloud has never been easier. By automating complex processes and minimizing customer effort, were empowering you to focus on building resilient applications while we handle the heavy lifting of infrastructure management.\nReady to migrate to Temporal Cloud? Contact us today to get started!",featureImage:{title:"social-card-brandon",description:"social-card-brandon",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1oX4jNjimgeS45r7uoaMha/d54d7043f6f959dc26a493a2e74d98c7/social-card-brandon.jpg"},publishDate:"2025-03-04",metaDescription:"Easily migrate from self-hosted Temporal to Temporal Cloud with zero downtime. Fully automated, seamless, and built to minimize effort.",metaTitle:"Zero Downtime Migration with Temporal Cloud Automation",tags:"Cloud",slug:"announcing-automated-migrations",contentType:"blogPost",entityId:"6SVAlqHXAYRBrEH5BqF9cV",authors:[{id:"5rRXBv9YX2HZHsbvCIr7ts",name:"Nikitha Suryadevara",slug:"nikitha-suryadevara",jobTitle:"Staff Product Manager",photograph:{title:"headshot-nikitha",description:"headshot-nikitha",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4OACKtdVPmoAygYiRKZnHU/d4033aa0852aae010c69fe249c9e90c0/headshot-nikitha.png"},biography:"Nikitha is a Staff Product Manager at Temporal based in San Francisco. She oversees several areas of the product such as high availability, worker management, and observability. Before Temporal, she worked on Compute Infrastructure (Borg) in Google Cloud. Her introduction to compute and cloud was through being a Product Line Manager at VMware. Nikitha started her career as a software engineer and product manager at various SaaS startups. She got her bachelor's degree in electrical engineering from the Manipal Institute of Technology and an MBA from UCLA Anderson.",company:"Temporal",contentType:"person"}],authorsString:"Nikitha Suryadevara",category:"Product News",readingTime:3},{title:"Announcing new Temporal capabilities from Replay 2025",content:"This morning at Replay 2025, we announced exciting new capabilities in Temporal to help you code more efficiently and focus on what matters: delivering systems as reliable as gravity.\nRead on to learn more, and reach out to us in Slack to let us know your questions and thoughts. Wed love to hear from you.\nCode More Efficiently With New Temporal SDKs and Primitives\nWeve released new and updated capabilities to improve your development experience with Temporal and let you code applications more efficiently.\nUse Ruby to Write Workflows and Activities\nWere excited to announce the Temporal Ruby SDK, now available in Pre-release. This SDK is the framework for authoring Workflows and Activities using the Ruby programming language, and its at full feature parity with the other Temporal SDKs.\nConnect Workflows Across Teams and Applications\nTemporal Nexus is now Generally Available. Nexus allows you to connect Temporal Applications across (and within) isolated Namespaces. This provides all the benefits of Durable Execution across team and application boundaries, with improved modularity, security, debugging, and fault isolation. Unlike other forms of inter-service communication, Nexus combines a familiar programming model with the resiliency of Temporal. Nexus GA enables you to:\n\n  Abstract Temporal primitives, like Workflows, with clean service contracts.\n  Run Nexus Services in Workers with Temporals queue-based architecture.\n  Use Nexus Operations through a Nexus Endpoint, a reverse proxy for Nexus Services.\n  Connect within and across regions in AWS and GCP using Temporal Cloud.\n\nSafely Launch New Deployments\nWhen deploying a new version of your Worker, you likely want to keep older Workflows running smoothly without encountering the new, incompatible code. Weve launched new Worker Versioning APIs, with our new Deployments abstraction to achieve this. These APIs, now in Pre-release, let you:\n\n  Pin Workflows to Deployment Versions to increase safety during rollouts.\n  Ramp or cut over traffic between Deployment Versions when you choose.\n  \n    Directly test a Workflow on your new Deployment Version to check its health before rolling out.\n    You can manage these so-called rainbow deployments directly using our APIs or adopt a pre-built Kubernetes controller.\n  \n\nEasily Optimize Workflows, Activities, and Workers\nWeve released several updates to let you improve and optimize live Workflows, Activities, and Workers for the best performance and results.\n\n  Minimize toil and simplify the management of Workers with resource-based auto-tuning, now Generally available in all SDKs.\n  Edit running Activities in production with new Activity Operations Commands, now in Public Preview. If you misconfigured Activities or need to fix issues, these operations let you quickly and safely pause, unpause, reset, and update live Activities.\n  Reset Workflows with Child Workflows with a new command, now in Pre-release. This feature lets you restart Workflows with Child Workflows from an earlier place.\n\nSimplify Operations and Enhance High Availability With Updates to Temporal Cloud\nTemporal Cloud provides an easier, faster, and more scalable way to run Temporal, with the same open-source SDKs and no lock-in. Weve released updates for reliability and more seamless operations.\nAutomate Migrations With Zero Downtime\nMigrating Workflows to Temporal Cloud requires a variety of steps and safeguards, especially if your use case is in production. Thats why weve released new migration tooling to let you migrate live Workflows with:\n\n  Zero downtime\n  End-to-end automation\n  No changes to application code\n  Minimal effort on your side\n  Full control and customization\n\nTake advantage of Temporal Clouds benefits without doing any of the heavy lifting.\nThe tooling is now in Pre-release, and were seeking early users. Learn more here and sign up here.\nEnhance High Availability\nTemporal Cloud provides built-in high availability with a 99.9 SLA for all Namespaces provided by database replication across AZs. For mission-critical use cases, we recommend enabling additional protections using our High Availability features (HA), now updated with several new releases.\n\n  Multi-region Replication is Generally Available. Ensure your applications remain online, even when network issues or entire region outages occur, with a 99.99 SLA. Multi-region Replication (previously known as Multi-region Namespaces) asynchronously replicates your Workflows to a Namespace in a secondary region and automatically fails over if necessary.\n  Introducing Same-region Replication in Public Preview. Same-region Replication asynchronously replicates all your Workflows to a Namespace within the same region, and fails over if a disruption occurs, to keep your applications online with a 99.99 SLA.\n\nLearn more about these HA features here.\nAdopt Temporal Cloud on Google Cloud\nTemporal Cloud on Google Cloud is now Generally Available to give you more options for deployment. Capabilities weve recently added include:\n\n  Multi-region Replication\n  Nexus\n  API Keys\n  Service Accounts\n  Export History\n  Terraform provider\n  Regions of us-east-4 and europe-west3.\n\nIf you need additional regions not currently available, you can reach out.\nSimplify Operations and Increase Security\nWeve released several automation features to let platform teams work more efficiently and increase security in Temporal Cloud.\n\n  Automate user provisioning with the new SCIM Integration, now in Pre-release. Use your identity provider to add new users to Temporal more quickly and securely. This feature is available in the Enterprise and Mission Critical plans, and you can contact your Support team to enable it.\n  Authenticate to Temporal Cloud with API Keys, now Generally Available. Weve added new capabilities to improve security and flexibility, such as Service Accounts, the ability to migrate from mTLS to API keys in production, a 2-year retention period for API keys, and more.\n  Improve operational efficiency with the Terraform provider, now in Pre-release. Automate common operations like Namespace, User, and Certificate management in AWS and Google Cloud Namespaces.\n\nIntroducing the Temporal Code Exchange\nWeve launched the Temporal Code Exchange, a curated collection of code samples, example applications, and creative uses of Temporal contributed by our community members from around the world.\nWe have launched with 11 examples that span 5 languages (Python, Go, TypeScript, .Net, and Java). Youll see sample apps and code for use cases like:\n\n  A library to orchestrate multi-agent workflows\n  A sample eCommerce app that integrates with Stripe\n  A full-stack template to simplify the development of applications using Temporal and React\n  A package that enables full visualization of end-to-end workflows\n  A sample Insurance application and workflows\n\nWell be adding more community submissions regularly!\nHow to Contribute to the Code Exchange\nThe Code Exchange is open for more submissions. Follow the links on the Code Exchange to access our Community GitHub repository where you can submit your own project or share an idea to be worked on with someone else in the community.\nWhats Next\nIf you have any questions about these updates, let us know in the Temporal community Slack. (Use the channels #nexus, #safe-deploys, and #migration-tooling for their respective features, and the SDK channel of your choice for all other questions). We cant wait to hear your thoughts as you begin using these new capabilities.",featureImage:{title:"social-waves",description:"social-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3VcwELyHT8XrKJCFB6yfht/552f942de9f308def0df62fe24787dcb/image-3D-waves.jpg"},publishDate:"2025-03-04",metaDescription:"Discover the latest Temporal updates announced at Replay 2025, including new SDKs, Nexus GA, Worker Versioning, Temporal Cloud enhancements, and the launch of the Temporal Code Exchange.",metaTitle:"Replay 2025: New Temporal Capabilities for Faster Development",tags:"Replay",slug:"replay-2025-product-announcements",contentType:"blogPost",entityId:"6iqqhR1BGDtoXIMEV0Mljk",authors:[{id:"4dsODPDNXZPwvTMknnOR7N",name:"Meagan Speare",slug:"meagan-speare",jobTitle:"Sr. Manager, Product Marketing",photograph:{title:"headshot-megan-speare",description:"headshot-megan-speare",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4cU6Eil7AyPgQDtc52XeS8/935bb30acca03ba2e011e5cc90be909c/meagan-speare.jpg"},contentType:"person"}],authorsString:"Meagan Speare",category:"Product News",readingTime:6},{title:"Build resilient Agentic AI with Temporal",content:"The current generation of Agentic AI frameworks was designed for short-lived chains of tools. While effective for simple tasks, they fall short when used for more complex, long-running workflows. Developers trying to push these frameworks beyond their limits run into fundamental problems: lack of durability, limited scalability, and rigid integration options.\nTemporal provides a more robust approach. It was built for reliability and scale, making it an ideal foundation for Agentic AI workflows that need to persist, interact with humans, and evolve with the fast-changing AI landscape.\nHeres how Temporal differentiates itself:\nDeveloper Velocity\nTemporal is designed to feel natural and idiomatic for developers. With the Python SDK and other language support, you dont have to think about state machines or complex orchestration  it just works, letting you focus on building rather than managing infrastructure.\nInsights and Observability\nStep-debugging workflows, tracking execution with detailed UI metrics, and leveraging Temporals visibility features make it easy to troubleshoot and optimize. Developers can quickly identify bottlenecks and ensure their agents run efficiently.\nScheduled Execution\nTemporal supports running workflows on a schedule, enabling AI agents to periodically poll for new data and act accordingly. This makes it an ideal choice for use cases requiring continuous updates and real-time responsiveness.\nDurable and Resilient\nLLMs are probabilistic by nature and can sometimes return incorrect or inconsistent responses. Temporals retry capability helps mitigate these issues, ensuring that workflows can recover from bad outputs and continue progressing reliably.\nIn addition, Temporal ensures workflows can survive real-world failures: process crashes, bad data, and network timeouts. Unlike single-process frameworks, Temporal retains state and automatically retries failed steps, ensuring that agents recover and continue without losing progress.\n\n  In many other frameworks, a crash means the whole process stops, forcing developers to rebuild context from scratch. With Temporal, thats never a concern.\n  \n  \n  Heres how a typical Temporal agent orchestrator workflow operates:\n\n\n  The user initiates a request (signal).\n  The agents (activities) determine the next step.\n    \n      If needed, the workflow queries an LLM with workflow text as context.\n    \n  \n  Possible agent responses:\n    \n      Ask the user for more information.\n      Request permission to run a tool.\n    \n  \n  The user confirms the tool run (signal).\n  The tool runs (API call), and the response is parsed by an LLM and sent back to the user.\n  Steps repeat until the agent reaches its goal.\n\nLong-Running and Stateful\nMost frameworks handle short-lived sequences. Temporal is built for workflows that last hours, days, or even months. It maintains state across the entire lifecycle, so your agent never loses track of its goal or context  no matter how complex or prolonged the interaction.\nHuman-in-the-Loop Support\nSome decisions require human oversight. Temporal makes it easy to involve people at critical moments:\n\n  Pause workflows for approval or input.\n  \n    Provide updates and notifications for human intervention when necessary.\n    This makes Temporal well-suited for enterprise applications where accountability and control matter.\n  \n\nFlexible and Extensible\nIn a constantly evolving AI ecosystem, flexibility is key. Many existing frameworks are tied to specific LLMs or databases, limiting adaptability. Temporal offers:\n\n  Support for multiple languages (Go, Python, Java, TypeScript, .NET, Ruby).\n  \n    Easy integration with any LLM, vector database, or external service.\n    Youre not locked into a single vendor or toolchain  new AI models and services can be added as they emerge.\n  \n\nCentralized Orchestration\nTemporal functions as a brain for coordinating API calls, services, and data sources. It is architected to be fault-tolerant and horizontally scalable, ensuring high availability and resilience even in large, distributed environments. It scales far beyond the single-process limitations of other frameworks, allowing developers to create distributed workflows without worrying about state management or fault tolerance.\nThe Future of Agentic AI\nAgentic AI is evolving quickly. Building agents that can persist, collaborate with humans, and adapt requires a solid foundation. Temporal offers the durability, flexibility, and scale needed to meet these demands without being boxed in by the constraints of traditional frameworks. Learn more about using Temporal for Agentic AI here.\nReady to build resilient, scalable AI agents? New Temporal Cloud users get $1,000 in free credits to get started. Sign up now and start building today.",featureImage:{title:"social card - green waves",description:"social card - green waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4GBHZR0vUnoRSbPtSTCH4s/daf7308a10e469059827e2169065d7ea/social_card_-_green_waves.jpg"},publishDate:"2025-02-25",metaDescription:"Learn how Temporal powers durable, scalable Agentic AI workflows with reliable state management, human-in-the-loop, and seamless orchestration.",metaTitle:"What are Agentic AI Workflows? Scalable & Durable Workflows",socialCard:{title:"agentic-ai-social-card",description:"agentic-ai-social-card",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3pmVeP1SxxfU9GSZYP1bej/df3de388b5865b5b00e768d05950bd40/Blog__11_.png"},tags:"AI/ML",slug:"build-resilient-agentic-ai-with-temporal",contentType:"blogPost",entityId:"1koM9i3HL18LEeOMAFrJI9",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"Temporal Concepts",readingTime:4},{title:"Durable Digest: February 2025",content:"This blog post is a public copy of our monthly newsletter. If youd like to receive upcoming updates by email, you can subscribe to our newsletter here.\nWeve got a packed update for you this month  new SDK releases, upcoming events in London, and a fresh Temporal 101 webinar for Java developers.\nFor more information on these updates and other things weve been working on, just keep reading! And as always, wed love to hear from you  feel free to share feedback in our Community Slack, or on X (@temporalio).\nSDK Updates\n\n  Java SDK 1.27.1 fixes an exception that can occur when receiving a failure from a Nexus operation.\n  TypeScript SDK 1.11.7 fixes a crash and includes security updates for its dependencies.\n  PHP SDK 2.13.0 adds support for Typed Search Attributes, and a workflow-init method.\n\nEvents\nOn Tuesday, March 11, 2025, in the Philadelphia area, Temporals Staff Solutions Architect, Rick Ross, will take the stage at the Philly JUG meetup to present Building Reliable Applications with Temporal, discussing how to simplify code and enhance application reliability using Temporals open-source programming model.\nWere thrilled to announce that Replay 2025 in London will feature a special performance by The Tech Roast Show, marking their debut in the city. Known for their unique blend of technology and comedy, The Tech Roast Show promises to deliver an unforgettable (and hilarious!) experience. Dont miss this exciting addition to our event lineup!\nResources\n\n  The Education team has just released two more .NET courses: Temporal 102 and Crafting an Error Handling Strategy. Read about them here.\n  The Education team is hosting a Temporal 101 in Java webinar on March 12 at 9:00 AM PST. Register here!\n  Temporal Cloud pricing page revised and updated with new information.\n  New documentation for circuit breaking in Nexus.\n\nCommunity Shout-Outs\n\n  Marek Sirkovsk created a nice blog post about Temporal.IO in .NET which gives a great introduction to Temporal terminology for .NET fans!\n  Sepehr Sobhani created kairos-cli, a snappy CLI application that helps maintain flow state while opening workflows in the cloud for a richer experience and deeper analysis.\n  Former beloved Temporalite Brian Hogan took our new Ruby SDK for a spin and ported the Get Address from IP example to Ruby.\n  And finally, Bar Moshe created Data Processing Service, a practical demonstration of building cross-language microservices with Temporal, orchestrating activities written in Go, Python, and TypeScript.\n\nBlog Highlights\n\n  Replay 2024 Highlights: Why Replay 2025 Will Be Even Bigger\n  Meet the Speakers Shaping the Future of Engineering at Replay 25\n  Simplifying Distributed Transactions in Microservices\n  Temporal in Space\n  Reduce Latency and Speed Up Your Temporal Workflows\n",featureImage:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},publishDate:"2025-02-21",metaDescription:"Explore Temporals latest developer updates: questions from the field, new releases, builder spotlights, learning resources, and ways to connect with our team.",metaTitle:"Durable Digest: February 2025",socialCard:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},tags:"",slug:"durable-digest-february-2025",contentType:"blogPost",entityId:"5IWpl2BPwAXYOJAApzgu7a",authors:[{id:"17hGmNrCwtXdBh7fhsLUnZ",name:"Temporal Technologies",slug:"temporal-technologies",photograph:{title:"temporal technologies logo",description:"temporal technologies logo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3g56zRXtFQYMeJxBBkVBIZ/7771670e5fc7da59f555837b086c35d6/temporal_technologies_logo.avif"},company:"Temporal Technologies",contentType:"person"}],authorsString:"Temporal Technologies",category:"Announcements",readingTime:3},{title:"How Layer.ai is upgrading mobile game design",content:"In 1994, Rise of the Robots promised to be the future of gaming: cutting-edge 3D visuals, groundbreaking AI, and a great soundtrack. And then people played it.\nWhat they got was clunky animations, lifeless characters, and duller-than-dull gameplay. Critics roasted it, players abandoned it, and Rise of the Robots went down in history as proof that cool tech means nothing if the experience sucks.\nFast-forward to today, and the stakes for visuals are even higher  especially in mobile gaming. Players demand breathtaking art and immersive worlds. Anything less is a speedrun straight to the app store graveyard.\nThe best game developers know this. Without strong visuals, its nearly impossible to attract new players, keep them engaged, or stand out in a crowded market. Thats why developers are always looking for ways to level up their designs without sacrificing quality, brand integrity, or valuable development time.\nLayer.ai gets this. Theyre revolutionizing game asset creation by blending professional game design with AI, giving developers the tools to create high-quality, custom assets in their unique brand style.\nTheir goal is simple: to work alongside game developers, helping them spend more time doing the work they love, creating art, without ever replacing the creative process.\nHow AI is Empowering Mobile Game Developers\nLayer.ai has a bold mission: to make high-quality game art accessible to every developer. As VP of Engineering Joona Rahko puts it, \"As a game developer, you have unlimited creativity, but often limited resources. We want to give every mobile gaming developer access to the best possible art, no matter their studio size or budget.\"\nWhat makes Layer.ai unique is its ability to generate production-ready assets in a developer's custom brand style. Whether its characters, environments, UI elements, or marketing assets the platform ensures visual consistency without sacrificing creativity.\nThis is possible by having users teach the tooling by uploading existing artwork. Once input, Layers platform trains an AI model to match the art style, allowing teams to generate anything from new characters to game UI elements in a fraction of the time it would take to create them manually.\nTransforming Game Design: Stories from Developers\nLayer is actively reshaping how studios approach game development. Here are a few examples of how Layers customers are using the platform to level up their production.\nAce Games: Saving 120 hours a month\n\n  \n\nAce Games, the team behind Fionas Farm, needed a new way to scale their in-house production pipelines for everything from character art to new level assets under high player demand.\nBy training Layers most popular AI mode, FLUX, on their existing game assets, they boosted productivity by 80%, saving over 120 hours monthly. This allowed them to quickly generate and refine assets for seasonal and event-based content, maintain visual consistency, and underburden their production team.\nTactical Strike: Saving 2500+ hours of production time\n\n  \n\nLokum Games faced delays and inconsistent styles when outsourcing character illustrations for Tactical Strike. With Layer, they created 40 unique characters in under 30 days  saving hundreds of hours.\nBy training Layers AI on their existing artwork, Lokum saved 2500+ in production team bringing the power of creation in-house, allowing them to focus on refining other aspects of the game while maintaining visual consistency.\nLBC Studios: 8x Boost in Productivity\n\n  \n\nLBC Studios, a medium size game studio, used Layer to create high-quality, on-brand assets for Brewtopia. What normally took 320+ hours for a character illustration was completed in just 40 hours with Layers AI.\n\n  \n\nThe studio produced 10 characters, vehicles, and props in one workweek  an 8x productivity boost. The ability to export assets to Photoshop for final tweaks helped LBC maintain quality while accelerating the process and reducing costs.\nBuilt for Trust\nBeyond Layers commitment to innovation in mobile game design, they have a steadfast, ethical foundation that depends on data security and privacy.\nLayer is the worlds first SOC 2-compliant gaming AI provider, a certification that ensures the highest standards of data processing and storage.\nWith a strong emphasis on privacy and compliance, Layer ensures that its platform is secure, accessible, and reliable for businesses that handle sensitive information. \"Even with all the advancements in gen-AI, the basis of building an enterprise tool remains the same,\" says Principal Engineer, Jacques Lemire. \"SOC Type 1 and 2 compliance was just the start. We want to make sure game studios can trust their data is always secure and confidential with us.\"\nHow Temporal Powers Layer.ais Scalability\nLayer uses Temporal to streamline their AI-driven workflows for scalable game asset production.\nBy offloading heavy tasks like asset generation and file processing, Temporal keeps Layers servers efficient and with automatic retries, the team can focus on high-impact work. This maintains consistent output at scale, allowing the team to tackle even more complex challenges.\nIdentifying Technical Challenges\nBuilding a scalable AI-powered tool like Layer came with its own technical challenges. \"Generative AI is an inherently complex and ever-evolving space,\" notes Joona. \"There are many permutations of base models, parameters, and training methods. What works today may not work tomorrow, which makes it challenging to keep up with rapid changes.\"\nIn their early backend implementation, Layer ran heavy asynchronous tasks like file pre-processing, model inference, and post-processing on the main servers. This caused bottlenecks, slowed user experience, and resulted in an unclear path to handle retries or recover from failures. \"Under heavy load, we had frequent task failures, which was a huge issue for maintaining our reliability,\" Joona adds.\nOvercoming Performance Bottlenecks with Temporal\nTo overcome these challenges, Layer integrated Temporal into their architecture. \"By offloading these tasks into Temporal, we were able to decouple them from our main server, preventing overload and improving performance,\" Joona explains. \"Temporal's built-in retries and clear observability gave us better control over task execution, reducing failures and ensuring reliability.\"\nLayers AI asset generation pipeline was drastically improved with Temporals durable workflows, which guarantee task retries if something goes wrong, ensuring consistency and reliability even under high demand.\nExample Architecture\nA prime example of how Temporal supports Layer is the FileUploadWorkflow, which handles the entire file upload process, which a key workflow is Layers product, from waiting for uploads to executing post-processing.\nThis workflow relies on Temporal to ensure that if any step fails (like a timeout during upload), the task is retried automatically, preventing failures from affecting the overall pipeline.\nHeres a snippet of the FileUploadWorkflow workflow definition:\n@workflow.defn\nclass FileUploadWorkflow:\n    TASK_QUEUE = TASK_QUEUE\n\n    def __init__(self) -> None:\n        self.is_file_uploaded = False\n\n    @staticmethod\n    def make_id(id: FileID) -> str:\n        return f\"file-upload-{id}\"\n\n    @workflow.run\n    async def run(self, input: FileUploadWorkflowInput) -> FileUploadWorkflowOutput:\n        self.bucket_path = input.bucket_path\n        try:\n            # Wait for the uploaded signal\n            await workflow.wait_condition(lambda: self.is_file_uploaded, timeout=FILE_PROCESSING_TIMEOUT)\n        except asyncio.TimeoutError:\n            # We reached the poll timeout without a signal\n            file_status = await workflow.execute_activity_method(\n                ProcessFileActivities.check_file_status,\n                CheckFileStatusInput(file_id=input.file_id),\n                start_to_close_timeout=datetime.timedelta(seconds=10),\n                retry_policy=RetryPolicy(\n                    maximum_attempts=2, initial_interval=datetime.timedelta(seconds=10), backoff_coefficient=1\n                ),\n            )\n            if file_status.uploaded:\n                self.is_file_uploaded = True\n\n        if not self.is_file_uploaded:\n            # Mark file as deleted since it wasn't uploaded within the processing timeout\n            output = await workflow.execute_activity_method(\n                ProcessFileActivities.delete_file,\n                DeleteFileInput(file_id=input.file_id),\n                start_to_close_timeout=datetime.timedelta(seconds=30),\n                retry_policy=RetryPolicy(maximum_attempts=5),\n            )\n            return FileUploadWorkflowOutput(file_id=output.file_id, success=False)\n\n        output = await workflow.execute_activity_method(\n            ProcessFileActivities.mark_file_uploaded,\n            MarkFileUploadedInput(file_id=input.file_id),\n            start_to_close_timeout=datetime.timedelta(seconds=30),\n            retry_policy=RetryPolicy(maximum_attempts=2),\n        )\n\n        if output.success:\n            await workflow.execute_child_workflow(\n                PostProcessFileWorkflow.run,\n                PostProcessFileWorkflowInput(file_id=input.file_id),\n                id=PostProcessFileWorkflow.make_id(input.file_id),\n                task_queue=PostProcessFileWorkflow.TASK_QUEUE,\n                id_reuse_policy=WorkflowIDReusePolicy.REJECT_DUPLICATE,\n            )\n            return FileUploadWorkflowOutput(file_id=output.file_id, success=output.success)\n\n    @workflow.signal\n    async def file_uploaded_signal(self, input: FileUploadedSignal) -> None:\n        if input.bucket_path == self.bucket_path:\n            logger.info(\"Received signal 'file_uploaded'\")\n            self.is_file_uploaded = True\nThis code is a low-level representation of the file upload and processing pipeline. It handles retries, timeouts, and checks to ensure that tasks continue executing, even if certain steps fail.\nThe diagram below provides a higher-level view of this process, showing how the different components interact within the broader workflow. It visualizes key steps like trigger events, decisions for prompt translation, and the orchestration of tasks like preprocessing, file generation, and post-processing.\n\n  \n\nAs seen in both the code and the diagram, Temporal's retry mechanism and clear visibility ensure that if something goes wrong, the system keeps running smoothly. This decoupling of tasks allows Layer to scale and process complex workflows more reliably.\nRedefining the Future of Game Design\nLayer.ai is redefining whats possible in game design, ensuring developers can focus on creating stunning, immersive worlds instead of wrestling with production bottlenecks. Its the kind of tool that prevents your game from becoming another Rise of the Robotsall hype, no substanceand instead helps you deliver an experience players will love and remember.\nBecause at the end of the day, cutting-edge tech only matters if it brings your creative vision to life.\nTo see Layer in action and explore how it can improve your game asset creation process, visit their website and follow them on X and LinkedIn for the latest updates.",featureImage:{title:"social-card-purple-waves",description:"social-card-purple-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2nvZtGhubV6XKQbGrFwUmH/c7c8144ccbc2a70cc9d1274206d26593/social-card-purple-waves.jpg"},publishDate:"2025-02-21",metaDescription:"Learn how Layer.ai is using Temporal to revolutionize game asset creation, blending professional game design with AI",metaTitle:"How Layer.ai is upgrading mobile game design",socialCard:{title:"How Layer.ai is upgrading mobile game design blog image",description:"How Layer.ai is upgrading mobile game design blog image",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3OcEDWJ8o593CjlxUcJM72/c7e7870a45dfe36400438b87a76e9069/How_Layer.ai_is_upgrading_mobile_game_design.png"},tags:"Cloud",slug:"how-layer-ai-is-upgrading-mobile-game-design",contentType:"blogPost",entityId:"1WSqOGSDzl5X198TBaBTFQ",authors:[{id:"780p8MZSlKh9AuMzW5FrA0",name:"Clair Byrd",slug:"clair-byrd",jobTitle:"CMO",photograph:{title:"Clair Byrd",description:"Clair Byrd",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2ENA9j4df6EfXCLgoWmt46/bb029b33e3f92fb2a7973348c8ccce88/861A2507.jpg"},biography:"Clair Byrd is the Chief Marketing Officer at Temporal, the company defining durable execution in software engineering. Before joining Temporal, Clair held senior marketing and leadership roles at Twilio, InVision, and Sauce Labs, and co-founded the front end builder platform Mason. Her work centers on elevating developer experience, connecting open-source ecosystems, and building brands that inspire technical creativity and trust. Clair is passionate about storytelling that helps engineers build faster, smarter, and with lasting impact.",company:"Temporal",contentType:"person"}],authorsString:"Clair Byrd",category:"Community",readingTime:8},{title:"Announcing new Temporal training courses for .NET developers",content:"The Developer Education team is excited to announce that our Temporal 101, Temporal 102, and Crafting an Error Handling Strategy courses are now available in .NET! These free, self-paced, hands-on training courses are designed to help developers build robust, reliable applications using the Temporal .NET SDK.\nWhether youre new to Temporal or ready to dive deeper, our .NET courses will provide the skills you need to start building and managing durable, fault-tolerant applications with Temporal.\nTemporal 101: Introducing the Temporal Platform\nIn this course, youll explore what durable execution is as well as Temporal's core concepts and architecture. Youll discover the basic building blocks of Temporal: Workflows and Activities.\nYou'll then get hands-on and develop an application that communicates with an external service using those Workflows and Activities\nBy completing Temporal 101, youll be able to:\n\n  Configure an environment for developing Temporal applications\n  Describe and implement a business process with Temporal\n  Interpret Temporal's Workflow execution model\n  Manage the lifecycle of your application with Temporal tooling\n\nTemporal 102: Exploring Durable Execution\nTemporal 102 builds on the concepts introduced in Temporal 101 to help you prepare your applications for production. This course emphasizes best practices and real-world challenges - not just solely focusing on advanced features.\nYoull test, debug, and deploy Temporal applications effectively, while also diving into the Event History to analyze and solve common problems that developers face. The course also provides insight into Temporals durability model, demonstrating how Temporal ensures state persistence and execution consistency.\nBy completing Temporal 102, youll be able to:\n\n  Describe how the Temporal platform achieves durable execution\n  Apply best practices to build robust applications\n  Debug Workflow issues and prepare your applications for production\n\nCrafting an Error Handling Strategy\nHandling errors effectively is essential to building resilient applications, and this course gives you the tools and techniques to do it right. Youll take advantage of how Temporal represents different types of failures, and how to design error-handling strategies that integrate seamlessly with your business logic.\nThe course covers essential concepts like idempotence, Heartbeating, and the Saga Pattern - applying these strategies to ensure your application remains both correct and responsive. Youll also explore features like custom retry policies, Activity timeouts, and Workflow cancellation mechanisms.\n\n  By completing Crafting an Error Handling Strategy, youll be able to:\n  Design appropriate error-handling strategies for different failure scenarios\n  Implement retries, compensating actions, and cancellation patterns in your Workflows\n  Create applications that gracefully recover from failure with Temporals error-handling mechanisms\n\nReady to Get Started?\nThese courses are accessible and flexible, allowing you to learn at your own pace while building real-world skills. Best of all, theyre free! Check out our Learn site to view our courses!\nWant to stay in the loop for future courses? Sign up here to receive updates!",featureImage:{title:"Amazon Bedrock with Temporal: Rock Solid",description:"Amazon Bedrock with Temporal: Rock Solid",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6vkAcFvdvpPI8GBeiNonrO/48c2d48998507594a0591ae6759f1e0e/bed_rock.jpeg"},publishDate:"2025-02-19",metaDescription:"Our Temporal 101, 102, and Crafting an Error Handling Strategy are now available in .NET. Take one of our free, self-paced, hand-on courses to learn everything you need to know about Temporal.",metaTitle:"Announcing new Temporal training courses for .NET developers",socialCard:{title:"New-Temporal-Courses-.NET",description:"New-Temporal-Courses-.NET",url:"https://images.ctfassets.net/0uuz8ydxyd9p/ndY52k5GhlfqJKIoiRdo4/97450b1d0da6af9c14bece52a781a20d/New-Temporal-Courses-.NET.png"},tags:".NET,Code Samples",slug:"new-temporal-training-courses-net-developers",contentType:"blogPost",entityId:"3pQ4r4KBDPNgKSCNOQy9W5",authors:[{id:"gz6Asa7ycvY1HZz9vcJk0",name:"Angela Zhou",slug:"angela-zhou",jobTitle:"Senior Technical Curriculum Developer",photograph:{title:"headshot-angela-zhou",description:"headshot-angela-zhou",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3FgLhuMJuEASXJmzoNevWN/c115937f066329eb77cd75caa831bfbe/headshot-angela-zhou.png"},contentType:"person"}],authorsString:"Angela Zhou",category:"Announcements",readingTime:3},{title:"Explore engineering solutions from Temporal Replay 2025 speakers",content:"The difference between a backend that hums and one that crumbles under pressure isnt a lucky break: its engineering. The best solutions dont come from you working in isolation, staring at logs, or fretting over your codebase. They come from people wrestling with real-world scaling problems, learning through failure, and designing for a future that isnt yet written.\nAt Replay 25, those engineers will take the stage to tell you how theyre pushing workflow orchestration, Durable Execution, and modernization efforts forward. Whether youre replacing brittle cron jobs, chasing millisecond-latency SLAs, or rethinking resilience from the ground up, this is where your next breakthrough might come from.\nHere are just a few of the great talks you can look forward to, grouped by industry.\nFinance and Payments: Building Systems That Cant Afford to Fail\nThese experts will put their money where their mouth is. If youre in FinServ and looking to cut down complexity or replace cumbersome Celery tasks, weve got something for you.\nHow Vinted uses Temporal to manage complex payment flows\nVinted is Europes largest online C2C platform for second-hand fashion, processing millions of payments every day across multiple currencies and banking systems. In this talk, Gytis Ramanauskas, Engineering Manager at Vinted, shares how integrating Temporal into their Ruby-based payments monolith reduced complexity, improved resilience, and changed the way their engineers design fault-tolerant workflows.\nAirwallex: Tucking In Your Legacy Tech Debt With Temporal\nAirwallex, a global finance platform used in over 150 countries, had a legacy microservice architecture that served them well until it didnt. Mits Kikotani will share how Airwallex fixed their third-party adapter microservices without a risky full rebuild.\nCheck: Durable Payroll in a Modular Monolith\nCheck manages payroll for thousands of businesses, processing billions in wages and tax filings. In their talk, Sam Wilson, Principal Engineer at Check, will break down how they replaced fragile cron jobs and Celery tasks with Temporal-powered orchestration, improving speed, reliability, and debugging.\nTransforming Customer Onboarding at Mollie: Our Automation Journey with Temporal\nLegacy PHP. A monolith struggling under scale. Join Sonnya Dellarosa, Software Engineer at Mollie, to learn how her team rebuilt their onboarding process with Temporal Workflows, improving developer velocity and compliance automation.\nCloud Migrations and Large-Scale Transformations\nWhen your system needs to move, its rarely a simple lift-and-shift. These teams are tackling everything from monolith evacuations to fleet-wide software rollouts.\nSalesforce: Migrating a Monolithic Cloud with Temporal\nSalesforce was in the middle of migrating Marketing Clouda massive multi-tenant applicationonto Hyperforce. With over 1,000 engineers involved, this migration was enormous. Trevor Grieger and Austin Deal, Principal Software Engineers at Salesforce, will explain how Temporal powered their cross-substrate migration system, orchestrating workers across multiple environments and coordinating teams seamlessly.\nVodafones Use of Temporal in Our Customer Premise Equipment Management Platform\nPushing software updates across millions of routers and home devices isnt simple. In his talk, Vodafones Principal Software Manager, James Irwin, will walk through how they built a highly resilient CPE management system to handle software deployment, security patches, and fleet-wide updates.\nInfrastructure and Global Systems Engineering\nBig systems demand big thinking. Whether youre orchestrating global network automation or running self-hosted clusters at scale, these talks will keep you ahead of the curve.\nEnabling Global Interconnections with Temporal Workflows in AI-Ready Data Centers at Equinix, the Worlds Digital Infrastructure Company\nEquinix is the backbone of the internet. In this talk, Vaibhav Tupe, Senior Staff Software Engineer at Equinix, will go in-depth to explain how their team uses Temporal-powered automation to scale and manage Software-Defined Networking (SDN) across global data centers.\nDatadog: Inside the Engine Room: Surviving the challenges of self-hosting Temporal\nSelf-hosting Temporal at Datadog started with a handful of clusters and grew to dozens. Over time, the increase in scale caused tremendous growing pains. In this session, Marcos Cela and Hardy Ferentschik, Senior Engineers at Datadog, will unpack the operational challenges they faced, from scaling surprises to outages and misconfigurations.\nResilience, Reliability, and Real-Time Response\nWhen failure isnt an option, resiliency becomes your architecture. These speakers will walk you through the workflows that keep their systems operational when the stakes are highest.\nControlling the Unknown: How KOHO Turned a Vendors Sev1 Outage Into a Non-Event\nAli Waseem, KOHOs Engineering Manager, will give a talk all about maintaining trust with your users. This talk centers around critical vendor integrations, real world factors, and the high-stakes decision that ultimately make the team choose Temporal.\nVerkada: Engineering a Durable Alarm System for Real-World Security\nVerkadas cloud-based alarm response system secures businesses, schools, and government buildings. The system detects threats, verifies visitors, and responds to intruders. Sai Teja Reddy Moolamalla, Engineering Lead at Verkada, will show how they built a fault-tolerant workflow engine for rapid, reliable security responses.\nDeveloper Platforms and Internal Tooling\nEngineering teams need to exceed whats considered good infrastructure: they need frictionless tools that let them move fast and build with confidence. These talks show how internal platforms are using Temporal to boost developer productivity.\nThe Saga of Orchestrating a Seamless Developer Experience at Maersk\nWith 4,500 engineers relying on Maersks internal platform, inefficiency is costly. Learn how Andrey Dubnik and Fatima Mookhtair, Platform Architects at Maersk, use Temporal alongside their entire team to power automation workflows, from infrastructure provisioning to deployment orchestration.\nNutanix: The Swiss Army Knife of Platform Engineering\nPlatform teams face an endless backlog of operational problems. Nutanixs Engineering Manager, Bharadwaj R Embar, shares how the team uses Temporal to automate workload orchestration, security approvals, and compliance enforcementand how they improved developer productivity and experience across the board.\nWhy Replay 25 Matters\n\n  You can read case studies, watch talks online, and even swap war stories on Slack, but nothing replaces being in the room with the minds whove already solved the problems youre facing.\n  Replay is where challenges get torn apart, examined, and put back together by the people building the most ambitious systems in the world.\n\nWhat youll take away:\n\n  Firsthand lessons from teams modernizing legacy systems and scaling distributed architectures.\n  Concrete technical deep divesno fluff, no hand-waving.\n  A chance to connect with engineers whove already tackled your toughest problems.\n\nWere in the final days counting down to Replay. Grab your tickets and join us in London, March 35!",featureImage:{title:"social-card-dark-waves (1) ",description:"social-card-dark-waves (1) ",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7fqbHM7iWOHKJo0GNha3Ou/ca1d6b6c63ab327d9e872eefa5a33627/social-card-dark-waves__1__1.png"},publishDate:"2025-02-13",metaDescription:"Explore engineering solutions for workflow orchestration from Temporal Replay 2025, featuring experts from Salesforce, Vinted, and Datadog.",metaTitle:"Temporal Replay 2025: Workflow Orchestration Solutions",socialCard:{title:"Replay-25-speaker-brag-blog",description:"Replay-25-speaker-brag-blog",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4oDJjGZFNWnXua8SiGqpyG/4b72897db3c03c025d90a923c30e24af/Replay-25-speaker-brag-blog.png"},tags:"Replay",slug:"meet-speakers-shaping-future-of-engineering-replay-25",contentType:"blogPost",entityId:"6OvDCL6LGsZUXDDylyuRW3",authors:[{id:"7GQtiP7y4Dmrje9sFWcVKl",name:"Lauren Bennett",slug:"lauren-bennett",jobTitle:"Content Marketing Manager",photograph:{title:"Lauren-Bennett-profile-photos",description:"Lauren-Bennett-profile-photos",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6jEqojw9RxBBjX5pytMzYf/4df0ef856a9efe4b7b52d5ebe7e83686/Lauren-Bennett-profile-photos.jpeg"},linkedInUrl:"https://www.linkedin.com/in/lauren-n-c-bennett/",contentType:"person"}],authorsString:"Lauren Bennett",category:"Community",readingTime:6},{title:"Reduce latency and speed up your Temporal Workflows",content:"If you're using Temporal for your workflows, you already know what a powerful tool it is for building durable and reliable systems. But what if you need your workflows to respond fasterespecially for user-facing applications? Latency can be a challenge when responsiveness matters. The good news is, there are ways to make your workflows snappier without sacrificing durability.\nWhen working with interactive user experiences, even small latency variations can cause significant problems. Temporal Cloud is fast, but its minimum workflow end-to-end latency is around 100ms. That might not seem like much, but it can quickly add up when you factor in necessary network calls and activity execution time. For workflows that need to fit within a 500ms latency budget, this end-to-end latency can become a real bottleneck.\nThis post covers techniques to improve workflow performance by optimizing response time. We will explain how to do this in a way that improves response time but maintains Temporals core strengths - durability and reliability.\nIt all begins with understanding where latency comes from.\nHot Paths and the Latency Problem\nDurable Execution with Temporal is a great solution for developers building simple, transparent, reliable systems, but there are valid objections for Temporal to be in the hot path for interactive user transactions. Take a look at this example, which is fairly standard for e-commerce use cases:\n\n  \n\nThe order has to be submitted, sent to the payment system, and sent to the pay order workflow where the transaction is validated, authorized, and captured. From there, the fulfillment process is triggered, and only then can the user receive the much-needed feedback regarding the success or failure of their payment.\nLatency reduction starts with breaking down and understanding where a workflow consumes time.\nMeasuring Temporal Workflow Latency\nWhen you manage your workflows with Temporal, the time it takes for the Workflow to complete depends on a variety of factors. This includes Workflow startup, Task scheduling, and network calls to the server.\nThis figure shows how latency can build up over time. Note, this is just an illustrative example and real latencies will vary.\n\n  \n\nIn this example, the Workflow Task requires some time for the Schedule and Start stages, plus some time to record results in the Completion stage, in addition to the 40 milliseconds of Worker run time.\nIn the corresponding Activity Task, the Schedule, Start, and Completion stages are also necessary. They add another 60 milliseconds to the 60 milliseconds used by the Activity Worker. As such, in this example, one single Activity takes 100 milliseconds (for the Workflow Task) + 120 milliseconds (for the Activity Task) to complete.\nLatency Testing Methodology\nThroughout this post, we use time measurements to show how Temporal application efficiency improves by adopting latency-reducing patterns and techniques. Heres how we did that:\n\n  We used a single laptop-based Worker written in Java.\n  We measured response times from the originating Client app, also on a laptop.\n  To simulate business logic in the Activities, we added a total of 120-milliseconds of sleep (see diagram below).\n  Our Worker was connected to Temporal Cloud in the US-East-1 region of AWS.\n\n\n  \n\nThe right number of properly tuned Workers, deployed closer to the Temporal Cloud Service, would have shown better performance and lower network latency, and investigating this is a great place to start to lower overall response time.\nUsing this testing methodology, the total end-to-end latency for the Workflow was 850 milliseconds before implementing the efficiency improvements discussed in this post.\nFaster User Feedback with the Early Return Pattern\nYou can deliver faster user feedback if you re-design this flow to run the payment and fulfillment tasks asynchronously.\nThe Early Return pattern is an effective way to reduce latency by splitting your workflow into two distinct parts:\n\n  The first part, Synchronous Quick Response, handles the essential tasks that need to be completed immediately, such as validation. It quickly processes these tasks and sends a response back to the user without delay.\n  The second part, Asynchronous Background Work, takes care of the longer, more complex tasks that dont require immediate user feedback. These tasks continue in the background, without blocking the user's workflow.\n\nThis approach improves the user experience, making your system feel more responsive without sacrificing your overall workflow integrity.\nHere is a diagram updated to show the validation is completed and returns to the user while the transaction completion in the workflow continues on asynchronously.\n\n  \n\nWhen we tested with Early Return, we found that our workflows were 40-50% (850 to 265 milliseconds) faster, as measured from the Client.\n\n  \n\nTry it out\nImplementing the Early Return pattern is a great way to reduce latency without sacrificing durability. Getting started with Early Return is easy, whether you're using Temporal Cloud or running a local or self-hosted Temporal Service.\nThese links let you try out the Early Return pattern for reducing latency in Java and Go:\n\n  Early Return Sample - Java\n  Early Return Sample - Go\n\nPlease note: Early Return uses the Update-with-Start feature:\n\n  In Temporal Cloud: Update With Start is in Public Preview.\n  Self Hosted/Local: If youre not using Temporal Cloud, update your Temporal server configuration to 1.26.2 - which includes the Public Preview release of Update With Start.\n\nUse Local Activities\nEarly Return lets you optimize your Workflows split into synchronous and asynchronous parts. But what if you cant split your workflow? You can still improve latency using Local Activities.\nLocal Activities run in the same process as your Workflows. This means theres no need to make a round-trip call to the Temporal Service. Local Activities can save 50ms or more for each activity.\nBe aware there are some limitations of Local Activities:\n\n  Local Activities work only for short activities that do not exceed the workflow task timeout. Local Activities do not support heartbeating.\n  Local Activities are not efficient for long retries. When a retry interval exceeds the workflow task timeout a timer is used to schedule the next retry. This implies that multiple events are added to the history on each retry. Normal activities can be retried practically indefinitely.\n  Local Activities have at least once semantics. A failure of a workflow task would lead to their re-execution. This includes re-execution of the whole sequence of Local Activities.\n  Local Activities extend Workflow task execution. While the task is running it cannot react to signals. So it increases the latency for signal and update handling.\n\nWhat you get, though, is a great tradeoff. You reduce the execution time significantly, making your Workflow speedier and more responsive.\n\n  \n\nHere you can see a breakdown of latency for Local Activity calls. Local Activities count as one Workflow Task, and they dont require a Start step to match with a Worker because theyre already matched to the Workflow worker. They can also save time by not recording completion until the end of a series of Local Activities.\nAs a result, our Local Activity results were 60-70% faster when measured from the Client versus regular activities. In our testing, the Local Activity implementation took only 275 milliseconds for the entire workflow vs 900 milliseconds for the original Workflow response time.\n\n  \n\n\n  What is Idempotency\n  Idempotency means designing your Activities to succeed once and only once. An idempotent approach avoids process duplication that could withdraw money twice or ship extra orders by mistake. Run-once actions maintain data integrity and prevent costly errors. Idempotency keeps operations from producing additional effects, protecting your processes from accidental or repeated actions, for more reliable execution.\n  For more information, check out Idempotency and Durable Execution.\n\nIn this example, our activities are short-lived and idempotent, so they are a good fit for Local Activity requirements.\nTry it out\n\n  Local Activity Sample - Java\n  Local Activities Workflow - Java\n\nCombining Techniques\nWant to squeeze even more speed out of your workflows? You can combine Early Return with Local Activities to return a response to the user more quickly while also continuing longer tasks in the background. This combination can cut your workflow response time by as much as 91%.\nIn tests, combining Early Return and Local Activities reduced total workflow time from the original 850ms to 160ms, making it 20% faster than Early Return alone, and 91% faster than the original workflow.\n\n  \n\nTry it out:\n\n  Java Sample\n  Go Sample\n\nEager Workflow Start to Make Workflows More Local\nIn a previous section, we discussed Local Activities. What if we could additionally make the Workflow local? Thats Eager Workflow Start.\nEager Workflow Start allows a Temporal Client to quickly execute a Workflow instead of delegating that execution to a separate worker. Normally, the Temporal Service assigns a task to a Worker that will durably execute the tasks. This assignment is called Matching. Matching adds extra time before the work begins to execute. With Eager Workflow Start, theres no need for that matching step, which allows your workflow to begin faster.\n\n  \n\nAs we said above, with Local Activities, the workflow went from running in 900ms to running in 275ms. When adding Eager Workflow Start (which cannot run without Local Activities), the workflow speed improved further to 262ms.\n\n  \n\nTry it out\n\n  In Temporal Cloud: You can request the pre-release \"Eager Workflow Start\" feature by opening a ticket or talking to your support team.\n  Self-Hosted/Local: If youre not using Temporal Cloud, set your Temporal server configuration by launching with the following flag to enable Eager Workflow Start:\n\ntemporal server [start-dev] \\\n--dynamic-config-value system.enableEagerWorkflowStart=true\n\n\n  Eager Workflow Start Sample - Java\n  Eager Workflow Start Sample - Go\n\nCalculate your Savings\nHeres a quick comparison of the different methods and their impact on latency:\n\n  Regular workflows: 850ms (total workflow)\n  Early Return: 199ms (first response)\n  Local Activities: 275ms (total workflow)\n  Early Return + Local Activities: 160ms (first response)\n  Eager Workflow Start + Local Activities: 265ms (total workflow)\n\n\n  \n\nMoving Forward\nThe techniques discussed in this post can help you drastically reduce latency, making your Temporal workflows faster and more responsive. Heres a summary of the techniques you can mix and match to achieve the latency your end users are looking for:\n\n  Worker Tuning\n  Worker Health and Deployment\n  Early Return Pattern\n  Local Activities\n  Eager Workflow Start\n\nDiscover More:\nWant to learn more about Temporal?\n\n  Take one of our amazing courses, such as Crafting an Error Handling Strategy, Versioning Workflows, Securing Application Data, Interacting with Workflows, and more!\n  Work through some of our Project-based tutorials.\n  Join our Support Forum and Community Slack.\n  Check out our local Meetups and Workshops.\n  Trying to explain Temporal to others? Show them our zine.\n",featureImage:{title:"hassaan-here-Ype8P9pAjXQ-unsplash (1)",description:"hassaan-here-Ype8P9pAjXQ-unsplash (1)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/KvEfARajfbO29cCpW6LFk/41429439f78f47be8e077b611fe16f23/hassaan-here-Ype8P9pAjXQ-unsplash__1_.jpg"},publishDate:"2025-02-12",metaDescription:"Latency can be a challenge when responsiveness matters. The good news is, there are ways to make your workflows snappier without sacrificing durability.",metaTitle:"Reduce end-user latency and accelerate Temporal Workflows",socialCard:{title:"hassaan-here-Ype8P9pAjXQ-unsplash (1)",description:"hassaan-here-Ype8P9pAjXQ-unsplash (1)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/KvEfARajfbO29cCpW6LFk/41429439f78f47be8e077b611fe16f23/hassaan-here-Ype8P9pAjXQ-unsplash__1_.jpg"},tags:"Code Samples",slug:"reduce-latency-and-speed-up-your-temporal-workflows",contentType:"blogPost",entityId:"74o7uSu8qSO2dBvNA6pLak",authors:[{id:"6SCT7ktnc7C7malyJV3UsQ",name:"Joshua Smith",slug:"joshua-smith",jobTitle:"Staff Solutions Architect",photograph:{title:"Josh Smith photo",description:"Josh Smith photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2DHNWCAITAPlTgzovWEEyW/1e105a12a16a24ca6db7f3c7ae0ef44b/1678726677795.jpeg"},contentType:"person"}],authorsString:"Joshua Smith",category:"Temporal Concepts",readingTime:10},{title:"Temporal in Space",content:"\nIntroducing our Official Mascot\nWhen we set out to create Temporals mascot, we had one goal: make it loveable, memorable, and unmistakably Temporal. A mascot isnt just a fun addition; its a way to make a brand feel approachable, relatable, and even inspiring.\nBut then we thoughtwhat if we did something truly out of this world? So we strapped a Raspberry Pi running a Temporal workflow to a weather balloon and launched it into space. Because why not?\nWhat on Earth is a Tardigrade?\nLets be clear, tardigrades are the only living species weve encountered that can survive in space. The tardigrade was an obvious choice for us to choose as our mascot. These teeny tiny, resilient creaturesknown as water bears or moss pigletsare natures ultimate survivors. Their unparalleled durability mirrors Temporals delivery of Durable Execution. And lets face it, tardigrades are quirky, fascinating, and just plain cooljust like the developers we work with every day.\nTardigrades are microscopic aquatic animals, with 8 legs and 4 to 8 claws. Not only are tardigrades super cute, theyre also nearly indestructible.\n\n  You can boil them, bake them, deep-freeze them, crush them, dehydrate them, or even blast them into space. - National Geographic (talking about Tardigrades, not Developers)\n\nFun Facts About Tardigrades:\n\n  Small but mighty: Tardigrades are typically 0.3 to 0.5 millimeters long\n  Temperature champions: They can survive at -458F / -272C or 302F / 150C\n  Radiation resistance: Tardigrades withstand radiation thousands of times higher than whats lethal to humans, thanks to their unique Dsup proteins that protect their DNA\n  Survival mode: In harsh conditions, they enter cryptobiosisa dormant state where they lose nearly all their body water and shut down metabolism. In this state, tardigrades can survive for decades without food or water\n  Diverse and adorable: With over 1,300 species, tardigrades inhabit moss, lichen, and soil, feeding on plant cells, algae, and small invertebrates\n\nCreating a Mascot\nWhen we pitched the idea of a tardigrade mascot to our co-founders, Samar Abbas and Maxim Fateev, it was an immediate hit, they never questioned our judgement, not even once. With their immediate and unconditional blessing, Lo McGuigan, our Staff Brand Designer, began sketching out concepts and exploring how to make the tardigrade both scientifically accurate and irresistibly cute.\n\n  \n  Behind-the-scenes sketches of Temporals mascot.\n\n\n  \n  Ziggys defining characteristics are: Expressive smile & tooth, eye highlights and cute blush, rounded claws on 8 legs.\n\nWhats in a Name?\nNaming our mascot was a truly collaborative effort. After much deliberation, we ultimately landed on Ziggy. The name is a nod to David Bowies Ziggy Stardust, tying in themes of space exploration, creativity, and individuality. But theres more to it than thatZiggy also means \"victorious protector.\" This meaning resonates deeply with our mission: empowering developers to conquer big challenges and safeguard their Workflows with Durable Execution.\nBringing Ziggy to Life\nOnce we had the name, we focused on refining Ziggys design for our first plushie. We worked hard to get the balance just right, ensuring Ziggy would be huggable, iconic, and memorable. To add to the excitement, we created limited-edition trading cards featuring Ziggy, giving our community a fun new way to engage with Temporal.\n\n  \n  A limited edition gold-foil Ziggy trading card given to attendees at Replay 2024 to commemorate the launch of our mascot.\n\nThe Plan: Launch Temporal into Space\nWe knew we wanted to debut Ziggy at Replay 2024, Temporals annual user conference, we just didnt know exactly how. While workshopping our Replay keynote outline, the idea magically came to us, and it seemed like a no-brainer to put Temporals durability to the test and send Temporal and Ziggy on an eco-friendly mission into space. So, we did exactly that.\nMeet Spencer\nHi! Im Spencer Judge, an engineer on Temporal's SDK team, whose day-to-day work involves contributing to the core library written in Rust that powers our SDKsexcept for Go and Java. But sometimes, working at a startup means you get pulled into unexpected and exciting projects. One of those moments came when Candace, our Head of Design, asked if I could help send Temporal into space.\n\n  \n  Ziggy after a space-suit-sleeve-cape fitting.\n\nI was intrigued. Who wouldnt be? It turns out the idea was to attach a Raspberry Pi 5 running a Temporal worker and a cell phone to a weather balloon and send it to the stratosphere. The goal? To showcase how Temporals robust fault tolerance and durability hold up, even in extreme conditions. Naturally, I said yes.\nThe Challenge\nWith just a week to pull this off, I had limited information:\n\n  Wed use a Raspberry Pi 5 to run the Temporal worker.\n  A USB-connected sensor would provide real-time GPS coordinates, altitude data, and more.\n  I had a sample data file to mimic the sensors output for testing.\n\nThe realistic approach wouldve been to send periodic signals back to Temporal Cloud, but wheres the fun in that? Instead, I aimed to run a full Temporal worker onboard the Pi. This approach would allow us to demonstrate Temporals ability to recover from connectivity loss and seamlessly continue operationsa core promise of our platform.\nBuilding the Application\nHeres how it all came together:\n\n  I wrote a simple Workflow in Python that invoked an Activity every five seconds. The Activitys job was to read data from a queue, parse it, and return the processed information.\n  Each data return was stored in Temporals Event History, allowing us to monitor GPS and altitude data directly in the Temporal UI.\n  I created a class to handle the USB sensor data. It connected to the device, parsed the incoming text line by line, and fed it into the queue for the Temporal Worker to process.\n  Using Pythons Serial library, I set up the connection, which (after some trial and error) worked reliablywell, mostly. The sensor required a manual reset each time it was initialized, so we made sure the launch team in the UK knew the exact procedure.\n\nTesting and Deployment\nDue to time constraints, I only had about an hour to test the setup remotely with the UK-based flight team. Despite the tight timeline, everything aligned. The data flowed from the sensor to the queue, the Temporal worker processed it, and the system worked flawlessly in the simulation.\n\n  \n  Ziggy is mounted to the space-rig and is ready for blastoff.\n\nThe Launch\nLaunch day arrived. The Raspberry Pi was strapped in, Ziggy was ready, and the countdown began. With a weather balloon as its vessel, Temporal took flight.\nHeres what we witnessed:\n\n  The device collected and processed sensor data as it climbed.\n  When the connection inevitably dropped in the upper atmosphere, Temporal handled it seamlessly, logging the interruption and resuming operations once connectivity was restored.\n  The workflow continued running, providing a real-time demonstration of Temporals fault-tolerance capabilities in a genuinely extreme environment.\n\n\n  \n  A screenshot of the Temporal Cloud Web UI reconnects after descending back to the Earths surface.\n\nTakeaways\nThis project wasnt just about sending Temporal into spaceit was about showcasing its resilience. While I knew Temporal would work (after all, we built it for reliability), the real-world challenges of working with hardware added an extra layer of excitement. Seeing everything come together and watching Temporal perform flawlessly was a proud moment for our team.\nThis experiment wasnt just about sending Temporal into spaceit was about proving that no matter how extreme the conditions, Temporal just works.\n\n  \n  Both Temporal and Ziggy survived the trip and landed gently in a random field.\n\nTemporal in Kerbal Space\nEven if Temporal isnt planning on doing real rocket science, its great for pretend rockets! Inspired by seeing Ziggy touch the edge of the atmosphere, Sean Gillespie, an infrastructure engineer at Temporal, had a little fun using Temporal Workflows to write an orbital computer for Kerbal Space Program. Temporal is rock solid, even if your Kerbal engineering isnt. Youre up, NASA!\nWhats Next for Ziggy?\nWhile Ziggys journey is just beginning, were already planning the next steps. Well continue to expand Ziggys world with different emotions, accessories, and customization options. Plus, theres plenty more Ziggy swag in the works, so stay tuned for exciting updates.\nHave you met Ziggy yet? Share your thoughts, tag us on social media with your Ziggy swag, and join us in celebrating Temporals mission to keep the world runningreliably and adorably.\n\n  \n  Ziggy poses for the camera while enjoying a sunset on the beach.\n\nOne small step for Ziggy and one giant leap for your Workflows. Try your hand at creating something great with a free trial of Temporal Cloud with $1,000 in free credits.",featureImage:{title:"Temporal Ziggy In Space",description:"Temporal Ziggy In Space",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7Fv20X7gIXVyoBtzVZVHh5/fd2f802eed0ad05ef5a2db921cfb05db/Tempora_Ziggy_In_Space.png"},publishDate:"2025-02-06",metaDescription:"Learn how we sent our favorite tardigrade, Ziggy, into space to see just how effective Durable Execution is.",metaTitle:"Temporal in Space",socialCard:{title:"Temporal-in-space",description:"Temporal-in-space",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2FoTpxDiWnbh8DaVfrSmI9/43a063f6854a3c01e6e00798ff89acbf/Temporal-in-space.png"},tags:"Industry Events",slug:"temporal-in-space",contentType:"blogPost",entityId:"5xFeoWh8S3WYP5B6SBiUMu",authors:[{id:"2UcuMJUqIceolZ3OJHiGMM",name:"Candace van Oostrum",slug:"candace-van-oostrum",jobTitle:"Head of Design",photograph:{title:"candace van oostrum",description:"candace van oostrum",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2BpFggz33vm1POFRxcr14M/12607eba7a929083b4e7637ee985b4d0/uVO-80gf_400x400.jpg"},twitterUrl:"https://twitter.com/candacevanoo",contentType:"person"}],authorsString:"Candace van Oostrum",category:"Community",readingTime:8},{title:"Mastering Saga patterns for distributed transactions in microservices",content:"\n  When building microservices, one of the biggest challenges is maintaining data consistency across decentralized systems. Distributed transactions can fail for a variety of reasons  network hiccups, service outages, or data conflicts  making reliable transaction management critical.\n  The saga pattern provides a robust, modern solution for handling these challenges seamlessly.\n\nIn this guide, well explore how the saga pattern works, its benefits, and tips for implementing it effectively in your microservices architecture.\nWhat You Should Know Before Learning About Sagas\nMicroservices are a collection of independent, loosely coupled services that collectively form a larger application. Unlike monolithic architectures, they emphasize modularity, making them more scalable and adaptable. Key aspects of microservices include:\n\n  Independent Services: Each service operates independently, allowing for more efficient development and deployment cycles.\n  Decentralized Data Management: Services manage their own databases, ensuring autonomy but complicating transaction coordination.\n  \n    Service Autonomy: Microservices communicate via APIs, promoting independence but requiring robust communication strategies.\n    Understanding these principles is essential before delving into the saga pattern.\n  \n\nACID Transactions in Traditional Systems\nACID transactions (Atomicity, Consistency, Isolation, Durability) ensure that operations either complete entirely or leave the system unchanged. This is feasible in monolithic systems with centralized databases. However, in distributed systems, achieving ACID compliance becomes impractical due to decentralized data, asynchronous communication, and varying failure modes.\nThese limitations demand alternative approaches, such as the saga pattern.\nSynchronous vs. Asynchronous Communication\nMicroservices rely on inter-service communication for coherence. The two primary communication methods are:\n\n  Synchronous Communication: Services interact in real-time, often using HTTP or gRPC. While intuitive, this introduces latency and tight coupling.\n  Asynchronous Communication: Services communicate via message brokers like Kafka, enabling scalability and fault tolerance. The saga pattern aligns well with asynchronous methods, reducing dependency bottlenecks.\n\nChallenges of Maintaining Consistency with Distributed Transactions\nDistributed systems introduce unique consistency challenges:\n\n  Eventual Consistency: Guarantees that services achieve a consistent state over time.\n  Partial Failures: Failures in one service can disrupt entire transactions.\n  \n    Concurrency Issues: Simultaneous transactions may conflict, requiring careful resolution.\n    Patterns like saga address these issues by coordinating actions and compensations across services.\n  \n\nWhat Are Sagas? A Simple Breakdown\nA saga is a sequence of distributed transactions where each step updates the system. If a step fails, compensating actions are triggered to revert changes. Its like booking a vacation and having something go wrong: if the flight reservation fails, hotel bookings and car rentals must be canceled to maintain consistency.\nTo explore this concept further, check out Saga Patterns Made Easy or watch our What Is a Saga webinar.\nHow Do Sagas Work? Coordinating Distributed Transactions\nSagas manage distributed transactions through two main approaches:\n\n  Choreography: Decentralized; each service listens for events and independently triggers subsequent actions.\n  \n    Orchestration: Centralized; a single orchestrator manages the transaction flow, invoking services and handling compensations when needed.\n    For more, read about saga compensating transactions.\n  \n\nChoreography Sagas\nIn a choreography-based saga, services publish events that other services react to. For example, an Order Created event could trigger payment processing and inventory updates.\nOrchestration Sagas\nIn an orchestration-based saga, a central orchestrator directs transaction steps, ensuring clear visibility and control over the workflow.\nOrchestration vs. Choreography\nChoosing between orchestration and choreography depends on system requirements:\n\n  Orchestration: Ideal for complex workflows needing clear visibility and control.\n  \n    Choreography: Suited for simpler, loosely coupled systems.\n    Learn more about this decision in Saga Orchestration vs. Choreography.\n  \n\nKey Components of the Saga Pattern\nThe saga pattern consists of:\n\n  Participants: Services that execute individual operations within the distributed transaction, like payment processing or inventory updates.\n  Compensation Actions: Reversal steps to undo changes if a failure occurs, ensuring system consistency (e.g., canceling a shipment or refunding a payment).\n  Steps: The sequence of operations forming the transaction, typically executed via either choreography or orchestration.\n  Coordinators: (In orchestration models) A central service that manages the transactions flow, ensuring steps execute in the correct order and triggering compensation actions when needed.\n  Event Logs/State Tracking: Mechanisms to track the progress of each step and maintain state, crucial for retrying failed operations or ensuring idempotency in distributed systems.\n\nWhen to Use the Saga Pattern in Microservices\nThe saga pattern is particularly beneficial in:\n\n  E-commerce: Managing orders, payments, and inventory.\n  Finance: Handling multi-step approval processes.\n  IoT Systems: Coordinating device interactions.\n\nSaga Example: Implementing a Saga in E-Commerce Systems\nAn e-commerce platform might use sagas to manage orders:\n\n  Order Creation: The order service logs the order and publishes an event.\n  Payment Processing: The payment service confirms the transaction.\n  Inventory Update: The inventory service adjusts stock levels.\n  \n    Shipping: The shipping service schedules delivery.\n    If a payment fails, the system cancels the order and restores inventory.\n  \n\nError Handling in Sagas: What Happens When a Step Fails?\nSagas are designed to handle failures gracefully. Compensation actions reverse the effects of failed steps, ensuring consistency. For example:\n\n  In orchestration, the orchestrator triggers compensations automatically.\n  In choreography, services independently handle failure events.\n\nBest Practices for Reliable Transaction Management\nTo implement sagas effectively:\n\n  Design for Failure: Anticipate and mitigate potential failures.\n  Ensure Idempotency: Enable repeated execution without side effects.\n  Define Compensation Actions: Plan rollback mechanisms for each step.\n\nBenefits of Using the Saga Pattern\nSagas offer:\n\n  Fault Tolerance: Minimize disruptions from failures.\n  Scalability: Decentralized operations handle increased workloads.\n  Flexibility: Adapt to diverse system requirements.\n\nCommon Pitfalls and Mistakes When Implementing Sagas\nAvoid these errors:\n\n  Undefined Compensation Actions: Ensure every step can be reversed.\n  Poor Timeout Management: Handle delays without cascading failures.\n  Overcomplication: Keep the workflow simple and manageable.\n\nHow to Monitor and Debug Sagas in Production\nMonitoring Sagas ensures smooth operations. Use:\n\n  Tracing: Track transaction flows across services.\n  Observability Tools: Identify and resolve bottlenecks.\n  Logs: Record detailed transaction histories.\n\nComparing Sagas with Other Transaction Management Patterns\nSagas differ from:\n\n  Two-Phase Commit: ACID-compliant but lacks scalability.\n  Compensating Transactions: Focus on rollback actions but lack orchestration.\n\nSuccess Stories from Real-World Applications\nTemporals platform has been instrumental in enabling organizations to adopt the saga pattern effectively:\n\n  ANZ Bank leveraged Temporal to streamline their home loan origination system, reducing a project timeline from over a year to mere weeks.\n  Maersk used Temporal to enhance logistics operations, cutting feature delivery times from 6080 days to just 510 days.\n  Similarly, DigitalOcean integrated Temporal to synchronize distributed transactions across storage systems, improving system reliability and engineering velocity.\n  Netflix also used Temporal to simplify workflow orchestration, boosting developer productivity and system resilience.\n\nThe Future of Sagas: Trends in Distributed Transaction Management\nThe saga pattern is evolving to enhance usability and effectiveness in distributed systems. Event-driven architectures are becoming central, enabling scalability and asynchronous communication by decoupling services. Improved data isolation mechanisms reduce anomalies in concurrent transactions, while tools like in-memory caching and commit-sync services address consistency challenges by committing only completed transactions to the database.\nKubernetes and service meshes simplify saga-based workflows with built-in support for service discovery, load balancing, and fault tolerance. Advanced tooling for monitoring and debugging makes tracing and resolving issues easier than ever. As these technologies progress, developers can expect more sophisticated frameworks, cementing sagas as a powerful solution for managing distributed transactions.\nMastering Sagas for Robust Microservices\nSagas are a cornerstone of modern microservices architecture, enabling reliable, scalable transaction management. By mastering this pattern, developers can ensure system consistency and resilience, paving the way for innovative, robust applications.\nWant to simplify distributed transaction management in your microservices? Start exploring Temporals durable execution platform with $1,000 in free credits and access our comprehensive documentation to get started.\nWe also cover SAGA patterns in our Error Handling Strategies Course, where youll learn practical techniques for managing failures in distributed systems.",featureImage:{title:"social-sphere",description:"social-sphere",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4DWjFPWLbTSnteonueNbg7/3b31c73c03bfa544469db528e918a4cd/dynamic-wang-KZuZAaEojq4-unsplash.jpg"},publishDate:"2025-01-31",metaDescription:"Learn how saga patterns handle distributed transactions in microservices, ensuring data consistency and system resilience with key concepts and best practices.",metaTitle:"Saga Pattern in Microservices: A Mastery Guide",socialCard:{title:"saga-distr-social-card",description:"saga-distr-social-card",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6EgkxeuNR7NbUl1Mdwvvws/1abebdff6e069188625e3ff12f078cc6/Blog__10_.png"},tags:"Saga Pattern",slug:"mastering-saga-patterns-for-distributed-transactions-in-microservices",contentType:"blogPost",entityId:"1IEEHWwOx3UijV1vbp8nNc",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"Temporal Concepts",readingTime:7},{title:"Replay 2024 highlights: Why Replay 2025 will be even bigger",content:"Replay is the conference where developer-first thinking takes center stage. We understand what youre up against: building visionary systems, navigating real-world challenges, sidestepping the hollow promises that dont address the true problems youre actually facing.\nReplay 2025 is your chance to connect, collaborate, and brainstorm practical solutions to backend challenges.\nDont sweat it if you missed Replay 2024  Replay 2025 will be even better. Curious about the kind of value youll gain this March 35 in London? Take a look at some of the key takeaways from Replay 24.\nHighlights from Replay 2024\nHeres a glimpse into the sessions led by industry leaders across fields:\nFinancial Services\nJPMorgan Chase Modernizes with Temporal Cloud\nWhen youre handling $10 trillion in daily transactions, you need a platform that doesnt flinch under pressure.\nJPMorgan Chase shared how theyve modernized their payment services with Temporal Cloud, improving fraud detection and ensuring every critical workflow runs reliably. Their talk highlighted how durable execution drives resilience at a staggering scale.\nWatch the talk\nTechnology and SaaS\nZoomInfos Real-Time Precision with Temporal Cloud\nZoomInfo walked us through their transformation, processing hundreds of millions of operations each month while eliminating infrastructure headaches. With Temporal Cloud handling the heavy lifting, their team could focus on building optimized workflows, slashing development time and achieving unmatched marketing precision.\nRead the full story\nSalesforce Streamlines with 95% Less Code\nWhat happens when you replace custom retry logic with Temporal workflows? For Salesforce, it meant a 95% reduction in workflow code complexity. Their engineers discussed how simplifying their system boosted resilience, increased developer productivity, and made time for the work that truly matters.\nRead the full story\nCloudflares Production Readiness at Scale\nCloudflare gave us a peek behind the curtain at how they keep their global edge network resilient. Automating production readiness checks with Temporal Schedules made their deployments safer, smoother, and more predictable.\nWatch the talk\nMedia\nThe Washington Posts 600% Efficiency Boost\nThe Arc XP team showed how Temporal powered a 600% increase in runtime efficiency for their media workflows. What used to take hours now takes minutes, enabling their teams to focus on creating content rather than wrangling infrastructure.\nRead the full story\nNetflixs Cross-Team Workflow Innovation\nNetflix revealed their strategy for simplifying durable execution within massive microservices architectures using Temporal Nexus. Their approach streamlines cross-team workflows without compromising reliability or scalability.\nWatch the talk\nConsumer and Retail\nYUM! Brands Global Workflow Success\nYUM! Brands detailed how Temporal supports loyalty programs and order systems across 53,000 locations worldwide. Their delayed execution workflows ensure everything  from promotions to order queues  runs seamlessly at a global scale.\nWatch the talk\nFinTech\n\n  Cash Apps Success with Temporal Platform as Product\n  Cash App described the journey of turning their reliable but underused internal platform into a developer-friendly solution. Their early if you build it, they will come mindset didnt prove to be true. Developers found workflows complex and questioned why they needed Temporal.\n\nTo change this, the platform team shifted to a \"Platform as Product\" approach. They tailored onboarding by grouping users into beginner, advanced, and expert levels, providing tools and documentation for each stage. This personalized approach met developers at their level, building trust and encouraging adoption.\nThe results? Temporal now powers over 60 use cases at Cash App, handling six billion actions monthly. The shift reduced incidents, improved workflow efficiency, and streamlined onboarding.\nRead the full guide\nWhy Replay 2025 Will Be Even Better\nThis year, Replay all about embracing change. Whether youre working with a legacy system or sprawling microservices, youll leave with a blueprint for building resilient, scalable systems.\nHeres what you can expect this year:\n\n  Keynotes: Learn from pioneers whove been in your shoes from companies like Salesforce, Datadog, Vodafone, and more.\n  Hands-on workshops: Roll up your sleeves and work directly with Temporal in Go, Java, and .NET.\n  Hackathon: Put your heads together with other developers to create something extraordinary.\n  Networking: Meet engineers, architects, and thought leaders who understand your challenges.\n\nReplay 2025 is where youll discover your next big idea  and meet the people who can help make it happen.\nGet your tickets now and join us in London, March 35, 2025!",featureImage:{title:"bedrock-post-micke-lindstrom-6REIcx1yeuI-unsplash",description:"bedrock-post-micke-lindstrom-6REIcx1yeuI-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6UsfEJOHJYe9px5G02SzYS/8370488f6dc6b817001daee185b11321/micke-lindstrom-6REIcx1yeuI-unsplash.jpg"},publishDate:"2025-01-29",metaDescription:"Join Replay 2025 in London, March 3-5, to learn from industry leaders like Salesforce and Vodafone. Attend keynotes, hands-on workshops, and a hackathon focused on building resilient, scalable systems. Dont miss the developer event of the year!",metaTitle:"Replay 2025: The Ultimate Developer-First Conference",socialCard:{title:"Replay-2024-highlights-why-2025-will-be-even-bigger",description:"Replay-2024-highlights-why-2025-will-be-even-bigger",url:"https://images.ctfassets.net/0uuz8ydxyd9p/32clH3G2IQLR0039k7EYYn/652d8ebf373a455b09cd3d4e9afc7f88/Replay-2024-highlights-why-2025-will-be-even-bigger.png"},tags:"Replay",slug:"replay-highlights-why-replay-2025-even-bigger",contentType:"blogPost",entityId:"5rYs2vmsHMwrZ1oHBTrF90",authors:[{id:"7GQtiP7y4Dmrje9sFWcVKl",name:"Lauren Bennett",slug:"lauren-bennett",jobTitle:"Content Marketing Manager",photograph:{title:"Lauren-Bennett-profile-photos",description:"Lauren-Bennett-profile-photos",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6jEqojw9RxBBjX5pytMzYf/4df0ef856a9efe4b7b52d5ebe7e83686/Lauren-Bennett-profile-photos.jpeg"},linkedInUrl:"https://www.linkedin.com/in/lauren-n-c-bennett/",contentType:"person"}],authorsString:"Lauren Bennett",category:"Community",readingTime:4},{title:"Durable Digest: January 2025",content:"This blog post is a public copy of our monthly newsletter. If youd like to receive upcoming updates by email, you can subscribe to our newsletter here.\nHappy New Year! Were kicking off 2025 with some exciting updates: a new Workflow Update feature, the Ruby SDK pre-release, and fresh SDK updates across multiple languages.\nMark your calendars for our Founders Lunch & Learn in NYC and Replay 2025 in Londonearly bird tickets wont last!\nFor more information on these updates and other things weve been working on, just keep reading! And as always, wed love to hear from youfeel free to share feedback in our Community Slack, or on X (@temporalio).\nProduct Updates\n\n  Introducing the Workflow Update, a powerful new feature that allows you to update running workflows dynamically, enabling greater flexibility for evolving business requirements without restarting or redeploying workflows. Discover more use cases in our blog post.\n  The Ruby SDK is officially in pre-release and includes nearly full feature parity with other SDKs. Were looking for your feedback! To get started, check out the README, and join the #ruby-sdk channel on our Community Slack for discussions, feedback, and questions.\n\nSDK Updates\n\n  Go SDK 1.32.1 is now available, including support for the revamped Worker Versioning/Safe Deploys feature, still in pre-release.\n  TypeScript SDK 1.11.6 introduces the new experimental Update-With-Start feature, allowing developers to start a Workflow and issue an Update to that workflow in a single API call.\n  Python SDK 1.9.0 and .NET SDK 1.4.0 introduce support for three new experimental features. Update-With-Start (described above), User Metadata, and custom slot suppliers in worker tuners. See the release notes for details!\n  PHP SDK 2.12.0 and subsequent releases add support for Update-With-Start, and a new Mutex class useful for synchronizing different handlers in the same Workflow.\n  The experimental Ruby SDK 0.3.0 adds support for writing and launching Workflows and Schedules. It drops support for the end-of-life Ruby 3.1 and makes some breaking changes to Activity definitions.\n  Temporal CLI 1.2.0 provides updated support for the experimental Worker Versioning/Safe Deploys feature, and includes additional commands for managing Activities.\n\nMeetups & Events\nTemporal Founder Lunch & Learn\nJoin us on February 6, 2025, for an exclusive Temporal Founder Lunch & Learn at Sequoia Capital in NYCa must-attend event for founders and technical leaders looking to scale smarter and ship faster.\nIn this interactive session, youll discover how Temporal can help you:- Simplify development and reduce technical debt- Ship features faster without sacrificing reliability- Minimize operational complexity so you can focus on growth\nDont miss this opportunity to learn how to accelerate your startups success with Temporal. Spots are limitedregister now! https://pages.temporal.io/startup-founder-lunch-learn-0225\nReplay 2025\nTemporals flagship conference happening March 3-5 in London! Join industry leaders from Verkada, Mollie, Vinted, Wise Payments, Salesforce, and more as they share insights on how to modernise and shape the future of application development.\nEarly bird tickets are only available until January 31 at 12:00 PM Pacific, so act fast to save your spot. Workshops in .Net and Java, plus the exciting hackathon, are still open for registrationvisit replay.temporal.io now to learn more!\nWebinars\n\n  Connect Temporal Applications Across Isolated Namespaces with Nexus\n  Designing High Performance Financial Ledgers\n\nResources\nThe Developer Education team just released Temporal 101 in .NET! We have a few more .NET courses coming your way soon. Sign up here to receive updates!\nWere also hosting a Temporal 101 in TypeScript webinar on February 12 at 9:00 AM PST. Register here!\nCommunity Shout-Outs\n\n  In this short video, Cecil Phillip shows you how to use Temporal to handle order fulfillment after receiving a payment with Stripe.\n  Ever wanted to Build an AI Agent with Temporal? Now you can, thanks to this great video (and repo) by Steve Androulakis.\n  For more agentic AI fun, see Jerron Lims Rojak project  A library for building highly durable and scalable multi-agent orchestrations.\n  And finally, Cornelia Davis continues churning out amazing blog posts, including this deep-dive into What does preserving state really mean in Temporal?\n\nIf you have content or code youve created around Temporal, please tell us about it in #show-us-what-you-got on Community Slack!\nBlog Highlights\n\n  Deploying Temporal Workers to Google Cloud Run\n  What is Fault Tolerance?\n  Building Durable Cloud Control Systems with Temporal\n  Reliable Data Processing: Queues and Workflows\n  Building Resilient Event-Driven Architecture for Financial Services with Temporal\n",featureImage:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},publishDate:"2025-01-28",metaDescription:"Explore Temporals latest developer updates: questions from the field, new releases, builder spotlights, learning resources, and ways to connect with our team.",metaTitle:"Durable Digest: January 2025",socialCard:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},tags:"",slug:"durable-digest-january-2025",contentType:"blogPost",entityId:"6CMiTGlPcZUZbQajl7o3wj",authors:[{id:"17hGmNrCwtXdBh7fhsLUnZ",name:"Temporal Technologies",slug:"temporal-technologies",photograph:{title:"temporal technologies logo",description:"temporal technologies logo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3g56zRXtFQYMeJxBBkVBIZ/7771670e5fc7da59f555837b086c35d6/temporal_technologies_logo.avif"},company:"Temporal Technologies",contentType:"person"}],authorsString:"Temporal Technologies",category:"Announcements",readingTime:4},{title:"Simplifying distributed transactions with microservices",content:"Distributed systems are the backbone of modern application architectures. They enable scalability and modularity, but they also introduce challenges. Distributed transactions in a microservices-based architecture exemplify this. How do you ensure reliability amid failures? How can you debug a problem that spans multiple services? Developers often struggle to answer these questions, as progress slows in response to increasing system complexity.\nTemporal transforms microservices orchestration by providing a fundamentally better approach for developing distributed applications. In this blog post, youll explore common pitfalls in managing distributed transactions and learn how Temporal simplifies them.\nMicroservices Application Example\n\n  \n\nThe illustration above represents an e-commerce application that uses four steps to process orders:\n1. Fraud Check: To protect the business against theft, the application first contacts the fraud service, which evaluates the order details and flags fraudulent transactions.\n2. Prepare Shipment: If the order passes the fraud check, the application contacts the inventory service to reserve the items ordered by the customer.\n3. Charge Customer: The application contacts the payment service to charge the customer for the products in their order currently available in inventory.\n4. Ship Order: The application contacts the shipping service, which generates a shipping label and schedules a driver to deliver the shipment to the customer.\nOrchestrating Microservices the Hard Way\nHere are some of the challenges that developers face when coordinating transactions across multiple services:\n- Ephemeral State: Processes may end prematurely due to unexpected failures, leading to incomplete transactions or debugging nightmares.\n- Lack of Visibility: State is strewn across multiple services, making it difficult to understand progress and diagnose problems in the application.\n- Limited Reliability: Service outages may cause interruptions, often requiring manual intervention and potentially leading to failures in other parts of the system.\nConventional Approaches and Their Shortcomings\nTeams have adopted various strategies to address these problems, including:\n1. Stateful Services: Each service maintains its own database to track state. While this ensures data isn't lost, it introduces multiple state machines that must be managed and synchronized, adding complexity to the system.\n2. Event Stores or Messaging Systems: Tools such as Kafka can provide protection against service outages by decoupling the service that produces a message from the service that consumes it. However, this can further reduce the lack of visibility in the overall system, especially after adding dead letter queues to deal with failures.\nClearly, these approaches mitigate certain risks but often introduce new problems.\nOrchestrating Microservices the Durable Way\nThe defining characteristic of a distributed application is the increased potential for failure. Temporal addresses this by providing Durable Executioncrash-proof executionthrough an abstraction known as a Workflow. A Workflow is a function or method that defines your business logic using a standard programming language, such as Java, Go, or Python. Unlike other methods or functions in those languages, it can overcome both software and hardware failures.\nHere is how Temporal simplifies distributed transactions by directly addressing these challenges:\nEliminate Ephemeral State Issues: Temporal Workflows automatically persist state at every step, eliminating the risk of losing it if the process crashes.\nGain Visibility Into Execution: Temporals Event History records the applications progress and results. This is accessible via a convenient web-based user interface, delivering insights into both current and past behavior of each execution.\nImprove Reliability: Temporal enables automatic retries to address service outages and intermittent failures, with retry policies you can customize to align with business requirements.\nCentralize Orchestration Logic: Temporal Workflows define the overall business logic in one place. This simplifies updates, debugging, and enhances clarity and maintainability.\nKey Components of Temporal Design\nTemporals design introduces abstractions that simplify handling distributed transactions:\n1. Workflows:\n\n  Each Workflow Execution has a unique ID. These are user-defined values, typically corresponding to a business-level identifier (such as an order number or account name), providing better traceability.\n  Temporals design ensures that no more than one Workflow Execution with a given ID will be running at any given point in time, which protects against duplicate processing.\n\n2. Activities:\n\n  Activities encapsulate operations that may fail, such as database queries or calls to external services\n  Built-in retry policies ensure that even error-prone steps succeed reliably.\n  Activities support modularity by enabling reuse across Workflows.\n  Activities enable cross-team collaboration even when teams dont share a common programming language. Each Activity can be written in any language that Temporal supports, even a different one from the Workflow itself.\n\n3. Event History:\n\n  Temporal stores the execution history of Workflows as a series of events, visible in the Temporal Web UI.\n  This history enables Workflows to be reset to any prior state, allowing for easy debugging and error recovery.\n  It also serves as a rich audit trail for compliance and observability.\n\nThese components address common pain points in distributed transactions, enhancing system reliability and manageability.\nTemporal in Action\nTemporal ensures that if any step fails  e.g., a payment gateway timeout occurs  the system automatically retries or resets to the previous state without losing progress. Instead of many disconnected events sent to multiple systems run by different teams, Temporal collects events related to a specific transaction into that Workflows Event History. This consolidation allows any team to see all events related to a process in one place.\nFor example, events like validating an account, credit or debit transactions, or checking for fraud which are typically scattered across services  are collected into a single Workflow. Real-world transactions often involve more complex and varied events. By consolidating these events into Workflows, Temporal enhances visibility and simplifies operations.\nWhy Choose Temporal?\nTemporal doesnt just address the challenges of distributed transactions  it fundamentally changes how developers design and manage systems. By abstracting away infrastructure complexities, Temporal empowers teams to focus on business logic rather than plumbing.\nThe result? Systems that are simpler, more reliable, and easier to evolve over time.\nReady to simplify your microservices architecture? Try Temporal today.",featureImage:{title:"buddha-elemental-3d-br5JFHhkoIA-unsplash (1)",description:"buddha-elemental-3d-br5JFHhkoIA-unsplash (1)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6KZNZOYRsAXONUbNuA5V7f/2f1ec7f2dd615ca6d4bb766d98271bff/buddha-elemental-3d-br5JFHhkoIA-unsplash__1_.jpg"},publishDate:"2025-01-28",metaDescription:"Simplify distributed transactions in microservices with Temporal. Learn how durable execution, automatic retries, and centralized orchestration improve reliability, visibility, and debugging in complex systems.",metaTitle:"Simplifying distributed transactions with microservices",socialCard:{title:"Simplifying Distributed Transactions with Microservices",description:"Simplifying Distributed Transactions with Microservices",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5YHiXOl8wQr3QaSSWW12rU/40fffb621daf8442991e061563b71f13/Simplifying_Distributed_Transactions_with_Microservices.png"},tags:"Architecture",slug:"simplifying-distributed-transactions-microservices",contentType:"blogPost",entityId:"3u6DFouA54uOLrr89YQIxR",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"How-To",readingTime:5},{title:"Building resilient event-driven architecture for finance with Temporal",content:"Event-driven architecture (EDA) has become the default approach for many financial services applications, promising scalability, modularity, and real-time responsiveness. However, traditional choreography-based EDA often introduces complexity that undermines these benefits. Temporal offers a new paradigm for building resilient, maintainable systems by centralizing control through durable execution and workflow orchestration.\nThis blog post explores the limitations of traditional EDA, Temporals unique approach, and practical strategies for implementing it in financial services.\nThe Problem with Choreography-Based EDA\nChoreography-based EDA structures applications around independent microservices that react to events autonomously. This design often seems like a natural fit for distributed systems, offering runtime flexibility and loose coupling between services. However, this approach frequently leads to substantial challenges, especially as systems scale in complexity.\n\n  Scattered Business Logic. With choreography, the logic for even simple workflows is fragmented across multiple services. Each service maintains its own state, processes events independently, and communicates through loosely defined contracts. This scattering makes it nearly impossible to understand the complete workflow from a single vantage point. Debugging requires sifting through logs and tracing events across numerous services, increasing the time and effort required to resolve issues.\n  Hidden Coupling. While choreography-based EDA promises loose coupling at runtime, the reality is more nuanced. Services become tightly coupled at the design level because they depend on shared event formats and protocols. A seemingly minor change  such as altering an event schema  can cascade through the system, breaking multiple services and leading to costly maintenance efforts.\n  Error Handling Complexity. In a choreography-based system, there is no centralized mechanism to manage errors, retries, or compensations. Each service must implement its own logic to handle failures. For example, if a service crashes while processing a payment request, the system could lose track of whether the payment was completed, resulting in inconsistencies like double charges or missed transactions. These gaps often force teams to rely on manual intervention, which is both inefficient and error-prone.\n  \n    Limited Observability. Choreography distributes state across services, hiding it in local databases, queues, and event logs. This lack of visibility creates a black box effect, where developers must piece together incomplete information to diagnose problems or understand system behavior.\n    The underlying issue is that choreography places events at the center of the system, making them the de facto unit of coordination. This creates incidental complexity  challenges that arise not from the problem itself but from the design choices made to solve it. Systems designed this way are brittle, hard to scale, and expensive to maintain.\n  \n\nTemporal: A Shift to Durable Execution\nTemporal addresses these issues by replacing event-centric design with durable execution. This approach centralizes business logic in Workflows that are resilient, observable, and easy to manage.\nKey Benefits\n\n  Stateful Workflow Management: Temporal maintains the state of Workflows across outages, ensuring processes resume from the exact point of failure without manual intervention.\n  Integrated Error Handling: Temporal provides built-in mechanisms for retries, compensations, and timeouts, making Workflows more reliable.\n  \n    Unified Observability: Temporals centralized view of Workflow execution allows developers to trace and debug processes efficiently.\n    Instead of fragmenting logic across services, Workflows in Temporal encapsulate the entire business process, while features like Nexus enable better communication between services. This makes systems easier to reason about, modify, and scale.\n  \n\nBest Practices for Implementing EDA with Temporal\nTo fully leverage Temporals capabilities, consider these technical strategies:\n\n  Workflows as Code. Temporal Workflows are written in standard programming languages like Go, Java, and Python. This enables version control, unit testing, and easier collaboration compared to DSLs or graphical tools like BPMN.\n  Modular Activities. Break Workflows into modular Activities, each representing a specific unit of work (e.g., calling an API or writing to a database). This modularity simplifies testing and reuse.\n  Error Recovery and Compensation. Define retry policies and compensation workflows to handle failures gracefully. For example, in a multi-step transaction, Temporal can roll back earlier steps if a downstream service fails.\n  Dynamic Workflow Design. Leverage Temporals ability to dynamically define workflows based on external configurations or runtime conditions. This flexibility enables workflows to adapt to changing business requirements without major rewrites.\n  Incremental Adoption. Integrate Temporal into specific components of your architecture before scaling its usage. For example, use Temporal to replace a state machine in one service, then expand its role over time.\n\nNext Steps: Future-Proofing Your Architecture\nTemporal not only addresses the pitfalls of choreography-based EDA but also enhances its core benefits, such as modularity and scalability. By centralizing orchestration, Temporal enables financial institutions to reduce risk, improve reliability, and accelerate modernization.\nFor a deeper dive into how Temporal can transform your event-driven systems, download our white paper on risk and reliability in financial services. To explore the technical nuances of EDA design, check out our comprehensive EDA guide. Both resources provide actionable insights for building resilient architectures in high-stakes environments.",featureImage:{title:"social-card-water-effect",description:"social-card-water-effect",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2KTpNohgF4VK8RxG2r4vlT/500df86e294043f8d19983961e4c2a0c/social-card-water-effect.jpg"},publishDate:"2025-01-23",metaDescription:"Discover how Temporal simplifies event-driven systems, replacing complexity with scalability, reliability, and centralized workflows.",metaTitle:"Resilient Event-Driven Architecture for Finance",tags:"Architecture,Finance",slug:"building-resilient-event-driven-architecture-for-finserv-with-temporal",contentType:"blogPost",entityId:"1SB8Zszm31jKgmPjoGJnT0",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"Temporal Concepts",readingTime:5},{title:"Reliable data processing: Queues and Workflows",content:"Picture a bustling restaurant kitchen where orders flow continuously from waiters to chefs. Now imagine if those orders could never be lost, even if the kitchen caught fire. That's the power of persistent queues in distributed systems  data structures that reliably store and forward messages between services, guaranteeing delivery even through system failures.\nIn this post, we'll continue our series (blog one, blog two) unpacking our Principal Software Engineer, Sergey Bykovs, talk Dealing with Failure. This post takes a deep dive to explore persistent queues  their strengths, their disadvantages, and crucial implementation patterns. We'll also unpack how Temporal revolutionizes the way you build distributed systems using Durable Execution.\nWhat is Durable Execution?\nDurable Execution is crash-proof execution.\nTemporal delivers Durable Execution through an abstraction known as a Workflow, which is a function or method guaranteed to continue running despite conditions that would otherwise cause it to fail. A Workflow can withstand service outages and network instability. It can even overcome application crashes and hardware failures by continuing execution in a new process, potentially on a different machine.\nDurable Execution abstracts away the complexity of building reliable distributed systems, which reduces the amount of code you need to develop, debug, and maintain.\nWhat Are Persistent Queues?\nA persistent queue is a message storage and transfer system that guarantees message delivery in distributed systems. Think of persistent queues as your system's safety deposit box  a place where messages aren't just passed through, but carefully stored on disk until they're properly handled.\nMessages stored in a persistent queue survive any disruption  server crashes, system restarts, or even complete power failures. When a message enters a persistent queue, the queue saves it durably to disk before confirming receipt. Only then can the message be delivered to its destination. This write-to-disk guarantee is what makes these queues \"persistent\" and differentiates them from in-memory queues that lose their contents when systems restart.\nPersistent queues decouple the services that send messages (producers) from the services that receive messages (consumers) in two important ways.\nFirst, they don't need to be running at the same time (time decoupling)  a service can send messages even when the receiving service is temporarily down.\nSecond, they don't need to know about each other's location (space decoupling)  producers only need to know how to send messages to the queue, not the final destination of their messages. For example, in an e-commerce system, the Order Service can send order notifications to a queue without knowing anything about the Shipping Service that will process them.\nThis means you can move the Shipping Service to different servers or replace it entirely without needing to update the Order Service. The queue acts as a reliable intermediary, ensuring messages are safely stored and delivered when consumers are ready to process them.\nIndustry giants rely on these persistent queues every day: Amazon SQS guarantees your shopping cart won't vanish, Kafka ensures Netflix knows exactly where you paused that movie, and RabbitMQ persists your bank transfers. Financial institutions use persistent queues to track transactions, e-commerce platforms depend on them to ensure not a single order slips through the cracks, and logging systems use them to capture every important system event  because in these scenarios, losing a message isn't just inconvenient, it's unacceptable.\nWhether you're building payment systems, order management platforms, or event-driven architectures, queues ensure reliability and scalability, which is key to building robust distributed systems.\nPros and Cons of Persistent Queues\nPersistent queues offer significant advantages. As mentioned, they preserve messages through system crashes and ensure data survival when everything else fails.\nImagine an e-commerce site during a flash sale where 1,000 orders flood in every second. Without a queue, the order processing service would be forced to handle all these orders immediately, likely causing it to crash. However, with a queue in place, the system can handle this traffic elegantly: all incoming orders are first stored safely in the queue, while the processing service works through them at a sustainable rate of 100 orders per second. The remaining orders wait in the queue, ensuring no orders are lost and all are processed correctly when the service is ready.\nThis separation between the services sending orders (producers) and the services processing them (consumers) is crucial. The website can keep accepting orders at high speed even if the processing service is running slowly, preventing any single component from becoming overwhelmed. Plus, if the system crashes, the queued orders remain safely stored and ready for processing when the system recovers.\nWhile queues excel at storing and delivering messages, they leave much of the complexity of handling failures to the development team. When processing fails, retries are critical. While message consumers can be programmed to retry failed operations, they require careful implementation to handle complex retry logic -- one downside of queues. Teams need to build exponential backoff logic to prevent overwhelming struggling systems, handle different types of failures appropriately, and track retry counts to prevent infinite loops.\nThe implementation becomes even more complex when dealing with edge cases: messages that fail mid-processing, operations that must occur in a specific order etc. Most critically, some messages may fail processing repeatedly despite multiple retry attempts.\nProblematic messages end up in dead-letter queues (discussed later), requiring careful monitoring and manual intervention to investigate and resolve issues. While retry patterns add crucial resilience to queue-based systems, the burden of implementing and maintaining them represents a significant operational overhead. Teams often find themselves duplicating retry logic across different services and reimplementing similar patterns in multiple programming languages, further increasing complexity and maintenance costs.\nAnother downside of queues is the loss of ordering. Since queues process messages independently, tasks may execute out of order, causing unexpected issues for dependent operations. Imagine a user updating their email address twice in quick succession - first to \"john@email.com\" and then to \"john.smith@email.com\". If these updates are processed out of order, the user's final email address would be incorrect. While some queue systems provide ordering guarantees within specific partitions, maintaining order across an entire distributed system often requires additional complexity and custom code.\nThe distributed nature of queue systems introduces yet another challenge: message duplication. Queue systems sometimes deliver the same message multiple times. For example, if there's a network issue when your website sends an order to the queue, your website might not receive confirmation that the order was received. To be safe, it sends the order again  but now the queue has two copies of the same order.\nSimilarly, if a service crashes while processing an order but before confirming completion, the queue will resend that order when the service restarts, thinking it was never processed. This forces development teams to implement idempotent processing - ensuring that processing the same message twice doesn't cause problems. Imagine charging a customer's credit card twice for the same order! Teams must carefully design their consumers to detect and handle duplicate messages, adding another layer of complexity to the system.\nChallenges with Dead-Letter Queues\nWe previously mentioned how some messages may fail processing despite multiple retry attempts. These problematic messages end up in dead-letter queues (DLQs).\nDead-letter queues serve as a critical safety net in message processing systems as they capture messages that repeatedly fail processing. Consider a payment processing system where a user's billing address validation fails repeatedly due to an upstream address verification service being down. Without a DLQ, these failed messages would either block the queue or be lost entirely. The DLQ captures these messages, preserving them for investigation while allowing other payments to continue processing.\nA growing DLQ can warn you about underlying issues that need attention. These might be subtle bugs in your services, APIs that have changed without all systems being updated, or resource issues that only appear under certain conditions. While DLQs serve an important purpose by preventing message loss, they can become a significant operational burden. As failed messages accumulate in DLQs, they can slow down the entire system and hide deeper problems.\nEach message in a DLQ represents a potential business transaction left incomplete, requiring careful investigation and handling. Teams must regularly monitor, analyze, and reprocess these failed messages, a process that demands both technical expertise and domain knowledge. Without proper automation and monitoring, this manual intervention creates operational bottlenecks and increases the risk of human error during reprocessing.\nBest Practices for Persistent Queues\nSuccessful implementation of persistent queues requires careful attention to several key architectural principles. First and foremost, consumer services must implement idempotent processing  the ability to handle duplicate messages without side effects. This becomes crucial during failure scenarios when messages may be redelivered multiple times.\nComprehensive monitoring is also vital. Teams should implement alerting systems that track key metrics: message processing latency, queue depth, and especially dead-letter queue accumulation. These metrics often provide early warning signs of system degradation or upstream issues.\nDead-letter queue management should be automated wherever possible. Rather than relying on manual intervention, implement automated systems to analyze, categorize, and potentially reprocess failed messages. This automation should include clear logging and diagnostics to facilitate root cause analysis.\nTracing and logging frameworks are another critical component of queue-based systems. Distributed tracing helps teams visualize message flows across services, while detailed logging at key processing steps helps diagnose failures. These observability tools become especially valuable when investigating why messages end up in dead-letter queues.\nWorkflows: A Reliable Alternative\nDue to the complexities of queue management, retry logic, and DLQ maintenance, many teams are turning to a different approach. A Workflow defines a series of steps that need to be executed in a specific order to complete a business process. Unlike queues which handle individual messages in isolation, workflows maintain visibility and control over the entire process from start to finish.\nThink of a Workflow like a recipe -- it defines not just individual steps, but how they connect and flow together. Workflows offer a fundamentally different way of handling distributed operations, one that addresses many of the challenges inherent in queue-based systems.\nImagine processing an e-commerce order: you need to check inventory, charge the credit card, update the warehouse system, and send a confirmation email. With queues, each of these steps would be a separate message, making it difficult to track the overall order status or handle failures at specific steps.\nWorkflows solve this by treating the entire order process as a single unit. Instead of managing individual messages, a Workflow tracks the complete order journey from start to finish:\n1. Validate the customer's payment information\n2. Check inventory availability\n3. Reserve the items\n4. Process the payment\n5. Send confirmation to the warehouse\n6. Notify the customer\n\nIf the credit card charge fails, the Workflow knows exactly where the process stopped and can retry just that specific step. Every action is automatically recorded, making it easy to see the status of any order and what steps have been completed. Think of it like a checklist that remembers what's done, what's next, and what failed - all while ensuring steps happen in the right order.\nUnlike queue-based systems where retry logic must be built for entire operations, workflows provide granular control. Temporal automatically retries just the failed step while maintaining the overall transaction state. This precise control eliminates many challenges inherent to queue-based systems  from handling out-of-order operations to managing complex retry scenarios. This makes workflows particularly valuable for operations where reliability and durability are critical.\nTemporals Approach to Queue Management\nTemporal is an open-source tool designed to handle complex processes in distributed systems, regardless of whether they take seconds or years to complete. While traditional queue-based systems require developers to manage message flow, retries, and state manually, Temporal provides these capabilities out of the box.\nOne key advantage of Temporal is that developers write workflows directly in their application code. Instead of juggling multiple tools and configurations  like setting up separate message queues, writing retry logic, and managing dead-letter queues - developers can express their entire business process in their familiar programming language. For example, a payment processing Workflow in Temporal might look like regular Java or TypeScript code:\nasync function proccessPaymentWorkflow(orderId: string) {\n    // Each step is an \"Activity\" that Temporal manages\n    const paymentResult = await processPayment(orderId);\n    if (paymentResult.success) {\n        await updateOrderStatus(orderId, \"PAID\");\n        await updateOrderStatus(orderId, \"PAID\");\n    }\n }\n\n*Check out the rest of the code here.\nThe foundation of Temporal's architecture rests on two key concepts:\nWorkflows serve as the orchestrators, defining the overall business process. A money transfer Workflow, for instance, represents the entire transaction lifecycle  from initiation to completion  in a single, coherent piece of code.\nActivities represent the individual units of work within a Workflow. In our transfer example, each Activity maps to a specific operation: verifying funds, executing the transfer, or sending notifications. These activities execute independently, with Temporal handling their scheduling, retries, and state management.\nWhat sets Temporal apart is its ability to maintain Workflow state automatically. When an Activity fails, Temporal automatically retries just that specific operation without repeating successful steps. For example, if a bank API becomes temporarily unavailable or a validation step fails, Temporal automatically handles retries at the precise point of failure. This eliminates the complexity of managing separate queues for retries or failed messages.\nDevelopers benefit with a more straightforward approach. Instead of debugging queue configurations and message flows, developers can step through their workflow code using familiar tools and practices. With a combination of more straightforward local development and more readability, the developer experience greatly improves.\nWhat sets Temporal apart is its state management model. Rather than storing individual messages, Temporal maintains a complete history of workflow execution. This means when an Activity fails, Temporal can intelligently replay the workflow from the last successful checkpoint, eliminating the complexity of managing message queues, retry queues, and DLQs separately.\nChoosing the Right Tool\nThe choice between different communication patterns in distributed systems depends heavily on your specific requirements and constraints. Simple service-to-service interactions might be best served by straightforward RPCs, offering immediate responses with minimal complexity. Persistent queues are effective in scenarios requiring decoupling and buffering between services, particularly when handling variable load or implementing event-driven architectures.\nHowever, as business processes grow more complex and reliability requirements become more stringent, durable execution with Temporal often emerges as the optimal solution. Message queues, while useful, provide the wrong level of abstraction - focusing on individual events rather than the complete business processes developers need to implement. Temporal aligns with how teams actually think about their applications by making workflows, not messages, the primary abstraction. This approach, combined with built-in state management, automatic retries, and comprehensive visibility, helps teams build robust distributed systems.\nConclusion\nPersistent queues have long served as a foundation for reliable distributed systems, providing essential guarantees for asynchronous communication. However, their operational challenges  from managing retries to handling dead-letter queues  have pushed the industry to seek more sophisticated solutions.\nDurable execution, using Temporal, represents a significant advancement by eliminating many of these complexities while enhancing visibility and reliability. As systems grow more complex, how they manage failure becomes increasingly valuable for building durable and resilient architectures.\nWant to see how Temporal can help you simplify fault-tolerant design? Sign up for a trial of Temporal Cloud with $1,000 in free credits and check out how to get started with Temporal.",featureImage:{title:"hazel-z-45AHiklPJH4-unsplash",description:"hazel-z-45AHiklPJH4-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Potp6G9LHoZ780AhLw3vs/861da43ba6e469417a7a9084b708e71f/hazel-z-45AHiklPJH4-unsplash.jpg"},publishDate:"2025-01-22",metaDescription:"Learn the ins and outs of persistent queues including what they are, how they work, the challenges, and the benefits.",metaTitle:"Reliable data processing: Queues and Workflows",socialCard:{title:"Reliable data processing queues and worklows",description:"Reliable data processing queues and worklows",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5v7rWbz5aCIbc2J3uylnVw/5f558ec4c11b2270df21b8eba745e130/Reliable_data_processing_queues_and_worklows.png"},tags:"Batch Processing,Temporal Primitives",slug:"reliable-data-processing-queues-workflows",contentType:"blogPost",entityId:"hoe60o5pd2Kq3048RckUQ",authors:[{id:"gz6Asa7ycvY1HZz9vcJk0",name:"Angela Zhou",slug:"angela-zhou",jobTitle:"Senior Technical Curriculum Developer",photograph:{title:"headshot-angela-zhou",description:"headshot-angela-zhou",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3FgLhuMJuEASXJmzoNevWN/c115937f066329eb77cd75caa831bfbe/headshot-angela-zhou.png"},contentType:"person"}],authorsString:"Angela Zhou",category:"Temporal Concepts",readingTime:13},{title:"Building durable cloud control systems with Temporal",content:"In todays world of managed cloud services, delivering exceptional user experiences often requires rethinking traditional architecture and operational strategies. At Temporal, we faced this challenge head-on, navigating complex decisions about tenancy models, resource management, and durable execution to build a reliable, scalable cloud service. This post explores our approach and the lessons we learned while creating Temporal Cloud.\nThe Case for Managed Cloud Services\nManaged services have become the default for delivering hosted solutions to customers. Whether its a database, queueing system, or another server-side technology, hosting a service not only provides a better user experience but also opens doors for monetization, especially for open-source projects. The challenge is how to do it effectively while maintaining reliability and scalability.\nOne of the first decisions we made was about tenancy models. Should we pursue single-tenancy  provisioning dedicated clusters for each customer  or opt for multi-tenancy, which allows multiple customers to share the same resources? While single-tenancy offers simplicity and isolation, its inefficiencies quickly become apparent. Customers end up paying for unused capacity, and providers shoulder higher operational costs. Multi-tenancy, though harder to implement, emerged as the clear winner. It optimizes resource usage, allows customers to pay for actual usage, and creates shared headroom for handling traffic spikes.\nData Plane vs. Control Plane: Defining Responsibilities\nArchitecting a managed service in terms of the data plane and control plane is an industry best practice that we followed, clearly defining and implementing their distinct roles within our cloud architecture.\n\n  Data Plane: This is where the actual work happens  processing transactions, executing workflows, and handling customer data. It must maintain high availability, low latency, and resilience to failures. For Temporal Cloud, we adopted a cell-based architecture to isolate resources and minimize the blast radius of potential failures.\n  Control Plane: This acts as the brain of the system, managing resources, provisioning namespaces, and handling configurations. While its performance is less critical than the data plane, reliability here still matters for customer experience. For instance, provisioning a namespace may not be urgent, but delays or errors in this process can frustrate users.\n\nImplementing the Data Plane: A Cell-Based Architecture\nFor the data plane, we applied a cell-based architecture to achieve strong isolation and scalability. Each cell operates as a self-contained unit with its own AWS account, VPC, EKS cluster, and supporting infrastructure. While this approach is framed within the context of AWS, we have applied the same principles to Google Cloud Platform (GCP), leveraging its equivalent primitives to ensure consistency and reliability across cloud providers. This approach ensures that failures or updates in one cell do not impact others, reducing the risk of cascading outages.\nEach cell in Temporal Cloud includes:\n\n  Compute Pods: Running Temporal services and infrastructure tools for observability, ingress management, and certificate handling.\n  Databases: Both primary databases and Elasticsearch for enhanced visibility.\n  \n    Additional Components: Load balancers, private connectivity endpoints, and other supporting infrastructure that ensures smooth operation and integration across environments.\n    Currently, Temporal Cloud operates across 14 AWS regions, and weve also added support for GCP. This architecture allows us to meet the diverse needs of our customers while maintaining reliability at scale.\n  \n\nDurable Execution: The Foundation of the Control Plane\nBuilding the control plane presented its own set of challenges, particularly around reliability and maintainability. Control plane tasks, such as provisioning namespaces or rolling out updates, involve complex long-running processes with many interdependent steps. Writing this logic as traditional, ad-hoc code often leads to brittle systems that are hard to debug and evolve.\nThis is where Temporals durable execution model shines. Designed based on experience with earlier systems like AWS Simple Workflow Service and Azure Durable Functions, Temporals approach separates business logic from state management and failure handling. Developers can write workflows as straightforward, happy-path code without worrying about retries, error handling, or state persistence. The system automatically manages these concerns, allowing workflows to seamlessly recover from failures.\nNamespace Provisioning: A Real-World Example\nConsider the process of creating a new namespace in Temporal Cloud. When a user clicks Create Namespace on the web interface, the control plane orchestrates a series of tasks:\n\n  Selecting a suitable cell within the chosen region.\n  Creating database records and roles.\n  Generating and provisioning mTLS certificates.\n  \n    Configuring ingress routes and verifying connectivity.\n    Each step involves external API calls, DNS propagation, and other potential points of failure.\n  \n\nWithout durable execution, managing retries, backoffs, and state persistence would result in a tangle of brittle code. With Temporal, these tasks are encapsulated in workflows, which transparently handle retries and maintain state across failures. Developers can focus on the high-level logic, confident that the system will handle the edge cases.\nRolling Upgrades: Ensuring Safe Deployments\nAnother common control plane scenario is rolling out updates to the Temporal Cloud fleet. Our deployment strategy involves organizing cells into deployment rings, progressing from pre-production environments to customer-facing cells with increasing priority of traffic.\nThe rollout process is carefully staged:\n\n  Ring 0: Synthetic traffic only, no customer impact. Changes are monitored here for at least a week.\n  Ring 1: Low-priority traffic namespaces, allowing for additional testing with minimal risk.\n  \n    Higher Rings: Gradually expanding to critical, high-priority traffic customers.\n    Within each ring, updates are applied in batches, with pauses between batches to observe for potential issues like memory leaks or race conditions. Temporal workflows handle this process, ensuring that even long-running deployments (which can span weeks) are resilient to failures or restarts.\n  \n\nEntity Workflows: A Powerful Pattern\nTemporals durable execution also enables powerful patterns like entity workflows. These are workflows tied to specific resources, such as cells or namespaces, providing a natural way to model state and operations. For example, each cell in Temporal Cloud has an entity workflow that manages its lifecycle, from provisioning to upgrades. This approach ensures consistency and simplifies concurrency control.\nDeveloper Happiness and Productivity\nOne of the biggest benefits of Temporals approach is the impact on developer experience. By eliminating the need to write boilerplate code for retries, backoffs, and state management, developers can focus on delivering business value. Temporals built-in tools for observing and debugging workflows further enhance productivity, making it easier to understand and troubleshoot complex systems.\nHappy developers are productive developers, and Temporals approach fosters this by reducing the cognitive load and frustration associated with traditional workflow coding.\nWhy Durable Execution Matters\nDurable execution is more than a technical innovation; its a paradigm shift for building cloud-native systems. By decoupling business logic from state management and failure handling, Temporal empowers developers to build reliable, scalable systems with less effort. Whether youre managing control planes, provisioning resources, orchestrating complex workflows, performing money transfers, training AI models, or processing social media posts, this approach delivers clear benefits.\nAt Temporal, weve seen firsthand how durable execution transforms the development process, enabling us to deliver a robust managed service that scales with our customers needs.\nReady to Transform Your Control Plane?\nTemporal isnt just a tool for building cloud systems; its a better way to think about workflows and application architecture. If youre building or planning a managed cloud service, consider how durable execution can simplify your journey and unlock new possibilities. For more insights into our approach, check out my full talk at QCon.\nReady to explore what Temporal Cloud can do? Nows the perfect time  get $1,000 in Temporal Cloud credits and start building today!",featureImage:{title:"social-card-temporalite-blog",description:"social-card-temporalite-blog",url:"https://images.ctfassets.net/0uuz8ydxyd9p/43c3wR1aXhf2oLpXy8WReZ/b280baada058cdc1d0dc9a4b2aaff37a/social-card-temporalite-blog.jpg"},publishDate:"2025-01-16",metaDescription:"Explore how Temporal leverages durable execution, multi-tenancy, and cell-based architecture to build scalable, reliable cloud control systems. Learn key lessons and insights for managed cloud services.",metaTitle:"How Temporal Builds Durable Cloud Control Systems",socialCard:{title:"Durable Cloud Control Systems",description:"Durable Cloud Control Systems",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5vWnCR10ANXfCzAa6soEyP/4e0525257e56d29845d96806dcf8e4c4/Blog__7_.png"},tags:"Cloud",slug:"building-durable-cloud-control-systems-with-temporal",contentType:"blogPost",entityId:"t8ZNhwwvEdhjzZ2myILYn",authors:[{id:"7lKzY3cqOY1thOiOjI9aUa",name:"Sergey Bykov",slug:"sergey-bykov",jobTitle:"Principal Software Engineer",photograph:{title:"Sergey Bykov Headshot",description:"Sergey Bykov Headshot",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5IH7T6geXArvRD5oS5Dgoi/80ad0ff235fa2f199376763da92b42ad/Sergey_Bykov_Headshot.jpeg"},biography:"Sergey Bykov is responsible for the architecture of Temporal Cloud. Before joining Temporal, Sergey was one of the founders of the Orleans project at Microsoft Research and led its development for over a decade. The mediocre state of developer tools for cloud services and distributed systems continues to fuel his passion for qualitatively improving developer productivity in this space.",twitterUrl:"https://twitter.com/sergeybykov",company:"Temporal",contentType:"person"}],authorsString:"Sergey Bykov",category:"How-To",readingTime:7},{title:"Announcing a new operation: Workflow Update",content:"Were excited to announce that Workflow Update is now Generally Available. This is a major new feature: in this blog post were going to look into why its important, see some examples of what it looks like to use it, and learn about design patterns when using Update in applications.\nIntroducing Workflow Update\nFundamentally, Update is about sending a message to a Workflow, waiting until the message handling is complete, and receiving a result or error in response. The Update handler in your Workflow code can do anything that normal Workflow code can do. Thats an extremely useful operation when building applications, but the existing messages, Query and Signal, did not provide it on their own. Lets recap why that is:\n\n  A Query returns a result, but an Update handler can additionally wait for any amount of time or for an arbitrary condition, execute Activities and Child Workflows, and mutate Workflow state; a Query can do none of those things.\n  A Signal handler can do all of those things but cant communicate anything back to the caller.\n\nSince getting a result back after your Workflow has done some async work is such a common need, there were workarounds  for example sending a Signal and then polling repeatedly with a Query, or using an Activity to get the result back to your client code by some other means  but these feel very much like workarounds, and can be inefficient, complex, and error prone. Contrast those with executing an Update in Python:\nupdate_result = await workflow_handle.execute_update(MyWorkflow.my_update, update_input)\nUpdate opens the path for many low-latency use cases (and combines well with triggering a Local Activity). Furthermore, your Workflow code can use an Update Validator to reject an invalid Update as soon as it's received, so that it doesnt leave any trace in Workflow history.\nHow Update works\nAs well see below, a common pattern is to use an Update to modify the Workflow in some way that involves executing an Activity. The client waits for the Activity to finish, and receives a result. Lets look at what happens behind the scenes when we do this. For comparison, the sequence diagram also shows the Signal + poll-for-result-with-Queries technique.\nUse Signal+Queries to execute an Activity\n  \n\nUse Update to execute an Activity\n  \n\nNote that for clarity the Activity worker is not depicted in these diagrams.\nAn important point here is that Signal is asynchronous  all you get is an immediate ACK from the server  whereas with Update your Worker must be online, and you wont get any response at all until the Workflow has received and responded to the Update. So a Signal on its own will have much lower latency than an Update. However, to track progress and/or get data back from your Workflow, Update has lower latency than sending a Signal and then polling with Queries, as this timing experiment showed:\n\n  \n\nThe sequence diagrams above give an overview of how Update works behind the scenes, but theres much more to say about how Update was built. For example, if you use an Update Validator to reject an Update then it leaves no trace in history. But if youre already familiar with Temporal, youll know that tasks dispatched to your Workers are typically backed by history events. So we had to extend Temporal internals to allow deferring the first write to history for an Update until after its been delivered to the Workflow.\nWorkflow Update design patterns\nIn this section were going to see what basic Update usage looks like, and look at some high-level design patterns that describe real-world Update usage. To make this more concrete, here are some scenarios in which a real-world application could use Update:\n\n  \n    \n      Role of Workflow\n      Role of Update\n      Pattern\n    \n  \n  \n    \n      A shopping cart in an e-commerce application\n      Add an item to the cart, wait for availability and pricing information to be fetched from the inventory DB, and return the new cart contents and subtotal.\n      1\n    \n    \n      A conversation with an LLM\n      Send a chat message and wait for the response.\n      1\n    \n    \n      A generic task queue\n      - Add an item to an in-Workflow queue data structure and receive the new queue size.- Enqueue a task, process it via an Activity, and receive the result or error when it's done.- Dequeue a task for processing.\n      0, 1, 2\n    \n    \n      A distributed lock service, with multiple clients contending for the lock\n      Acquire the lock.\n      2\n    \n    \n      A multi-stage financial transaction\n      Wait for an intermediate result from one of the initial stages, leaving the workflow running in the background. (Take a look at the early return pattern in the Public Preview feature Update With Start for a latency-optimized version.)\n      2\n    \n    \n      An AI agent\n      Start the agent and wait for a short while until it's ready for users to interact with it.\n      2\n    \n  \n\nPattern 0: mutate local Workflow state and receive a result\nThis is the simplest form of Update: it makes use of Updates ability to mutate Workflow state. For example, your Workflow might be maintaining a queue of some sort in a Workflow-local data structure, and you use an Update to add an item to the queue and return the new queue size. Heres an example in Java:\nThe caller executes the update by calling the Update method on a Workflow stub:\nMyWorkflow workflow = client.newWorkflowStub(MyWorkflow.class, workflowOptions);\n...\nint queueSize = workflow.addItem(\"my-item\");\nAnd the Workflow uses an annotation to mark the Update handler method:\n@WorkflowInterface\npublic interface MyWorkflow {\n  @UpdateMethod\n  int addItem(String item);\n  ...\n}\n\npublic static class MyWorkflowImpl implements MyWorkflow {\n  private final List\u003CString> queue = new ArrayList\u003C>(10);\n\n  @Override\n  public int addItem(String item) {\n    queue.add(item);\n    return queue.size();\n  }\n  ...\n}\nYou can see examples of basic Update usage (including the optional Update validator feature) in all languages in the docs and samples:\nDocs: Go | Java | PHP | Python | Typescript | .NET\nSamples: Go | Java | PHP | Python | Typescript | .NET\nPattern 1: execute an Activity or Child Workflow and receive a result\nThis pattern involves sending an Update that executes an Activity, mutating Workflow state in some way, and waiting for the result (the sequence diagram above is an example of this.) To see a working code example, look at the assign nodes to job and delete jobs Updates in the Safe Message Handlers sample:\nWorkflow with Update handler: Go | Java | Python | Typescript | .NET\nClient code calling the Update: Go | Java | Python | Typescript | .NET\nHeres how Update is used in the Python sample. The client code is straightforward; it uses the languages native concurrency APIs to execute multiple updates concurrently:\nfor i in range(6):\n    deletion_updates.append(\n        wf.execute_update(\n            ClusterManagerWorkflow.delete_job,\n            ClusterManagerDeleteJobInput(job_name=f\"task-{i}\"),\n        )\n    )\nawait asyncio.gather(*deletion_updates)\nThe Update handler in the Workflow waits until the Workflow is in a certain state and then executes an Activity. Although the client sent multiple concurrent Updates, for this Workflow allowing their handler executions to interleave would be a bug, which the Workflow avoids by using one of the standard mutexes offered by this SDK language:\n  # Even though it returns nothing, this is an update because the client may want to track it, for example\n  # to wait for nodes to be unassigned before reassigning them.\n  @workflow.update\n  async def delete_job(self, input: ClusterManagerDeleteJobInput) -> None:\n    async with self.nodes_lock:\n        nodes_to_unassign = [\n            k for k, v in self.state.nodes.items() if v == input.job_name\n        ]\n        # This await would be dangerous without nodes_lock because it yields control and allows interleaving\n        # with assign_nodes_to_job and perform_health_checks, which all touch self.state.nodes.\n        await workflow.execute_activity(\n            unassign_nodes_for_job,\n            UnassignNodesForJobInput(\n                nodes=nodes_to_unassign, job_name=input.job_name\n            ),\n            start_to_close_timeout=timedelta(seconds=10),\n        )\n        ...\nPattern 2: wait for the Workflow to reach a certain state\nIn this pattern, all the real work is done in the main Workflow run method, with the Update handler using the SDKs wait-for-condition API to wait until a certain stage is reached.\nA key point here is that you should write the main Workflow run method so that it will work whether or not the Client sends an Update: the Update handler is just observing, as opposed to doing. But remember: Query handlers cant do this! They can only return a value computed from local Workflow state, without blocking.\nAs an example, look at the way that the Cluster Manager exposes an Update for the Client to wait until the Cluster is ready to be used:\n@workflow.update\nasync def wait_until_cluster_started(self) -> ClusterManagerState:\n    await workflow.wait_condition(lambda: self.state.cluster_started)\n    return self.state\nAs you can see, the Update handler itself is very simple; all the real work is done in the main Workflow run method:\n@workflow.run\nasync def run(self, input: ClusterManagerInput) -> ClusterManagerResult:\n    cluster_state = await workflow.execute_activity(\n        start_cluster, schedule_to_close_timeout=timedelta(seconds=10)\n    )\n    self.state.nodes = {k: None for k in cluster_state.node_ids}\n    self.state.cluster_started = True\n    workflow.logger.info(\"Cluster started\")\n\n    while True:\n        # The cluster is now ready to accept the delete_job\n        # update discussed above.\n        ...\nWorkflow with Update handler: Go | Java | Python | Typescript | .NET\nClient code calling the Update: Go | Java | Python | Typescript | .NET\nAn interesting variant of this pattern is to use Update as a broadcast, in which multiple clients all pass the same Update ID and wait on the same Update: from the Workflows point of view its a single Update, and all subscribing clients will be notified when the desired Workflow state is attained.\nLong-running Updates\nIn the examples weve looked at so far, the client has sent the Update and waited for the result in one go. But the SDKs offer a second way to invoke an Update. Using this second way, as soon as your Workflow accepts the Update, the call returns an Update handle object that you can use subsequently to fetch the result or error. Every Update has an associated Update ID that the caller can set, and any client can create an Update handle for a pending Update if they have the Update ID. Heres a comparison between the two ways of invoking an Update:\nWait for completed Update result in one go\nThis is called execute update in SDKs other than Go and Java. In Go, you use UpdateWorkflow, passing Completed as the waitForStage, and in Java you call the Update method on the Workflow stub.\n\n  \n  \nWait for accepted Update handle and subsequently fetch the result\nThis is called start update in SDKs other than Go. In Go, you use UpdateWorkflow, passing Accepted as the waitForStage.\n\n  \n  \nBehind the scenes, the SDK client will always poll repeatedly until the desired stage is reached. And as long as your worker is online, waiting for your Update to be accepted and return a handle should be fast. But how long it takes for your Update to complete thereafter depends on what you are doing in the Update handler, and there are no constraints on Update handler code: you can design long-running Updates that take seconds, or months, to complete.\nGet started building with Update\nUpdate is ready for production use. In fact, were using Update ourselves, both in Temporal Cloud and in the server core (e.g. here and here). If youd like to read more about it, you could look at the introduction to message passing, the Robust Message Handlers blog post, and the Update docs for your language:\nGo | Java | PHP | Python | Typescript | .NET.\nPlease join us in Temporal Slack with any questions.",featureImage:{title:"social card - green waves",description:"social card - green waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4GBHZR0vUnoRSbPtSTCH4s/daf7308a10e469059827e2169065d7ea/social_card_-_green_waves.jpg"},publishDate:"2025-01-14",metaTitle:"Announcing a new operation: Workflow Update",socialCard:{title:"social card - green waves",description:"social card - green waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4GBHZR0vUnoRSbPtSTCH4s/daf7308a10e469059827e2169065d7ea/social_card_-_green_waves.jpg"},tags:"Temporal Primitives",slug:"announcing-a-new-operation-workflow-update",contentType:"blogPost",entityId:"3qridKn1ohd8VPjsqvhTyD",authors:[{id:"36tkq3KvOzYVGfBLXtwlb2",name:"Dan Davison",slug:"dan-davison",jobTitle:"Senior Software Engineer",photograph:{title:"temporal logo meteor indigo",description:"temporal logo meteor indigo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2oW0u2iqUzwysozUjaURhY/f5defd004671314cf254ba53b54c4e47/temporal_technologies_logo"},contentType:"person"}],authorsString:"Dan Davison",category:"Product News",readingTime:10},{title:"Understanding fault tolerance in distributed systems",content:"When you build distributed applications, youre building with the expectation that things can go wrong. Youre wary of hardware breaks, software bugs, and network hiccups. This is where fault tolerance becomes useful. Fault tolerance is all about preparing for those inevitabilities.\nFault tolerance is the ability of a system to keep operating during failures. It keeps disruptions minimal and ensures that services stay up for users, even when the unexpected occurs.\nBuilding with fault tolerance in mind saves you from downtime and data loss, while helping you deliver a consistent, reliable experience for your users.\nWhy Fault Tolerance is Essential in Modern Applications\nYouve just wrapped up a little online shopping and now youre in your jam-packed cart ready to check out. Youre excited about your items, the coupon you applied means youre getting a deal, and you happily click buy. Then, suddenly, your cart items disappear as the platform crashes mid-purchase.\nNot only is that experience frustrating for a user, it chips away at the trust they have for your brand and can lead previously loyal customers to run into the arms of your competitors.\nThats where fault tolerance shines. Modern cloud-based applications are built on interconnected components that can fail at any time. Without fault tolerance, a small glitch in one part of the system can ripple out and cause a full-blown outage. Your application cant afford that risk.\nBy building systems that can handle partial failures, you make sure your application recovers smoothly and stays reliable, no matter what.\nKey Components of a Fault-Tolerant System\nWhat makes a system fault-tolerant? Although it may seem like magic from the end user experience, developers know that fault tolerance comes from strategic work and smart choices. Here are the main strategies:\n\n  Redundancy: Have backups in place so if one component fails, another can take over.\n  Replication: Copy and synchronize data across different nodes so nothing is lost if one goes down.\n  Failover Mechanisms: Automatically reroute traffic to healthy instances when something breaks.\n  Graceful Degradation: Instead of crashing entirely, the system continues to work with limited functionality until the issue is fixed.\n\nWhen these strategies work together, your application can weather all kinds of failures without users even noticing.\nHigh Availability vs. Fault Tolerance\nHigh availability and fault tolerance may sound similar and even be used interchangeably, but theyre not the same thing.\n\n  High Availability (HA): This is all about maximizing uptime. It uses redundancy and load balancing to keep systems running with as little downtime as possible.\n  Fault Tolerance: This takes it a step further by ensuring the system keeps running seamlessly, even if individual components fail.\n\nAnother way to think of it is as high availability being like having multiple restaurant locations, so theres always one open near you, whereas fault tolerance is like having a generator kick in at your singular location if the power goes out.\nKey Factors to Consider in Fault Tolerance\nWhen youre designing a fault-tolerant system, youll need to balance a few key factors:\nCost of Redundancy\nHow much are you willing to spend on backups and extra infrastructure?\nPerformance Trade-Offs\nWill adding fault tolerance slow things down, and if so, is it worth it?\nRecovery Time Objectives (RTOs)\nHow quickly do you need your system to recover after a failure?\nIn distributed systems, you also have to think about:\nData Consistency\nHow do you keep data consistent across nodes when failures happen?\nNetwork Partitioning\nWhat happens if parts of your system cant communicate due to a network issue?\nNode Failures\nHow will your system respond when individual nodes drop off?\nBalancing these trade-offs is part of what makes a fault-tolerant system design such an interesting challenge.\nFault Tolerance in Cloud and Microservices Architectures\nCloud and microservices architectures are distributed by nature, which means failures are inevitable. Services like AWS, Google Cloud, and Azure offer built-in fault tolerance features like auto-scaling, multi-region deployments, and disaster recovery. Theres a catch, though: developers still need to handle resilience at the application level.\nFor example, deploying workloads with Google Cloud Run helps mitigate microservice failures, but application-level solutions (like retrying failed operations and managing state) are still critical. This is where Temporal shines.\nTemporal helps by automatically preserving workflow state and retrying failed tasks so that even complex, long-running processes can recover without extra manual code. It simplifies resilience, making your system better with less effort.\nWhat are Fault Tolerance Requirements?\nA fault-tolerant system needs a few foundational pieces in place:\n\n  Hardware Redundancy: Extra servers, storage, and network resources to take over when something fails.\n  Consistent Data Replication: Synchronize data in real-time or near real-time across nodes.\n  Automated Failovers: Quickly detect failures and switch to backup systems.\n  Real-Time Monitoring: Keep an eye on system health so you can spot issues before they become major problems.\n\nThink of it as building a safety net, with each piece supporting the system and helping catch potential failures.\nBest Practices for Designing Fault-Tolerant Systems\nEvery system is different, but some best practices apply across the board. You should always:\n\n  Eliminate single points of failure.\n  Use redundancy and replication at multiple levels.\n  Implement automatic retries and timeouts.\n  Ensure data consistency through smart synchronization.\n  Enable graceful recovery so users arent affected during failures.\n  Monitor everything in real time and set up alerts for fast response.\n\nWhile this list is a solid starting point, all the details cant be hashed out here. If youre looking for a more in-depth approach to building a fault tolerant system, check out our failure handling guide.\nReal-World Examples of Fault-Tolerant Systems\nFault-tolerant systems are all around us, keeping daily life running smoothly even when things go wrong.\nIn banking, resilient workflows make sure your payments go through reliably. For example, banking sweep systems automatically recover from failures to keep funds moving without delays.\nIn e-commerce, platforms handle massive traffic spikes during flash sales without crashing. Distributed caching and load balancing work together to keep the site running smoothly, even when millions of shoppers are clicking buy all at once.\nIn logistics, global shipping networks depend on data replication and automated retries to maintain shipment tracking accuracy. Even if a regional server drops offline, the system ensures the data stays consistent across regions.\nThese examples show how fault-tolerant design helps businesses avoid downtime and keep their operations resilient.\nWhat is Fault Tolerance in Cloud Computing?\nIn the cloud, fault tolerance means using tools like auto-scaling, multi-region backups, and disaster recovery to keep your system resilient. But application-level resilience is still key.\nWith solutions like Temporal Cloud on the AWS Marketplace, you get automated retries, configurable timeouts, and stateful recovery to make sure your workflows recover smoothly. This simplifies the process and reduces the need for custom error-handling logic.\nDoes Temporal Offer a Fault Tolerance Solution?\nAbsolutely. Temporal makes fault tolerance easier with durable workflows, automatic retries, and failure handling. You can build applications that bounce back seamlessly from node failures, network issues, and other disruptions.\nTemporals key features include:\n\n  State Management: To retain workflow state even during failures.\n  Automatic Retries: Failed operations retry without manual intervention.\n  Timeouts and Failure Alerts: Get notified and handle failures faster.\n  Visibility: Enable real-time monitoring of your processes in flight.\n\nFault Tolerance is Key to Reliable Systems\nFault tolerance is your lifeline for reliable, distributed systems. By designing for resilience, you save yourself from unexpected headaches and build something your users can count on.\nWant to see how Temporal can help you simplify fault-tolerant design? Sign up for a trial of Temporal Cloud with $1,000 in free credits and check out our docs to get started.",featureImage:{title:"li-zhang-ZvVydsVkyTI-unsplash",description:"li-zhang-ZvVydsVkyTI-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3WwtmBoVCX8MFqaV2ZTQUq/fc4fc75dd2e1d75a6a36d292827b8d80/li-zhang-ZvVydsVkyTI-unsplash.jpg"},publishDate:"2025-01-08",metaDescription:"Discover what fault tolerance is and how it ensures reliable systems with key principles and examples in cloud environments.",metaTitle:"Fault Tolerance in Distributed Systems | Reliable Workflows",socialCard:{title:"What is Fault Tolerance",description:"What is Fault Tolerance",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2jXarsh460w922Op212B7A/2ab70a7169d243d4e97565c476e45f5e/What_is_Fault_Tolerance.png"},tags:"Architecture",slug:"what-is-fault-tolerance",contentType:"blogPost",entityId:"1Aa2NjamWi7IF4zGLVIADg",authors:[{id:"7GQtiP7y4Dmrje9sFWcVKl",name:"Lauren Bennett",slug:"lauren-bennett",jobTitle:"Content Marketing Manager",photograph:{title:"Lauren-Bennett-profile-photos",description:"Lauren-Bennett-profile-photos",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6jEqojw9RxBBjX5pytMzYf/4df0ef856a9efe4b7b52d5ebe7e83686/Lauren-Bennett-profile-photos.jpeg"},linkedInUrl:"https://www.linkedin.com/in/lauren-n-c-bennett/",contentType:"person"}],authorsString:"Lauren Bennett",category:"Temporal Concepts",readingTime:7},{title:"Deploying Temporal Workers to Google Cloud Run",content:"1/6/2025 Update: Google Cloud Run now supports autoscaling by CPU Utilization, which is critical for running Temporal Workers. The code has also been updated to use newer versions of Spring Boot and the Temporal SDK.\nUnlike Kubernetes, Google Cloud Run makes it trivial to deploy container-based applications. Have a web API that you want to deploy? Package it up in a container and let Cloud Run take over provisioning the underlying infrastructure, load balancer, and DNS endpoint, and your application is ready to receive traffic. As traffic to your popular API goes up and down, Cloud Run automatically scales based on the inbound traffic and CPU utilization. It's truly amazing how easy it is to deploy, run, and scale web-based applications.\nTemporal Worker applications, however, operate differently. They long-poll Temporal Cloud and process tasks as they become available. Because of this inherent difference, Cloud Run, by default, will not see any activity (no inbound requests) and stop the Worker from running. Clearly not an optimal situation.\nAnother limitation is that Cloud Run only allows a single port to be publicly exposed, which means you need to decide what to bind to that port. Temporal Workers that also bind a UI or API to that port can't expose SDK metrics. Temporal Workers that do not have a UI or API could theoretically expose SDK metrics, but you likely don't want to expose internal details of your application to the public.\nWith some configuration and a sidecar container, getting a Temporal Worker running on Cloud Run is straightforward. This article will focus on the required Cloud Run configuration and sidecar container aspects and will not focus on handling mTLS secrets or other application-specific details. A complete example that includes application details and can be found here.\nConfiguring Your Application\nOne of the nice features about Cloud Run is that for most applications, you just need a containerized application. Since this example requires non-default behavior, you need to use a Cloud Run Service YAML file to configure it.\nDisable CPU Throttling\nTo ensure that the Worker stays running, you'll need to disable CPU throttling. Note that this means your Worker will continue to run even when there isn't work to process.\nspec:\ntemplate:\nmetadata:\nannotations:\nrun.googleapis.com/cpu-throttling:  'false' # we need to keep the CPU running\nSet Minimum Number of Instances\nBy default, an application running in Cloud Run is scaled down to zero instances if there is no inbound web traffic. To change this, set the minimum number of instances:\nspec:\ntemplate:\nmetadata:\nannotations:\nautoscaling.knative.dev/minScale:  '1'  # keep one instance available\nSidecar Container\nSidecar containers are a common deployment pattern in the Kubernetes ecosystem. They are another application that is deployed alongside the primary service or application that provides additional functionality. Service meshes in Kubernetes like Istio and Linkerd use sidecars to control traffic in and out of the application. Cloud Run recently added sidecar containers.\nTemporal Workers can be configured to emit metrics. These metrics are made available as a prometheus scrape endpoint. Since the application won't be making these metrics publicly visible, a sidecar container will be deployed to read the metrics endpoint and send the metrics to Google Cloud Managed Service for Prometheus using the Open Telemetry Connector.\nOpen Telemetry Connector\nOpenTelemetry is an observability framework and toolkit that is designed to manage telemetry data such as traces, metrics, and logs. It is vendor- and tool-agnostic. The Open Telemetry Connector acts like a proxy to receive, process, and export data to a supported platform. In addition to supporting Google Cloud Managed Service for Prometheus, other exporters include Datadog, Splunk, and Google Cloud Pubsub. A full list of exporters is available here.\nCollector Configuration\nThe OpenTelemetry collector uses a configuration file that specifies the receivers, processors, exporters, and the service section. The receivers section needs to look similar to this:\nreceivers:\nprometheus:\nconfig:\nscrape_configs:\n-  job_name:  'temporal-metrics-app'\nscrape_interval:  5s\nmetrics_path:  '/prometheus'\nstatic_configs:\n-  targets:  ['127.0.0.1:8081']\nThe two important lines are metrics_path, which is the path used to read the application's metrics, and targets, which indicates the IP address and port number of the application. Notice that the IP refers to localhost, and the port must match the port of the application that exposes the metrics.\nIn Cloud Run, sidecar containers share the same network namespace and communicate with each other using localhost and the corresponding port.\nFor the exporters section, the configuration is trivial:\nexporters:\ngooglemanagedprometheus:\nSimply defining googlemanagedprometheus is sufficient. The OpenTelemetry Connector supports multiple exporters (and receivers too), so if you wanted to send the metrics to an additional destination, or to somewhere other than Google Managed Service for Prometheus, you would need to add the appropriate configuration here.\nThere are other sections that were used but have left them out for brevity. The full configuration file is available here.\nViewing the Metrics\nOnce the application is deployed, and Workers have been triggered, metrics will be sent to Google Managed Service for Prometheus. To view them, open up the Google Cloud Console and navigate to Monitoring, Metrics Explorer. In the Metric drop down under Select a Metric, scroll down to Prometheus Target, Temporal to see a list of active metrics.\n\n  \n\nClick a metric, such as Prometheus/temporal_long_request_total/counter, and click on Apply. In the time box near the upper right of the screen, click the down arrow and select the Last 30 minutes. If you have activity, you should see a graph that might look similar to this:\n\n  \n\nFeel free to experiment with adding additional metrics. The Temporal documentation on SDK metrics provides detailed information on metrics, their type, and other key information. Key metrics for tuning performance on workers can be found here.\nScaling\nScaling instances in Cloud Run is done in one of two ways: based on the incoming requests and/or CPU utilization. Cloud Run changes the scaling characteristics based on the billing type.\nWhen request-based billing is configured, CPU utilization scaling only works in conjunction with incoming requests. Since Temporal Workers run continuously, this approach will not work. With instance-based billing, Cloud Run scales based solely on CPU utilization, which works better for Temporal Workers. Additional details on scaling and billing settings can be found here.\nCloud Run handles the scaling of Temporal Workers if CPU utilization is a good metric to scale the number of instances either up or down. For workloads that require different metrics, you will need to come up with a custom scaling solution that reads either the appropriate metrics or backlog metrics and updates the number of instances using the gcloud command:\ngcloud run services update \u003CSERVICE_NAME> --region=\u003CREGION> --min-instances=X\nWrapping It All Up\nWhen should you use Cloud Run, and when should you use Kubernetes? The answer to this question is not that simple because it depends on a number of factors. How much experience does your team have with Kubernetes? How quickly will you need to scale? How many distinct Temporal Workers will you be running? Are you using a microservices architecture?\nMy general recommendation, without knowing the specifics of your requirements, skills, and objectives, would be to start with Cloud Run. If you outgrow Cloud Run, then use GKE Autopilot, and if you run into a limitation on Autopilot, use GKE Standard.\nHopefully, this postplus some help from a sidecar containerwill prepare you for deploying Temporal Workers to Cloud Run and viewing SDK metrics. For a full working example, be sure to check out the repository here.\nWhat types of Temporal Workers will you be deploying on Cloud Run? Let us know in our Community Slack Channel!",featureImage:{title:"feature",description:"feature",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2EEnqUnw856LFbhAdyugoK/08219c70105f0a6f77586f24705fb8c7/feature.png"},publishDate:"2025-01-06T00:00-04:00",metaDescription:"Learn how to deploy Temporal Workers on Google Cloud Run with a sidecar container for metrics collection, scaling, and efficient task processing.",metaTitle:"Temporal Workers & Google Cloud Run",socialCard:{title:"social",description:"social",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3NQbhIffegb9N7rCsvPNO8/e34e7821c740e237430e5d33581681cf/social.png"},tags:"",slug:"deploying-temporal-workers-to-google-cloud-run",contentType:"blogPost",entityId:"3bUNFtVLKNniwtYoYoplVf",authors:[{id:"12mIRRFzezOnxRJbKc8Mlz",name:"Rick Ross",slug:"rick-ross",jobTitle:"Solutions Architect",photograph:{title:"Rick Ross Photo",description:"Rick Ross Photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1C9Ba19HRSsps5CM6V93ks/d11af9119a55b7120a3edbe22c67364f/Rick_Ross_Headshot.jpg"},company:"Temporal",contentType:"person"}],authorsString:"Rick Ross",category:"Temporal Concepts",readingTime:7},{title:"Announcing Temporal 101 for .NET developers",content:"The Developer Education team is excited to announce that our Temporal 101 course is now available in .NET! This free, self-paced, hands-on training course is designed to help developers build robust, reliable applications using the Temporal .NET SDK.\nIn this course, youll explore what durable execution is as well as Temporal's core concepts and architecture. Youll discover the building blocks of Temporal: Workflows and Activities.\nYou'll then get hands-on and develop an application that communicates with an external service using those Workflows and Activities.\nBy completing Temporal 101, youll be able to:\n\n  Configure an environment for developing Temporal applications\n  Describe and implement a business process with Temporal\n  Interpret Temporal's Workflow execution model\n  Manage the lifecycle of your application with Temporal tooling\n\nReady to Get Started?\nThis course is accessible and flexible, allowing you to learn at your own pace while building real-world skills. Best of all, its free! Check out our learn site to view all our courses!\nWere also excited to share that we now offer live training in .NET. Check out the #request-live-workshop channel in our Community Slack to see how to request a live training near you.\nKeep your eyes out for more .NET courses coming your way soon. Sign up here to receive updates!",featureImage:{title:"bedrock-post-micke-lindstrom-6REIcx1yeuI-unsplash",description:"bedrock-post-micke-lindstrom-6REIcx1yeuI-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6UsfEJOHJYe9px5G02SzYS/8370488f6dc6b817001daee185b11321/micke-lindstrom-6REIcx1yeuI-unsplash.jpg"},publishDate:"2024-12-20T00:00-08:00",metaDescription:"Take the free, self-paced, introductory course in Temporal for .NET.",metaTitle:"Announcing Temporal 101 for .NET developers",socialCard:{title:"Temporal 101 for .NET announcement",description:"Temporal 101 for .NET announcement",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7rwuLP62Lzy9g3jT4ppRP9/6edf4b2bab660f66e866a427566c638a/Temporal_101_for_.NET_announcement.png"},tags:".NET",slug:"temporal-101-net-developers",contentType:"blogPost",entityId:"2F0CHW7FtD7jckQzefxVhK",authors:[{id:"gz6Asa7ycvY1HZz9vcJk0",name:"Angela Zhou",slug:"angela-zhou",jobTitle:"Senior Technical Curriculum Developer",photograph:{title:"headshot-angela-zhou",description:"headshot-angela-zhou",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3FgLhuMJuEASXJmzoNevWN/c115937f066329eb77cd75caa831bfbe/headshot-angela-zhou.png"},contentType:"person"}],authorsString:"Angela Zhou",category:"How-To",readingTime:2},{title:"Announcing Nexus: Connect Temporal Applications across isolated Namespaces",content:"Connecting Workflows across teams and applications is critical for scaling distributed systems, but it must be done in a way that supports Durable Execution and integrated observability for reliable operation and execution debugging.\nExisting solutions have notable limitations\n\n  Direct Workflow-to-Workflow integrations are a leaky abstraction with high degree of coupling between caller and handler Workflows due to the lack of a service contract. They often require full write access to a target Namespace resulting in an overly permissive security posture. Child Workflows in Temporal Cloud must run in the same namespace, which means everyone has access to everything and the blast radius for misbehaving Workers is not isolated.\n  Custom integrations with bespoke APIs and webhooks often have a high operational burden and require lots of boilerplate code that must be made reliable. Teams must agree on a common communication protocol that enables Durable Execution. Even if you create such a system, it often results in a disjoint execution debugging experience in production with manual Namespace traversal and log correlation.\n\nAnnouncing Temporal Nexus\nWere excited to announce Temporal Nexus, a built-in feature of the Temporal Platform to connect Temporal Applications across (and within) isolated Namespaces. Nexus is available in Public Preview both in the open source and Temporal Cloud. Nexus provides all the benefits of Durable Execution across team and application boundaries with improved modularity, security, debugging, and fault isolation.\n\n  \n\nUnlike other forms of inter-service communication, Nexus combines a familiar programming model with the resiliency of the Temporal Platform and its queue-based Worker architecture.\nTeams like Netflix are using Nexus to eliminate the need for custom APIs and webhooks for cross-namespace communication and enable seamless, secure collaboration across teams.\nConnect Temporal Applications\nNexus is a fully integrated feature of the Temporal platform that enables cross-team, cross-domain, cross-namespace, and multi-region use cases:\n\n  Connect Temporal Applications - across team and Namespace boundaries\n  Abstract Temporal primitives, like workflows, with clean service contracts\n  Run Nexus services with Temporals queue-based Worker architecture\n  Improve reliability with at-least-once and exactly-once execution guarantees\n  Secure sensitive workflow state with isolated Namespaces for each team\n  Streamline debugging and monitoring with integrated observability\n\nCreate Nexus Endpoints in the Nexus Registry\nNexus Services are exposed from a Nexus Endpoint created in the Nexus Registry. Adding a Nexus Endpoint to the Nexus Registry deploys the Endpoint, so it is available at runtime to serve Nexus requests. The Nexus Registry is scoped to an Account in Temporal Cloud and scoped to a Cluster for self-hosted deployments.\n\n  \n\n\n  A Nexus Endpoint is a reverse proxy that decouples the caller from the handler and routes requests to upstream targets. It currently supports routing to a single target Namespace and Task Queue. Nexus Services and Nexus Operations are often registered in the same Worker as the underlying Temporal primitives they abstract.\n  Nexus connectivity across Namespaces is provided by the Temporal Service. Temporal Cloud supports Nexus connectivity within and across regions and has built-in access controls. Self-hosted Nexus connectivity is supported within a single Cluster and custom Authorizers may be used for access control.\n\nBuild and use Nexus Services\nNexus has a familiar programming model to build and use Nexus Services using the Temporal SDK. The Nexus Operation lifecycle supports both synchronous and asynchronous Operations. It is suitable for low-latency and long-running use cases. Nexus Operations can be implemented with Temporal primitives, like Workflows, or execute arbitrary code.\nAdd a Nexus Service to an existing Worker\n\n  Temporal SDKs have builder functions to create Nexus handlers like New-Sync-Operation and New-Workflow-Run-Operation that reduce boilerplate code, auto-wire callbacks and support bi-directional links for easier cross-namespace execution debugging.\n  For example, the New-Workflow-Run-Operation SDK helper is used to build a Nexus Service with a Nexus Operation that starts a Workflow:\n\nvar MyOperation = temporalnexus.NewWorkflowRunOperation(\n  \"my-operation-name\",\n  MyWorkflowToExposeAsAnOperation,\n  func(\n       ctx context.Context,\n       input MyInput\n       options nexus.StartOperationOptions,\n  ) (client.StartWorkflowOptions, error) {\n\t\t           return client.StartWorkflowOptions{\n\t\t           ID: businessID(input),\n \t}, nil\n  })\nservice := nexus.NewService(\"my-service-name\")\n_ = service.Register(MyOperation)\nmyTemporalWorker.RegisterNexusService(service)\nmyTemporalWorker.RegisterWorkflow(MyWorkflowToExposeAsAnOperation)\nA Nexus Service is typically registered in the same Temporal Worker as the underlying Temporal primitives they abstract. The Worker polls the Endpoint's target Task Queue for Nexus requests to handle. This eliminates the need to run a bespoke API server, streamlines deployment and provides automatic load balancing.\nExpose Nexus Services from a Nexus Endpoint\nFor others to use a Nexus Service, it must be exposed from a Nexus Endpoint. This is done by creating a Nexus Endpoint in the Nexus Registry and configuring the Endpoint target to route Nexus requests to the Namespace and Task Queue that a Nexus Worker is polling. Multiple Nexus Services may be run on a single Task Queue. Nexus Endpoints may be managed using the Temporal UI, the CLI, or the Cloud Ops API.\n\n  \n\nUse a Nexus Service from a caller Workflow\nTemporal SDKs currently support calling Nexus Operations from a caller Workflow. For example, in the Go SDK a Nexus Operation is invoked as follows:\nfunc MyCallerWorkflow(ctx workflow.Context, input MyInput) (MyOutput, error) {\n\tc := workflow.NewNexusClient(\"my-endpoint-name\", \"my-service-name\")\n\n\tfut := c.ExecuteOperation(ctx, \"my-operation-name\", MyInput{Message: message}, workflow.NexusOperationOptions{})\n\n\tvar res MyOutput\n\tif err := fut.Get(ctx, &res); err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn res, nil\n}\n\nStart building Nexus Services with the Temporal Go SDK and Java SDK quick start guides and code samples for the open source and Temporal Cloud.\nQueue-based Worker architecture\nNexus uses the Temporal queue-based Worker architecture and built-in Nexus machinery to ensure reliable execution of Nexus Operations. If a Nexus Service is down, a caller Workflow can continue to schedule Nexus Operations and they will be processed when the Service is up.\nBuilt-in Nexus Machinery\nThe built-in Nexus Machinery uses state-machine-based invocation and completion callbacks. It guarantees at-least-once execution and supports exactly-once execution using Workflow policy. Nexus provides automatic retries, circuit breaking, rate limiting, and load balancing.\nWhats next\nThe roadmap for Temporal Nexus includes:\n\n  Multi-cloud Nexus connectivity across AWS and GCP in Temporal Cloud.\n  GA release of Nexus in 2025.\n  Nexus support in all Temporal SDKs.\n  Contract-first developer experience with IDL and code generation.\n  Direct Nexus calls from external clients beyond a caller Workflow.\n  Per-caller rate limiting on Nexus Endpoints.\n  Terraform support for managing Nexus Endpoints\n  Much more!\n\nGet started with Nexus today!\nLearn how Nexus connects Temporal Applications and provides all the benefits of Durable Execution within and across Namespace boundaries with improved modularity, security, debugging, and fault isolation.\n\n  Register for the upcoming webinar featuring Netflix and the Temporal Nexus team.\n  Join the #nexus community channel in Temporal Slack.\n  Evaluate why you should use Nexus and watch the Nexus keynote and demo.\n  Learn key Nexus concepts and how Nexus works in the Nexus deep dive talk.\n  Build your first Nexus Service using the Go SDK and Java SDK quick starts.\n  Explore additional resources to learn more about Nexus.\n",featureImage:{title:"social-card-temporalite-blog",description:"social-card-temporalite-blog",url:"https://images.ctfassets.net/0uuz8ydxyd9p/43c3wR1aXhf2oLpXy8WReZ/b280baada058cdc1d0dc9a4b2aaff37a/social-card-temporalite-blog.jpg"},publishDate:"2024-12-20T00:00-08:00",metaTitle:"Announcing Nexus: Connect Temporal Applications across isolated Namespaces",tags:"Temporal Primitives",slug:"announcing-nexus-connect-temporal-applications-across-isolated-namespaces",contentType:"blogPost",entityId:"6y59blXHIusE16i395bZGk",authors:[{id:"3Kphz7jmScrDXEXQXzv3Or",name:"Phil Prasek",slug:"phil-prasek",jobTitle:"Sr. Staff Product Manager",photograph:{title:"Phil Prasek Headshot",description:"Phil Prasek Headshot",url:"https://images.ctfassets.net/0uuz8ydxyd9p/25ix1Mi0zw7jnVTdMPJPzl/8bf86d92d6e4b23dc89924397d10a3cf/Phil_Prasek_Headshot.png"},biography:"Phil is a Sr. Staff Product Manager at Temporal where he is working on durable execution in multi-team environments. Phil previously led Product for the core platform at Apollo GraphQL including Apollo Federation and the Apollo Router, a high-performance supergraph runtime. Phils past roles at Upbound working on Crossplane, Chef, and HPE bring over two decades of experience with a mix of open source and enterprise in dev tooling, control planes, and infrastructure as a service. Phil also enjoys skiing and hiking in the Pacific Northwest.",company:"Temporal",contentType:"person"},{id:"2TPGyzrWW6fxp5iLXi0vov",name:"Roey Berman",slug:"roey-berman",jobTitle:"Tech Lead, SDK",photograph:{title:"roey",description:"roey",url:"https://images.ctfassets.net/0uuz8ydxyd9p/k28KhefNpIUrrGopwiiLy/efbc604dfb1b729a460ae53f0086f5f9/roey.jpg"},contentType:"person"}],authorsString:"Phil Prasek, Roey Berman",category:"Product News",readingTime:6},{title:"Transforming GPU resource management with Temporal",content:"\n  Transforming GPU Resource Management with Temporal: From Complexity to Efficiency\n  We recently spoke with a senior engineer at a leading technology company renowned for its GPU-powered cloud services. The engineer shared how Temporal has been a game-changer in their operations, helping the team automate critical workflows, streamline processes, and deliver faster results with fewer headaches. By deploying Temporal, they built an extensible platform for managing long-running GPU workflows in just three months, unlocking new levels of scalability and efficiency.\n\nThe Challenge: Managing Millions of Long-Running Tasks\nIn this companys cloud services division, GPUs are the backbone of high-performance computing and AI workloads. Managing thousands of these resources  health checks, updates, and repairs  is a monumental task. Were dealing with resources that are operational for years, the engineer explained. The operations we perform on them are inherently long-running and asynchronous, which makes them a perfect match for Temporal.\nPreviously, these workflows were cumbersome, requiring extensive manual oversight and brittle, hard-to-maintain systems. Alternatives like state-machine-based tools didnt provide the flexibility the team needed. With those systems, every state has to be explicitly modeled ahead of time, the engineer said. Temporal, on the other hand, lets us build durable workflows that can adapt to different scenarios.\nThe team didnt just explore Temporal  they leaned into it. I was hired specifically to bring Temporal expertise, the engineer revealed. Our leadership saw the value and wanted to build a solution around it.\nThe Solution: A Unified Resource Management Platform\nThe teams answer was to create a Resource Management Platform powered by Temporal. Designed for extensibility, this platform could manage various types of GPU resources and operations under a single system.\nWe launched the platform in just three months, the engineer shared. Temporal gave us the reliability and durability we needed to move quickly. Now we can manage resources at scale without worrying about retries, failures, or state management  its all handled for us.\n\n  Nexus is a game-changer for integrating different workflows seamlessly.\n\nThe platform uses child workflows to manage tasks and is now evolving to leverage Temporal Nexus, Temporals new feature for extensibility. Nexus is a game-changer, the engineer said. It makes it even easier to integrate different workflows seamlessly. Were already migrating parts of our platform to use it.\nIn addition to the platform, the team developed a flexible automation pool  internally dubbed the Pirate Galley  to handle smaller, ad-hoc tasks that fit Temporals capabilities. For small use cases, we can spin up workflows in less than a sprint  just a couple of weeks, the engineer explained. Its a great way to tackle automation quickly without overengineering solutions.\nA New Mindset: Durable Execution as a Developer Superpower\nWhen asked why the team chose Temporal Cloud over self-hosting, the engineer didnt hesitate. At our scale, we could have self-hosted, they admitted. But the overhead wasnt worth it. We dont have a massive DevOps team, and the cost of Temporal Cloud is modest compared to the developer time wed spend maintaining it. It was a no-brainer.\nTemporal Cloud also delivers a level of scalability and reliability that would have been difficult to replicate internally. It lets us focus on solving business problems rather than managing infrastructure, the engineer added.\n\n  Developing with Temporal is like starting on third base  its a cheat code for developers.\n\n\n  Temporal hasnt just improved the teams workflows  its changed how they approach development. Developing with Temporal is like starting on third base, the engineer quipped. It solves concurrency, idempotency, and retries out of the box. Its a bit of a cheat code for developers.\n  This shift has unlocked space for innovation. As a distributed systems engineer, I used to spend so much time solving foundational problems, they said. With Temporal, I can focus on the actual application logic. Its faster, more reliable, and honestly, just more fun.\n\nThe engineer believes that durable execution  Temporals core strength  is a true superpower for developers. Once youve worked with Temporal, you cant go back. It fundamentally changes the way you think about building distributed systems.\nReal Results: Faster Development, Greater Impact\nThanks to Temporal, the team has:\n\n  Built an extensible platform in just three months.\n  Automated long-running GPU resource management workflows.\n  Enabled rapid development of smaller use cases in weeks.\n  \n    And unlocked developer time to focus on higher-value tasks.\n    There really isnt an alternative to Temporal, the engineer concluded. For the problems were solving, its unmatched. Durable execution isnt just a feature  its the foundation for building scalable, resilient systems.\n  \n\nThe team sees even more potential with Temporals new features, such as Nexus, which simplifies workflow extensibility across teams. Were already converting parts of our platform to use Nexus, the engineer revealed. Its opening up new possibilities for us and will make our workflows even more flexible.\nThis interview was conducted at Replay 2024, Temporals annual conference, where industry leaders gather to share insights and advancements in workflow orchestration.\nTemporal empowers developers to automate complex processes and focus on what matters most  building, innovating, and delivering results. See what Temporal can do for your team with $1000 in Temporal Cloud credits for a limited time.",featureImage:{title:"social-waves",description:"social-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3VcwELyHT8XrKJCFB6yfht/552f942de9f308def0df62fe24787dcb/image-3D-waves.jpg"},publishDate:"2024-12-19T00:00-08:00",metaDescription:"See how a leading tech company used Temporal to automate GPU workflows, boost scalability, and streamline resource management.",metaTitle:"Efficient GPU resource management with Temporal",tags:"Scaling",slug:"transforming-gpu-resource-management-with-temporal",contentType:"blogPost",entityId:"7tQUCcE2VMZEqCWbLB6Yl6",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"Community",readingTime:5},{title:"10 reasons you should attend Replay 2025",content:"Ready to kick off 2025 with some serious technological know-how? Whether youre a seasoned pro or just starting out, Replay 25 is best place to dive deep into the world of durable execution, modernizing legacy systems, and shaping the future of scalable, resilient architectures.\nAnd the best part? This year, our flagship conference is happening in London, from March 3rd through 5th!\nHere are just some of the many reasons why Replay 25 is the must-attend event for every developer, engineer, and tech leader in the backend world.\n1. Talk with Experts\nReplay '25 isnt just about attending talks from the brightest minds in backend engineering. Its about engaging with them, learning from their experiences, and walking away with insights that will make a difference to your team.\nAt Replay, youll hear from leaders at top companies like the ones we had at Replay 24 including Netflix, Block, and SpiralScout, and get inspired by their strategies for modernizing monoliths and scaling their systems. This year, you can look forward to speaking with attendees from companies like Maersk, Miro, Plaid, Rippling, and more.\nAnd lets be real: Who wouldnt want to chat about the future of backend tech with the people who are building it?\n2. Get Hands-on with Temporal\nIf youve ever wanted to learn Temporal from the inside out, Replay 25 is the perfect place to do it. Whether youre a beginner or a seasoned developer, weve got you covered with hands-on workshops designed to help you master Temporals powerful capabilities.\nWorkshops are available in Go, Java, and .NET, with everything from developer fundamentals to more advanced topics. The best part is that these sessions are designed to get you up to speed with Temporal  no prior experience required. Plus, our 102 courses can help you dive deeper into advanced concepts like error handling and workflow orchestration.\n3. Join the Hackathon\nFeeling collaborative? Join the Replay 25 Hackathon and work with fellow devs to build cool apps and write awesome workflows. Whether youre working solo or teaming up with others, this is your chance to get creative and push your skills to the next level.\nThe Hackathon runs from 10 a.m. to 4 p.m. on Day 1, and you can sign up for just 175 during the early bird period (ends January 31st). Bring your best ideas and work side by side with like-minded engineers to see just what you can build!\n4. Learn from Real Users\nThe best way to learn is from those whove been there, done that. At Replay, well showcase real-world success stories from customers whove embraced Temporal to modernize their systems and take their software development to new heights.\nThis isnt just theory  these are actual, hands-on insights that you can take back to your team to start solving challenges in your own workflows.\n5. Community Building\nReplay 25 is all about building community. Whether youre an introvert or an extrovert, theres a space for you. Get to know fellow attendees, swap tips, solve problems together, and maybe even get inspired for your next big project.\nWith plenty of networking opportunities, youll meet developers who are pushing the boundaries of backend tech. And lets not forget: community is what makes Temporal such an exciting place to be.\n6. Swag, Swag, and More Swag\nWho doesnt love cool event swag? This years Modernizing the Monolith theme brings some truly epic visual storytelling to life. Think historic landmarks like the Colosseum and Stonehenge, reimagined to showcase the evolution of technology. Well bring this theme to life through captivating talks and a whole lot of fun.\nAnd yes, there will be swag. Expect unique goodies that will help you remember just how awesome Replay 25 was.\n7. Ask the Experts (No Question is a Bad Question)\nGot a burning question about Temporal, moving beyond monoliths, or even scaling your systems? Dont worry  Replay 25 has you covered. With our new Ask an Expert sessions, youll have the chance to chat directly with the Temporal team and get personalized advice to take your project to the next level.\nWhether its a simple question or a complex challenge, were here to help. Dont miss your chance to engage with the team thats driving Temporals future!\n8. Learn About New Features\nAt Replay 25, youll get an exclusive look at the newest Temporal features and whats coming next. Stay ahead of the curve by learning directly from our team of experts about the tools and capabilities being added to Temporal that will make your workflows even more powerful and be the first to know how to use these new features to improve your systems.\n9. Fun Events!\nReplay 2025 will be packed with plenty of opportunities to connect with fellow backend development enthusiasts in a fun setting. Its the perfect chance to unwind and make valuable connections in a fun, low-pressure environment.\nTheres sure to be spontaneous meetups and group chats after sessions, and we also have some great informal networking events planned. These are designed to help you connect with like-minded people, spark new ideas, and foster great professional relationships.\n10. Be Part of Something Greater\nReplay 25 is far more than just another tech conference. Replay is an opportunity to be part of something bigger. With a focus on modernizing the monolith, this event brings together the best minds in backend engineering to discuss, innovate, and create.\nWhether you're looking to deepen your technical skills, grow your network, or just be part of a community thats as passionate about resilient systems as you are, Replay '25 offers a truly unique experience you wont find anywhere else.\nDont wait until the last minute. Get your ticket now to secure your spot.\nSee you in London!",featureImage:{title:"social-card-purple-waves",description:"social-card-purple-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2nvZtGhubV6XKQbGrFwUmH/c7c8144ccbc2a70cc9d1274206d26593/social-card-purple-waves.jpg"},publishDate:"2024-12-18T00:00-08:00",metaTitle:"10 reasons you should attend Replay 2025",socialCard:{title:"10 Reasons You Should Attend Replay 2025",description:"10 Reasons You Should Attend Replay 2025",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2rTXNRbdaTTNBdeqLflC8g/a203c4b798e21d6a3f01f872e45883ff/10_Reasons_You_Should_Attend_Replay_2025.png"},tags:"Replay",slug:"10-reasons-attend-replay-2025",contentType:"blogPost",entityId:"1QPyPyam9kKIg8XrF4JJTH",authors:[{id:"7GQtiP7y4Dmrje9sFWcVKl",name:"Lauren Bennett",slug:"lauren-bennett",jobTitle:"Content Marketing Manager",photograph:{title:"Lauren-Bennett-profile-photos",description:"Lauren-Bennett-profile-photos",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6jEqojw9RxBBjX5pytMzYf/4df0ef856a9efe4b7b52d5ebe7e83686/Lauren-Bennett-profile-photos.jpeg"},linkedInUrl:"https://www.linkedin.com/in/lauren-n-c-bennett/",contentType:"person"}],authorsString:"Lauren Bennett",category:"Community",readingTime:5},{title:"How modern Workflow orchestration solves scalability challenges in distributed systems",content:"Scalability is critical for modern industries. From e-commerce to healthcare, financial services to cybersecurity, growing businesses must support increasing customer bases and higher service demands. Yet, many organizations are held back by systems that buckle under pressure, leaving them scrambling to keep up. High-throughput distributed systems can struggle with failures, where even minor disruptions and bottlenecks can lead to slow performance, downtime, and frustrated customers.\nIn this post, well explore how scalability can transform operations, why many distributed systems fall short, and how modern tools enable businesses to thrive  including a real-world story of innovation from Bugcrowd.\nThe Complexity of Scaling State and Retries in Distributed Systems\nScaling effectively involves solving specific challenges like managing state in distributed systems, coordinating retries across services, and ensuring workflows recover from interruptions. As systems grow, so does the complexity of handling these challenges, until systems become increasingly difficult for developers to reason about, maintain, update, and debug.\nManaging State and Dependencies in Decoupled Services\nWhen each part of a system operates independently, teams can scale components as needed without affecting others. However, in distributed systems, this modularity introduces challenges, especially in managing dependencies and ensuring consistency across services.\nConsider the complexities of coordinating tasks using the saga pattern. Sagas manage distributed transactions by breaking them into smaller, coordinated steps. While effective, this approach requires developers to handle retries, compensations, and error recovery manually. Each service must account for failures in preceding or dependent processes, adding unnecessary complexity and increasing the risk of inconsistencies.\nModern workflow orchestration platforms simplify this by providing a central, durable execution model to manage sagas. Instead of manually implementing retries or compensations, engineers can focus on business logic while the orchestration layer handles state persistence and failure recovery automatically.\nSimplifying Resilient Workflow Management with Orchestration\nBuilding scalable systems often involves managing complex state machines, which require careful tracking and maintenance.\nState machines are valuable tools for managing state consistency in distributed systems, but they can quickly become brittle as systems grow. Developers must implement manual mechanisms to track state, introducing overhead and potential failure points. For example, in a payment processing workflow, ensuring the system retries failed transactions without double-charging customers is critical but challenging to get right.\nModern orchestration tools abstract this complexity. They automatically persist workflow state, resume operations from the point of failure, and provide visibility into the systems progress. This eliminates the need for developers to build error-handling logic from scratch, resulting in more reliable systems.\nA New Approach: Scalable Workflow Orchestration\nModern workflow tools focus on simplicity, resilience, and empowering developers. Picture this: instead of manually coding sagas, state machines, retries, and failure-handling logic, your team defines simplified workflows in code. The workflows provide an abstraction layer and automatically orchestrate processes to automatically recover from failures, scale effortlessly, and let developers innovate rather than firefight.\nWhen scalability is a given, possibilities open up. Heres what to look for in a scalable workflow orchestration tool:\nSeamless Scalability\nThe right tool should allow you to:\n\n  Scale workflows effortlessly across distributed systems.\n  Use familiar programming languages for workflow definition, avoiding the need for proprietary DSLs.\n  Debug and modify workflows with transparency and ease.\n\nBuilt-in Resilience\nModern tools provide:\n\n  Automatic retries to handle transient failures.\n  State persistence to recover from disruptions.\n  Robust error-handling mechanisms to ensure smooth operations.\n\nDeveloper Empowerment\nBy abstracting away the complexities of error handling and orchestration, modern solutions free developers to:\n\n  Focus on business logic.\n  Deliver features faster.\n  Build systems that are easier to maintain and scale.\n\nHow Bugcrowd Achieved Scalability with Workflow Orchestration\nBugcrowd, a leading crowdsourced cybersecurity platform, was at a crossroads. Their legacy Ruby monolith couldnt keep up with their vision to integrate machine learning and scale their hacker engagement processes. Bottlenecks and inefficiencies frustrated the team.\nBy transitioning to microservices and adopting Temporal  a modern orchestration platform,  Bugcrowd achieved:\n\n  2x Faster Engagements: Automated hacker selection cut project timelines in half.\n  400% Capacity Increase: More simultaneous engagements without additional effort.\n  15 Hours Saved Weekly: Reduced manual processes freed engineering resources.\n\nBugcrowds team could finally move forward without being held back by their tools.\nIn Conclusion\nScalability is critical for navigating todays operational challenges. Whether its managing peak traffic, integrating new services, or driving innovation, the ability to scale ensures systems remain efficient and reliable.\nModern orchestration tools make scalability achievable. They empower businesses to move beyond legacy limitations, delivering reliability, efficiency, and agility in competitive markets.\nIf youre ready to take the next step, explore how a modern orchestration platform can reshape your operations. Download our white paper to learn more.",featureImage:{title:"social-card-brandon",description:"social-card-brandon",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1oX4jNjimgeS45r7uoaMha/d54d7043f6f959dc26a493a2e74d98c7/social-card-brandon.jpg"},publishDate:"2024-12-17T00:00-08:00",metaDescription:"Discover how modern workflow orchestration simplifies scaling distributed systems by managing retries, state, and failure recovery. Build resilient, efficient systems without added complexity.",metaTitle:"Simplifying Scalability in Distributed Systems with Workflow Orchestration",socialCard:{title:"social-card-brandon",description:"social-card-brandon",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1oX4jNjimgeS45r7uoaMha/d54d7043f6f959dc26a493a2e74d98c7/social-card-brandon.jpg"},tags:"Scaling,Durable Execution",slug:"how-modern-workflow-orchestration-solves-scalability-challenges",contentType:"blogPost",entityId:"1PZZQRkgEhVkmZ2OfzVQVb",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"How-To",readingTime:4},{title:"Achieving $2.25 million in savings: ROI analysis of migrating to Temporal Cloud",content:"This report, based on a single Temporal Cloud client, reflects insights developed in consultation with Temporal Solution Architects. The estimates provided represent a typical use case for a large customer with complex operational needs, high-quality service expectations, and numerous opportunities to adopt Temporal internally.\nThe following ROI analysis compares the Total Cost of Ownership (TCO) of the Client's existing homegrown Inventory Management System (IES) with Temporal Cloud.\nBy implementing Temporal as a replacement for their current IES, the Client stands to gain significant advantages, including reduced infrastructure and human resource costs, improved system stability, and enhanced long-term scalability.\nKey Findings\nThis detailed analysis of the Clients current state data shows that by implementing Temporal, the Client will save $2.25 million annually across three critical areas:\n\n  $477,000 in infrastructure costs\n  $1.2 million ($100,000/month) in maintenance and incident management costs\n  $576,000 in human capital costs\n\nIn addition to cost savings, the use of Temporal Cloud offers several other benefits that improve the clients operations. Temporal Cloud enables faster feature development, keeping your organization innovative and ahead of market changes. It improves system stability and enhanced data accuracy, leading to greater customer satisfaction by fostering greater trust and loyalty. And finally, Temporals architecture ensures that the clients IES grows with the business, reducing the risk of future technical debt and operational failures.\nThe following research delves deeper into these advantages and their implications for the clients long-term success.\nEvaluating Infrastructure Costs\nThe Clients current infrastructure costs associated with their IES show significant financial implications. The existing setup, using EventDB and Confluent Cloud, costs them $46,600, totaling an annual cost of $559,200, excluding AWS support fees.\nIn contrast, if the Client used Temporal Cloud, their estimated monthly actions would cost $6,549 with a storage cost of $327, making their total monthly expenditure $6,876 and their annual expenditure $82,517.\nSwitching to Temporal Cloud reduces the Clients annual infrastructure costs from $559,200 to $82,517, a potential savings of $476,683 annually.\nSource: Temporal at Stripe: Mastering Kafka at Scale..\nMaintenance and Incident Management Costs\nPresently, the Client's existing IES is prone to a significant number of incidents, with an average of six active issues  four classified as low severity and two as medium severity  occurring at any given time.\nThese incidents not only contribute to operational instability, but they also have a substantial financial impact, with a revenue loss estimated at $100,000 monthly, or approximately $10,000 per incident.\nThe time required for incident resolution varies: low severity incidents typically take one to two weeks, medium severity can take two to five weeks, and high severity issues may extend beyond a month.\nBeyond this, the frequent instability of the system requires ongoing troubleshooting, patching, and remediation, creating a continuous drain on resources.\nCurrently, capturing and quantifying incident data poses challenges due to the complexity of the disparate systems in use. Its a time-intensive process that requires custom queries. Moreover, troubleshooting involves piecing together logs from multiple services and manually re-executing events to reproduce failures. This prolonged approach not only heightens the risk of escalation into more severe disruptions but also incurs additional costs for senior technical staff or external consultants.\nThe Impact of Temporal Cloud\nTransitioning to Temporal Cloud offers significant improvement in terms of cost and time. The Client can expect a 40% reduction in incident-related tasks for the Engineering and Innovation (EII) team, effectively repurposing approximately 384 hours of engineering time per month  equivalent to three full-time employees  toward proactive feature development and innovation.\nBeyond this, there is a 60% reduction of the Sustain teams workload, allowing the Client to eliminate most reactive support tasks. This shift leads to fewer support tickets, less troubleshooting, and substantial cost reductions.\nSchedule time with an expert to talk about your use case, and get advice and assistance on your project.\nTime Savings\nAdditionally, the enhanced workflow visibility, automatic retries, and deterministic execution reduces the time needed to identify and resolve issues by 50-75%. This improvement stems from the elimination of manual error reproduction and the ability to pinpoint failure points through Temporals workflow history.\nHow Temporal Helps\nTemporals strengths shine through in the following features:\n\n  Automatic Retries and State Management: Temporal maintains the full state of workflows and automatically retries failed steps. This eliminates the need to manually check logs or database states to identify where things went wrong.\n  Clear Workflow History: Temporal provides complete visibility into the history of each workflow, making it easier to trace errors and understand the sequence of events that led to the problem.\n  Deterministic Execution: Temporal ensures that workflows are deterministic, enabling the replay and re-execution of errors from the point of failure. This feature alone can cut down the time spent replicating bugs for investigation.\n  Simplified Error Handling: Temporal supports centralized error handling strategies, which reduce the complexity of dealing with edge cases and failures spread across multiple services or components.\n\nMany of our other customers experiences support these claims, with companies like Bugcrowd reporting a 50% reduction in downtime and Turo highlighting significant improvements in development velocity and maintainability after adopting Temporal.\nTransitioning to Temporal Cloud eases the burden of ongoing maintenance associated and paves the way for operational efficiency and innovation.\nHuman Capital Costs\nThe current staffing model for the Client includes two teams that maintain and troubleshoot the IES. Team 1 (EII) is a group of six full-time employees: one Engineering Manager, three Senior Managers, one mid-level Engineer, and two Junior Engineers. This team handles business flow fixes and feature development. However, because of the instability of the current system, they spend 60-70% of their time on reactionary tasks such as incident resolution and system patching. Over the past three years, this has impeded their production flow, resulting in only three new features being developed.\nTeam 2 (Sustain) is a group of six contracted employees: one Senior Engineer and five mid-level Engineers. Theyre dedicated to triaging incidents and providing 24/7, on-call support.\nBy using Temporal Cloud, the Client would reduce their time spent on labor-intensive, reactionary work for both teams. For Team 1, Temporal would decrease the time spent on reactive tasks by 40%, freeing up resources for strategic initiatives and enabling the development of more features at a faster pace.\nFor Team 2, Temporals enhanced system stability and streamlined troubleshooting capabilities would reduce the need for 24/7 support by 60%, significantly lowering labor costs.\nA move to Temporal allows both teams to focus on strategic initiatives rather than an endless stream of problem solving.\nData Reliability and Productivity Gains\n\n  The Clients current system experiences frequent data inaccuracies and reliability issues, leading to ongoing maintenance and patching. During peak periods, inventory events spike up to 10x, putting further strain on the infrastructure. The instability of the Client's IES directly hampers productivity, as the Client has only delivered three new features over the past three years. This is largely due to the heavy focus on incident management. Because of this, each feature takes 2-3 months to implement.\n  Improved Feature Velocity with Temporal\n  Temporals improved reliability would not only enhance data accuracy but also allow for faster, more agile development cycles. This would result in:\n\n\n  Faster Feature Delivery: Enabling the business to better respond to market demands.\n  Increased Revenue: Through higher system uptime and fewer lost sales because of outages.\n  Improved Customer Satisfaction: Thanks to more reliable inventory data and fewer disruptions.\n\nLong-Term Sustainability and Future Proofing\nCurrently, the Client faces an accumulation of technical debt because of the ongoing patching and reactive nature of the current IES.This only makes future maintenance even more costly and time-consuming. Temporal provides a solution by eliminating much of the need for reactive measures, lowering the long-term costs of system maintenance.\nIn addition to this, Temporal's scalable architecture allows the Client to grow its operations without compromising reliability, even during high-demand periods like the holidays. Processing millions of transactions robustly can be a complex problem. Traditional order services often utilize state machines, databases and distributed sagas to keep track of all the various steps that an order must go through in its lifetime. Each of the steps in a saga can fail or become unavailable. Ensuring that the system can handle spikes in activity without the risk of failure is crucial to any organization invested in long-term growth and a successful future.\nConclusion: Direct Cost Savings and Strategic Value\nMigrating to Temporal Cloud offers the Client substantial direct cost savings and long-term strategic benefits. The estimated annual savings total $2.25 million, broken down as follows:\n\n  $477,000 in infrastructure cost reductions\n  $1.2 million saved by reducing revenue loss from system downtime and data inaccuracies\n  $576,000 in labor savings annually by repurposing 40% of the EII teams resources and reducing 60% of the on-call support for the Sustain team.\n\nTo explore a detailed comparison of Temporal OSS and Temporal Cloud, including aspects like staffing, infrastructure, scalability, and maintenance, download our white paper.\nSchedule time with an expert to talk about your use case, and get advice and assistance on your project.",featureImage:{title:"social-card-dark-waves",description:"social-card-dark-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2EnRRWXLoTeCWl9m4xuZvn/d01871a31191cc3054b7f6a08f29d628/social-card-dark-waves.jpg"},publishDate:"2024-12-12T02:22-08:00",metaDescription:"This report, based on a single Temporal Cloud client, reflects insights of migrating to Temporal Cloud developed in consultation with Temporal Solution Architects.",metaTitle:"Achieving $2.25 million in savings: ROI analysis of migrating to Temporal Cloud",socialCard:{title:"social-card-dark-waves",description:"social-card-dark-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2EnRRWXLoTeCWl9m4xuZvn/d01871a31191cc3054b7f6a08f29d628/social-card-dark-waves.jpg"},tags:"Cloud",slug:"achieving-usd2-25-million-in-savings-roi-analysis-of-migrating-to-temporal",contentType:"blogPost",entityId:"6RxlitPXkiOfW6Ebz804Gq",authors:[{id:"1ixl3MvlJq3HHeOAybbItw",name:"Alex Garnett",slug:"alex-garnett",jobTitle:"Sr. Curriculum Developer",photograph:{title:"headshot-alex-garnett",description:"headshot-alex-garnett",url:"https://images.ctfassets.net/0uuz8ydxyd9p/AQU0azmUuAr68eADoogUJ/63d8023152958926ce5a524b8439c227/headshot-alex-garnett.png"},contentType:"person"},{id:"1VQRqr0fVS9svnoX57cPKm",name:"Mason Egger",slug:"mason-egger",jobTitle:"Sr. Technical Curriculum Developer",photograph:{title:"mason egger",description:"mason egger",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7ouhODOdbYXBCMY8wynrGa/a184aa85abb1880f8857a60dc99ca825/11214847"},contentType:"person"}],authorsString:"Alex Garnett, Mason Egger",category:"How-To",readingTime:8},{title:"Salesforce cuts Workflow code by 95% with Temporal",content:"We recently spoke with Varun Gupta, VP of Engineering at Salesforce, and Sahil Vazirani, Principal Architect, to discuss how Temporal has become a foundational technology for Salesforce. Through Temporals orchestration capabilities, the company has significantly reduced manual intervention, optimized developer workflows, and accelerated its ability to deliver enterprise-grade solutions.\nThe Journey to Temporal: From Evaluation to Implementation\n\n  Temporal is that glue that helps us stitch these complex systems together and support their interoperation.\n\nAs one of the largest enterprise software providers, Salesforce operates a vast network of applications and infrastructure, much of it inherited through acquisitions. Managing this complex ecosystem posed significant challenges, particularly in coordinating distributed systems that are prone to failure.\nAs we work to unite these systems, we need a common technology that helps them work seamlessly together to provide a unified experience for our customers, Vazirani explained. Temporal is that glue that helps us stitch these complex systems together and support their interoperation.\nThe search for a solution began with thorough research. I started reading more about the founders, Samar and Maxim, and realized the innovation theyd done in the industry, going back to 2009 with simple workflows, their work on Cadence, and how Cadence was open-sourced, Vazirani recalled. His investigation included studying Cadence implementations at Uber and examining how Temporal evolved to address the limitations of previous orchestration systems.\nBefore Temporal, Salesforce relied on disconnected automation scripts and manual processes. Engineers had to oversee workflows in stages, executing individual steps across different systems. For a large setup like a brand new region setup, it could take anywhere from days to months, according to Gupta. The process required constant human intervention, with engineers needing to press a button and then execute the next automation, execute the next automation.\nBuilding a Platform for Enterprise-Scale Automation\n\n  What previously required 1,000 lines of code can now be done with just 50, thanks to the primitives provided by Temporals SDKs.\n\nThe implementation started small but quickly demonstrated value. One of our biggest challenges was finding a solution for running durable, reliable long-running workflows, Vazirani explained. Our existing solutions werent designed to support workflows of this duration.\nThe impact on development efficiency was immediate. What previously required 1,000 lines of code can now be done with just 50, thanks to the primitives provided by Temporals SDKs, Vazirani shared. The ability to unit test code rather than work with domain-specific languages particularly improved the software development lifecycle and developer productivity.\nAs success stories emerged, information spread through Salesforces internal channels. Our chief architect suggested to me, Hey, this looks interesting and your recent success with the smaller use case allows us to unlock other possibilities, Vazirani recalled. He presented at the cross-cloud architecture forum, where other teams recognized similar challenges in their own work.\nThis momentum led to a strategic evolution in their approach. We need to make this a real platform, Vazirani explained. How do we make it even further easy for our developers to avoid having the learning curve to learn a new technology, and start investing in developer productivity? Their team began building an ecosystem of tools around Temporal, focusing on self-service capabilities, auto-debugging, and other features to support broader adoption.\nScaling for Enterprise Needs\n\n  By reducing manual involvement and increasing automation, were making better use of our most valuable resource  our engineers.\n\nThe transition to Temporal has transformed how Salesforce approaches workflow automation, but the team maintains a careful balance between expansion and reliability. We want to enable every team at Salesforce to utilize this technology, Gupta noted, but we want to make sure that we are able to scale Temporal, and that we can handle the transaction volume at Salesforces immense scale, and serve our enterprise customers with the kind of performance they have come to expect.\nThe impact on engineering productivity has been substantial. Weve seen tremendous productivity gains in engineering, Gupta emphasized. By reducing manual involvement and increasing automation, were making better use of our most valuable resource  our engineers. Instead of managing manual tasks and bespoke systems, they can focus on building core capabilities, developing features, and improving our infrastructure.\nThe reliability improvements have been equally significant. Engineers no longer receive middle-of-the-night calls because they can trust their code will work. Even in failure scenarios, Temporals retry capabilities ensure processes resume from where they stopped, maintaining application reliability.\nFuture Vision\nThe scope of Temporals application continues to expand. We are using it for a lot of infrastructure automation use cases, but now we are also expanding it to allow our applications to manage the application business workflows, Gupta explained. This includes enabling inter-application workflows, where different applications need to interact to complete business processes.\nFor teams considering Temporal, Vazirani emphasizes the importance of starting small: Dont be intimidated by the technology. Try out the examples from the GitHub repositories  once you do, you wont want to go back. This approach of gradual adoption has proven effective for Salesforce, allowing them to transform their workflow automation while maintaining reliability at enterprise scale.\nThe team sees themselves as part of a larger community solving complex distributed systems challenges. We are very invested in continuing to see this technology flourish, Gupta noted. We want to work with the community and increase community participation. We love being part of this collaborative effort to solve hard engineering problems.\n\n*This interview was conducted at Replay 2024, Temporals annual conference, where Gupta and Vazirani joined other industry leaders to share their experiences with durable execution and workflow orchestration.\nSalesforces journey illustrates the broader adoption of Temporal across industries, as organizations seek reliable solutions for complex distributed systems challenges. Join the next generation of industry leaders at Replay 2025, taking place in London from March 35, 2025. Buy your ticket now to be part of the conversation and try Temporal for free today.*",featureImage:{title:"social-orb",description:"social-orb",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5ZQDJyHkj4M3RrOA5LZ0ct/2d915cc986593cef13c8260c8f6311df/social-orb.png"},publishDate:"2024-12-09T00:00-08:00",metaDescription:"Learn how Salesforce uses Temporal to reduce workflow code by up to 95%, boost developer productivity, and scale enterprise solutions.",metaTitle:"Salesforce streamlines Workflows, cuts code by 95%",socialCard:{title:"social-salesforce-interview",description:"social-salesforce-interview",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5l3A16rfH0gKNEt8x3m8Lh/98c87e6ecc5c53bfe32ffeb471e09cb1/Blog__5_.png"},tags:"Durable Execution",slug:"salesforce-reduces-workflow-code-by-as-much-as-95",contentType:"blogPost",entityId:"2AXzhLUhOB5l4X9SryFRKX",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"Community",readingTime:5},{title:"Snakes, chaos, and the resilience of Temporal: A live demo breakdown",content:"When we set out to create a live demo for the Temporal Keynote, we wanted something fun, memorable, and a little chaotic. Enter: Snakes.\nYes, snakes. Specifically, the kind that slither around in a multiplayer game where chaos is not just possible but inevitable. What better way to showcase Temporals ability to handle unpredictability than with a snake game running on distributed systems?\n\n  \n\nThe Setup: Multiplayer Snakes Meet Distributed Systems\nThe Snakes demo wasnt just an arcade nostalgia trip. It was a live, multiplayer game powered by Temporal, with players controlling their snakes in real time. Every move, collision and apple consumed  Temporal orchestrated it all.\n\n  The entire game was powered by Workflows: the game itself, each round, and even each snake operated as independent Workflows.\n  \n  \n\nOur Ingredients\nFor the demo UI, we wrote a Svelte application and used the awesome Socket.io websocket framework to communicate with the Temporal backend. This gave us the low latency we needed to make the game responsive.\nThe game Workers (processes executing workflows) ran on a mix of Temporal Cloud and tablets stationed at the front of the stage.\nPowered entirely by Temporal, the game managed:\n\n  Every players snake as independent workflows.\n  Game rounds as separate workflows.\n  Moves, collisions, and apple consumption  all orchestrated flawlessly.\n\nThen, we got the game started.\nRound One: Smooth Sailing\nAngie invited three audience members up on stage to play the game and Steve gave them a quick run down on how to play. For the first round, we kept things simple. Players got to take their time, get a feel for the game, and enjoy devouring apples without any disruption. It was smooth sailing, and the audience cheered as snakes slithered and apples disappeared from the board.\nBut then, it was time to make things interesting.\nRound Two: Introducing Chaos\nIn the second round, we added some chaos. Every apple eaten would restart a Temporal Worker powering the snakes. The stakes were raised, and the games stability was put to the test. Temporal had to recover from these induced outages while ensuring the game continued to run smoothly.\nAt first, the delays were barely noticeable. Temporal recovered quickly after each Worker restart, and the game barely skipped a beat. But it wasnt long before the players, quickly improving at controlling their snakes, managed to eat apples faster than they were coming back.\nFor a brief moment, the game frozean inevitable consequence of overwhelming the system, all of the Workers were down. But as soon as the first restart completed, Temporal picked up exactly where it had left off. The snakes resumed their slithering, and new apples appeared as the audience cheered.\nRound Three: More Chaos\nNot content with eating an apple to restart a Worker, I decided that Id go for something more dramatic: unexpected node failure! After a few apple-eating outages and recoveries, I (sneakily disguised in my Temporal hoodie) crept across the front of the stage, pulling the network cables out of the tablets on stage that were running the Workers!\nFaced again with the loss of all its Workers at once, the snakes froze. The team on stage quickly realized what had happened, and Drew came to the rescue, plugging everything back in. Within seconds, the snakes were back on the move, carrying on from where they left off.\nThese disruptions mimic real-world scenarios like server crashes or sudden hardware failures, showcasing how Temporals resilience translates to handling unexpected outages in production environments.\nWhy It Worked\nTemporals resilience lies in its Durable Execution model. By persisting every step of the Workflows, it ensures that even in the face of chaos, nothing is truly lost. Whether its a snakes position on the board or a critical business process, Temporal makes recovery seamless. You won't need to write code to save state or recover from failures, you get it all for free.\nWriting the game was a lot of fun, its liberating not having to worry about the normal drudgery of writing a reliable application, and instead focusing on the interesting parts. Less pondering what happens if something crashes in the middle of a round, and more time spent preventing snakes from teleporting across the board or spontaneously splitting in half. I spent longer making sure the snakes eyes were facing in the right direction than I did writing any error handling code, and yet as weve seen, the game wasnt phased by anything we threw at it.\nYou can find the code here if youd like to have a look around. The Temporal code is in the game directory, and the UI code is in the snakes directory. And, if you want to watch the demo as it played out on the stage, you can watch it on YouTube.\nWhat did we learn?\nWhat did we learn from writing a game, and then crashing it in front of a live audience?\n1. Temporal is reliable: We knew this already, but Temporal is bullet proof. There was not a single Temporal failure during any rehearsals or the live demo.\n2. Socket.io does the job: Coupling Socket.io (or more specifically websockets) with Temporal worked very well. It made it easy to integrate a low latency UI with a reliable Temporal backend.\n3. Tablets are flaky: If we were to do this again, we would not use tablets, they were a liability  While tablets initially seemed like a convenient choice due to their portability and all-in-one design, their limitations became evident once we started rehearsals. The tablets would sometimes turn themselves off, had poor performance due to the virtualization required to run Linux for the Workers and refused to keep a browser window full-screen if the page reloaded. In retrospect, Raspberry PIs with a small screen attached would have saved us a lot of stress!\n4. Go performance shines: To handle the Worker restarting mechanism, we ran the snake Workers inside Activities (very meta!). When the Worker was killed because a player ate an apple, the Activity would be retried, bringing the Worker back up. Using the Typescript SDK on the tablets didnt work very reliably. We ended up having to rewrite the snake Workers in the Go SDK to get the performance we needed. While not something wed worry about in production use cases on standard nodes, Go worked out better resource wise on our poor underpowered tablets.\n5. Activities + unusual observability requirements = magic: While its not an everyday requirement, having an Activity that polled the history of the snake Workflows to show which Worker they were on in the UI worked very well. We can imagine this being used for unusual observability requirements, for example auditing a subset of Workflows.\nThese lessons arent just about snake games. Theyre a reminder that Temporal excels in demanding scenarios and its flexibility and range of SDKs allows you to choose the right tool for the job!\nWhats next?\n\n  The Snakes demo wasnt just a fun highlight of the keynote  it was a testament to Temporals ability to thrive under pressure. Whether youre orchestrating games, workflows, or entire systems, Temporal ensures youre always ready to bounce back.\n  We cant wait to see what you build with it. (Just maybe leave the snakes for us, okay?)\n\nSee the full demo from Replay 24, join us in London for Replay 25, and create something fun just like we did with a free trial of Temporal Cloud and $1,000 in free credits.",featureImage:{title:"snake-game-webui-hires",description:"snake-game-webui-hires",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5thwvz2c00ypDH7Kfow6z8/e229941b96bc7e3eaf515b0e7b8740d6/snake-game-webui-hires.png"},publishDate:"2024-12-05T00:00-08:00",metaDescription:"We used a live, multiplayer snake game powered by Temporal workflows to showcase the power of Durable Execution. Learn all about it in this blog post.",metaTitle:"Snakes, chaos, and the resilience of Temporal: A live demo breakdown",socialCard:{title:"Snakes and Chaos",description:"Snakes and Chaos",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7cFJgfUW9aijDLlEG9TwA1/dc06b5a5f2c8fa9bbfd30d65c34afd7a/Snakes_and_Chaos.png"},tags:"Code Samples,Temporal Primitives",slug:"snakes-live-demo-on-resilience",contentType:"blogPost",entityId:"aqz3sdolMFhO3LjOWyFOg",authors:[{id:"765ncnsHQZyTqc5R3DmGMf",name:"Rob Holland",slug:"rob-holland",jobTitle:"Staff Developer Experience Engineer",photograph:{title:"Rob Holland",description:"Rob Holland",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5TYAt2gPMiffTdA6ZRdgY3/bfcc87ff9e19765d53c736981313889b/9563"},company:"Temporal",contentType:"person"}],authorsString:"Rob Holland",category:"How-To",readingTime:7},{title:"Event-driven systems and the truth about \"loosely coupled\" architectures",content:"Event-driven architectures (EDAs) provide a solid foundation for scalable, resilient systems. They power systems by breaking down monoliths into decoupled components. Relying on message APIs to communicate makes them flexible and scalable, allowing self-contained services to interact with each other and with client workflows.\nLike any design pattern, event-driven architectures have their own set of challenges. Whether its coupling, troubleshooting, or developer experience, understanding these challenges helps you leverage EDAs more effectively while avoiding common pitfalls.\nThe Temporal platform delivers the benefits of event-driven architectures without overwhelming you with complexity. By abstracting away low-level failure and retry logic, Temporal helps your teams focus on delivering business value, so you wont get bogged down in the intricate details of event handling.\nLoose Coupling in Event-Driven Systems\nA system is \"loosely coupled\" when its components, such as services or endpoints, can be built or modified independently. For example, you might source payment transactions from one vendor, GPS queries from another, and personnel assignments from yet another. Loose coupling is one of the main selling points of event-driven systems.\nServices that operate independently improve overall system resilience. If one service fails or becomes unreachable, others continue functioning. For example, an event-driven e-commerce application can generate events for shopper actions such as adding an item to the cart, placing an order, or paying for a purchase.\nFor example, say the service that dispatches customer email notifications develops issues and is temporarily unavailable. Loose coupling means that customers can still log into their accounts, shop for items, and place orders. A major outage, such as one affecting a payments service, might stop customers from placing orders, but it wont prevent them from browsing or adding items to their carts. So long as other servers and services can publish and consume messages, your system stays operational, even when parts of it are temporarily impacted.\nLoose coupling means that you can scale and add new services downstream without disrupting ongoing flows. This flexibility lets you adapt quickly to changing business needs and integrate new technologies or features more easily as your system evolves. It lets you grow your system over time, adding components and upgrading or replacing them to modernize without widespread disruption. As you accommodate these new demands, you dont need to rework your existing components.\n\n  This flexibility makes EDAs ideal for large-scale, distributed systems, where service health and reliability are top priorities. Helping services stay active, even during failure events, improves your deployments fault tolerance and it supports scalability. The result is an agile system thats responsive to both user needs and technological advancement.\n  EDAs and decoupling breaks monoliths into simpler, easier-to-maintain systems. This, in turn, speeds up feature development. It opens the door to creative use of each service beyond its original purpose. As services evolve, your system becomes more adaptable. This helps your teams move faster and innovate more effectively.\n\nAs with any powerful design pattern, EDAs come with a set of challenges.\nTight Coupling at Design Time\nWhile EDAs shine at runtime flexibility, they remain tightly coupled at \"design time.\" Structural dependency between services relies on a pre-determined protocol of communication and interaction. If an event publisher changes message structurefor example, altering format or field sequencethis can and will cause unexpected downstream issues.\nThe impact on downstream services can be hard to predict. Because services are encapsulated behind their API surfaces, you wont always know which services consume which events, or how they internally rely on and process its structure. Imagine updating a global variable. Changing its structure or meaning in any way could break any number of downstream functions that depend on it. As EDAs evolve, that loss of visibility into their dependencies makes them tricky to manage.\nHidden dependencies create a sense of uncertainty, leading many system architects to fear making changes to event-driven systems. They hesitate to cause a ripple effectwhere one small change leads to bigger, unforeseen issues. This creates a culture of avoidance. Teams may struggle to evolve their systems because, often, they can't predict what might break and where.\nThis problem intensifies during troubleshooting. By nature, event-driven systems are difficult to trace. Unlike RPC (Remote Procedure Call) systems, which offer tools like timestamps, queued events are ephemeral. Tracking message flow between services can be nearly impossible. A bottleneck in one part of the system can quickly snowball, slowing down or even corrupting operations.\nWhile the fear of change is real, reducing system complexity can overcome these challenges and make event-driven systems more manageable. Both complexity and cognitive load dont fix themselves without the right tooling.\nComplexity and Cognitive Load\nWhile event-driven architectures (EDAs) are powerful, they introduce real complexity. As systems grow, so does the demand on developers and architects. They must think, evaluate, and design robust solutions to address potential issues that can and will arise in loosely coupled architectures. For all their strengths and advantages, decoupled deployments still require testing, debugging, tracking, and updates.\nCognitive load is the mental effort needed to anticipate each possible challenge the system might face as part of its design. Although disjoint deployments may seem simpler on the surface, you must juggle multiple moving parts. You need to make decisions on how to test, monitor, and update a decoupled system without disrupting the flow of existing tasks or introducing new issues and regressions.\nSince events are processed asynchronously, the order in which events process will vary. That makes it harder to test for consistency and timing-related bugs. Architectures whose services communicate through events mean that end-to-end integration tests must simulate entire event flows. This flow includes the delivery and consumption of those events, requiring more robust tools and strategies to ensure reliability.\nDebugging is another pain point. Events can be lost or duplicated. This can arise from network blips to misconfigured services, rate limits, or problems that impact only a subset of events under specific conditions. To identify and handle these problems requires robust monitoring and fault tolerance mechanisms. Without these safeguards in place, diagnosing and resolving problems can be time-consuming and error-prone. Its harder to maintain system reliability and performance.\nSince event-driven systems are usually highly concurrent, debugging concurrency issues such as race conditions, deadlocks, or inconsistent states can be a handful. Event-driven systems dont have a single entry point to trace requests. Debugging may require you to trace event chains, which can span across services and systems and may be triggered by multiple sources.\nTo manage this complexity, its essential to use the right tooling and framework.\nRead next: Event-Driven Architectures - A better way forward \nHow Temporal Reduces the Cognitive Load\nEvent-driven architectures add measurable complexity to the maintenance component of distributed deployment. As that complexity increases, so does the cognitive load. Managing, understanding, and troubleshooting these systems distract from the core taskshipping features and maintaining reliable systems.\nThis is where Temporal comes into play.\nLike OpenTelemetry, Apache Kafka, or Apache Pulsar, Temporal is an open source software created to help teams build, run, and maintain modern event-driven architectures. Instead of abstracting away low-level failure and retry logic, Temporal lets you focus on delivering business value so you dont get bogged down with event-handling details.\n\n  All state is tracked and monitored, with each workflow taking a first-class role in the overall architecture. Even in the case of catastrophic failure, workflows can be replayed and resumed without repeating already performed tasks and moving forward to reliable completion.\n  Temporal improves the experience of working with scalable, resilient systems. The platforms built-in tools manage state, handle retries, and keep processes running smoothly even when things go wrong. As a result, you spend less time worrying about failures or chasing elusive bugs, like those caused by changes in event structures.\n\nSay, for example, events evolve and you still have in-flight long-running workflows that track orders or subscriptions or even individual customer activity. Temporals SDKs let you update workflow logic in tandem with evolving event API surfaces. This means your flows can reliably continue to deliver results.\nWith Temporal, reliability flows from resilience.\nDurable Execution\nWe call this resilience durability and the process of resilient workflows durable execution. Temporal allows event-driven systems to adopt durable execution so they automatically handle the issues that arise in event-driven deployment. With EDAs, the shopper can still browse and add items to their cart. With EDAs and Temporal, they can do all that and the customer will receive the email that got interrupted.\nAs for event evolution, a feature called version patching allows you to route your work based on the event protocol used when your workflow first went live. Versions, which are stored on the Temporal service, are persisted with each workflow. They help long-running work to choose the right code to run, for example using the original field structure, even while new work picks up the latest event changes that use updated activities. Admittedly, this approach only works if your system is designed to gradually integrate new event fields when your API details change.\nIf your architecture doesnt support simultaneous versioned event contracts, Temporal can still help. It lets you stop your in-flight workflows and replay them from the start without duplicating work thats already been done. These replayed workflows will handle your updated activity implementations using new event handling and payloads, so long as doing so doesnt violate Temporals principle of determinismthat is, given the same input, your workflow will always produce the same outcome, regardless of the original event field structure.\n\n  If your customer bought an air fryer, that air fryer will be billed through the payment processor, the customer will receive their emailed receipt, the cart will be cleared, the internal invoice generated, and a sparkling new air fryer will arrive a few days later at the correct address. All this happens even if one of your services is interrupted for a time.\n  Ultimately, Temporal balances the event-driven flexibility and scalability you value with the ease of use and reliability you need to stay productive. By simplifying complex workflows, Temporal allows your teams to focus on what really mattersshipping features quickly and confidently.\n\nConclusion: The Best of Both Worlds\nEvent-driven architectures are a great but challenging choice for building resilient, scalable systems. You may struggle when tracing messages and managing change. Temporal addresses these issues with an abstraction layer that reduces complexity and preserves the power and flexibility of the event-driven systems you rely on. With Temporal, your teams can build systems that are not only resilient and scalable but also developer-friendly and ready to evolve and maintain.\nIn a world where speed and reliability are critical, Temporal gives you the best of both worlds.",featureImage:{title:"li-zhang-ZvVydsVkyTI-unsplash",description:"li-zhang-ZvVydsVkyTI-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3WwtmBoVCX8MFqaV2ZTQUq/fc4fc75dd2e1d75a6a36d292827b8d80/li-zhang-ZvVydsVkyTI-unsplash.jpg"},publishDate:"2024-12-04T08:00-08:00",metaDescription:"Explore the challenges of event-driven systems and how loosely coupled architectures improve developer experience and troubleshooting.",metaTitle:"Event-Driven Systems & Loosely Coupled Architectures Explained",socialCard:{title:"li-zhang-ZvVydsVkyTI-unsplash",description:"li-zhang-ZvVydsVkyTI-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3WwtmBoVCX8MFqaV2ZTQUq/fc4fc75dd2e1d75a6a36d292827b8d80/li-zhang-ZvVydsVkyTI-unsplash.jpg"},tags:"Architecture",slug:"event-driven-systems-and-the-truth-about-loosely-coupled-architectures",contentType:"blogPost",entityId:"27gKFLI88EszmUMd37gC1d",authors:[{id:"7xjOTwCkACUXjgVqDQpWrA",name:"Erica Sadun",slug:"erica-sadun",jobTitle:"Senior Technical Content Engineer",photograph:{title:"erica-sadun",description:"erica-sadun",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5x6LNkYL0iG0Di4yNJLJi6/d99bb2ffc5f6c3b1947bd587fae3e090/erica-sadun.png"},company:"Temporal",contentType:"person"}],authorsString:"Erica Sadun",category:"Temporal Concepts",readingTime:9},{title:"How BPMN and legacy orchestration tools are holding you back",content:"For decades, many companies, especially in financial services, have relied on tools like BPMN and legacy orchestration frameworks to manage complex workflows. Even though these tools were once seen as the best option, using them now will only slow progress in industries that require more agility and innovation than ever.\nThe familiarity of these tools makes them the comfortable, go-to option, but this comfort will cost you, as these tools no longer meet the demands of todays consumer. This is where a forward-thinking solution becomes vital.\nIn this post, we'll discuss the downsides of legacy orchestration tooling, share examples from real companies, and give you advice to help your team improve development efficiency.\nThe Limitations of BPMN and Legacy Orchestration Tooling\nThere are a variety of limitations to BPMN and legacy orchestration frameworks. Two of the most common limitations are that the tools struggle to scale and slow down development.\nStruggling to Scale\nMany modern systems are too complex and large-scale for legacy tools to handle. As applications and workloads continue to grow, these tools become more of a bottleneck than an aid.\nLegacy tools often rely on visual representations that can become difficult to manage as workflows grow in complexity. Additionally, their architecture was not built to handle high throughput. This makes it challenging for them to adapt to your business needs that are ever growing and changing and hard to integrate with modern systems.\nFor example, think about managing growing transaction volumes or introducing new services to your system. Legacy tools struggle to handle these demands, which forces your engineering team to create workarounds that only waste time and potentially increase technical debt.\nSlow Development\nBesides these scalability issues, legacy tools introduce inefficiencies that are often overlooked. Many legacy orchestration tools require proprietary domain-specific languages (DSLs) or inflexible languages like XML, JSON, or YAML to define them. This makes it difficult for developers to implement changes, debug workflows, and maintain workflows.\nFor developers, this translates to spending more time doing tiring tasks like managing brittle, inflexible workflows and less time delivering features that add value. The result? Missed deadlines, frustrated teams, and systems that cannot keep pace with industry standards.\nWhat to Look for in a New Tool\nAs a company seeking to modernize, you need tools that can scale effortlessly, integrate easily, and take the tedious tasks off of your plate so that your developers can innovate. When evaluating a new tool, make sure that it can provide you with the following benefits:\nScalability\nThe right tool gives developers the ability to design and manage processes with clarity and control. Your solution should be a system that centers your code and enables your team to work directly in their preferred programming languages, eliminating rigid templates and opaque configurations.\nThis transparency not only simplifies debugging but also allows teams to tailor workflows to your specific business needs, resulting in faster and more informed decision-making.\nReliability\nReliability is at the foundation of any stable system. The right solution ensures that critical processes (in financial services, these include payments, transfers, and data reconciliation) recover seamlessly from interruptions.\nAdditionally, built-in capabilities like automated retries and state persistence keep workflows running smoothly, reducing the risk of costly downtime and protecting both your revenue and your reputation.\nA Code-First Approach\nDevelopers thrive when they can focus on innovation instead of repetitive, manual tasks. By abstracting away the complexities of error handling and orchestration, a modern tool reduces overhead and streamlines workflow creation. This efficiency allows engineering teams to deliver new features faster, while fostering a more rewarding development environment.\nBenefits like this are what Temporals product is based on. Our approach is one that allows our customers to overcome the problems they faced with legacy tools and achieve new heights.\nHow One Bank Achieved 8x Faster Project Delivery with Temporal\nANZ Bank, one of the largest financial institutions in Australia and New Zealand, faced significant challenges while building their app, ANZ Plus. The team spent over 18 months struggling with the complexities of re-architecting legacy systems using their existing legacy orchestration tool. It wasnt until they adopted Temporal that progress sped up dramatically.\nWithin six weeks, ANZ had their app in production  an 8x improvement in project delivery speed. Temporal allowed the team to simplify their workflows by:\n\n  Abstracting error-handling and state management, allowing developers to focus on business logic.\n  Integrating seamlessly with third-party APIs like Salesforce, preventing timeouts and ensuring smooth processes.\n  \n    Providing the resilience needed to deliver a reliable, customer-friendly experience.\n    Writing workflows in Golang, the same language as their application.\n  \n\nAs ANZ put it, Over the course of a single weekend, we achieved with Temporal what had eluded us for an entire year.\nIn Conclusion\nExpectations for reliability and scalability are only going to continue to increase, so organizations are being forced to choose an alternative path to adapt. Its critical to ensure that your path only leads you to more success and future stability.\nWith Temporal, engineering teams gain a modern, scalable platform that empowers developers, enhances reliability, and supports innovation. Its not just about managing workflows  its about creating a foundation for the future.\nIf youre ready to take your next step, start by downloading our white paper. It explores everything you need to know to reduce risk and increase reliability with a modern, code-first workflow tool.",featureImage:{title:"social-card-purple-waves",description:"social-card-purple-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2nvZtGhubV6XKQbGrFwUmH/c7c8144ccbc2a70cc9d1274206d26593/social-card-purple-waves.jpg"},publishDate:"2024-12-04T00:00-08:00",metaDescription:"Learn about the downsides of legacy orchestration tooling alongside examples from real companies and get advice to help your team improve your dev efficiency.",metaTitle:"How BPMN and legacy orchestration tools are holding you back",socialCard:{title:"How BPMN and Legacy Orchestration Tools are Holding You Back",description:"How BPMN and Legacy Orchestration Tools are Holding You Back",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1x6cYdW6IP6Yu59wjap6Zs/c4398ffe1b280271fb5537ebf0e55013/How_BPMN_and_Legacy_Orchestration_Tools_are_Holding_You_Back.jpg"},tags:"Architecture",slug:"bpmn-legacy-orchestration-tools-holding-you-back",contentType:"blogPost",entityId:"hY0VsTwbgoyBXf2zOYcVb",authors:[{id:"7GQtiP7y4Dmrje9sFWcVKl",name:"Lauren Bennett",slug:"lauren-bennett",jobTitle:"Content Marketing Manager",photograph:{title:"Lauren-Bennett-profile-photos",description:"Lauren-Bennett-profile-photos",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6jEqojw9RxBBjX5pytMzYf/4df0ef856a9efe4b7b52d5ebe7e83686/Lauren-Bennett-profile-photos.jpeg"},linkedInUrl:"https://www.linkedin.com/in/lauren-n-c-bennett/",contentType:"person"}],authorsString:"Lauren Bennett",category:"How-To",readingTime:5},{title:"Multi-agent Workflows: What are they? Use cases & example architecture",content:"Multi-agent workflows involve the orchestration and coordination of tasks or processes carried out by multiple autonomous agents. These agents can be software applications, artificial intelligence models, bots, or even human participants. Multi-agent workflows are often used in scenarios where tasks are distributed, asynchronous, or require collaboration among diverse systems or entities.\nMulti-agent workflows also share some similar characteristics, even though the use cases may vary widely (conversational AI, data pipelines, autonomous vehicles, similarity search and recommendation engines, etc could all be a multi-agent workflow). Those characteristics are:\n\n  Decentralization: Tasks are distributed among agents that operate independently. No single agent has complete control; instead, a coordinating system ensures tasks are executed as intended.\n  Coordination and Communication: Agents need to exchange data or signals to complete their individual tasks. Orchestration frameworks often act as the \"manager,\" ensuring proper communication and timing.\n  Autonomy: Each agent can perform its tasks independently based on its programming or training. Agents can make decisions locally (e.g., retrying a failed task or escalating an issue).\n  Interdependency: Tasks performed by one agent often depend on the outputs of another, requiring seamless handoffs and state management.\n  State Management: Maintaining workflow state across agents is crucial, especially in long-running workflows.\n\nTemporal is well-suited to support multi-agent workflows because it handles the orchestration, state management, and coordination across different agents (AI or otherwise).\nIn addition to this, Temporal doesnt need you to build specific code for each agentic framework.\nAs Anton Tsitou, CTO at Spiral Scout, noted:\n\n  \"Most 'agentic' frameworks require you to build code for the framework specifically, but Temporal doesn't. It already provides the service mesh, so you dont have to reinvent it.\"\n\nThis distinction not only streamlines implementation but also reinforces Temporals role as a general-purpose backbone for agentic systems.\nHeres how Temporal can specifically support such a use case:\n1. Orchestrating Multi-Agent Interactions\nThink of Temporal as the \"conductor,\" managing interactions among multiple agents by setting up workflows where agents communicate and pass information as tasks are completed.\nIn a multi-agent workflow, each agent may handle a specific part of a task  say, one agent for data processing, another for analyzing results, and a third for final reporting. Temporal ensures these tasks happen in the correct order and within defined parameters.\n2. Stateful Coordination Across Agents\nAgents in a multi-agent system may need to maintain context or state throughout a workflow, especially when they need to reference prior steps, adapt based on changing information, or retry parts of the workflow.\nTemporals state management capabilities allow it to store and retrieve data across these interactions, ensuring each agent has the correct context at every stage. Temporal can also time out, retry, or roll back actions if an agent fails, giving resilience to the overall system.\nI recently spoke with the Twilio AI Assistants team to hear about their learnings on multi-agent workflows. One of the biggest challenges theyve faced is enabling shared user context across multiple agents, channels, and conversations  a crucial element in delivering seamless, personalized experiences.\n\n  As part of addressing this challenge, Twilio has invested in our Customer Memory capability which is powered by Twilio Segment, shared the team. Customer Memory enables each agent to access the businesses context on any user into every conversation and to store learnings from each interaction back to the shared context so that they can improve future interactions.\n\nThis ability to maintain shared context is essential in complex workflows, ensuring that agents can pick up where the previous one left off, making the system more effective and reliable for the user.\n3. Reliable Async Communication\nMulti-agent systems often require asynchronous communication since agents can take variable time to complete tasks or may have dependencies on each other. Temporals ability to manage async and sync processes smoothly means that agents can be orchestrated effectively regardless of individual response times.\nTemporals timers, retries, and error handling ensures that if one agent fails or takes too long, the entire workflow doesnt collapse. Instead, it can adapt or notify other agents as needed.\n4. Parallel Processing for High Efficiency\nFor multi-agent systems that involve parallel tasks, Temporals parallelism and concurrency control enable multiple agents to work simultaneously without blocking each other. This is ideal when agents operate independently on sub-tasks that later need to converge.\nFor example, in a recommendation system, separate agents might handle user data processing, item analysis, and scoring. Temporal can coordinate the simultaneous execution of these tasks and merge results efficiently.\n5. Long-Running Workflows with Multi-Step Processes\nIn use cases where agents contribute to a long-running process  like generating and refining a report over several steps  Temporals ability to maintain workflows over hours or even days is invaluable. Each agent can do its part, and Temporal keeps the process stable over time.\nTemporals workflows can sleep, wait for new data, or pause until a signal (such as an update from an agent) arrives, allowing for workflows that evolve as agents contribute data at different times.\n6. Event-Driven Triggers and Signals\nMulti-agent systems often operate in response to events (like incoming data or status updates from other agents). Temporal supports signals and queries that let agents or external triggers start, modify, or stop workflows in real time.\nThis approach not only enables flexible workflows, but it also integrates seamlessly into a unified hub for activities within a product. This means that anything that Temporal interacts with inside the system can be used as part of the agentic workflow, without the need to build separate agentic functions.\nFor example, a monitoring agent could signal other agents to update their analysis if new data arrives or a condition changes, ensuring that all activities across the system can be orchestrated as part of a single, cohesive workflow.\nPractical Example: A Multi-Agent Workflow for Customer Support\nImagine a customer support system where Temporal coordinates multiple agents:\n\n  Agent A: Analyzes incoming customer requests and classifies them by their level of urgency.\n  Agent B: Looks up customer history and finds relevant data.\n  Agent C: Routes the request to the appropriate support team or initiates an automated response.\n\n\n  \n\nTemporal would:\n\n  Trigger Agent A upon receiving a request.\n  Wait for Agent As result, then pass the data to Agent B.\n  Manage async calls to Agent C for routing and initiate follow-up workflows based on responses.\n\nTemporals orchestration here allows each agent to function independently yet stay coordinated, enabling seamless and efficient customer support automation.\nIn summary\nTemporals orchestration, durability, and ability to manage complex stateful and stateless interactions make it a perfect foundation for multi-agent workflows in AI applications. Temporal ensures that these interactions are reliable, efficient, and resilient, even as workflows grow in complexity or scale.\nLearn more about Temporal and get started with a free trial + $1,000 in credits today.",featureImage:{title:"social-card-purple",description:"social-card-purple",url:"https://images.ctfassets.net/0uuz8ydxyd9p/UbL8tEOAIBjMrI6OCSeNN/62aecca8ce16e11e288c1fd7ef4e346d/social-card-purple.jpg"},publishDate:"2024-12-03T00:00-08:00",metaDescription:"Learn how Temporal powers multi-agent workflows with orchestration, state management, and real-time communication, without custom code.",metaTitle:"Multi-agent Workflows: Use cases & architecture with Temporal",socialCard:{title:"Multi-Agent Workflows social card",description:"Multi-Agent Workflows social card",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3JfmJ3g7xOSIPkTz8zpumW/57426c26779cd6df4cacfff20deb9b4c/Multi-Agent_Workflows_social_card.jpg"},tags:"Architecture,AI/ML,Code Samples",slug:"what-are-multi-agent-workflows",contentType:"blogPost",entityId:"640HlTIhiuah8SBqFEiAtT",authors:[{id:"780p8MZSlKh9AuMzW5FrA0",name:"Clair Byrd",slug:"clair-byrd",jobTitle:"CMO",photograph:{title:"Clair Byrd",description:"Clair Byrd",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2ENA9j4df6EfXCLgoWmt46/bb029b33e3f92fb2a7973348c8ccce88/861A2507.jpg"},biography:"Clair Byrd is the Chief Marketing Officer at Temporal, the company defining durable execution in software engineering. Before joining Temporal, Clair held senior marketing and leadership roles at Twilio, InVision, and Sauce Labs, and co-founded the front end builder platform Mason. Her work centers on elevating developer experience, connecting open-source ecosystems, and building brands that inspire technical creativity and trust. Clair is passionate about storytelling that helps engineers build faster, smarter, and with lasting impact.",company:"Temporal",contentType:"person"}],authorsString:"Clair Byrd",category:"How-To",readingTime:6},{title:"How ZoomInfo cluster powers real-time marketing with Temporal Cloud",content:"Frank Shaw, Senior Principal Engineer at ZoomInfo, recently shared how adopting Temporal transformed their data processing capabilities, enabling them to handle hundreds of millions of operations monthly while dramatically reducing development time.\nShaw detailed how Temporal's workflow orchestration capabilities helped them evolve from a challenging homegrown solution to a scalable, maintainable system that powers critical business features.\nThe Challenge: Dynamic Audience Management at Scale\nZoomInfos account-based marketing product serves dynamic audiences based on continuously updating data. We have 90 million companies and about 300 million contacts that were constantly gathering new data for and updating, Shaw explained. The differentiator for their product is the dynamic nature of these audiences  as new companies or contacts enter their database matching audience criteria, they're automatically added, while others may be removed if they no longer fit the parameters.\nThe team faced significant challenges with their original homegrown solution. We had built a homegrown solution where this whole process was kind of running in background threads, and then we had another kind of homegrown job scheduler, Shaw recalled. They encountered throughput limitations and struggled with batch processing. We were trying to run all of our audiences in one batch at one point, and it was really hard to figure out how to either spread that out throughout the day or really solve those throttling and throughput issues.\nWhile evaluating solutions including AWS Step Functions and GCP Workflows, Shaws team discovered Temporal. The platforms cloud-agnostic nature particularly appealed to them as they were amid a cloud migration. Selecting a tool that solves similar problems as these cloud native solutions but in a cloud agnostic manner was really helpful, Shaw noted.\nWhat set Temporal apart was its workflow-as-code approach. Shaw pointed out that other tools force developers to define workflow logic through complex configuration files. With Temporal, they define workflows using the same programming language they use for other parts of the application. Seeing how Temporal designed workflow primitives as code, to me it was a no-brainer. It was a much better developer experience for all of our developers, Shaw explained.\nThe built-in visibility tools also played a crucial role in their decision. Out of the box, you get immediate observability into what your workflows are doing and what their current state is. If they fail at a specific step, you see the failure message directly in the workflow, so you can map that to the logs.\nTransformational Results\nThe impact was immediate and substantial. Before Temporal, the team faced weekly issues requiring extensive debugging. When we were running on our old infrastructure, I would say probably once a week we had issues where a developer would have to spend almost an entire day debugging, going through logs, figuring out what went wrong, Shaw shared. After implementing Temporal, these issues virtually disappeared. Until we add any new audience types, this code is almost in maintenance mode now. It runs on itself.\n\n  With Temporal, we were able to complete all the necessary migrations  four or five audience types in one two-week sprint.\n\nThe development process also became significantly more efficient. What previously took weeks could now be completed in two days. Shaw recalled a striking example: We introduced a new audience type and it required us to speed up the migration of all the other audiences. With Temporal, we were able to complete all the necessary migrations  four or five audience types in one two-week sprint.\n\n  Based on what were using now, were actually going to be spending about a thousand dollars less a month moving to Temporal Cloud.\n\nFollowing the success of this effort, the team saw an opportunity to streamline operations by moving from a self-hosted deployment to Temporal Cloud. The migration decision was driven by both operational efficiency and cost considerations. Based on what were using now, were actually going to be spending about a thousand dollars less a month moving to Temporal Cloud, Shaw explained. Having to tune that self-hosted cluster to match the usage and not over-provision, its really easy to over-provision. And then we would probably be paying more to host our cluster than we are paying to use Temporal Cloud.\nScaling New Heights with Long-Running Workflows\nThe robustness of Temporals long-running workflows proved particularly valuable when launching their new Copilot product with Account AI feature. We launched a new product earlier this year called Copilot, and as part of that was a feature called Account AI. We used Temporal to build generative AIenabled account summaries for our customers, Shaw explained. The system processes data from multiple sources including email, CRM calendar events, and Zoom meeting recordings.\nThe scalability has exceeded expectations. Initially, we were going to launch this in a soft beta for the first six months to a year to about 200 customers, Shaw said. Were about six months in, and we already have over 300 customers just because the product has worked. These pipelines have been able to handle the amount of data that were throwing at them.\nThe numbers tell a compelling story. In this new product thats only been out for about six months, were already running 200 million actions per month in Temporal Cloud, Shaw revealed. We had to do nothing to the cluster. Weve worked with our support team to adjust the rate limits and everything within our namespaces, but other than that it's just worked for us.\nZoomInfos Advice to Others\nFor organizations considering Temporal, Shaw offers straightforward advice: If you're thinking about it, try it. Just take a small project that you have and just try to run it in Temporal. He emphasizes not to think of Temporal as just a workflow system. Ive even talked to developers at my company where they ask me, Can I use Temporal here? And Im like, Of course you can. And they're like, I need responses in less than a second.\nShaw points to real examples of Temporals versatility: I pointed them to a place in the application where you click a button, we run a Temporal workflow that fetches data from Google Bigtable, processes all that data together, returns a count of the unique accounts, and it happens in 300 milliseconds. Anything you want to run, you can run it in Temporal if you really want that process to be durable and stable.\nThe impact has extended beyond technical capabilities. The second I see any sort of data pipeline or something, I start to think about how we would build this in Temporal, Shaw notes. This shift in mindset has enabled his team to focus on innovation rather than infrastructure maintenance.\nShaw particularly appreciates Temporals developer experience: With the local development tools that Temporal provides you, you dont even have to set up a cloud instance, you don't have to set up a cluster. You can set up and run a Temporal workflow within a day.\n\nThis interview was conducted at Replay 2024, Temporals annual conference, where industry leaders gather to share insights and advancements in workflow orchestration.\nZoomInfos experience is just one example of how Temporal Cloud can transform workflow orchestration. For teams interested in exploring Temporals full potential, $1000 in Temporal Cloud credits are available for a limited time.",featureImage:{title:"social-card-purple",description:"social-card-purple",url:"https://images.ctfassets.net/0uuz8ydxyd9p/UbL8tEOAIBjMrI6OCSeNN/62aecca8ce16e11e288c1fd7ef4e346d/social-card-purple.jpg"},publishDate:"2024-12-03T00:00-08:00",metaDescription:"Learn how ZoomInfo used Temporal Cloud to scale dynamic audience management, speed up development, and process 200M+ monthly actions.",metaTitle:"How ZoomInfo Built a Scalable Cluster with Temporal Cloud",socialCard:{title:"Blog (4)",description:"Blog (4)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/21YyFnqhosymgDg8YfK7Pv/f4682bbb3cd34e472ba1feb62eb1c3c6/Blog__4_.png"},tags:"Scaling,Cloud",slug:"zoominfo-drives-real-time-marketing-precision-with-temporal-cloud-cutting",contentType:"blogPost",entityId:"1JuLTfcf3RkIov3ZLBuoO1",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"Temporal Concepts",readingTime:7},{title:"Join us for live hands-on Temporal training at Replay 2025",content:"This year, Replay 2025 is heading to London! The Developer Education Team is excited to offer workshops this year in Go, Java, and .NET. These hands-on workshops are designed to deepen your understanding of Temporal and equip you with practical skills to build resilient applications and tackle real-world challenges.\nWhether youre just getting started with Temporal or learning how to manage failures effectively, our workshops will combine strategy with hands-on practice to level up your skills.\nTemporal 102: Exploring Durable Execution Workshop\nThis workshop is for developers who have completed our foundational Temporal 101 training course. This workshop will be based off of our Temporal 102: Exploring Durable Execution course.\nIn this workshop, you will acquire skills necessary to use Temporal throughout the development lifecycle by exploring how to test, debug, and deploy applications. You'll encounter several common problems faced by Temporal developers, understand why they occur, and how to identify, solve, and avoid them.\nYou'll explore key concepts and best practices, how to develop and run tests for your Temporal applications, how to interpret the Event History, and how to debug common problems. Most importantly, you'll gain a deeper understanding of how Temporal works and how to use it effectively.\nCrafting an Error Handling Strategy Workshop\nThis workshop is for developers who have completed our foundational Temporal 101 and Temporal 102 training courses, and is based off of our Crafting an Error Handling Strategy course.\nIn this workshop, you will learn how to design and implement effective error handling strategies that map your business logic to the Temporal platform. You'll explore the nature of different types of failures and investigate the support that Temporal provides for addressing them. You'll also learn essential design patterns, such as idempotence, sagas, and heartbeating. These concepts will help you to ensure the correctness and responsiveness of your application.\nGet Your Tickets!\nBoth workshops will run from 9:00 AM until 5:00 PM, with an hour-long break for lunch (provided) and short breaks throughout the day.\nSpace is limited, so dont delay. Get your tickets today! We hope to see you there!",featureImage:{title:"Careers Page Hero Carousel 16",description:"Careers Page Hero Carousel 16",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5F22Iu0yzYmKX2Pss43J3J/7cfdd8ee73d43882cfa1c717d7e9da87/Careers_Page_Hero_Carousel_16.jpg"},publishDate:"2024-12-02T08:00-08:00",metaDescription:"Replay 2025 is coming to London, England! The Developer Education Team is excited to offer workshops this year in Go, Java, and .NET.",metaTitle:"Join Us for Live Hands-On Temporal Training at Replay",socialCard:{title:"Careers Page Hero Carousel 16",description:"Careers Page Hero Carousel 16",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5F22Iu0yzYmKX2Pss43J3J/7cfdd8ee73d43882cfa1c717d7e9da87/Careers_Page_Hero_Carousel_16.jpg"},tags:"Replay",slug:"join-us-for-live-hands-on-temporal-training-at-replay-2025",contentType:"blogPost",entityId:"7wrzZpHgWaY4qaZJPb3Hcd",authors:[{id:"gz6Asa7ycvY1HZz9vcJk0",name:"Angela Zhou",slug:"angela-zhou",jobTitle:"Senior Technical Curriculum Developer",photograph:{title:"headshot-angela-zhou",description:"headshot-angela-zhou",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3FgLhuMJuEASXJmzoNevWN/c115937f066329eb77cd75caa831bfbe/headshot-angela-zhou.png"},contentType:"person"}],authorsString:"Angela Zhou",category:"Community",readingTime:2},{title:"Juleps vision for the future of AI Workflows",content:"Artificial intelligence is becoming increasingly essential in the consumer world. While much of the conversation about AI centers on chatbots and memory-based systems, Julep AI is breaking new ground.\nJulep is an API created to build multi-step workflows, as co-founder Ishita Jindal puts it. Julep is a platform that enables AI agents to remember past interactions and execute complex tasks. The product serves as an infrastructure layer between large language models (LLMs) and your software, providing built-in support for long-term memory and multi-step process management.\nJuleps mission is to fill the existing gaps in AI and foster collaboration between humans and AI for advanced applications.\nBeyond Chatbots: Juleps mission to push the boundaries of AI\nJuleps vision goes beyond the conventional uses of AI. The team wants to enable collaboration between humans and AI for tasks that require deep thinking and long-term involvement.\n\"Think about a scenario like using AI in drug discovery, to author a novel, or perform end-to-end research,\" says Diwank Singh Tomer, co-founder of Julep. \"These are the sorts of complex and dynamic workflows that Julep wants to power.\"\nRather than building systems that repeat simple tasks or interact based on short-term memory, Julep is designing intelligent agents that understand context over time and across multiple steps. This creates value in enterprise settings, where these tasks are often too large or complex for traditional tooling.\nCreating an innovative engineering culture\nJuleps engineering culture reflects their forward-thinking approach. Theyve embraced a mono-repository culture, open-source development, and specification-driven processes because they understand that the best way to build systems is by keeping things simple and focusing on velocity. This is why Julep believes in continuous refactoring and a pragmatic approach to problem-solving.\nHow Julep helps their customers\nJulep is already improving industries by enabling businesses to create intelligent, AI-powered systems that solve the problems theyre facing. With the 8-factor agent methodology, Julep helps customers build integral workflows like the following.\nVideo Editing Workflows\n\n  Content creation companies use Juleps AI agents to improve and streamline video editing processes. Through multi-step workflows, the platform automates tasks like video segmentation, logo overlaying, transcription, and the addition of subtitles.\n  The platform handles these tasks as distinct steps, each managed by a dedicated prompt that defines the task and connects tools in a modular, adaptable way. Juleps flexibility allows clients to use multiple model providers, ensuring that different AI models can be swapped in based on specific editing needs.\n\nPersonalized Content Creation\nA sports magazine uses Julep to personalize content for millions of subscribers. Using AI-driven workflows, Julep collects user interaction data and continuously updates user profiles to tailor content recommendations.\nThis process involves workflows that span several stages, starting from data collection (using specific prompts to query interaction data), to AI-powered content selection, and ultimately delivering personalized articles or newsletters to each user.\nWith seamless tool integration, the platform scales as the number of users grows, ensuring that the right content reaches each user at the right time. The platform continuously updates each user's profile based on their interactions, ensuring the right content reaches them at the right time.\nZero-Knowledge Proof for Identity Verification\nJuleps AI agents are at the core of a secure identity verification process for applications that handle personally identifiable information (PII). Julep uses zero-knowledge proofs to verify user identity without exposing sensitive data.\nThe platform uses AI to drive workflows that securely guide users through the verification process, from uploading documents to generating cryptographic proofs, and these workflows are designed using specific prompts that ensure data privacy.\nScaling AI to manage thousands of tasks across complex workflows\nHowever, as with any ambitious project like Juleps, scaling AI at this level comes with its challenges.\nFor Julep, at scale means managing workflows that handle tens of thousands of tasks, running across different systems, all while ensuring that every task is retried until completion without sacrificing performance. Whether its automating video editing or personalizing content for millions of users, Julep needs to provide reliability even as their customers' needs grow in both size and complexity  this is no easy feat.\nThis is where Temporal comes in. Temporals expressiveness allows Julep to manage these complex workflows with fewer lines of code, making it easier to debug and maintain.\nTemporals ability to automatically retry tasks and handle multi-step workflows ensures reliable execution of long-running tasks. By using YAML, Julep can easily customize and define workflows, whether internal or customer-facing, with workflows that can stretch to 500+ lines of code still staying well-structured and reliable.\nAs workflows scale to tens of thousands of tasks, Temporals design guarantees that tasks are retried until completion without performance loss. Additionally, Temporals live, interactive UI enhances observability, allowing Julep to debug and provide transparency to customers, while its deterministic workflow design and Python integration ensure system reliability and scalability.\nWhere Julep is headed\nJulep continues to innovate. Their recent launch on Product Hunt marks an exciting milestone in their journey to redefine AI-powered workflow automation.\nTheir next phase of development promises to further push the boundaries of what AI can accomplish, helping businesses scale their operations and improve efficiency in ways that were once unimaginable.\nTo see Julep in action, head over to their GitHub repository, follow their journey on X and LinkedIn, and get involved with their open-source projects.",featureImage:{title:"hazel-z-45AHiklPJH4-unsplash",description:"hazel-z-45AHiklPJH4-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Potp6G9LHoZ780AhLw3vs/861da43ba6e469417a7a9084b708e71f/hazel-z-45AHiklPJH4-unsplash.jpg"},publishDate:"2024-11-22T00:00-08:00",metaDescription:"Julep AI is changing AI-powered workflows, helping businesses automate complex tasks like video editing and content personalization at scale with reliability and scalability, powered by Temporal.",metaTitle:"Juleps vision for the future of AI Workflows",socialCard:{title:"Julep's Vision for the Future of AI-Powered Workflows",description:"Julep's Vision for the Future of AI-Powered Workflows",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5qrrnmUpylQcfPEGMwEUre/5a75bd6d244651c10aa9dc08d1ece192/Julep-s_Vision_for_the_Future_of_AI-Powered_Workflows.jpg"},tags:"AI/ML",slug:"julep-ai-future-ai-workflows",contentType:"blogPost",entityId:"4l7woklmHGzQzXNrtXGUHO",authors:[{id:"780p8MZSlKh9AuMzW5FrA0",name:"Clair Byrd",slug:"clair-byrd",jobTitle:"CMO",photograph:{title:"Clair Byrd",description:"Clair Byrd",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2ENA9j4df6EfXCLgoWmt46/bb029b33e3f92fb2a7973348c8ccce88/861A2507.jpg"},biography:"Clair Byrd is the Chief Marketing Officer at Temporal, the company defining durable execution in software engineering. Before joining Temporal, Clair held senior marketing and leadership roles at Twilio, InVision, and Sauce Labs, and co-founded the front end builder platform Mason. Her work centers on elevating developer experience, connecting open-source ecosystems, and building brands that inspire technical creativity and trust. Clair is passionate about storytelling that helps engineers build faster, smarter, and with lasting impact.",company:"Temporal",contentType:"person"}],authorsString:"Clair Byrd",category:"Community",readingTime:5},{title:"Temporal use case roundup: Generative AI",content:"Generative AI is transforming industries by taking on the superhuman scale tasks, like processing massive data sets, drawing previously undrawable conclusions through deep learning, and delivering highly personalized automated experiences to make applications better. Managing the complexity of these long-running, stateful workflows is where Temporal truly shines.\nThe crew at Docker recently featured us among the top solutions for agentic orchestration in their new Generative AI Catalog, a curated list of open-source projects and Docker images forming the backbone of modern generative AI apps and agentic workflows.\nOver the past few months, Ive been digging through the community to find and chronicle all the cool ways developers are already using Temporal to power Generative AI use cases and agentic workflows. Check out these examples where Temporal powers AI applications, all live and in production today:\n1. Video Content Processing and Translation\nIf youre working with video pipelines, Temporal is a game-changer for reliability, speed, and efficiency in parallel processing. Temporal coordinates complex workflows for content ingestion, AI-powered translation, and subtitles, creating a seamless video editing experience that scales. Managing real-time video becomes easier, with consistent, high-quality output.\n2. Conversational AI and Call Center Transcription\nConversational AI is everywhere, especially in customer support. Temporal helps you build reliable workflows for transcription, sentiment analysis, and insights extraction. For instance, one provider uses Temporals Python SDK and workflows written in several programming languages to automate thousands of call transcriptions daily, increasing both speed and accuracy while minimizing downtime.\n3. Synthetic Data Generation and Processing\nNeed high-quality data while keeping privacy in check? Temporal orchestrates synthetic data generation, anonymization, and processing, making it easier to build reliable datasets. Get the throughput you need, with the accuracy you can rely on, by adding Temporal to complex processes.\n4. AI Platform for Predictive Analytics and Customer Insights\nTemporal supports AI platforms that deliver predictive insights by orchestrating data collection, model training, and prediction workflows. One example is a company using Temporal to analyze billions of data signals, helping teams predict customer trends and target their next best opportunities with confidence.\n5. Market Intelligence and Cryptocurrency Data Enrichment\nAI-driven market intelligence platforms like Messari transform vast data streams into actionable insights for users. Temporals reliable data ingestion and enrichment workflows ensure smooth, scalable processes that handle large data volumes with ease.\n6. AI-Powered HR Workflows\nOne HR platform uses Temporal to power AI-driven workflows for onboarding, benefits management, and leave processing. Temporal coordinates approvals, validations, and employee notifications, streamlining the HR experience and giving employees the support they need when they need it.\n7. AI Infrastructure and Resource Optimization\nFor platforms that manage AI resources like GPUs, Temporal orchestrates everything from setup to monitoring and teardown. It maximizes resource utilization, helps control costs, and keeps the infrastructure in great shapeperfect for teams that need efficient, scalable resources for high-performance AI.\n8. State Tracking in Generative AI Workflows\nTemporals durability and state management make it a natural fit for tracking conversation states and managing session timeouts. You benefit from smoother user interactions in generative AI applicationseven with complex querieswhile keeping latency low.\n9. Research and Applied AI Workflow Orchestration\nTemporal supports teams working on AI research and applied production. Research teams benefit from Temporals cloud-based approach, which allows them to quickly iterate and scale up their experiments. Applied AI teams love Temporals reliability, which enables them to deploy their models to production with confidence.\nOne team is even exploring it for workflows like image uploads and safety scans. Temporals payload encoding and durable execution help ensure that sensitive content meets compliance standards every time.\nBenefits of Temporal for Generative AI\n\n  Reliable Performance: Run your workflows smoothly with built-in retries, rollbacks, and flexible error handling.\n  Cost Savings: Reduce LLM processing costs by ensuring only essential data gets processed.\n  Faster Development: Build, deploy, and innovate faster with Temporals easy workflow orchestration.\n\nWhy Temporal?\nStreamline your operations from start to finish with Temporal, the go-to solution for orchestrating complex, stateful workflows that need to run reliably in generative AI applications. With features like automated state management, high resilience, and scalability, Temporal equips teams to manage every stage of their AI processes smoothly and efficiently.\nTemporal addresses common challenges in generative AI, including:\n\n  Sync/Async Process Handling: Temporal coordinates synchronous and asynchronous tasks efficiently, reducing latency.\n  State Tracking: Ideal for applications where tracking state is critical, such as chatbots or conversational AI.\n  Scalability: Built to scale flexibly, Temporal is suited for high-demand AI applications.\n\nWith Temporal, your teams can launch AI-driven products that are efficient, reliable, and ready to grow with your vision and strategic plans.\nAre you working on an agentic workflow, an AI app, or another Temporal-powered AI solution? Wed love to hear about it! Feel free to email me directly at clair.byrd(at)temporal.io.",featureImage:{title:"social-card-newsletter",description:"social-card-newsletter",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3k9UpZsjFZDXElTHI4BCLz/3a72dd7f1c60ada1f5bd28f46f684810/social-card-newsletter.jpg"},publishDate:"2024-11-19T00:00-08:00",metaDescription:"See how Temporal boosts generative AI applications across industries, from video processing to conversational AI, by orchestrating complex, reliable workflows.",metaTitle:"9 Real-World Generative AI Use Cases Powered by Temporal",socialCard:{title:"Temporal Use Case Roundup: Generative AI",description:"Temporal Use Case Roundup: Generative AI",url:"https://images.ctfassets.net/0uuz8ydxyd9p/20QAPLwWIEQ0v1MDA20Ih6/f9d1c08b02f31bd19723bb9c3f9720e6/Blog__3_.png"},tags:"AI/ML",slug:"temporal-use-case-roundup-generative-ai",contentType:"blogPost",entityId:"2xwzAX7oIxCHfp6v0XT5Tr",authors:[{id:"780p8MZSlKh9AuMzW5FrA0",name:"Clair Byrd",slug:"clair-byrd",jobTitle:"CMO",photograph:{title:"Clair Byrd",description:"Clair Byrd",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2ENA9j4df6EfXCLgoWmt46/bb029b33e3f92fb2a7973348c8ccce88/861A2507.jpg"},biography:"Clair Byrd is the Chief Marketing Officer at Temporal, the company defining durable execution in software engineering. Before joining Temporal, Clair held senior marketing and leadership roles at Twilio, InVision, and Sauce Labs, and co-founded the front end builder platform Mason. Her work centers on elevating developer experience, connecting open-source ecosystems, and building brands that inspire technical creativity and trust. Clair is passionate about storytelling that helps engineers build faster, smarter, and with lasting impact.",company:"Temporal",contentType:"person"}],authorsString:"Clair Byrd",category:"Temporal Voices",readingTime:5},{title:"Top engineering predictions for financial services in 2025",content:"Over the years IT engineering departments have had to deal with many paradigm shifts. Sometimes older ideas come back into fashion, and sometimes technology enables new ways of doing things.\nIn my role as a Solutions Architect, I work with engineering teams across various enterprises, including many of the larger European banks. As 2024 comes to a close, let's explore some of the major trends I've observed in engineering in financial services, and predictions for how these trends will evolve in 2025.\nToday, change is the only constant in FinServ\nBefore diving into trends and predictions, it's important to understand the context. The banking industry has been facing significant change in recent years for various reasons:\n\n  Regulations, already extensive, have evolved further following the banking crisis of 2008 and the turmoil in 2023 to ensure the stability of the banking sector.\n  The impact of the Covid-19 pandemic continues to impact us, driving expectations of doing more online.\n  New competition continues to arise, especially from startups that take a fully digital approach and move faster than traditional brick-and-mortar banks.\n  The rise of technology companies has changed how businesses implement and operate enterprise scale solutions. (Will banks become tech companies? - A debate that rages.)\n\nUltimately, banks must be more agile because the financial industry is evolving at a speed never before seen. To stay competitive and profitable banks need to deliver new capabilities ahead of the competition, while maintaining the strict rules for regulation, security and scale. This means taking a close look at the structure of engineering organizations as well as the technology and architectures used to deliver services.\nPrediction 1: The shift to agile will continue\nNew technologies like microservices architectures, and PaaS and SaaS services, combined with the rise of agile software delivery methodology have driven change in engineering over the past two decades. Modern engineering organizations tend to have small teams (for example, the Amazon two pizza team) that seek to provide deliverables every sprint (typically two weeks), incrementally adding value with each delivery.\nHowever, many banks are still trying to adapt to this new methodology. Historically, financial services engineering departments have been organized to deliver new projects and functionality with a hierarchical waterfall approach. This approach results in long analysis and extensive documentation, and it can take months or years to deliver projects. Much of the focus is on documentation.\nChanges to processes which have been built up over decades at banks cannot be altered overnight. In 2025, I predict banks will continue to shift their organization to align with modern practices, gradually changing their processes to fit in with agile development and gain the benefits of microservices architecture.\nPrediction 2: Migration to microservices and event-driven architecture will be a top priority\nBanks, in particular, have relied on the mainframe at the core of their business to this day. Often services have been extended/created with applications using client/server or a tiered architecture - frequently referred to as monolithic applications. However, using this legacy architecture is not conducive to the new agile delivery methods. Typically the deployment frequency is very low, change risk is high, scaling is non-trivial, and production operations become complex.\nI've observed various levels of maturity in the adoption of microservices architectures. New products and services use microservices. Older services remain on legacy products with plans to modernize frequently getting stalled by processes which have been built up over many years. However, as more teams want to benefit from modern architecture and methodologies, we will see these legacy products move to microservices in 2025 and beyond.\nPrediction 3: Platform teams will be critical for modernization success\nA well-written microservice will follow the 12-factor principles and address a specific domain problem, which ultimately results in many microservices being used to deliver a business process. Providing a run-time environment that ensures availability, scalability, security, and the communications needed for thousands of microservice instances is a non-trivial task.\nPlatform teams have evolved as a critical part of engineering departments at banks to handle the increased complexity of the engineering environment. They must create a stable, easy-to-use, secure microservices environment to let engineers deliver application-ready services. Often using DevSecOps concepts to automate the management of these complex platforms.\nPlatform teams will be critical to the success of banks in 2025, as they expand the use of microservices. Platform teams must ensure they treat the platform as a product with a full lifecycle. They will need to add new capabilities to the platform in line with market trends, developer needs, architecture changes, improved security, and new technologies. Older functionality may be replaced by more elegant and customer-friendly solutions to make developers more successful.\nPrediction 4: AI usage will expand\nAny view on recent trends in technology has to include a reference to Artificial Intelligence (AI) and its subset, Machine Learning (ML), which are permeating everyday life. AI technology is still fairly nascent, but is of great interest to financial institutions, particularly to improve customer experience, security and efficiency. For example it can be used in:\n\n  Fraud detection - analyzing spending patterns and identifying unusual transactions\n  Credit scoring - analyzing customer data to provide more informed credit decisions\n  Customer support - AI powered chatbots and virtual assistants\n  Investment strategies - studying investment opportunities\n\nAI developers must consider two sets of critical processes to deliver value to the business. Firstly, they have to consider how to build up Large Language Models (LLMs) and to train the AI applications in using the data and keeping them current. Then there is the consideration of using the data to deliver business value, this often means developing processes that chain together multiple AI applications or look to enhance the AI answers with data from other sources - Retrieval-Augmented Generation (RAG).\nAI and ML developers often bump into rough edges of system orchestration as they look to build these processes. Ideally an AI developer wants to focus on the models, training and data flows. They dont want to have to think too much about failure scenarios, consistency and scheduling.\nAI is clearly a major trend happening in all industries, and as it matures we will see expanded usage in Financial Services in 2025.\nPrediction 5: Workflow-driven microservices will become a more popular architecture\nMicroservices enable business agility and ease of scaling, but as microservice usage increases, so does complexity. Platform teams help manage that complexity. However, engineers still encounter issues. As banks adopt microservices, they are more frequently running into the various challenges.\n\n  Transactional integrity may be at risk. In monolithic systems we had the option of using Global or XA Transactions, which would allow us to have a high degree of confidence that a commit has occurred to two or more persistent resources. In a microservices world, the services should own only the data they use, and are generally accessed using web protocols. This means two-phase commit is not an option. Developers must then implement rollback or compensating transactions (often using the Saga pattern). Having the certainty of completing transactions or successfully compensating is critical to Financial Services.\n  Its difficult to understand and manage business processes. Business processes frequently involve multiple services being chained together to ensure client requests are fulfilled. There are several strategies to accomplish this, each with their own drawbacks:\n    \n      Microservice-to-microservice calls. Microservices can propagate context/control between microservices. However, this ends up with business logic scattered in many locations. Inadvertently, the microservices can have dependencies between them, leading to fragile systems where updates are risky to implement and end-to-end testing is difficult.\n      Central choreography service. Some teams introduce central services to coordinate all the microservices, but that central service can become a performance bottleneck or introduce functional limits on the business logic that can be defined.\n      Event-driven architectures. Some teams have elected to make the data key to managing the process and are using Event Driven Architectures, where every event gets put onto a queue and those interested consume the event to perform processing. Tracking the status of any given business then means understanding many different services and querying the data to observe progress. It is very hard to follow, and full end-to-end testing becomes labor-intensive.\n    \n  \n  Business processing is mixed with system error handling. Complex business logic can become obfuscated by the need to add system logic performing retries to handle failures.\n  Observability is challenging. With the business logic implemented in many microservices, it becomes hard to observe the status of a business process.\n  Reliability is challenging. If a component fails while processing a request, it can be difficult to ensure that this request is processed and not lost.\n\nMany engineering teams at financial institutions understand the issues with microservices, but the benefits outweigh these problems. The ideal answer is to implement solutions to make microservices work better. This is where new, code-first workflow technologies can solve many problems. In 2025, I predict more banks will realize the need for code-first workflow technologies and begin evaluating and implementing them.\nHow to stay ahead of these trends in 2025\nFinServ organizations need to modernize legacy services to deliver new capabilities at the speed expected by customers. Implementing the modern technologies following many of the trends mentioned in this post will help in this journey, but there are a lot of potential pitfalls in creating a golden path to production.\nBy empowering developers through a workflow-as-code approach, Temporal unlocks the value of microservices and resolves much of the complexity associated with distributed systems. It makes mission-critical services more reliable, and lets development teams rapidly build complex systems and AI applications.\nTo find out how Temporal achieves this, you can download our guide: How Temporal Reduces Risk in Financial Services.",featureImage:{title:"image-3D-waves",description:"image-3D-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/62stYfm7wc5gZJaaldJ4jy/4f585ec2bd98307d1b4593c6c5f6ca92/Screenshot_2024-11-13_at_12.44.34_PM.png"},publishDate:"2024-11-14T00:00-05:00",metaDescription:"Explore top 2025 engineering trends in financial services, from AI and microservices to platform teams and workflow orchestration.",metaTitle:"2025 Engineering Predictions for Financial Services",socialCard:{title:"Top FinServ Predictions 2025",description:"Top FinServ Predictions 2025",url:"https://images.ctfassets.net/0uuz8ydxyd9p/bbcQSqLtHccgp1PvEKvGC/51d070a70d5df4ec48e3b1c67f76d9d2/Linkedin_Ad_-_ad_2_-_nobutton.png"},tags:"Finance",slug:"top-engineering-predictions-for-financial-services-in-2025",contentType:"blogPost",entityId:"206RwAsCnolKndApisfLRk",authors:[{id:"2J8wzkt6lgH8VigzW3gwPu",name:"Donald Forbes",slug:"donald-forbes",jobTitle:"Staff Solutions Architect",photograph:{title:"Donald Forbes",description:"Donald Forbes",url:"https://images.ctfassets.net/0uuz8ydxyd9p/53mtmbNButcupivkognoen/e2b02f33c6882af0cb0a4822394788f9/TT31S6VK5-U06UFK1465A-8c6b5f446ee0-512.jpg"},contentType:"person"}],authorsString:"Donald Forbes",category:"Temporal Voices",readingTime:9},{title:"Events are the wrong abstraction: Rethinking distributed systems",content:"Rethinking Distributed Systems: Why Events Fall Short\nChanging how you think about a system can have big implications. Consider the example of Copernicus, where a simple change of perspective holds a valuable lesson for all of us.\nIn the early sixteenth century, Copernicus realized that existing models of the solar system were overly complicated. They looked beautiful, but when it came to figuring out where things might be relative to others, it was a rather difficult working model:\n\n  \n\nHe believed that those models could be dramatically simplified by changing the frame of reference. Rather than modeling everything with Earth at the center of the universe, by placing the Sun at the center you could produce a simpler system that was far easier to understand:\n\n  \n\nThis new model drastically simplified the understanding of planetary movements and enabled a whole new series of discoveries and developments that we now call the Copernican Revolution. This simple change of perspective holds a valuable lesson for all of us; changing how you think about a system can have big implications.\nSimpler Diagrams are Better Diagrams\nEvent-Driven Architecture (EDA) is one of the most common patterns in modern applications built with microservices. Like the model with Earth at the center, some architecture diagrams look rather beautiful. Once you are forced to work with them at scale, however, many developers discover theyre extraordinarily complex, fragile, and frustrating. Consider this relatively simple Payment Accumulation architectural diagram:\n\n  \n\nCopernicus Insight: Try Shifting the Center\nIf you shift the center of your world view away from events, you might help be able to reduce the intricacy of your software systems. This, in turn, could unlock and unblock projects that are hopelessly complicated by an overly convoluted EDA system.\n\n  Heres how that same Payment Accumulation system looks with Temporal:\n  \n  \n\nCommon Problems of Event-Driven Architecture\nEvent-Driven Architecture is a common approach for building distributed applications. However, EDA has major pitfalls, especially when scaled:\n\n  No APIs: Implementing EDA usually leads to the loss of clear, well-defined APIs. Events lack the documentation and structure that APIs provide, leading to ambiguity about which events each service consumes and produces.\n  Tightly Coupled: Despite the perception of loose coupling, EDA systems are often effectively highly coupled, as changes in one service can cause unintended consequences throughout the system. Events are effectively global variables, and changes to those events and event formats can break services throughout the system. For more on this, see Event-Driven Systems and the Truth About \"Loosely Coupled\" Architectures.\n  Scattered Logic: Business logic becomes fragmented and spread across many different services which makes it difficult to understand and maintain.\n  Poor Debuggability: If an event handler doesnt happen as expected, tracing through the prior events to figure out where the chain got broken is tedious and requires a lot of careful investigation. And, often, understanding what that chain of events might include can be its own non-trivial research project.\n  Proliferating Ad-hoc State Machines: Each service becomes an ad-hoc state machine, complicating state management. This state is dispersed across different systems and events, making it hard to get a clear picture of what is happening and why.\n  Increased Latency: The queuing and infrastructure overhead necessary to manage event flows can introduce considerable latency.\n  Race Conditions: Unless you use the outbox pattern to guarantee data consistency, you will have race conditions between queues and databases that can be extremely difficult to diagnose and troubleshoot.\n  System Upgradability: Upgrading EDA systems is extremely difficult because of poorly defined and understood dependencies and scattered state management.\n\nDurable Execution: A Better Abstraction\nDurable Execution offers a compelling alternative to event-driven architecture, addressing many of its shortcomings. Platforms like Temporal use this approach to provide more resilient and maintainable distributed systems.\n\n  Collect Your Business Logic and Simplify Your Life\n  With Durable Execution, developers define business logic with code that lives in one central place, significantly improving understanding and debuggability.\n\n\n  Manage State Consistently\n  Durable Execution handles state management, retries and more so that network outages, flaky endpoints, long-running processes and other transient failures dont overwhelm your system with the complexity of managing unreliable processes.\n\n\n  Survive Crashes with Grace\n  Durable Execution inherently supports resilience. The execution state is preserved even in the face of process crashes or system outages, allowing the app to resume from where it left off. This capability ensures consistency and reliability, making operations more dependable and resilient.\n\n\n  Design Processes Flexibly\n  Durable Execution handles long-running and intricate processes. This flexibility supports synchronous and asynchronous processes, accommodating a wide range of application needs. Developers can build systems that span hours, days, or even longer periods without sacrificing reliability.\n\nEmbracing a New Approach\nShifting from Event-Driven Architecture to Durable Execution is more than just a different way to model systems; it's a fundamental change in how you can build reliable and maintainable software. By addressing the shortcomings of event-driven designs and offering a more intuitive and effective framework, Durable Execution empowers you to create distributed systems that are easier to understand, maintain, and expand.\nAs we seek to build better, more reliable systems, having the right frame of reference can make a big difference. Yes, you can model the whole universe as revolving around Earth, but if you take a page from Copernicus, you might find that changing your frame of reference will make your system much, much easier.\nRead next: Event-Driven Architectures - A better way forward \nReady to Rethink EDA?\nWhether you're just starting with events or already have built an event-driven system and feel the pains, we encourage you to check out Temporal and see how it can simplify your architecture and code and make building distributed systems durable, flexible, and clear:\n\n  Get Started with Temporal and try it out yourself\n  Ask an Expert for advice and assistance on your project\n  Join our Community Slack and dive into how you can simplify your architecture with Temporal\n",featureImage:{title:"buddha-elemental-3d-br5JFHhkoIA-unsplash (1)",description:"buddha-elemental-3d-br5JFHhkoIA-unsplash (1)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6KZNZOYRsAXONUbNuA5V7f/2f1ec7f2dd615ca6d4bb766d98271bff/buddha-elemental-3d-br5JFHhkoIA-unsplash__1_.jpg"},publishDate:"2024-11-12T00:00-08:00",metaTitle:"Events are the wrong abstraction: Rethinking distributed systems",socialCard:{title:"buddha-elemental-3d-br5JFHhkoIA-unsplash (1)",description:"buddha-elemental-3d-br5JFHhkoIA-unsplash (1)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6KZNZOYRsAXONUbNuA5V7f/2f1ec7f2dd615ca6d4bb766d98271bff/buddha-elemental-3d-br5JFHhkoIA-unsplash__1_.jpg"},tags:"Architecture",slug:"events-are-the-wrong-abstraction-rethinking-distributed-systems",contentType:"blogPost",entityId:"bnJC6kZ8C8UI43UO4KNQi",authors:[{id:"z0YINcrJm9K1OKuVjyLuW",name:"Drew Gorton",slug:"drew-gorton",jobTitle:"Senior Director of Developer Relations",photograph:{title:"drew gorton",description:"drew gorton",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2wPVU7lb49G980vj54Aogy/d0bc3527300e3cbf60780654e8b93c23/TT31S6VK5-U06G8DMAZPB-852595c814a1-512"},company:"Temporal",contentType:"person"}],authorsString:"Drew Gorton",category:"Temporal Concepts",readingTime:6},{title:"Resource-based engineering: Auto-tuning for Temporal Workers",content:"11/12/2024 Update: Resource-based worker auto-tuning is now in Public Preview in Go, Java, Python, .NET and TypeScript! Documentation is now available for improving worker performance via tuning and the worker slot metrics are available as well. An important addition in Public Preview is better container support, i.e. the resource-based tuner now reads cgroups' memory limits and uses them as the memory ceiling when inside a container.\n\nWe're excited to announce resource-based auto-tuning for Workers -- a much-anticipated feature that aims to simplify Worker management in Temporal in Pre-release. Think of it as self-driving, but for Workers!\nBefore we dive into the details, lets take a quick look at some key concepts.\n\n  \n    A Temporal Worker is the entity you control that runs your code and works with the server to make forward progress on your Workflows and Activities. A single process can have one or many Workers.\n  \n  \n    Tasks are maintained in Task Queues. Tasks contain the information needed for a Worker to make progress on Workflows and Activities. There are two types of tasks:\n  \n\nWorkflow Tasks, which include the type of the Workflow and some or all of the Event history.\n\n  \n    Workflow Tasks, which include the type of the Workflow and some or all of the Event history.\n  \n  \n    Activity Tasks, which specify the Activity to run as well as inputs and other data.\n  \n  \n    Task Slots represent how much capacity Workers have to actually perform work concurrently.\n  \n\nWorkers are responsible for making progress on your Workflow and they do so by receiving Tasks from a Task Queue. When Workers start, they open long-polling connections to the Server to get new tasks from the specified Task Queue. Before a Worker starts processing a Task, a Slot is reserved, and then marked used once the worker obtains a Task. Increasing the number of Task Slots allows for more concurrent tasks to be executed by Workers.\nCurrent state of the world\nToday, Workers have to be manually right-sized by monitoring a handful of metrics that indicate how long Tasks are staying unprocessed in Task Queues, and how much capacity Workers currently have.\nFundamentally there are two situations you might encounter.\n\n  All your Workers are at capacity, and the backlog of tasks is growing. In this situation, you might need to horizontally scale out Workers, i.e. add more Workers.\n  If the backlog of Tasks is growing, but Worker hosts still have capacity, you would increase the Workers' maxConcurrentWorkflowTaskExecutionSize or maxConcurrentActivityExecutionSize options, which define the number of total available slots of their respective types for a Worker. This is vertical scaling of Workers, i.e. increasing the amount of work a Worker can accept.\n\nThe future! Introducing resource-based auto-tuning for Workers\nTo minimize toil and simplify the configuration and management of Workers, we're introducing resource-based auto-tuning for Workers, starting with the automatic adjustment of available Slots[1]. This allows Workers to scale up to the maximum bounds of CPU and Memory of the underlying compute node you are running Workers in.\nResource-based tuning is particularly suitable for two use cases:\n\n  Avoiding out-of-memory problems.\n  Handling large bursts of low-resource-usage activities. Ex: Activities that spend the vast majority of their time waiting on slow HTTP or other I/O bound requests.\n\nYou can simply set targets for CPU and memory usage per Worker using the options targetMemoryUsage and targetCpuUsage in the Java SDK, Go, TypeScript, .NET and Python. Depending on how \"utilized\" you want your Worker to be, you can choose a value between 0 and 1[2]. Based on the targets set, Slots will be allocated until resource usage reaches those values. Keep in mind that setting values of 1 is typically ill-advised, especially when it comes to memory usage.\nIf you set these target values, you no longer have to monitor low-level workflow task executions[3]. Instead, you can simply specify the maximum resource capacity that you would like your Workers to utilize, and just allow the SDK to auto-burst up to available capacity when needed.\nTo verify that auto-tuning is working as expected, monitor the overall CPU and Memory usage of the system and confirm that it matches the target values you have set when the Worker is fully loaded.\nOptionally\nYou can more granularly control the allocation of Slots by setting values for minimumSlots, maximumSlots, and rampThrottleMs for Workflow Tasks and Activity Tasks respectively. These values are fully optional and the SDK will use sane defaults for each if unspecified. minimumSlots defines the minimum number of slots that will be issued without considering available resources, while maximumSlots defines the maximum number of slots permitted to be handed out.\nrampThrottleMs is the minimum time the SDK will wait (after passing the minimum slots number) between handing out new slots in milliseconds. This is an advanced option that needs to exist since Workers cannot know a-priori resources a given task will consume. Because of this, it is necessary to wait a brief period between making slots available so that the Worker can get a read on how resource usage has changed since the last task began processing.\nIf you have activities that you know spend some period of time idling before they start consuming significant amounts of CPU or memory, you might want to increase this value. Keep in mind that doing so will limit how quickly the worker can burst up to the number of available slots.\nAlternatively\nIf you prefer not to use the resource-based tuning defined above, you could simply set a static value numSlots for the maximum number of slots you want issued. Use this option when you have clear, fixed limits on how many concurrent instances (typically of Activities) of a task type should be run and the resources your Workers have available to them. You can know this ahead of time through experimentation or observation of a workload.\nWhat's coming next?\n\n  Support for auto-tuning of pollers in SDKs\n\nFeedback\nWe would love to hear feedback and understand how auto-tuning is working for you. Please find us in the Temporal Community Slack or email us at product@temporal.io.\n__\n\n  Please note that this feature is in Pre-release (otherwise known as Experimental) and may be subject to change.\n  These limits apply to resource usage system-wide and take into consideration language specific concerns like JVM heap size, for example. This means that you probably dont want to run other resource-intensive processes on the same host as your Worker(s).\n  Note that you can't set maxConcurrentWorkflowTaskExecutionSize or maxConcurrentActivityExecutionSize and resource-based targets for a Worker at the same time. The SDK will throw an error if you attempt to do so.\n",featureImage:{title:"pulsar-abstract-7",description:"pulsar-abstract-7",url:"https://images.ctfassets.net/0uuz8ydxyd9p/50pZ7NH1mWQz6D31exRr1T/3105dfafe8251c547cd186552be56cdc/pulsar-abstract-7.png"},publishDate:"2024-11-12T00:00-07:00",metaDescription:"Explore how resource-based engineering powers auto-tuning for Temporal Workers, streamlining performance and management.",metaTitle:"Resource-based auto-tuning for Temporal Workers",socialCard:{title:"pulsar-abstract-7",description:"pulsar-abstract-7",url:"https://images.ctfassets.net/0uuz8ydxyd9p/50pZ7NH1mWQz6D31exRr1T/3105dfafe8251c547cd186552be56cdc/pulsar-abstract-7.png"},tags:"Temporal Primitives",slug:"resource-based-auto-tuning-for-workers",contentType:"blogPost",entityId:"6NPFowbngNXuhq7MrIHra4",authors:[{id:"5rRXBv9YX2HZHsbvCIr7ts",name:"Nikitha Suryadevara",slug:"nikitha-suryadevara",jobTitle:"Staff Product Manager",photograph:{title:"headshot-nikitha",description:"headshot-nikitha",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4OACKtdVPmoAygYiRKZnHU/d4033aa0852aae010c69fe249c9e90c0/headshot-nikitha.png"},biography:"Nikitha is a Staff Product Manager at Temporal based in San Francisco. She oversees several areas of the product such as high availability, worker management, and observability. Before Temporal, she worked on Compute Infrastructure (Borg) in Google Cloud. Her introduction to compute and cloud was through being a Product Line Manager at VMware. Nikitha started her career as a software engineer and product manager at various SaaS startups. She got her bachelor's degree in electrical engineering from the Manipal Institute of Technology and an MBA from UCLA Anderson.",company:"Temporal",contentType:"person"},{id:"1PHz8Dl88bVpiHHLc3Vq4f",name:"Spencer Judge",slug:"spencer-judge",jobTitle:"Engineering",photograph:{title:"spencer judge",description:"spencer judge",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2pXA865gLawVaXFgiDOdEy/183b52c3df3e3ced8338157d981f0a06/Screen_Shot_2022-08-12_at_5.33.14_PM.png"},contentType:"person"}],authorsString:"Nikitha Suryadevara, Spencer Judge",category:"Product News",readingTime:6},{title:"Temporal Cloud pricing update",content:"Note: Please always refer to the pricing page for our most current pricing.\nWere introducing a new pricing structure for Temporal. This update includes changes to our support tiers, volume pricing, usage aggregation, and pricing for Actions and Retained Storage.\nTimeline\nIn January, these changes will become the default offerings for new customers signing up for Temporal Cloud. For existing customers we will begin migrations to our new offering in February 2025. For customers that currently have Temporal Credits migrations will begin after current credits are utilized. If these changes will significantly impact your costs, we will reach out directly in January to help you navigate the transition.\nTemporal Cloud Plans\nWe are introducing four new Temporal Cloud Plans to better match the needs of our customers: Essentials, Business, Enterprise, and Mission Critical. These plans include bundled Actions, Storage, Support and other features to simplify getting started without worrying about unpredictable spending. SSO will now be included in Enterprise and Mission Critical plans without an additional charge. Many customers will see simplified bills, and some will see cost reductions.\n\n  \n    \n      \n      Essentials\n      Business\n      Enterprise\n      Mission Critical\n    \n  \n  \n    \n      Availability(Subject to Timezone)\n      P0-3: 9-5 Mon-Fri\n      P0-3: 9-5 Mon-Fri\n      P0: 24x7 (On Page Service)P1-3: 9-5 Mon-Fri\n      P0: 24x7 (On Page Service)P1: 9-5, 7 days/weekP2-3: Mon-Fri\n    \n    \n      Response Time\n      P0: 1 business dayP1: 1 business dayP2: 1 business dayP3: 2 business days\n      P0: 2 business hoursP1: 2 business hoursP2: 1 business dayP3: 2 business days\n      P0: 30 minutesP1: 1 business hourP2: 4 business hoursP3: 1 business day\n      P0: 15 minutesP1: 1 business hourP2: 4 business hoursP3: 1 business day\n    \n    \n      Channels\n      CommunityZendesk\n      CommunityZendesk\n      CommunityZendeskPrivate Slack\n      CommunityZendeskPrivate Slack\n    \n    \n      Dedicated Support Engineer\n      \n      \n      Available as an Add-on\n      Included\n    \n    \n      Billing Assistance\n      Generic Billing Questions\n      Generic Billing Questions\n      Quarterly review of spend\n      Proactive support in managing billing\n    \n    \n      Platform Benefits(monthly allocation)\n      1M Actions1GB Active Storage40GB Retained Storage\n      CommitmentsSSO Add-on2.5M Actions Incl.2.5GB Active Storage100GB Retained Storage\n      CommitmentsSSO Incl.10M Actions Incl.10GB Active Storage400GB Retained Storage\n      CommitmentsSSO Incl.10M Actions Incl.10GB Active Storage400GB Retained Storage\n    \n    \n      Price\n      $100/Mo or 5% of monthly usage, Whichever is greater\n      $500/Mo or 10% of monthly usage, Whichever is greater\n      Billed Annually, Contact Sales\n      Billed Annually, Contact Sales\n    \n  \n\nCustomers currently on our Basic support tier will need to choose between our Essentials and Business offerings.\n\n  Essentials: For customers with lower usage and support needs, the Essentials plan will typically satisfy all usage needs and simplify your bill. This plan reduces the base monthly support fee from $200 to $100 and includes up to $82 of Actions/Storage Value.\n  Business: For customers who need more support, running production applications, or planning to scale.\n\nCustomers currently on our Premium support tier will be migrated to our Enterprise plan offering with the ability to upgrade to our Mission Critical plan.\n\n  Enterprise: For enterprise businesses that need prompt responses, a direct communications channel and have additional support requirements.\n  Mission Critical: Customers with stringent uptime requirements that need the fastest and most personalized support.\n\nVolume Pricing and Usage Aggregation\nVolume pricing will now be available to all customers, not just those purchasing credits. Discounts start at 5 million Actions (down from 300 million) and apply across all namespaces in an account. Compared to volume discounts on a per namespace basis, this means better pricing as you grow, on a pay-as-you-go basis.\nMonthly Actions and Storage Pricing\nAn initial amount of Actions and Storage are now bundled in the Temporal Cloud Plans. This eliminates the need for separate purchases when getting started. Once usage exceeds the allocated amount, customers will pay for additional usage based on new rates:\n\n  Actions Pricing: Starts at $50 per million Actions for the first 5 million (previously $25).\n  Storage Pricing: Retained storage will now cost $0.00105 per GBh (up from $0.00042). Active storage pricing remains unchanged.\n\nOur Monthly Actions pricing will be changing to:\n\n  \n    \n      Actions\n      Price Per MIllion Actions\n    \n  \n  \n    \n      First Bundled Actions\n      Included\n    \n    \n      First 5M\n      $50\n    \n    \n      Next 5M, up to 10M\n      $45\n    \n    \n      Next 10M, up to 20M\n      $40\n    \n    \n      Next 30M, up to 50M\n      $35\n    \n    \n      Next 50M, up to 100M\n      $30\n    \n    \n      Next 100M, up to 200M\n      $25\n    \n    \n      Over 200M\n      Contact Us (More Discounts, Helpful Humans)\n    \n  \n\nStorage pricing will be changing to:\n\n  \n    \n      Storage Type\n      Price per GBh\n    \n  \n  \n    \n      Active Storage\n      $0.042\n    \n    \n      Retained Storage\n      $0.00105\n    \n  \n\nCommitments\nLastly, we are introducing minimum spend commitments for customers that want to predictably scale on Temporal Cloud. In exchange for commitments, Temporal will offer additional discounts based on the size and duration of the commitment and provide customers with a flat price per million actions. Staying true to our pay-per-use model, we spent the time to design a customer friendly commitment model.\nCommitments will be offered on 1, 2 and 3 year terms. Commitments represent a minimum spend on the platform, with usage across Actions, Storage and Support contributing to the commitment. Commitments do not have punitive overages, once you reach your commitment, additional usage will continue to be billed at the discounted rate. Commitments will require the purchase of Credits for annual portions of the commitment. Please reach out to sales@temporal.io for discounts and pricing estimation.\nContinued Dedication to Improving our Value\nOur new pricing structure simplifies billing by providing discounts on an account, rather than on a namespace basis. This provides you with clearer, more predictable costs, while rewarding your entire business with lower prices per unit as you scale.\n\n  With Temporal, you can build reliable, scalable workflows with reduced operational overhead, enabling faster development and seamless integration into your systems. These pricing adjustments will help us continue to invest in product improvements that support your success while also maintaining high-quality engineering support from the Temporal team.\n  For any questions please reach out to your account manager or open a ticket.\n\nExamples\nThe following examples will help demonstrate the impacts of some of the billing changes.\nLight Use Case Example:\nA customer currently on Basic Support with monthly consumption of 1.5M Actions, 500 GBh of Active Storage and 5,000 GBh of Retained Storage. Their bill today would be:\n$200 Basic Support + 1.5 Million Actions * $25 Per Million Actions + 500GBh Active Storage * $0.042 Per GBh + 5,000 GBh Retained Storage * $0.00042 Per GBh= $260.60\nOn the new offerings, this customer could choose between 1) the Essentials plan and 2) Business Plan.\n\n  On the Essentials plan their bill would be:\n\nIncluded 1M Actions, 1GB Active Storage (744 GBh) and 40 GBh Retained Storage (29,760 GBh). After these allocations, the account would be billed for 0.5M Actions, and no additional storage.\n$100 Essential Plan + 0.5M Actions * $50 Per Million Actions = $125\n\n  On the Business plan their bill would be:\n\nIncluded 2.5M Actions, 2.5 Active Storage (1860 GBh) and 100 GBh Retained Storage (74,400 GBh). These allocations would cover the usage of the account, so they would only see the plan fee.\n$500 Business Plan = $500\nVolume Discount Example:\nA customer currently on Basic support with 10M Actions, 1,500 GBh Active Storage, and 25,000 GBh Retained Storage. Their bill today would be:\n$200 Basic Support + 10 Million Actions * $25 Per Million Actions + 1,500GBh Active Storage * $0.042 Per GBh + 25,000 GBh Retained Storage * $0.00042 Per GBh = $523.50\nOn the new Essentials Plan their bill would be:\nIncluded 1M Actions, 1GB Active Storage (744 GBh) and 40 GBh Retained Storage (29,760 GBh).The account would be billed for an additional 9M Actions, 756 GBh Active Storage and no additional Retained Storage.\n$100 Business Plan + 5M Actions * $50 Per Million Actions First Volume Tier + 4M Actions * $45 Per Million Actions Second Volume Tie + 756GBh Active Storage * $0.042 Per GBhr = $561.75\nOn the new Business Plan their bill would be:\n\n  Included 2.5M Actions, 2.5 Active Storage (1860 GBh) and 100 GBh Retained Storage (74,400 GBh).\n  The account would be billed for an additional 7.5M Actions and no additional storage.\n\n$500 Business Plan + 5M Actions * $50 Per Million Actions First Volume Tier + 2.5M Actions * $45 Per Million Actions Second Volume Tier = $862.50\nFAQ\n- When will the changes take effect?\nNew pricing starts for new customers in January 2025, and for existing customers in February 2025.\n- What plan will I be migrated to?\nWe will reach out with a plan recommendation in January based on your platform and support usage. We will provide an option at that time to specify a different plan if desired.\n- Are all customers being migrated to the new plans?\nAll customers on our Pay as You Go pricing will be moving to the new plans in February. For customers that have previously purchased credits with Temporal we will continue to honor our current pricing until your credits are fully utilized. Credit renewals in the future will then move to our new commitments model.\n- Why are Actions and Storage being bundled into Temporal Cloud Plans?\nWe believe that including a base amount of Actions and Storage lets you quickly get started on Temporal without immediately worrying about estimating usage based costs. As you scale you will continue to benefit from usage based billing so you only pay for what you use.\n- What discounts are included with commitments?\nDiscounts will be based primarily on the commitment size, and duration. To get an accurate estimate please reach out to sales.\n- Are Actions prices doubling?\nNo, but we are holistically changing our pricing structure so the impacts specific to your company may differ. Our new pricing structure includes bundled Actions and Storage. For many customers this will be sufficient and your bill may be lowered. For companies that have scaled beyond these allocations the initial prices at low volumes will be higher. However, we have introduced more aggressive volume discounts that kick in at 5M actions instead of 300M and no longer require a credit purchase. We now also attribute all usage towards these discounts compared to per namespace discounts before. Lastly, for customers that make commitments we offer additional discounts.\n- What are the impacts of the Retained Storage price increases?\nThe vast majority of customers will have their Retained Storage bill covered by their base plan. For the few customers with very high storage volumes we are reaching out directly. Retained storage can be optimized to minimize costs by reducing data stored in workflows, or adjusting a workflows retention period for example.\n-Why do your base plans include a % fee at scale?\nTemporal Cloud plans are priced at the greater of a base price or a % of your usage cost (Actions+Storage). This is because as customers scale, they often need additional support and have more complex issues. The scaling price allows us to continue offering the best support possible as customers grow with Temporal. While the scaling price existed previously on Temporal we have also introduced the Essentials plan which both has a base price 50% lower than the previous Basic tier, but also has a lower scaling cost (5% instead of 10%). This increases customer options to opt into the support plan that best suits their needs.",featureImage:{title:"Social card - Temporal",description:"Social card - Temporal",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3A4UpeAUYabwGjkyPPHEC4/f695115bb2ed3d2ff5cf3ae05aad1bb5/Twitter_Card.png"},publishDate:"2024-11-06T09:00+00:00",metaDescription:"Were introducing a new pricing structure for Temporal. This update includes changes to our support tiers, volume pricing, usage aggregation, and pricing for Actions and Retained Storage.",metaTitle:"Temporal Cloud Pricing Update",socialCard:{title:"Social card - Temporal",description:"Social card - Temporal",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3A4UpeAUYabwGjkyPPHEC4/f695115bb2ed3d2ff5cf3ae05aad1bb5/Twitter_Card.png"},tags:"Cloud",slug:"temporal-cloud-pricing-update",contentType:"blogPost",entityId:"7byrIF6j2329hbjzacICa0",authors:[{id:"5qlPoVqfd3yW3KvpwUvaBa",name:"Tomas Lorinc",slug:"tomas-lorinc",jobTitle:"Sr. Staff Product Manager",photograph:{title:"Tomas Lorinc",description:"Tomas Lorinc",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3CynoCUjE67L2TjK0PmCZ5/8bc119307d3a63d7c18cfdb8496528a8/TT31S6VK5-U0781PY1K47-7bcefcf1a6bd-512.png"},company:"Temporal",contentType:"person"},{id:"7GV0xjBamDpDSZZ543r8yX",name:"Irina Belova",slug:"irina-belova",jobTitle:"Product Marketing",photograph:{title:"headshot-irina-belova",description:"headshot-irina-belova",url:"https://images.ctfassets.net/0uuz8ydxyd9p/BJ0w7WeAjw83DatmJ7Fin/a8facdb4b7206afe1e66dc73b216ec09/headshot-irina.png"},contentType:"person"}],authorsString:"Tomas Lorinc, Irina Belova",category:"Announcements",readingTime:10},{title:"Get $1,000 in free credits and build better Workflows with Temporal Cloud",content:"Temporal Cloud is now even easier to access with self-service sign-up  a seamless way for developers to dive into the Temporal platform without worrying about infrastructure management. And, as part of this launch, were offering $1,000 in free credits to new users. That means you can start building resilient, scalable applications right away, without any initial financial commitment.\nHeres what youll get:\n\n  $1,000 in Free Credits  Explore Temporal Clouds full functionality, risk-free, to see how it fits your development needs.\n  Quick Start for New Users  Our credits make onboarding smooth, so you can focus on building powerful workflows from day one.\n  Low-Risk Exploration  Temporal Cloud minimizes upfront costs, which makes testing and scaling cost-effective.\n\nWith just a few clicks, youll have access to the full power of Temporal Cloud, enabling you to build strong applications faster, without the infrastructure headaches.\nHow Does Temporal Cloud Work?\nTemporal Cloud improves how developers manage workflows by abstracting away infrastructure complexities. At its core, Temporal Cloud manages task distribution, error handling, and retries, so developers can spend more time coding and less time managing systems.\nBuilt for high availability, scalability, and durability, Temporal Cloud provides a fully managed, production-ready platform where developers dont have to worry about maintenance. The system topology is designed to scale with your applications  from simple workflows to complex, distributed architectures.\nLearn more about Temporal Clouds system architecture in our Introduction to Temporal Cloud course.\nWhy Try It?\nTemporal Cloud opens up new possibilities for development teams by removing the burden of infrastructure management, giving you the freedom to focus on building, testing, and iterating.\nHeres why Temporal Cloud makes sense for teams:\n\n  Hassle-Free Management  Temporal Cloud takes care of the operational load, so you dont have to.\n  Scalability, Availability, and Durability  Temporal provides an enterprise-ready foundation that adapts to your applications demands.\n  No Financial Risk  Explore Temporal Clouds capabilities with the $1,000 credit  its a low-risk way for decision-makers to assess value while keeping costs in check.\n\nWho Should Use It\nTemporal Cloud is built for developers and teams looking for efficiency, speed, and reduced operational overhead. Heres who will benefit most:\n\n  Open-Source and Self-Hosted Temporal Users  If youre tired of handling infrastructure, Temporal Cloud provides an easy, managed alternative.\n  Infrastructure-Agnostic Developers  Perfect for developers who want to bypass the complexities of system management.\n  Teams in High-Stakes Fields  From financial services to AI pipelines and distributed systems, Temporal Cloud is ideal for industries that require reliability and scalability.\n\nWhat Our Customers Are Saying\nDont just take our word for it  heres what customers from our Replay 24 event have to say about Temporal Cloud:\nAlaska Airlines:\n\n  With Temporal, we improved booking confirmation speed by 72%, minimizing delays and enhancing our customer experience.\n\nWashington Post (Arc XP):\n\n  Temporal cloud was a big selling point for us because we needed someone else to handle task orchestration. The flexibility and support we receive has made Temporal indispensable for our video and photo team.\n\nZillow:\n\n  The aha moment for us was realizing we could use Temporals orchestration without needing a new temperate language. We just write code. Its simple, transparent, and a technical marvel.\n\nSalesforce:\n\n  Temporal powers critical user journeys like payments and transfers, allowing us to focus on high-impact work instead of infrastructure management. Knowing Temporal just works for our transfers gives us  and our users  peace of mind.\n\nThese teams rely on Temporal Cloud to meet their goals without compromise.\nStart your free trial by claiming your $1,000 in free credits and see how Temporal Cloud can redefine your approach to application development. Sign up now and start building resilient, scalable workflows today!",featureImage:{title:"social card - green waves",description:"social card - green waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4GBHZR0vUnoRSbPtSTCH4s/daf7308a10e469059827e2169065d7ea/social_card_-_green_waves.jpg"},publishDate:"2024-11-06T00:00-08:00",metaDescription:"Start your free trial with Temporal Cloud and get $1,000 in free credits to build better workflows. Experience powerful cloud solutions today!",metaTitle:"Get $1,000 in Free Credits with Temporal Cloud",socialCard:{title:"Self-service launch v1",description:"Self-service launch v1",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2HiJhiC0NnnqHPsniuGaSl/14d53cc736310c902baabdd4dd153c31/Blog__2_.png"},tags:"Cloud",slug:"get-usd1-000-in-free-credits-and-build-better-workflows-with-temporal-cloud",contentType:"blogPost",entityId:"4opQ5fJ8MxWG2P7NPcVJI7",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"Announcements",readingTime:4},{title:"Why top developers prioritize failure management",content:"Theres a saying: Amateurs study tactics, while professionals study logistics. In software, this translates to: Amateurs focus on algorithms, while professionals focus on failures.\nAt J on the Beach, I took time in my talk to expand on this saying and explain that real-world systems dont just need code that works on the happy path  they need a safety net for when things go wrong.\nModern software development has layers of complexity. Youre not just writing code; youre connecting systems across time and space, handling data that doesnt sleep, and ensuring flawless performance at scale. What sets top developers apart is how they manage failures. Building resilience focuses on ensuring reliability when things inevitably go wrong, not just maintaining uptime.\nIn this post, well walk through three common approaches to handling failures in software, each with its own strengths and weaknesses. Then well introduce Temporals approach, workflow-as-code, which makes it easier to build reliability into your systems from day one.\nThree Ways to Handle Failure in Your Software\nFailures are inevitable in your distributed systems. When a network link fails, a server times out, or a service crashes, systems need strategies to respond properly and ensure that your operations remain reliable.\nBelow, well explore three common approaches to coordination between systems  Remote Procedure Calls (RPCs), persistent queues, and workflows  and their relationship to failure management.\n1. Request-Response (RPC)\nThe request-response, or RPC model, is a classic approach. A client makes a request, the server processes it, and sends back a response. In the best-case scenario  the happy path  everything works smoothly. Imagine a money transfer request: one service debits the sender while another credits the receiver. If all goes as planned, the transfer completes with no issues.\nPros of the RPC Model\n\n  Simplicity: The direct client-server connection makes this model easy to implement for straightforward workflows.\n  Efficiency on the happy path: When things go smoothly, RPC provides fast, efficient responses and low latency.\n\nCons of the RPC Model\n\n  Limited resilience for partial failures: If the clients request is successful, but a response isnt received, or a step in the process fails, RPC often requires extensive error-handling code on the client side.\n  Heavy client burden: Clients must handle errors, recovery, and retries, complicating systems as they scale.\n\nThe RPC model works well for simple, synchronous tasks. However, for resilience, it falls short by placing the onus on developers of the RPCs and those consuming them to manage every failure scenario  and this is no trivial matter.\n2. Persistent Queues\nPersistent queues add a degree of flexibility by decoupling the client from the server. Messages are placed in a queue, and the system processes them asynchronously. Queues help distribute workloads: they support automatic retries and asynchronous processing, which can smooth out demand spikes.\nPros of Persistent Queues\n\n  Automatic retries: Persistent queues often support automatic retries, attempting tasks multiple times if they initially fail.\n  Load distribution: Queues smooth processing under heavy loads, distributing requests over time, to improve system reliability.\n  Producer-consumer separation: Decoupling producers and consumers allow the queue to function independently, improving fault tolerance.\n\nCons of Persistent Queues\n\n  Loss of ordering: Since queues process messages independently, tasks may execute out of order, causing unexpected issues for dependent operations.\n  Dead-letter queues: Tasks that continuously fail may require a separate dead-letter queue, adding complexity and, typically, manual intervention.\n  Limited visibility into status: Visibility becomes even more challenging when you have systems that use multiple queues, requiring additional tooling and infrastructure.\n\nQueues work well when you need flexibility and decoupling, but they lack the control and visibility needed for comprehensive failure management.\n3. Workflows\nWorkflows provide a robust solution for orchestrating complex processes across distributed systems. Unlike RPC or queue-based models, workflows manage retries, state, and error handling automatically, making them ideal for long-running or multi-step processes.\nPros of Workflows\n\n  Built-in resilience: Workflows handle retries, recovery, and compensation steps automatically, reducing the need for custom error-handling code.\n  Support for long-running processes: Workflows accommodate processes that span minutes, hours, or even days, making them well-suited for complex tasks.\n  Enhanced visibility: Workflow systems enable real-time tracking and querying, so both clients and developers can see exactly where each process stands.\n\nCons of Workflows\n\n  Infrastructure requirements: Workflows require a solid infrastructure to manage states, retries, and tracking, which some teams may lack.\n  Setup complexity: Workflow systems can be complex to set up, especially when building custom solutions to manage workflows.\n\nFor complex processes that demand reliability and transparency, workflows provide the most comprehensive solution, though they require dedicated infrastructure to deploy effectively.\nResilience Without Extra Overhead\nAt Temporal, we addressed these challenges by designing a platform that handles resilience, error handling, and state management so you dont have to.\nWith Temporal, you write workflows as code - no extra XML, JSON, or YAML definition of workflow logic that is difficult to understand and debug down the line. Define your steps in regular code, and Temporal does the rest, managing retries, maintaining state, and ensuring that your workflows are reliable and simple to create.\nCompanies like ANZ Bank, one of the largest banks in the Asia-Pacific region, rely on Temporal to strengthen the resilience and reliability of critical financial processes. With Temporal, ANZ orchestrates and manages complex operations across distributed systems, ensuring tasks are retried automatically, failures are handled, and long-running processes are tracked seamlessly. This has enabled ANZ to boost system reliability, reduce operational complexity, and uphold strict compliance standards in their high-stakes FinServ environment.\nFailure Management Is a Strategy, Not a Setback\nAny complex system will encounter failures. But how you handle those failures makes all the difference. For developers, focusing on failure management from the start distinguished exceptional teams from the average. Building resilience into your system sets your project up for long-term success.\nDiscover how to make your app resilient with examples from leading companies like Snap and Coinbase, or start a free trial of Temporal Cloud today.",featureImage:{title:"social-orb",description:"social-orb",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5ZQDJyHkj4M3RrOA5LZ0ct/2d915cc986593cef13c8260c8f6311df/social-orb.png"},publishDate:"2024-11-05T00:00-08:00",metaDescription:"Discover why leading developers focus on failure management. Explore 3 failure-handling strategies and how workflows boost resilience.",metaTitle:"How to handle fault tolerance in microservices",socialCard:{title:"SERGEY TOFU BLOG SOCIAL CARD",description:"SERGEY TOFU BLOG SOCIAL CARD",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2yJdfVKwbXbXdiNhPx6VkT/ee64b0d5edf5f0432d87717cb2ef8786/SERGEY_TOFU_BLOG_SOCIAL_CARD_REVISED__1_.jpg"},tags:"Timeouts,Retries",slug:"why-top-developers-focus-failures-not-code",contentType:"blogPost",entityId:"4MtQkpnZKvY0hWC2BRd7y6",authors:[{id:"7lKzY3cqOY1thOiOjI9aUa",name:"Sergey Bykov",slug:"sergey-bykov",jobTitle:"Principal Software Engineer",photograph:{title:"Sergey Bykov Headshot",description:"Sergey Bykov Headshot",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5IH7T6geXArvRD5oS5Dgoi/80ad0ff235fa2f199376763da92b42ad/Sergey_Bykov_Headshot.jpeg"},biography:"Sergey Bykov is responsible for the architecture of Temporal Cloud. Before joining Temporal, Sergey was one of the founders of the Orleans project at Microsoft Research and led its development for over a decade. The mediocre state of developer tools for cloud services and distributed systems continues to fuel his passion for qualitatively improving developer productivity in this space.",twitterUrl:"https://twitter.com/sergeybykov",company:"Temporal",contentType:"person"}],authorsString:"Sergey Bykov",category:"Temporal Concepts",readingTime:6},{title:"Temporal supercharges video processing at The Washington Post",content:"We recently had the opportunity to sit down with Eric Ziegler, Principal Software Engineer at The Washington Posts Arc XP division. In a candid conversation, Ziegler shared how Temporal has helped them revamp their media workflows, enhanced efficiency, and allowed his team to focus on innovation rather than infrastructure, resulting in a 600% improvement in runtime efficiency.\nFrom Legacy Headaches to Streamlined Workflows\nArc XP, The Washington Posts in-house media content management system (CMS), serves numerous major media organizations worldwide. We focus on building and selling our media CMS system to other news organizations, Ziegler explained. Clients include Reuters, Gray Television, the Boston Globe, and the Atlanta Journal-Constitution. Zieglers Digital Asset Management (DAM) team handles videos and photos, focusing on efficient and cost-effective video broadcast on the web.\nThe journey with Temporal began when Zieglers predecessor sought a better way to synchronize video and audio streams for 24/7 TV programming. The team needed to manage channel construction, ensure videos and audio remained in sync, and orchestrate the insertion of ads at specific intervals.\nThe existing internal orchestration system was cumbersome and difficult to maintain. We had this system that existed for about 10 years, and it was painful to use, Ziegler recalled. The internal tool required significant effort to manage, and with a decades worth of code layered onto it, making changes was a daunting task. It was impacting the business by slowing down development cycles and making it challenging to innovate. We were maintaining this huge monkey of a project, Ziegler said with a chuckle.\nThe pain points were clear  continuing with the old system would hinder their ability to meet evolving business needs and deliver new features to clients efficiently. Faced with these challenges, the team began exploring alternatives that could offer durable execution and simplify workflow orchestration  among them were Apache Airflow, JobRunr, and Celery. However, these solutions had limitations, especially in handling complex, long-running processes and providing seamless support across multiple programming languages.\nThis is where Temporal entered the picture. Temporal is an open-source, code-based workflow orchestration platform that enables developers to write scalable applications without worrying about the complexities of distributed systems. It offers durable execution, meaning workflows can survive process failures, restarts, and even extended downtimes, resuming exactly where they left off. Plus, Temporal supports a variety of programming languages  a distinction critical for Zieglers team.\nIt respects the core language features of Python and Java, making it easy to integrate without needing to learn new constructs, he explained. This meant that his team could use familiar tools and syntax, reducing the learning curve and increasing productivity.\nZiegler shared an aha moment when he realized how effortlessly Temporal could handle asynchronous tasks. I asked, If I made six coroutine activities and passed them to a gather method, what would happen? The response was, Theyd just go out to all the workers and execute. It was kind of magical.\nTemporal worked out wonderfully, he said. Its durability and scheduling features made it perfect for orchestration. The team appreciated Temporals ability to handle asynchronous distributed execution without the complexity of their old system.\nIn Use: Building an Automated Thumbnail Selection System\nUsing Temporal, Zieglers team developed an automated thumbnail selection system for videos. Thumbnails are crucial for attracting viewers, especially when dealing with thousands of videos daily. If you have a bad thumbnail, you lose out on clicks, he emphasized.\nThe system uses machine learning to assess the aesthetic quality of video frames, selecting the best ones to use as thumbnails. Initially, processing one minute of video took about 80 seconds  a delay that was unacceptable for busy video editors. We needed to process videos much faster, Ziegler said.\nBy leveraging Temporal, they achieved a 600% runtime improvement. We got it down to about 10 seconds for a four or five-minute video, he reported. Temporal allowed them to distribute workloads across inexpensive AWS instances, making the process both faster and more cost-effective.\nTemporal also enhanced the supportability of the teams products. Given the high-profile nature of their clients, any downtime or failures could be disastrous. Temporals Replay feature proved invaluable. Failures happen, but being able to atomically repeat tasks is really nice, Ziegler said. Support staff who arent expert engineers can go into Temporal Cloud and simply hit Replay.\nThis ease of use contrasts sharply with their previous system, which required digging through arcane system logs and database entries. When youre in the middle of an incident, its really painful, he admitted. Temporals user-friendly console and separation from their internal systems made debugging and managing workflows much easier.\nA Shift in Mindset: Focusing on Innovation\nAdopting Temporal has allowed Ziegler and his team to shift their focus from managing complex infrastructure to innovating and improving their services. Theres always so much to do, he said. If you can take some of the minutiae away, it opens up more space for innovation.\nHe mentioned how Temporals new features, like the recently announced Nexus, have sparked ideas for future projects. When Nexus was announced, I immediately thought, I could use this, he shared. Its like the old marketing saying: I didn't know I needed it, but now I do.\nWhile not actively evangelizing, Ziegler has seen colleagues from other teams show interest in Temporal after hearing about its benefits. We just talk about what were doing, he said modestly. People ask, Are you using Step Functions? and we say, No, were using Temporal. That usually sparks their curiosity.\nFor other organizations contemplating Temporal Cloud, Ziegler offers practical insights. The Temporal team is highly responsive, he said. Using Temporal Cloud helps separate internal system problems from orchestration tasks. Its easier to manage and debug workflows through the Temporal console.\nHe also highlighted the benefits of Temporals multi-language support. We have Java, Python, TypeScript, even some Golang, he explained. Temporal allows us to use the best language for each task without being bound to a single ecosystem.\nLooking Ahead\nReflecting on his experience, Ziegler summed up the impact of Temporal on his work life. Temporal simplifies things and makes our workflows more efficient, he stated. Id much rather be working on machine learning stuff than making sure my infrastructure is all talking to each other correctly.\nBy embracing Temporal, Eric Ziegler and his team at The Washington Posts Arc XP division have not only optimized their media workflows but have also set the stage for future innovations.\nThis interview was conducted at Replay 2024, Temporals annual conference, where industry leaders gather to share insights and advancements in workflow orchestration.\nReady to transform your workflows like The Washington Post? Nows your chance to see what Temporal can do for your team  with $1000 in Temporal Cloud credits for a limited time! Get hands-on experience with Temporals powerful orchestration capabilities without any upfront cost. Dive in, explore, and unlock the potential to streamline operations and innovate faster.",featureImage:{title:"social-card-purple-waves",description:"social-card-purple-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2nvZtGhubV6XKQbGrFwUmH/c7c8144ccbc2a70cc9d1274206d26593/social-card-purple-waves.jpg"},publishDate:"2024-11-04T00:00-07:00",metaDescription:"See how The Washington Post used Temporal to supercharge video processing, achieving a 600% improvement in runtime efficiency and streamlining media workflows.",metaTitle:"Temporal Boosts Video Processing by 600% at The Washington Post",socialCard:{title:"WaPo Image (Blog)",description:"WaPo Image (Blog)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5q6lgijlDt9yfJcpWXx8Yf/98a3aed757727c4f5798cc66cbc941b3/Blog__1_.png"},tags:"Cloud",slug:"temporal-supercharges-video-processing-at-the-washington-post",contentType:"blogPost",entityId:"23Vk93EWJ2eJcWBTlwYvO",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"Community",readingTime:6},{title:"Spooky Stories: The vanishing messages at Snap tower",content:"They say something strange happens deep within Snap Tower, hidden behind the pristine walls and endless lines of code. Not everyone hears about it, but developers know  whispering late into the night over debug logs.\nAt first, everything runs perfectly. Snaps microservices hum like a chorus, sending ephemeral messages that vanish just as quickly as they appear. But sometimes... sometimes, messages dont just disappear on purpose  they disappear wrong.\nOne foggy October evening, Emily, an engineer on-call, sat alone at her desk. Her team had deployed a new workflow using Temporal earlier that day  routine updates, nothing out of the ordinary. But tonight, her alerts app began to glow with unread notifications.\n500 Internal Server Error\nStatusRuntimeException: UNAVAILABLE: io exception\n503 Service Unavailable\nEmily groaned. Not now. She had planned to head home, maybe carve a pumpkin, and unwind with a true crime podcast. But it looked like the system had other plans.\nShe stared at the cascading failures in front of her. The ephemeral messaging service, Snaps pride and joy, was throwing errors everywhere. It wasnt just one queue  it was everything, all at once.\n\n  Her fingers danced over the keys, digging into traces, following cross-service calls and state changes from one span to the next. But as she reached the root cause, her terminal froze.\n  A chill filled the air. The overhead lights flickered. A whisper curled out from the darkness beyond her screen, soft but unmistakable.\n\nThe messages are not yours to retrieve\nEmilys pulse quickened. She could have sworn she heard it. A voice  no, a presence. Something ancient, something vast, watching from the depths of her system, where code and chaos intertwined.\nShe tried restarting her tools, but every attempt spiraled into deeper anomalies. Message traces pointed to workflows that didnt exist. Dead-letter queues spat out strange symbols, glyphs Emily had never seen before.\n\n  She knew the message queue was implemented to help the system weather network hiccups and other brief disruptions. It was supposed to make these failures manageable. But this this was something else. This wasnt just a system error  it felt alive, and it didnt want her meddling.\n  Her terminal buzzed to life once more, but the output was... wrong. An endless loop of timestamps from the future, each accompanied by the same ominous message:\n\nThe void remembers.\nDesperate, Emily escalated to her team. But no one answered. Every chat, every call, every request for help was met with silence. Outside the window, the fog pressed tighter against the glass, as if sealing her in with the haunted code.\nShe had no choice. With a trembling hand, she triggered the emergency state designed to purge and restart the system. The screen flickered, and for a moment, everything went dark.\nThen, a notification appeared:\nWorkflow Complete: All systems operational.\nRelief washed over Emily, though unease lingered in the pit of her stomach. She packed her things quickly, eager to escape the oppressive silence of the office.\nAs she left, her phone buzzed once more  a final status page? A new incident? She glanced down at a message from an unknown number:\nYou fixed nothing. The void remembers.\nEmily felt her heart skip a beat. Somewhere deep in the system  in the unseen space between ephemeral messages and retries  something was still watching. And it wasnt done with her yet.\nThe Real Story\nWhile Emilys tale is fiction, the eerie struggle she faced mirrors Snaps real-world challenges with managing ephemeral messaging across a microservices architecture. With millions of users posting stories from around the world, the Snap engineering team had to contend with high volumes of data interacting across multiple services, databases, and cloud providers.\nEnsuring resiliency and consistent event delivery in these circumstances is no small feat. And with their modern microservices architecture, the team at Snap faced a familiar challenge. The team was spending considerable time and effort orchestrating these services, writing code to handle errors and implement state tracking to ensure system resiliency.\nWhile message queues are essential for decoupling services and handling asynchronous processes, they come with inherent limitations, especially for ephemeral messaging. In the event of a network outage or a high-volume failure, queued messages can get backed up or even lost, undermining reliability. Additionally, message queues can be tricky to scale efficiently. Snaps team encountered these challenges firsthand: notifications would sometimes fail to deliver, and duplicate data processing jobs strained resources, driving up costs. While message queues provide short-term solutions, they dont solve the fundamental problem of tracking message states reliably across services.\nRecognizing that reliability was key to offering high-quality experiences for users and advertisers, Snap turned to Temporal to solve these issues. Temporals workflows allowed Snaps engineering team to create durable systems that manage retries automatically, track message states, and ensure no data gets lost, even when parts of the system falter. With Temporal, Snap could recover gracefully from disruptions  avoiding the nightmare of dropped messages and failed queues.\nIn the end, adopting Temporal ensured not only peace of mind but also a reliable platform to build on, free from the lurking horrors of ephemeral chaos.\nFor a more detailed exploration of this story, please see: Build a Reliable System in a Microservices World at Snap.\nIn the end, adopting Temporal ensured not only peace of mind but also a reliable platform to build on, free from the lurking horrors of ephemeral chaos.",featureImage:{title:"social-spooky-crypt",description:"social-spooky-crypt",url:"https://images.ctfassets.net/0uuz8ydxyd9p/53OWeaA3D9yMQjporZuNvC/d720fcb2b660524fd9a5cf6257b4e54d/social-spooky-crypt.png"},publishDate:"2024-10-31T00:00-07:00",metaDescription:"They say something strange happens deep within Snap Tower, hidden behind the pristine walls and endless lines of code.",metaTitle:"Spooky Stories: The vanishing messages at Snap tower",socialCard:{title:"social-spooky-crypt",description:"social-spooky-crypt",url:"https://images.ctfassets.net/0uuz8ydxyd9p/53OWeaA3D9yMQjporZuNvC/d720fcb2b660524fd9a5cf6257b4e54d/social-spooky-crypt.png"},tags:"Durable Execution,Architecture",slug:"spooky-stories-the-vanishing-messages-at-snap-tower",contentType:"blogPost",entityId:"5b5JJhBsTREAJSosGAeV3d",authors:[{id:"70yNkqv3xtx9IABfYGNpY1",name:"Tim Imkin",slug:"tim-imkin",jobTitle:"Technical Writer",photograph:{title:"tim-imkin",description:"tim-imkin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41KTMkWysUKnEJ5sbRqxL4/da2659d494eb36aae47787e9453d9cf8/tim-imkin.png"},company:"Temporal",contentType:"person"}],authorsString:"Tim Imkin",category:"Community",readingTime:5},{title:"Spooky Stories: Taming deployment complexity with Temporal",content:"(Part of our Spooky Stories series; there's also a video version available.)\nMeet Daniel Abraham, Founding Engineer at autokitteh, with a career history that has him standing at the crossroads of backend services, infrastructure, and developer productivity. Through his stints at DataDog and Google, he's accumulated battle-worn insights into managing deployment complexitya topic both terrifying and thrilling for those brave enough to navigate the depths.\nIn contrast to some of our other Spooky Stories where our theme has been things you should avoid doing in Temporal, this talk is about a common engineering nightmare that has nothing specifically to do with Temporal. However, as you will see, using Temporal will allow you to deal with this complexity much more easily, providing useful building blocks based on hard-won experience.\nIn a similar vein to Maxim Fateevs Designing a Workflow Engine from First Principles talk, let us descend together through the 7 Levels of Hell Deployment.\nLevel 0: Building a Single Repository\nLets start with a use case which many of you can probably recognize as very simple and trivial: I have a repo in GitHub I want to build.\nHere is an example from GitHubs own website on how to build and deploy a simple Go application:\nname: Go\non: [push]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n      - name: Setup Go\n        uses: actions/setup-go@v5\n        with:\n          go-version: '1.21.x'\n      - name: Install dependencies\n        run: go get .\n      - name: Build\n        run: go build -v ./...\n      - name: Test with the Go CLI\n        run: go test\n\nAs you can see, it's a simple YAML file that contains a few lines of code, and you can actually read it. You check out the code, you set up Go, you build it, you test it, and you're done!\nLevel 1: Deploying a Single Repository\nNow, if you want to deploy that repo somewhere, such as a Cloud provider, there are numerous starter workflow deployment examples available. Generally speaking, youre no longer doing ~10 lines of YAML for this; now its more like ~60 lines of YAML, requiring another ~30 lines of explanation to describe the file and how to configure it.\nSo while theres a little bit more trickery, once you know what youre doing, youre golden. So we can end this talk now and give everyone 50 minutes back, right?\nNot so fast! ;-)\nOnce you take this simple and trivial example out into the real world, especially for large companies, it gets much more complicated, very quickly, and starts to look like this:\n\n  \n\nLevel 2: Deploying Multiple Repositories\nLets start with just a taste of this complexity: instead of building a single repository, let's say we have multiple repositories in a single organization. For example, one for the UI, one for the backend, maybe a few different backend services, and they all interact with some common libraries.\nYou can no longer build a single repo and be done with it. Now, you have to build multiple repos and in order to do that, its basically whats known as a DAG (Directed Acyclic Graph), where you have multiple starting nodes because some of these repos can be built concurrently; they don't react with each other.\nYou don't want to build them sequentiallythat would be too slowbut also, some of them are dependencies for some other repo, so you have to join some of these builds as inputs for another build at a higher level, and ultimately you end up with some big binary based on builds from multiple repos.\nAnd, consider building for multiple operating systems, or hardware architectures. You take all of this complexity, and multiply it several times over.\n\n  \n\nYou ask yourself: Cant I just build one thing after another sequentially? While you can, with enough dependencies, this could potentially take hours to build a single binary, so this approach is a non-starter from a developer experience perspective.\nThe GitHub Actions approach we saw in the initial example for a single repo build still sort of works. But, imagine you have to run a few things in parallel. Considerations include:\n\n  How do you synchronize workflows in different repositories? (While there are triggers you can use, they relate to the beginning of something or progress within it, not necessarily the completion.)\n  How do you support fan-out and fan-in workflows that spawn multiple workflows in multiple repositories? (Repositories dont talk to each other!)\n  How do you differentiate between the success of a build and failure of a build? (Not just the fact that its started and has had some progress, or is finished.)\n\nTaken together, all of these things mean that if you want to solve these problems in a really robust way, you need to create a system for managing this. A system that includes software developers, getting together, in a team, with a charter, calling themselves Developer Excellence maybe, and undertaking a huge effort.\nAnd even if you think of this effort as only two people, or timeboxed to three monthswhich is optimistic, but possible, depending on the size of your buildseven that is a lot of time when you sit down and calculate it.\nYou also need to factor in considerations for this system:\n\n  The system needs to be as fast as possible\n  But, it also cant waste resources infinitely; you need to throttle it\n  But, this efficiency has to be subtle and not in a way thats perceivable by developers, in order to maintain velocity\n  You also need to maintain artifacts and provenance, like this build depended on that build, and that source code, and this version\n\nIf you think about designing the UI for all of this, the database for all of this it quickly becomes a nightmare in itself.\nAnd remember, we havent even gotten to a lot of the hard stuff yet. ;-)\nLevel 3: Blue Green Deployments\n\n  \n  *Image source: redhat.com\n  *\n\nFor people not familiar with the concept of blue green deployments, it means that instead of having one set of infrastructure components that you update whenever you do a release, you have two mirror environments: one of them is running the production code, and you have another backup environment. (Resulting in the famous adage: why pay for one system when you can pay twice for two systems? ;-))\nThe advantage of this approach is that when you deploy new code, you can release it to the backup environment and then route users to the new environment gradually as you make sure everythings working properly. This ensures the product is always up and responsive.\nHow a deployment works in this scenario is a procedure, where you start in some state, you deploy and install things in a specific place, you configure the router to switch to that place, and finally you wait anywhere from a few moments to a few hours, and then the procedure is complete.\nThis type of procedure is exactly what a Temporal Workflow can do. If you capture your deployment logic in a Temporal Workflow and Activities, you get all sorts of advantages for free. For instance, the deployment of a specific node could be an Activity. If that specific node failed, the Activity could be retried. And if something more fundamental failed, the whole Workflow can fail, thats very easy to implement. As opposed to needing an entire system that does this.\nTo be fair, Cloud providers usually do provide some kind of blue green deployment options, but if you stray just a little bit off the trodden path, you find that what you need to do is Impractical and sometimes impossible, unless again you have a system for it.\nSo now we have a system of Builds, were extending it to be a system of Builds and Deployments. This is a lot of work. Unless you can use Temporal, and then all of this is basically just two Workflowsone to handle Builds, one to handle Deploymentsand youre done! All of the configuration information such as where its being deployed, where its being built these are just input parameters for that Workflow. The different repos in a build can be represented by different Activities or Child Workflows.\nLevel 4: Manual Approval Steps\n\n  \n\nI mentioned before that we can wait during deployments. For example, as were monitoring the results of a blue green deployment to determine whether an old deployment is no longer necessary, in case we want to roll back.\nA common way to do that sometimes is to have manual approval steps. You can have a person such as an Ops Engineer, or a Site Reliability Engineer, signing off on some checklist of conditions and saying Ok, now we can declare this deployment done and move onto the next step. (Or, alternately, Now we can start the deployment, because Im sure that the code is correct.) This sort of manual approval process can also sometimes be a legal requirement.\nSo at the end of the day, you have a big red button and you need to press it in order to get it to do something.\nIf youve ever tried to create a system that allows for manual approval with people, you know that you will have:\n\n  A UI for that, because God Forbid you let people do something in a non-cool UI. ;-) (even if its internal)\n  A database, to keep the state of their choices and map it to all the things that they approve\n  A history of actions taken that can be audited\n\nThats quite a lot for something that ought to be a simple system.\nHow would you do this in Temporal?\nTemporal doesnt have a built-in fancy UI for manual approvals, but actually it can. For example, you can use Slack as your medium for approvals. People can send a Slack command or approve it as a message in some kind of channel, and all you have to do is have a Slack worker built in Temporal that receives events from your workspace and allows the code to send interactive messages.\nSo the Workflow we discussed earlier, that handled the deployment, it can start with an Activity that sends a message to a relevant channel or relevant person, asking Do you approve this? Is it ok?\nAnd thats about it! Because once they click that button or reply to that message, the Workflow gets that response as a Signal, as an Event, etc. and continues the Workflow.\nWhat happens if our Temporal server crashes during that time? Nothing. It will keep that knowledge. What happens if anything else crashes in the middle and comes back up? Nothing. We keep that State in Temporal.\nThe Workflow lives on practically forever (or however you configure it) waiting for people to make the choice and knowing how to map that choice to the right destination.\nLevel 5: Cloud Regions and Availability Zones\nNow, lets say your company is really successful, so much so that its becoming a victim of its own success. And now you have to deploy that product not just on that laptop thats hidden away somewhere in a closet, but rather in a real data center.\nPeople who have dealt with this for real, such as DevOps Engineers, know that this is not something for the meek. Theres a lot of support, a lot of help, a lot of examples on how to do things but this is where complexity really rears its ugly head.\n\n  \n\nHere is a map of AWS regions across the world. Google and Azure have something similar. You have multiple regions per continent (some in the US, some in Europe, some in Asia) and within each region, there are multiple availability zones.\nLets focus on availability zones first. Were not that successful yet, were just working in US East region, as a common example. But, you have to deploy your code in multiple availability zones in that region, because if something happens to that physical data centera natural disaster, a network outage, a fire in the building, etc.you want the other two data centers in its vicinity to continue working, doing some load balancing between the two.\nTherefore, you always want to deploy your code concurrently to multiple availability zones. Cloud providers have some solutions for that, but stray a little and once again you have to start deploying things on your own.\nThis might mean you need to manage deploying your own Kubernetes nodes to multiple availability zones in a region. You have to make sure the deployments happen not just concurrently but in a very synchronous way. You want to make sure that as much as possible the versions are the same in the same region. Maybe theres a backward compatibility bug where the UI for the latest version changes something that breaks with the older infrastructure. You want to make sure that this risk is averted as much as possible.\nLevel 6: Rolling Deployments\n\n  \n\nNow, what happens with regions? Your business is now even more successful, and have customers in the US, in Europe, in Asia. Some of them have requirements related to data residency, where they want to make sure their data doesnt leave the borders of their country.\nInitially, its easy to think of this naively: Ive seen this problem before with Availability Zones, so Ill just deploy everything at the same time! Right?\nEnter the concept of rolling deployments, another tactic for minimizing risk. This is a deployment that goes to US East first, then US West, then EU North, then EU East, and so on. If one of them fails, you pause, or maybe you roll back. But you dont deploy everything everywhere. Because when you have an outage, or bad code, or bugs, you limit the exposure of that bug by deploying it as a sequence of deployments rather than all at once.\nIn Temporal, this now evolves to a main workflow that controls subordinate Child Workflows. Once you know how to do a deployment in a given region, you can sequence deployments in a series. If one of them fails, you fail the entire Workflow for the entire world. The Saga Pattern is appropriate to use here, since you dont want to merely abort a Workflow if it errors out, you also need mitigations to undo those deployments and return the system to its most recent working state.\nIn DIY land, were now adding another system for Rolling Deployments that needs to be maintained. This system would need to see the progression of deployments as they made their way around the globe, and also provide insight if something broke, so you can see which deployments are the latest and which rolled back to their previous state. You also probably need another system to analyze logs of various components to find out what went wrong and how to fix it.\nMeanwhile, on the Temporal side, we are now up to three workflows. And we get deployment insight and error inspection for free, as the Temporal UI has the full history of all workflow execution.\nSide note: Companies who are able to afford this type of development of internal systems spend absurd amounts of money and time on them because they are necessary to be able to develop quickly. These systems are also generally seen as less valuable and important than the real customer-facing product, and so it becomes one uphill battle after another to not only build the internal systems in the first place, but also maintain them over time, let alone redesign them for lessons learned. The amount of time and money being poured into internal systems is amazing, and is entirely non-trivial to a companys bottom line.\nLevel 7: Canaries\n\n  \n\n(This is a concept that might not be as familiar to junior engineers.)\nWhat are canaries? How do they relate to deployments? How are they being implemented? And how does this relate to Temporal?\nA canary (as in canary in a coal mine) is a practice used by miners where if there was a risk of suffocation, they brought a canary in a cage with them. Since a canary is a small bird, it would suffer from these consequences first. So if you saw a canary in distress, you knew it was time to leave the mine.\nAs a metaphor in software engineering, we use canaries as a term that means basically that were deploying something in a minimal way, and want to see whats happening with it. Is it good? Is it bad? Is it incompatible with the previous version, so we need a more careful deployment? Does it have extra errors that we didnt used to have? Does it display an issue to users that is unexpected? Or, it might have a cool feature people were waiting for and theyre happy to experiment with it once they see it.\nIn order to implement canaries, theres not really a good system that Im familiar with. You always develop this internally, in house, because you need to manage that kind of experimentation. Its not just the building blocks of Ill deploy XYZ but rather Ill deploy them but I also need to monitor them to understand whats happening with them.\nThis also applies to a similar term called A/B Testing where you deploy two versions of the same thing, such as the front-end, and each version looks a little different. And you measure the engagement of both UIs to determine which is getting better engagement, better feedback, and you choose that one. This is also a type of canary.\nWhy do you need to handle canaries as special kinds of deployments? Because, you usually need to define the terms of these experiments in a very detailed way, such as exposing a specific percentage of users to a given version, or a specific group (segment) of users, or a random sampling of users.\nYou have to be careful about the percentage because you want to minimize risk. So you will start small, with only 1-5% of users seeing something new. (How do you tell thats happening in practice? You guessed it! Another system, this one an Experimentation Framework which allows you to define experiment variables and look at them like a lab experiment and measure the results). How do you measure an experiments effectiveness? You can use a monitoring system, such as DataDog or Prometheus, and look at metrics that youve defined, see them in a dashboard. And based on what you see, you decide to move forward with the experiment or not.\nAll of this is very manual, and if you manage to automate it, you need yet another system! And that system needs to implement the API to talk to your metrics systems that are measuring your experiments effectiveness, and thats yet another layer of complexity.\nWhile its not fair to say that a simple Workflow or a couple of Workflows could capture the complexity of canaries, there are many building blocks in Temporal to make this easier. For example, allow for gradual changes or undo a previous step if it failed. (Once again, drawing on the Saga pattern.) But there are other helpers as well. For example, talking to your metrics API. You can add that API into a Worker and it basically becomes a retrieval Activity.\nWrap-Up: Bringing it Back to Temporal\nSo how does all of this relate to Temporal?\nTemporal provides you with infrastructure that allows you to just plug in your additions to your code and logic and see it run robustly and reliably for you this is a huge step that a lot of companies usually dont have. Temporal helps to democratize this kind of technology and make it more widely available.\nAs we saw throughout, what requires numerous fully-fledged (and fully-staffed) internal systems to accomplish can be done with just adjustments to a handful of Workflows in Temporal. And the quality between the two (having managed Developer Excellence and Infrastructure teams at DataDog and Google before) is comparable, and in some ways Temporal is better than systems Ive used at previous companies.\nTemporal also supports the notion of composability. Workflows can be superimposed on top of other Workflows, and now you have a composition of logic rather than interconnection. Composition is almost always easier and safer than connecting systems together.\nTemporal components support the concept of blackboxing, where responsibility for one or more Workers can be assigned to specific developers. (For example, this developer is in charge of the workflow that handles blue green deployments and that developer is in charge of the rolling deployments.) While its expected these developers will talk to each other, they dont actually need to synchronize anything between them as long as the contracts are clear between their workers. They dont need to care how all the nitty-gritty is implemented under the hood, as long as the specified inputs and outputs match expectations.\nTemporal really is an ecosystem. Ive been to the last two Replay conventions, and you can see the change. Its not just developers scoping it out, you also have a whole ecosystem of service providers, people who know how to use Temporal and are ready, willing, and able to help companies integrate it into their systems. (Temporal themselves are working in this way of thinking with Nexus.)",featureImage:{title:"spooky-stories-oct29",description:"spooky-stories-oct29",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6p9FlqElI0LKL3LFTLhC3v/c4d4c755761436e43b2a9da7d2064816/spooky-stories-oct29.png"},publishDate:"2024-10-30T00:00-07:00",metaDescription:"Using Temporal to address deployment complexity, based on hard-won experience",metaTitle:"Spooky Stories: Taming deployment complexity with Temporal",socialCard:{title:"spooky-stories-oct29",description:"spooky-stories-oct29",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6p9FlqElI0LKL3LFTLhC3v/c4d4c755761436e43b2a9da7d2064816/spooky-stories-oct29.png"},tags:"Architecture",slug:"spooky-stories-taming-deployment-complexity-with-temporal",contentType:"blogPost",entityId:"2yMQuZZUq9RR5zQ5WxIkoy",authors:[{id:"7N32QQKdB8UlfWX27BOdmb",name:"Daniel Abraham",slug:"daniel-abraham",jobTitle:"Founding Engineer",photograph:{title:"autokitteh",description:"autokitteh",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2js0VrRK8ndHngwAkwVYeh/a4656127f74091e2e8ba8f691aa75138/1681758038931"},company:"autokitteh",contentType:"person"}],authorsString:"Daniel Abraham",category:"Community",readingTime:18},{title:"Modernizing monoliths with Temporal",content:"We regularly get asked, how can I modernize my monolith with Temporal? or How can Temporal help improve my systems if Im not using microservices?\nIn this post, well talk through the process we recommend for how and why you can improve your monolithic systems with Temporal.\nWhy Change a Monolith?\nI commonly see these reasons for monolith modernization:\n\n  Agility: monoliths can be hard to manage, complex, hard to change, hard to test. Microservices are smaller and might be quicker to change, test, and release.\n  Performance & scalability: scaling up a monolith requires a lot of resources. Usually there are certain parts of the monolith that need more resources, so they could be spun out and scaled up as separate services.\n  Cognitive load: monoliths are complex, with everything packed into one big application, which makes it difficult to understand, reason about, and contribute to.\n  Quality: monoliths are often built without reliable tests. Rewriting is seen as a path to add tests, gain a deeper understanding, and a chance to do it the right way this time.\n  Unclear domains and responsibilities: often monoliths are maintained by large teams or even multiple teams. The boundaries between areas of a monolith are often fuzzy or undefined, and as a result, responsibilities for maintenance are unclear or undefined.\n  High time to value: monolith release cycles are often long, due to the time needed to test and deploy them, which results in fewer releases to minimize the risk of change. Features are usually done for months before they are released.\n\nNot every monolith needs improvements. Well talk about improving a monolith without breaking it apart later.\nHow to Modernize: Domain Thinking\nWe recommend starting to understand and improve a monolith by breaking it down into domains. For this blog, you dont need to be an expert on Domain Driven Design. Our example will show a big system broken up into smaller pieces with relatively clear boundaries (domains), and we will talk about the benefits and challenges of breaking a system up this way.\nFor further reading, Domain Driven Design is a great book on the subject, and lays out an excellent path for breaking down a monolith:\n\n  Break the monolith design down into domains with bounded contexts\n  Identify entities and their relationships\n  Build a ubiquitous language for shared understanding of the domains, and the broader system\n\nThis method lays an excellent foundation for understanding and then improving a big system.\nHere we take an Order Management System monolith with everything written in J2EE. As we think about the different problem areas that lie within an order management system  things like the shopping cart, checking for fraud, etc., each of these is considered a domain in Domain Driven Design. (We can also split out certain elements to use technologies that are a better fit for our developers or easier to implement in a certain technology).\n\n  \n\nOnce domains are defined, a team can segment out pieces of a system that need clearer ownership, higher quality, better performance, and faster delivery time. In this way, modernization delivers value quickly and can be prioritized according to business objectives.\n\n  \n\nWe have helped many teams modernize their monoliths this way. We found success and created much business value using this approach.\nLimitations of Domain Deconstruction\nOne challenge we discovered was coordinating transaction processes that cross domain boundaries. In our order management system, an order spans many domains: the Order domain, an external fraud check service, the Inventory domain (to let it know an order is coming, check that inventory is available, and reserve it), a payment processing domain, the inventory domain again (to ship the order), and finally the Order domain again to close it.\nEach service has its own state (inventory counts, orders, catalog pricing, etc.), but an order processwhich spans domainshas its own state as well, and must keep all domains correctly updated as the order proceeds. A crash or an mishandled error will likely lead to loss of order state, and then the domains and systems will be out of sync.\nEphemeral State\nEphemeral state is a term for transaction process information that is only needed while the process is in flight (see Omar Diabs excellent article about this topic). One risk of keeping ephemeral state only in memory is that it might be lost if a system crashes. Cross-domain data consistency is a challenge with monoliths, and it comes to the foreground when solving monolith pain.\n\n  Turning monoliths into microservices means you must manage ephemeral state. Managing distributed transaction state with durable events, such as with Kafka, is one approach, but it brings its own set of pains: automated testing, keeping databases and the various event logs in sync, provisioning and modifying topics as the process changes, and trying to build visibility for all of these data stores.\n  \n  \n\nTemporal and Process Thinking\nOne of my (Joshs) great regrets from my time modernizing monoliths is that I didnt know about Temporal Workflows backed by event sourcing. In doing modernization without Temporal, the development teams I worked with pulled hot, high-change services out of the monoliths, resulting in clearer domains and better team ownership. But our modernization efforts ran out of momentum when there was a risk of losing ephemeral state. We ended up leaving complex processes in the monolith. They were slow to change, hard to test, and painful.\nSince my introduction to Temporal, my thinking has changed. Complex, distributed transactions become easy to define and make durable when using Temporal Workflows. Each process has its state, stored durably. Every step in the process is stored and tracked as an event. And nothing can get lost due to a bug or a crash. Theres no need to set up a database or event stream infrastructure to manage ephemeral state. Its as easy as writing code and using the Temporal SDK.\n\n  The result is the process can work across systems without any risk of state loss.\n  \n  \n\nIn this workflow, Temporal keeps the information about the process durably, and orchestrates the process across several different systems.\nBenefits Of Process Thinking and Temporal\nWith this approach, things get a lot nicer. With Temporals code-first orchestration, you get:\n\n  Process visibility\n  Cognitive simplicity\n  Domain division with orchestrated control\n  Management of ephemeral data\n  Testing simplicity\n  Scalability without data loss\n  No need for additional architecture to manage for keeping ephemeral state\n\nHeres how the orchestration code might look in Temporal:\n        public OrderOutput execute(OrderInput input) {\n        log.info(\"Order workflow started, orderId = {}\", input.getOrderId());\n\n        // Get items\n        List\u003COrderItem> orderItems = localActivities.getItems();\n\n        // Check fraud\n        activities.checkFraud(input);\n\n        // Prepare shipment\n        activities.prepareShipment(input);\n\n        // Charge customer\n        activities.chargeCustomer(input);\n\n        // Ship order items\n        List\u003CPromise\u003CVoid>> promiseList = new ArrayList\u003C>();\n        for (OrderItem orderItem : orderItems) {\n            log.info(\"Shipping item: {}\", orderItem.getDescription());\n            promiseList.add(Async.procedure(activities::shipOrder, input, orderItem));\n        }\n\n        // Wait for all items to ship\n        Promise.allOf(promiseList).get();\n\n        // Generate trackingId\n        String trackingId = Workflow.randomUUID().toString();\n        return new OrderOutput(trackingId, input.getAddress());\n    }\nThe events and orchestration all happen because of this code: a Temporal Workflow calling Activities. Because it is implemented as code, its much simpler to test compared with a process spanning four distributed systems, each with their own event topic, database, and microservice. Here, the orchestration is in one place, can be owned by a single team, and the ephemeral state is kept all in Temporals Workflow History.\n\n  Individual microservices dont need to manage ephemeral state, and can focus on their own domain. For example, the Inventory service doesnt need to manage in-flight orders - it can just manage inventory and accept changes driven by this orchestration. This makes for much simpler microservices that are easier to understand, change, and debug.\n  Heres how the an order would look in Temporal:\n\n\n  \n\nEvery order is tracked, inputs and outputs are part of the Event History, and debugging or inspection is so much easier.\nTemporal does a lot of the heavy lifting in this architecture: state, events, process metadata, and process history are all built-in to Temporal. Temporal Workflow code isnt complex (see the code snippet above), and it powerfully solves difficult challenges with modern distributed systems. Temporal SDKs let you focus on what should happen, while the management of process state is automatically handled for you.\nThe result of this refactoring of the monolith is a system built out of Workflows in Temporal and simple microservices. The architecture is simpler. Stronger boundaries now exist between services. There is much more transparency into the work being done by the system. Testing is also easier, with simple automated tests and no need to check for ephemeral state loss or consistency between services. The end result is a simpler, happier modernization path with a more reliable system at the end.\nKeep the Monolith, Add Durability\nYou may ask, what if I like my monolith, but I want to add durability and visibility. Can Temporal help? The answer is yes!\nAdding Temporal gives you visibility into your monolith, lets you test cross-domain processes easily, and most importantly, adds durability to these processes so data is never lost. This can make a monolith much easier to support, and make the processes flowing through your monolith more visible and reliable.\nStart by looking for processes that flow around and through your monolith, like the order example above, sort them by the ones you want to add reliability to the most, and implement Temporal Workflows for these processes. Temporal can manage these processes that touch databases, call external services, and interact with the domains in your monolith. Adding Temporal makes your monolith more durable and increases visibility. As part of using Temporal Workflows in your monolith, you can add tests for these key processes. This will let you change your monolith with more confidence and lower risk.\nConclusion\nWhether rearchitecting a monolith to microservices, or improving a monolith by adding Temporal Workflows, you can add durability, visibility, clarity, and increased feature turnaround time. By putting the focus on transaction processes, you can manage ephemeral state across domains easily and keep your system consistent and reliable.\nCheck out Temporal and see how it can simplify your architecture and code and make building distributed systems durable, flexible, and clear.",featureImage:{title:"yue-ma-KtEx7LYscXM-unsplash",description:"yue-ma-KtEx7LYscXM-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/66R2v0sappsE9EIPfGDbH5/8afe080b10586bbcecfdd9661de115bf/yue-ma-KtEx7LYscXM-unsplash.avif"},publishDate:"2024-10-30T00:00-04:00",metaDescription:"Break down your monolith, or improve your monolith, by adopting Temporal",metaTitle:"Modernizing monoliths with Temporal",socialCard:{title:"yue-ma-KtEx7LYscXM-unsplash",description:"yue-ma-KtEx7LYscXM-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/66R2v0sappsE9EIPfGDbH5/8afe080b10586bbcecfdd9661de115bf/yue-ma-KtEx7LYscXM-unsplash.avif"},tags:"Architecture",slug:"modernizing-monoliths-with-temporal",contentType:"blogPost",entityId:"2rOIi66GmobdPKoY2O2MvE",authors:[{id:"6SCT7ktnc7C7malyJV3UsQ",name:"Joshua Smith",slug:"joshua-smith",jobTitle:"Staff Solutions Architect",photograph:{title:"Josh Smith photo",description:"Josh Smith photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2DHNWCAITAPlTgzovWEEyW/1e105a12a16a24ca6db7f3c7ae0ef44b/1678726677795.jpeg"},contentType:"person"},{id:"4dsODPDNXZPwvTMknnOR7N",name:"Meagan Speare",slug:"meagan-speare",jobTitle:"Sr. Manager, Product Marketing",photograph:{title:"headshot-megan-speare",description:"headshot-megan-speare",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4cU6Eil7AyPgQDtc52XeS8/935bb30acca03ba2e011e5cc90be909c/meagan-speare.jpg"},contentType:"person"}],authorsString:"Joshua Smith, Meagan Speare",category:"Temporal Concepts",readingTime:9},{title:"Craft an error handling strategy with free hands-on training",content:"Today, we are delighted to announce the availability of four new hands-on training courses. Each course covers how to craft an error handling strategy using a specific SDK:\n\n  Crafting an Error Handling Strategy in Go\n  Crafting an Error Handling Strategy in Java\n  Crafting an Error Handling Strategy in Python\n  Crafting an Error Handling Strategy in TypeScript\n\nWhy Should I Take the Crafting an Error Handling Strategy Training?\nErrors happen. And when they do, you have to know how to handle them. Properly identifying and handling errors is crucial to the success of your application. With this knowledge, you can develop durable, stable applications that you can rely on.\nWhat Do These Courses Cover?\nWe have three main learning objectives that you will be able to do once you complete the course.\n1. Recommend an error handling strategy\nYoull acquire an understanding of how Temporal represents and handles errors. By the end of this course, youll understand the difference between platform and application errors, and how Temporal deals with both. Additionally, youll grasp the distinctions between timeouts and failures, and how they affect Temporal applications. Youll determine when its appropriate to fail an Activity Execution, how to fail a Workflow Execution, and when its appropriate to do either. Decisions like these significantly impact the reliability and efficiency of your Temporal applications.\n2. Implement an error handling strategy\nOnce you know how Temporal handles errors, youll be ready to implement strategies for handling failures. This includes creating custom Retry Policies to retry failures, associating Retry Policies with Activity Executions, and how to handle these failures when a retry isnt the solution. Youll also recognize when its appropriate for an error to not be retried, and instead propagated up the call stack.\n3. Integrate appropriate mechanisms for handling various types of errors\nFinally, youll handle Workflow Executions that dont go according to plan with a variety of techniques and patterns. Youll implement Activity Heartbeating for your long-running Activities to keep track of their progress. Youll decide when its appropriate to cancel a Workflow or terminate it. And youll use compensating actions to restore state following a failure in the Workflow Execution with the Saga pattern.\nWho Should Take this Course?\nThis course is appropriate for any Temporal application developer. Seriously, code fails, and you have to know how to handle it. We believe this course is foundational for every developer building Temporal applications. Because the topics covered in this course refer to Temporal 101: Introducing the Temporal Platform, we recommend that you first complete that course, as well as our Temporal 102: Exploring Durable execution course, which covers other topics related to successfully implementing of Temporal applications.\nIf you're ready to craft an error handling strategy, follow one of the links below and begin your free hands-on training:\n\n  Crafting an Error Handling Strategy in Go\n  Crafting an Error Handling Strategy in Java\n  Crafting an Error Handling Strategy in Python\n  Crafting an Error Handling Strategy in TypeScript\n\nWhat's Next for Temporal Training?\nThe Education Team is making progress on our developer track courses. One of our next milestones is to create course material about our newest SDK, .NET, and bring it up to parity with our other SDKs.\nReplay 2025 attendees will have a first hand opportunity to take these .NET courses live!, Be on the lookout for registration to open.",featureImage:{title:"mehdi-messrro-oOBZb7IfTMI-unsplash",description:"mehdi-messrro-oOBZb7IfTMI-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/71GQjvxHfMiYtelPXBYeiz/97ee62e2737069a67240f6aa1b2974ec/mehdi-messrro-oOBZb7IfTMI-unsplash.jpg"},publishDate:"2024-10-29T00:00-05:00",metaDescription:"Errors are bound to happen. When they do, you'll be able to craft a great error handling strategy with the information from our course.",metaTitle:"Craft an error handling strategy with free hands-on training",socialCard:{title:"Craft an Error Handling Strategy with Free Hands-on Training",description:"Craft an Error Handling Strategy with Free Hands-on Training",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5fNbW4QoZcbEqNbCAAn64K/542a4af1a956e4be64e2a7c6589eab21/Craft_an_Error_Handling_Strategy_blog.png"},tags:"Code Samples",slug:"error-handling-strategy-free-hands-on-training",contentType:"blogPost",entityId:"2ATu1ZOgxGoCgjz8Z7lJU8",authors:[{id:"1VQRqr0fVS9svnoX57cPKm",name:"Mason Egger",slug:"mason-egger",jobTitle:"Sr. Technical Curriculum Developer",photograph:{title:"mason egger",description:"mason egger",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7ouhODOdbYXBCMY8wynrGa/a184aa85abb1880f8857a60dc99ca825/11214847"},contentType:"person"}],authorsString:"Mason Egger",category:"How-To",readingTime:3},{title:"Multi-cloud: A giant leap for reliability with Temporal",content:"Temporal Cloud is now a multi-cloud platform. In this post, well explore how we leveraged Temporals own capabilities to expand our infrastructure from AWS to Google Cloud, the challenges we faced along the way, and how we solved them using cloud-agnostic workflows. Whether youre considering a multi-cloud strategy or interested in scaling distributed systems, our experience offers valuable insights into managing complexity while maintaining consistency across cloud providers.\nSoftware-as-a-Service (SaaS) and multi-cloud\nIn today's SaaS ecosystem, multi-cloud isn't just a technical choice  it's a business imperative driven by evolving customer needs and market dynamics.\nFor SaaS providers, multi-cloud generally means deploying and running your infrastructure and systems on different cloud providers without major modifications, while providing the same core functionality and user experience.\n\n  \n\nSeveral factors drive the SaaS industry to move toward multi-cloud solutions:\n\n  Customer preferences: Customers often have existing relationships with specific cloud providers. They prefer SaaS solutions that align with their cloud strategy.\n  Data residency and compliance: Different regions have varying data sovereignty laws, requiring data to be stored in specific geographic locations. Some regions might be available in some cloud providers but not others.\n  Risk mitigation: Some industries have requirements of having backup deployments in other providers. Offering multiple cloud providers enhances the disaster recovery of your customers, and reduces your dependency on a single cloud provider.\n  Market expansion: Accessing new markets where certain cloud providers have a stronger presence or are preferred/mandated.\n  Leveraging features: Some cloud providers offer unique services or capabilities you can use to create a great product experience.\n  Future-proofing: Pricing, features, and other factors might cause customers to move to a different cloud in the future. Going multi-cloud gives your customers the flexibility to adapt to future cloud strategies without needing to change SaaS providers.\n\nFundamentally, multi-cloud for SaaS is about adapting to a landscape where the choice of cloud infrastructure is increasingly driven by customer needs and preferences, rather than solely by the SaaS provider's technical considerations.\nThis is also true for Temporal Cloud: between 2023 and 2024, we took a journey to expand our presence from only Amazon Web Services (AWS), to get closer to customers trusting Google Cloud for their services.\nCloud, we have a problem\nThe path to multi-cloud isn't without its hurdles, from increased architectural complexity as you try to handle all the special cases, to ensuring consistency across environments with different features and APIs.\nOn top of that, managing multiple cloud platforms require a broader skill from engineering teams, and can complicate cost optimization efforts. Adding to the mix, you now need to maintain feature parity between cloud providers, adding to your development cycles.\nWhen deploying Temporal Servers for Temporal Cloud, we follow a few common and effective strategies for deploying consistent and repeatable infrastructure. However, when trying to leverage those for multi-cloud deployments, we hit their limitations pretty fast.\nContainerization and orchestration technologies like Kubernetes help standardize the deployment process for compute resources, but Kubernetes itself needs to be deployed first, as well as the nodes and network resources for your cluster, and those deployments are Cloud Provider-specific. There is also the Kubernetes Deployment annotations that providers offer to allow to configure special behaviors for the pods, such as load balancer configurations, which are different between the Cloud Providers. As an example, we can look at the manifest to deploy a service in AWS Elastic Kubernetes Service (EKS):\n# AWS EKS annotation example\napiVersion: v1\nkind: Service\nmetadata:\n  name: my-service\n  annotations:\n    service.beta.kubernetes.io/aws-load-balancer-type: nlb\n    service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing\n    service.beta.kubernetes.io/aws-load-balancer-attributes: load_balancing.cross_zone.enabled=true\nTo expose our service in EKS, we need to add three (3) different annotations for the aws-load-balancer-controller, to indicate that we want a network load balancer to expose our service (nlb), that the NLB should be publicly accessible (internet-facing), and that we authorize cross-zone load balancing  which means the load balancer can use all available backends even from different Availability Zones.\nIf we want to expose a similar service in Google Kubernetes Engine (GKE), we would need the following manifest:\n# GCP GKE annotation example\napiVersion: v1\nkind: Service\nmetadata:\n  name: my-service\n  annotations:\n    cloud.google.com/l4-rbs: enabled\nTo expose our service in GKE, we only need a single (1) annotation to instructs GKE to create a backend service-based external passthrough NLB, or more simply put the equivalent to what we did above for EKS.\nInfrastructure-as-Code (IaC) tools, such as Terraform or Pulumi, are invaluable for spawning and maintaining infrastructure. However, when a new Cloud Provider enters the equation, net new code often needs to be written. This is because IaC tools, for good reasons, tend to align closely with each Cloud Provider's specific APIs and resource models. As an example, the following is the HCL necessary for deploying an AWS load balancer with TLS termination using Terraform. Note that for simplification, this does not include the declaration of the linked resources (subnets, certificate, service receiving the traffic, ).\n# AWS Application Load Balancer in Terraform\nresource \"aws_lb\" \"example\" {\n  name               = \"example-lb\"\n  load_balancer_type = \"application\"\n  subnets            = [\"subnet-1\", \"subnet-2\"]\n}\n\nresource \"aws_lb_listener\" \"front_end\" {\n  load_balancer_arn = aws_lb.example.arn\n  port              = \"443\"\n  protocol          = \"HTTPS\"\n  certificate_arn   = \"arn:aws:acm:region:account:certificate/cert-id\"\n\n  default_action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.front_end.arn\n  }\n}\nWe need to create two (2) resources. First a load balancer using the aws_lb Terraform resource and defining the type of the load balancer and the list of subnets to attach to the load balancer. We also create a load balancer listener using the aws_lb_listener resource, which configures the port on which to receive traffic, the protocol for that traffic, and links to both the certificate to use for terminating TLS and the service to forward traffic to (target_group_arn).\nNow to set up a similar HTTPS load balancer in Google Cloud, we would need the following HCL file:\n  # GCP HTTPS Load Balancer in Terraform\n  resource \"google_compute_global_forwarding_rule\" \"default\" {\n    name       = \"global-rule\"\n    target     = google_compute_target_https_proxy.default.id\n    port_range = \"443\"\n  }\n\n  resource \"google_compute_target_https_proxy\" \"default\" {\n    name             = \"test-proxy\"\n    url_map          = google_compute_url_map.default.id\n    ssl_certificates = [\"projects/my-project/global/sslCertificates/my-cert\"]\n  }\n\n  resource \"google_compute_url_map\" \"default\" {\n    name            = \"url-map\"\n    default_service = google_compute_backend_service.default.id\n  }\nThis time we need to create three (3) resources. First a URL map using the google_compute_url_map resource, which allows to define rules and route requests to a backend service  in our case, we just use the default service. Then a target HTTPS proxy using the google_compute_target_https_proxy resource, which links to the certificate to use for terminating TLS, and to the URL map we just created. Finally, a global forwarding rule using the google_compute_global_forwarding_rule resource, which exposes the target proxy we defined on a specific port.\nWe can observe here that the difference in model between Google Cloud and AWS is not only in the name and type of resources, but in the chain of dependencies to create those resources: in AWS we define a load balancer and we attach listeners to it, while in Google Cloud we define routing rules and we attach a load balancer to those.\nAnd no matter what you do, there are sometimes clear differences in features between the Cloud Providers. For instance, Temporal depends on a visibility layer, for which we use AWS OpenSearch with no clear equivalent in Google Cloud directly compatible with ElasticSearch 7. This required us to work with another vendor to deploy our visibility layer in Google Cloud, thus a clearly different path than the one taken for AWS deployments.\nDeveloping abstraction or encapsulation layers to centralize the handling of discrepancies between providers becomes inevitable to keep sane codebases and processes. We have talked on a few occasions about how Temporal Cloud uses Temporal Cloud to deploy Temporal Cloud, and when building our services on Google Cloud, this definitely came in handy.\nFailure is not an option: using Temporal\n quick interlude: what is Temporal?\nNow if youre here reading about this, you probably know about Temporal or are at least intrigued by it. Lets put it this way: if youre building distributed systems, or even just distributed applications, you already know the headaches that come with it. State management, error handling, retries  the list goes on. Thats where Temporal comes in: it lets you write your business logic as if it were a monolithic, linear program.\nTemporal brings Durable Execution. This means that no matter where theres a failure, whether its bad code, an unavailable API or a burning computer, your code will continue to execute (probably on another machine, in the latter case, though  unless you succeed at salvaging it). Temporal allows for cleaner code, easier debugging, and more resilient systems. It's not the silver bullet that will find the question to life the universe and everything, but it sure makes life easier when you're dealing with complex, distributed processes.\n\n  \n\nAnd if youre curious, I gave a presentation about Temporal itself at Pycon Sweden last year, that you can watch here.\n ok, now were back in orbit!\nSo lets go back to what I was saying: we use Temporal to deploy Temporal Cloud, and this brought us a few advantages when setting up a new Cloud Provider. Internally, we have two control planes: one that is the user-facing control plane (User CP), which handles resources logically, and another that is the infrastructure control plane (Infra CP), which handles resources physically (as physically as cloud resources can be).\n\n  \n\nThanks to these two control planes, we already have an abstraction layer in place. The Infra CP is responsible for communicating with the external providers and provisioning (and deprovisioning) the required resources. It provides APIs to the User CP, which in turn does not need to communicate with any provider. Those two control planes are actually Temporal Namespaces with separate workers, and they exchange messages which generally contain all the information to identify a Temporal cluster, including the Cloud Provider in which it is deployed.\nAt the beginning of our journey, we identified a few limitations in the way we were doing things: the Infra CP assumed that all requests from the User CP were for AWS, since the latter was not provider-aware, and we only used single provider. Some of our Workflows were also written around AWS-specifics, which required different inputs for Google Cloud deployments, such as the AWS OpenSearch deployment parameters which were not matching one-to-one with the required parameters for our other search vendor.\nAs we started writing parallel, Google Cloud-specific Workflows, we took paused and looked at what we were building and how we could prevent our codebase from becoming messy, but also make it easier for our future selves. Instead of cluttering our code with if-else statements, we went with the creation of cloud-agnostic Temporal Workflows. These Workflows are built around the use of a factory that passes in the Cloud Provider received as input from the User CP, and returns an object implementing a known interface, that can then be used to spawn Child Workflows from our cloud-agnostic Workflow.\nLets take a look at a trimmed-down example in Go of how we use this factory pattern in our cloud-agnostic Workflows. We have defined an interface TemporalClusterProvider with all the methods we expect our provider to implement:\n// TemporalClusterProvider is an interface representing a provider that\n// can be used to deploy, manage and destroy a Temporal Cluster\ntype TemporalClusterProvider interface {\n\t// DeployPersistenceStore deploys the persistence store used\n\t// by the Temporal Server, e.g. cassandra\n\tDeployPersistenceStore(DeployPersistenceStoreInput) (DeployPersistenceStoreOutput, error)\n\n\t// DeployVisibilityPersistenceStore deploys the visibility persistence\n\t// store used by the Temporal Server, e.g. elasticsearch\n\tDeployVisibilityPersistenceStore(DeployVisibilityPersistenceStoreInput) (DeployVisibilityPersistenceStoreOutput, error)\n}\nAnd we wrote a factory function GetTemporalClusterProvider to return an implementation of the TemporalClusterProvider for the cloud provider required to handle the cluster passed as parameter. In this example, we support only AWS and Google Cloud, or raise an error if the provider is unsupported.\n// GetTemporalClusterProvider is a factory function that returns the\n// implementation of a TemporalClusterProvider that matches the Cloud\n// Provider of the provided Cluster\nfunc GetTemporalClusterProvider(cluster Cluster) (TemporalClusterProvider, error) {\n\tswitch cluster.CloudProvider {\n\tcase \"aws\":\n\t\treturn NewAwsTemporalClusterProvider(), nil\n\tcase \"gcp\":\n\t\treturn NewGcpTemporalClusterProvider(), nil\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"unsupported cloud provider: %s\", cluster.CloudProvider)\n\t}\n}\nWe can then use GetTemporalClusterProvider in the context of one of our cloud-agnostic Workflows to get a matching provider for the functionality we are looking for. Depending on the cloud provider, the operations can be very different, but from the code point of view of our cloud-agnostic Workflow, we are following the same set of tasks, as shown in DeployTemporalCluster below.\n// DeployTemporalCluster is a cloud-agnostic Workflow to deploy all the\n// resources needed for a Temporal Cluster, from the networks to the\n// persistence stores to the Temporal Server itself\nfunc (w *Workflows) DeployTemporalCluster(ctx workflow.Context, input DeployTemporalClusterInput) (DeployTemporalClusterOutput, error) {\n\t// Get the provider for the provided cluster details\n\tprovider, err := GetTemporalClusterProvider(input.Cluster)\n\tif err != nil {\n\t\treturn DeployTemporalClusterOutput{}, err\n\t}\n\n\t// Deploy the persistence store\n\tpers_stor_out, err := provider.DeployPersistenceStore(ctx, DeployPersistenceStoreInput{\n\t\t// ...\n\t})\n\tif err != nil {\n\t\treturn DeployTemporalClusterOutput{}, err\n\t}\n\t// Deploy the visibility persistence store\n\tvis_pers_stor_out, err := provider.DeployVisibilityPersistenceStore(ctx, DeployVisibilityPersistenceStoreInput{\n\t\t// ...\n\t})\n\tif err != nil {\n\t\treturn DeployTemporalClusterOutput{}, err\n\t}\n\n\t// Perform zero-gravity operations and other galactic activities\n\n\t// Return the details of the deployed Temporal Cluster\n\treturn DeployTemporalClusterOutput{\n\t\t// ...\n\t}, nil\n}\nWe get cloud-specific behaviors while keeping our code clean, easier to maintain and extensible. It also ensures not to miss feature parity, at least at the infrastructure level, as adding any new method to our provider interface will remind us to add it for other cloud providers.\nAs we combined this approach to Temporals handling of retries and replay-based recovery, we were able to save a lot of time and headaches. Indeed, when it happened that we missed some permissions that our Temporal Workers required, or overlooked that little detail in our code, Temporal was our escape shuttle. Instead of restarting entire processes from the beginning for each issue or mistake (and some resources can take time to deploy!), we could add the missing permissions, update the code, and wait for the next retry to happen. This streamlined our development and debugging processes, making our multi-cloud adaptation much more efficient.\nI see Temporal Cloud on Google Cloud! It is so beautiful.\nYes! Temporal Cloud is now available on Google Cloud. You can go to your account and create a new Namespace in any of our currently available regions, or talk with our sales teams about any other region you would be interested to see.\n\n  \n\nThe final frontier?\nWe are still working on getting to feature parity with AWS. Coming soon are features such as private connectivity (which is a great example or something requiring a different architecture between AWS and GCP, especially with GCPs limitations regarding the proxy protocol v2 headers), API keys support, export, Nexus and Multi-Region Namespaces.\n\n  \n\nWe also have plans to get to Azure next, where we will be able to once again leverage our cloud-agnostic Workflows to build the underlying infrastructure. Our factory pattern and interface-based approach will let us easily extend our system to support Azure-specific services while maintaining a consistent API for our cloud-agnostic Workflows. However, this does not mean that the Cloud Provider itself wont bring its share of challenges!\nKey Takeaways\n\n  Multi-cloud strategies are becoming essential for SaaS providers to meet diverse customer needs.\n  Challenges in multi-cloud deployments include managing different APIs, ensuring consistency, and maintaining feature parity.\n  Temporal's durable execution model can significantly reduce the complexity of managing distributed systems across multiple cloud providers.\n  Using cloud-agnostic Workflows with provider-specific implementations can help maintain a clean, extensible codebase in multi-cloud environments.\n  Temporal Cloud's journey to multi-cloud serves as a real-world example of these principles in action.\n",featureImage:{title:"Meerkat multi-cloud",description:"Meerkat multi-cloud",url:"https://images.ctfassets.net/0uuz8ydxyd9p/h0mKFz3G04WXJ3tpQGl08/8fe77cc39a978b468ebef53701dd428f/Meerkat_multi-cloud__1_.png"},publishDate:"2024-10-28T00:00-04:00",metaDescription:"Learn how Temporal Cloud expands to a multi-cloud platform, offering enhanced flexibility and scalability for diverse cloud environments.",metaTitle:"Making Temporal Cloud a Multi-Cloud Platform",socialCard:{title:"Global Footprint Replay 2024",description:"Global Footprint Replay 2024",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2iKwNQxTc6Dko41fld6D87/d694c629bdaf24d6fe81c410fff5cae6/Global_Footprint_Replay_2024.jpg"},tags:"Durable Execution,Cloud",slug:"multi-cloud-thats-one-small-step-for-temporal-one-giant-leap-for-reliability",contentType:"blogPost",entityId:"66aokPWjGfZP9BdIysDUPg",authors:[{id:"1t27RQ93yVE4rX4KmUeOjo",name:"Raphal Beamonte",slug:"raphael-beamonte",jobTitle:"Technical Lead, Infrastructure & Security",photograph:{title:"Raphael",description:"Raphael",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5z4hyVmP6HhEJzAGkVl78l/c767402b7e227a4abd67dc09d7fc86ee/Raph.jpeg"},biography:"Raphal is the Technical Lead, Infrastructure & Security at Temporal Technologies Inc. With a Ph.D. in Computer Engineering, he has spent over a decade immersed in the world of distributed systems, balancing hands-on work and the instruction of these complex concepts. His passion lies in scaling and optimizing not only systems but also teams and individuals. He joined Temporal to contribute to building the next era of distributed systems and aiding developers in crafting superior software more efficiently, all with a layer of open source.",contentType:"person"}],authorsString:"Raphal Beamonte",category:"Product News",readingTime:14},{title:"Spooky Stories: Chilling Temporal anti-patterns (part 2)",content:"Because it's Octoberthe spookiest time of yearI've used some of my favorite spooky movies to explain Temporal best practices and their corresponding anti-patterns in a fun, top 10 list format. If you haven't already seen it, please also check out Spooky Stories: Chilling Temporal Anti-Patterns (part 1).\nIf you prefer video/audio format, you can also check out the on-demand version of the original webinar.\n4. The MEGA Workflow\n\n  \n\nWhat does Steve McQueen have to do with Temporal? Sometimes people build workflows that try to do everything: model 50 different processes, automate everything that a whole team or organization might want to do in a single workflow. And that can be very hard to manage, and might also eat a car or a train. ;-)\nThere is a better way! Instead of a single \"blob\" process, model processes that are simple and straight-forward. If a process kicks off another process which kicks off yet another process, you're probably looking at three workflows rather than one big workflow that does it all.\nHow to tell when you might be facing a \"blob\" workflow? Here are some questions to ask yourself include:\n\n  Can you keep this whole process in your head at one time?\n  Does it adhere to the principles of Domain-Driven Design?\n  Can it be supported with a two-pizza team?\n  If something goes wrong, is it very easy to track down by workflow name which part of the application was the culprit?\n\nIf you answered \"no\" to one or more of these, this starts to create some nervousness around operating in production and maintaining the code long-term. It might be better to take certain parts of it and push it to a \"sub\" workflow or a workflow that you call separately. Another approach is to abstract concepts away, such as putting a particularly complex piece into its own function and not in the main Workflow code.\nThere's also a new feature in Temporal called Nexus which was highlighted during the Replay 2024 keynote. Nexus makes breaking out complex processes into simpler steps and management of processes between teams a lot easier.\nIn short: Check out Nexus, workflows should model one process, and you can break sub-processes into separate workflows and use standard distributed systems patterns for managing them.\n3. Arguing With Yourself\nLet Workflows Manage Process Status\n\n  \n\nSometimes people really love state machines, and they want to have a state machine in their Temporal Workflow. There are valid use cases for this, but I've noticed that sometimes the state machine can have a list of the next possible states and valid states to transition to, and the workflow can have the same thing, and sometimes they can be in conflict. At minimum, it's duplicate maintenance. But worst-case, the state machine may block valid workflow progress that could otherwise continue if there was no state machine. This can happen in the case of a bug or unanticipated state in the state machine, for example.\nA great resource about the general area of state management and Temporal is our State Machines Simplified technical guide.\nIf you're going to use Temporal to model your processes and model process state, you probably don't need an extra state machine. Instead, use the code-first development of Temporal to make State Management really easy.\nIn short: Don't have split-brain; use Temporal to manage process State.\n2. Hiding Behind the Chainsaws\nErroring Workflows and Activity Error Handling\n\n  \n\nFrom a classic Geico ad about horror movie characters making decisions that get them killed too soon. With Temporal, don't make decisions that kill your Workflows too soon!\nBy default with Temporal, when you call an Activity, it will retry forever. And this is fantastic in the situation where you're calling an external system such as an API or a database, because if it fails you don't need to write any retry code. You just write the code to call the external system, and Temporal will automatically retry activities until they work. This is one of Temporal's core strengths, and it can really simplify the code you write.\nThere are instances where this approach is suboptimal, however. For example, a workflow needs to finish really quickly or respond super fast so as not to hold up other work. Examples might be a workflow that blocks a UI response, or workflows that must finish within a certain time, such as a daily report. For this type of use case, Temporal allows you to customize the Retry Policiesfor example, to only make 3 retry attempts, or stop retrying after X seconds.\nIf your Workflow can handle responding in the fastest time (seconds) as well as a longer time, such as 10 minutes or more, and this is okay for your business process, don't customize your retry policies! Because if you do these customizations and the Activity fails, even in such a way as it could recover on subsequent retries, your entire Workflow will fail.\nSo ask yourself: Do you have to try that Action only 3 times? Would it be better if the Workflow eventually succeeded? If so, don't worry about customization, and let Temporal smart defaults handle it for you!\nIn short: If it fits your business processes, use the default settings to let Temporal Activities infinitely retry. Your workflows will then automatically succeed and won't die too soon, unlike the young people in this commercial.\n1. Hiding In a Room With One Exit\nUse Compensation to Give Yourself a Successful Outcome\n\n  \n\nI'm sure you've all seen a movie where someone's running away from a bad guy, and they run into a room and they hide, and then the bad guy walks through the one door and then they're trapped. Workflows can be like this too! You can write a Workflow that optimistically assumes everything will work out, but what if something doesn't work?\nWhen first starting out, it can be tempting to say, \"Well, if something goes wrong, I'll just fail the Workflow, and that'll be the end of that.\" But an interesting thing about Temporal is we make it really easy to elevate your thinking: If something goes wrong, can we still set things right?\nAs a concrete example, let's say you're writing a process that does booking for a rental car, a hotel, and a flight. Let's further suppose that the rental car booking went fine, the hotel booking went fine, but something goes wrong with the flight and it can't be booked. If you don't give yourself a way out, a way to succeed, you might stop there and say the process failed. But now, the user has an error, and also two reservations they can't use.\nFortunately, there is a technique in programming called compensation, sometimes talked about in the context of using the Saga Pattern. This means that you effectively \"undo\" the actions that preceded the failed action. In our booking example, we would fail on the airline reservation, and then un-reserve the hotel and rental car.\nAs mentioned in the previous point, for technical failures, Activities handle these very well, for example if an API is down or a database is slow temporarily. However, Temporal also allows you to think at a higher level about how to manage business failures, such as not being able to make a booking because the plane is full, or a money transfer from Account A to Account B failing because Account B doesn't exist or is invalid.\nTemporal allows you to ask a business stakeholder, \"If I can't do step 2, what should I do about step 1?\" The correct thing to do in these situations is to cancel the reservation and put money back into Account Athese are \"success\" from a business model point of view. And Temporal lets you program the answer into your Workflows so that they can always succeed.\nIn short: Give yourself an out, use compensation to have a backup plan in case your main plan fails. (And watch the Scream movies. :-))\nBut that's not all! There's also\nBonus Spookiness\nThese are not necessarily Temporal anti-patterns, but more horror-themed suggestions.\n\n  \n\n11. Bonus: Wandering into a Dark Alley\nUse Metrics and Visibility Built Into Temporal\n\n  \n\nPro-tip: Don't be the horror actress who walks down a dark alley. Temporal offers lots of ways to help you get out of the dark and understand how your Workflows are working:\n\n  Temporal SDK Metrics to monitor individual workers and your code's behavior\n  Temporal Cloud Metrics to measure the health and performance of Temporal infrastructure\n  Temporal Web UI with Workflow Execution state and metadata for debugging purposes\n  Temporal Visibility which allows you to set Search Attributes on your workflows and view, filter, and search for Workflow Executions that have a certain status or important attribute\n\n12. Bonus: Vampires Sucking Up All Your Resources\n\n  \n\nYou don't want vampires to suck up all of your blood, nor do you want Temporal to run out of capacity. For folks who are self-hosting, you can have a workload on your Temporal server that ends up using a lot more resources than you might expect, and this can cause major performance problems.\nIf you find yourself impacted by this, use rate limits to prevent \"Noisy Neighbor\" problems. The community posts Rate limit configuration and best practices and Rate limiting by Namespace allude to strategies you can use here.\n(Alternately, move to Temporal Cloud and our SaaS configuration will automatically make sure vampires aren't sucking up your resources.)\n13. Bonus: Splitting the Party!\n\n  \n\nIf you're a fan of the X-Files, you know that Mulder (the guy who believes in aliens) and Scully (the skeptical scientist) frequently don't stick together, which leaves Mulder seeing aliens and Scully not, and it drives me nuts.\nSo don't go it alone, don't split the party. Join the community, work with us, let's build some awesome applications together!",featureImage:{title:"social-lurch",description:"social-lurch",url:"https://images.ctfassets.net/0uuz8ydxyd9p/58fYwroKVsyJ6t0ehA2DiZ/b12b0af0d859098de4b6a9b25d8e0c2a/social-lurch.png"},publishDate:"2024-10-21T08:00-07:00",metaDescription:"Even more Temporal best practices (and their corresponding anti-patterns) explained.",metaTitle:"Spooky Stories: Chilling Temporal anti-patterns (part 2)",socialCard:{title:"social-lurch",description:"social-lurch",url:"https://images.ctfassets.net/0uuz8ydxyd9p/58fYwroKVsyJ6t0ehA2DiZ/b12b0af0d859098de4b6a9b25d8e0c2a/social-lurch.png"},tags:"",slug:"spooky-stories-chilling-temporal-anti-patterns-part-2",contentType:"blogPost",entityId:"1FqPHF5frAOe4FuKtQ4fWa",authors:[{id:"6SCT7ktnc7C7malyJV3UsQ",name:"Joshua Smith",slug:"joshua-smith",jobTitle:"Staff Solutions Architect",photograph:{title:"Josh Smith photo",description:"Josh Smith photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2DHNWCAITAPlTgzovWEEyW/1e105a12a16a24ca6db7f3c7ae0ef44b/1678726677795.jpeg"},contentType:"person"}],authorsString:"Joshua Smith",category:"Community",readingTime:9},{title:"Spooky Stories: Chilling Temporal anti-patterns (part 1)",content:"I was excited to present this topic, because my favorite part of my job is helping people learn how to use Temporal, solve their pain points, avoid perilous pitfalls, and just have fun using Temporal to make being a developer easier.\nBecause it's Octoberthe spookiest time of yearI will use some of my favorite spooky movies to explain Temporal best practices and their corresponding anti-patterns in a fun, top 10 list format. If you prefer video/audio format, you can also check out the on-demand version of the original webinar.\n10. Wrapping SDKs in Scary Ways\n\n  \n\nOne of the things we observe at Temporal is developers love to wrap libraries (for example, our SDKs) in other libraries, and then wrap those libraries in other libraries. (Hence, the chance for a mummy pun!)\nSometimes, wrapping the Temporal SDKs can be okay. For example, wrapping a thin \"shim\" layer that allows you to simplify security practices at a company, or make connections to Temporal Cloud easier, or make hooking up to metrics simple for developers. Another useful pattern is when people build a layer on top of Temporal for new developers to do simple workflows really easily (as long as they can also opt to use the SDKs directly). There's a fantastic Replay talk on this very topic from our friends at Cash App  Great tech is not enough: building trust to get the most out of Temporal. Essentially, adding a little bit to the Temporal SDKs to make development easier is awesome!\nThe anti-pattern is, if you wrap the Temporal SDK too far, you can end up hiding important features, or making it really difficult to update the SDK as improvements are made upstream. We've worked hard to ensure our SDKs are idiomatic, and they're open source, and if you have suggestions for improvements we'd love to hear them!\nIn short: Don't wrap the SDKs too deeply, to the point that they are hard to upgrade or maintain, or to the point where you end up breaking or hiding useful SDK features. We encourage you to work with us if you want improvements!\n9. Jump Scares: Not Done Yet\nIdempotency and Local Activities\n\n  \n\nOne of my favorite series of movies is Scream, and if you watch the Scream movies you might know that there's always a killer (sometimes two!) and without fail, once the killer's finally defeated, they come back one more time and jump scare everybody in the audience.\nHow does this relate to Temporal? Sometimes, people think things are done when they're not done yet. This is important when it comes to things like idempotency and Local Activities.\nWhen you're writing a function or a method in any programming language, \"idempotency\" means when you execute it multiple times it always has the same result, so you can execute it multiple times safely.\nLocal Activities are a variation of Activities in Temporal which run as part of the Workflow Execution process, and in order to reduce latency, they don't write their completion to Workflow History until they all have completed.\nIf you put these two togethera Workflow with a series of Local Activities, and whose Local Activities are not idempotentthis can cause surprise consequences.\nTake for example a use case of money transfers. You have a series of Local Activities that move money, and you are not correctly using Idempotency Keys to understand if an Activity is called more than once. If your application hits a bug (for example, one of the later Local Activities calls an API that your code relies on goes down after the money is moved by an earlier Local Activity), your Local Activity sequence will keep firing, and end up moving far more money than it's supposed to, because the Workflow History will never tell it to stop, because the Local Activity series hasn't completed in full yet.\nFor this reason, in general I recommend using regular Activities, not Local Activities. But if you do use them, know how they work, and always use idempotency when you're writing Temporal Activities.\nSee Idempotency and Durable Execution for best practices around this topic, as well as Max's community post that lays out the exact execution sequences between Local and regular Activities.\nIn short: Don't let your Workflow processing jump out at you and not be done yet when you think it's done.\n8. Not Using the Time Machine\nUse Time Travel to Save your mom your workflows\n\n  \n\nLike the movie Totally Killer, Temporal also gives you time travel superpowers.\nLet's say you have 100,000 Workflows and they all hit the same bug in one of your Activities. Maybe that bug did some math, and now your calculations are wrong, and all of your customers have 10,000 extra widgets.\nBut fear not Temporal has time travel! Every Workflow records every step within it to the Workflow Event History. And you can rewind that using a feature called Temporal Reset. If a Workflow pod in Temporal crashes, its Workflow Event History is also replayed.\nSo in our example, you would deploy a fix for your math Activity to production, and then reset your Workflows in batch back to an earlier step. Temporal will rewind all of your Workflows back before the problematic Activity was called, and then re-execute them through the same fixed code path, and now the math is correct.\nI've worked with several people who've done this in production with their workflows, and it's basically magic! You have a bug in production, you can rewind and replay with the bug fixed, and it fixes all of the workflows automatically.\nFor more information on this feature, see Temporal Time Traveling: Replay.\nIn short: Use Temporal time travel to save your mom or your workflows, in this case.\n7. An Overwhelming Amount of Tribbles\nManage workflow history size\n\n  \n\nTemporal's Workflow History is amazing: it lets you go back in time, it lets you keep track of every workflow you've ever done, and it's very performant. But one of the things you can't do is have unlimited Workflow History size, or you end up with Star Trek Tribble Trouble.\nWorkflow History has limits (albeit pretty high) in order to keep Workflow Replay and Reset performant. And new Temporal users can incorrectly assume that the Workflow History can have unlimited size, because Temporal is kind of magic. And unfortunately If the Event History exceeds 50Ki (51,200) Events, the Workflow Execution is terminated.\nHere are a couple of ways to keep the size of Workflow History down:\n\n  Don't keep too much data in your Temporal Workflows. If you need to work with large data, access it externally to the Workflow History.\n  Use Continue-As-New as needed; this passes the latest relevant state to a new Workflow Execution, with a fresh Event History.\n\nIn short: Be aware that Workflow History size has a limit, and keep this in mind when designing your workflows.\n6. Crossing the Streams\nTest for Determinism\n\n  \n\nIn Ghostbusters movies, there's a rule: don't cross the streams of the proton packs. In Temporal, we have a rule as well, which is that Workflows can be rewound, replayed, and reset. To support that, Workflows must be deterministic (meaning, given a particular input, it will always produce the same output).\nWhat you don't want is to cross one time stream with another time stream and cause weird things to start happening to your timeline. If you need to make a change to Workflow code, or a Workflow that's already running somewhere, you can do that as long as you don't break anything deterministically. To support this, we have features Workflow Versioning and Workflow Patching, which are both ways to make changes to your Workflow time stream without breaking existing Workflows in their Replay and Reset.\nNote: Activities do not have to be deterministic and you can make changes to them without consequences. Same with a Workflow that's still under active development. But if a Workflow is running in production, this is where Versioning and Patching come in.\nThere's an excellent course on Versioning Workflows which covers this topic more in-depth, and is highly recommended.\nA couple of great resources on testing for determinism are:\n\n  Replay Testing To Avoid Non-Determinism in Temporal Workflows\n  Altering Space-Time Continuum: Testing for Determinism in Temporal Workflows\n\nIn short: Don't cross your streams. Test for determinism and use Versioning to make sure you don't have any errors when you go to production.\n5. Leaving Handy Tools Sitting There\nUse Features like Signals, Updates, Polling\n\n  \n\nSometimes when you watch a horror movie, the heroes run right by something that would be super helpfula fire extinguisher, a first aid kit, a crowbar, a flashlightand it's SO frustrating! \"NO! Why?? Why don't you pick up the thing that would be super helpful to you?!\"\nI sometimes have the same feelings when I'm helping people out with Temporal. There are so many great Temporal features in our documentation and training you can rely on, such as:\n\n  Signals, Queries, and Updates\n  Best practices for Activity polling (code sample)\n  Interactive Workflows hands-on course\n  Examples of how to use Temporal\n\nIn short: Don't forget to \"loot the bodies\" and take from / learn about all the helpful Temporal features and resources that are available.\nKeep reading! Spooky Stories: Chilling Temporal Anti-Patterns (part 2)",featureImage:{title:"social-lurch",description:"social-lurch",url:"https://images.ctfassets.net/0uuz8ydxyd9p/58fYwroKVsyJ6t0ehA2DiZ/b12b0af0d859098de4b6a9b25d8e0c2a/social-lurch.png"},publishDate:"2024-10-17T07:00-07:00",metaDescription:"Temporal best practices (and their corresponding anti-patterns) explained.",metaTitle:"Spooky Stories: Chilling Temporal anti-patterns (part 1)",socialCard:{title:"social-lurch",description:"social-lurch",url:"https://images.ctfassets.net/0uuz8ydxyd9p/58fYwroKVsyJ6t0ehA2DiZ/b12b0af0d859098de4b6a9b25d8e0c2a/social-lurch.png"},tags:"",slug:"spooky-stories-chilling-temporal-anti-patterns-part-1",contentType:"blogPost",entityId:"2rFooh7Bd1z8DJPhyTiwtY",authors:[{id:"6SCT7ktnc7C7malyJV3UsQ",name:"Joshua Smith",slug:"joshua-smith",jobTitle:"Staff Solutions Architect",photograph:{title:"Josh Smith photo",description:"Josh Smith photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2DHNWCAITAPlTgzovWEEyW/1e105a12a16a24ca6db7f3c7ae0ef44b/1678726677795.jpeg"},contentType:"person"}],authorsString:"Joshua Smith",category:"Community",readingTime:9},{title:"Safe and scalable signal handling in Temporal Workflows",content:"Imagine these scenarios:\n\n  Your shipment-tracking Workflow needs to know when the item leaves the warehouse and is loaded into a truck. You could signal your Workflow when the truck driver scans the barcode, and the Workflow will update the status and send out notifications.\n  Users can add items to your e-commerce shopping cart Workflow. Update it to add the item, calculate the subtotal, and receive back the subtotal and updated item list to render.\n\nSignals and Updates are the Temporal messages that power these scenarios, enabling outside callers to interact with Workflows. But handling these messages can be tricky. Weve heard consistent customer feedback that due to three distinct categories of concurrency problems, its not always easy to code up blocking message handlers in Workflows.\nSo, weve launched a flurry of improvements to the developer experience for Signal and Update handlers. They will allow you to create powerful, interactive Workflows faster and with fewer lurking bugs.\nRead on to learn about them. But first, youll need a bit of background.\nMessage handling styles\nWhen youre handling a Signal or Update message in your Workflow, there are two coding styles you can adopt: Processing the requests in a handler, or using the handler only to queue up the work. Which should you choose?\nTo answer, Ill give a small Temporal history lesson as a way to introduce the styles and compare them on their merits, and then, Ill announce improvements that will help you choose the convenience of handlers more often.\nThe battle between handlers and queues\nThe Go SDKthe OG of Temporal SDKsexclusively uses Signal Channels which the main Workflow method receives Signals from. That is, there are no provided Signal handlers. Often, people receive a Signal from a channel and put it into a queue for later processing at a time of their choosing.\nHeres a Python example in this queueing style. Its inspired by the EntityBedrockWorkflow sample in Python, which demos a chatbot where Signals come in when a user prompts the AI.\nIn the handler, we do some light validation and put the work into a queue:\n@workflow.signal\nasync def user_prompt(self, prompt: str) -> None:\n    if self.chat_ended:\n      workflow.logger.warn(f\"Message dropped due to chat closed: {prompt}\")\n      return\n\n      self.prompt_queue.append(prompt)\n\nThis is not too complicated, but now imagine adding a second type of Signal that needs to be handled in the order it was received. Youd end up with an event loop that iterates through your queue and switches on the Signal type. It quickly gets complicated and becomes hard to make type safe.\nThis is a shame, given that Temporal, by its nature, already provides you an event loop.\nSo, when we launched the Java SDK, we created Signal handlers and hoped people would shift to using them. And we continued this pattern in all subsequent languages.\nHeres the same Signal in handler style:\n@workflow.signal\nasync def user_prompt(self, prompt: str) -> None:\n  if self.chat_ended:\n     workflow.logger.warn(f\"Message dropped due to chat closed: {prompt}\")\n     return\n\n  self.conversation_history.append((\"user\", prompt))\n  #Get a response\n  response = await self.send_prompt_to_bedrock(prompt)\n  self.conversation_history[-1].add_response(response)\n\nAs you can see, this style is more convenientit looks like an API in any web application.\nHowever, theres a catch. During the call to send_prompt_to_bedrock, this handler might interleave with others as Signals come in, causing race conditions. Can you spot it? Well fix it later.\nUsers reported three main types of issues with Signal handlers:\n\n  As above, its hard to reason about interleaved handlers, making it easy to write concurrency bugs.\n  With no initializer method available, in certain circumstances, handlers could run before the Workflow initialized, causing crashes.\n  It was hard to ensure that handlers complete before the Workflow exits.\n\nConfronted with these issues, developers often resorted to queues. After all, if you simply loop through your queue and process one message at a time, your work is serialized and there are no race conditions.\nAs we turned our attention to Workflow Updates, we saw that the handler style was even more suitable, enough so that we switched to handlers for Updates in Go. This is because returning values and exceptions directly to clients is much easier from a handler.\nSince the three problems apply to Updates as well, this gave us even more motivation to make all handlers safer and more useful, as youll see below.\nThere are still great use cases for queues, which give you absolute control over the ordering and timing of your work. Queues are especially useful when different messages are not processed independently of one another. For example, in a streaming-to-batch scenario where you want to aggregate various Signals before sending their payloads in a batch to an activity, place the work into a queue and periodically send out the work.\nWhat we built\nThis brings us to today, where we are announcing three improvements to Signal and Update handlers. Weve also completely revamped our docs and added samples.\nSynchronization Primitives\n\n  To help you serialize interleaved handlers without using a queue, you need concurrency primitives like locks.\n  Primitives are now available in all Temporal SDKs. These extensions guard critical sections, are replay-safe, and in most cases can be interrupted by Workflow cancellation.\n\nIn our chat example, we might fix the race condition with an asyncio.Lock like so:\n@workflow.signal\nasync def user_prompt(self, prompt: str) -> None:\n  # ...\n  async with self.conversation_history_lock:\n      self.conversation_history.append((\"user\", prompt))\n      #call an activity.\n      response = await self.send_prompt_to_bedrock(prompt)\n      self.conversation_history[-1].add_response(response)\n\n\n  Here in Python, we were able to simply recommend the built-in locking libraries with no wrapper. But in all other SDKs, we provide our own or recommend a third-party library, while embracing the style of its languages native primitives.\n  See our documentation for links to the appropriate locking primitives in each SDK.\n\nWorkflow Initialization Methods\n\n  Initialize your Workflow's state before handling messages. This prevents reading uninitialized instance variables.\n  In Typescript or Go, the game is the same: wait until after youve initialized before registering message handlers.\n  But if you use one of our object-oriented SDKs: Java, Python, .NET, or PHP, you havent had an easy way to do this until now.\n\n\n  Initializing at the top of your Workflows main method can cause faults:\n  @workflow.defn\n\nclass MyBadWorkflow:\ndef __init__(self) -> None:\n     self.helloee: Optional[str] = None\n\n@workflow.run\nasync def run(self, helloee: str) -> None:\n     self.helloee = helloee\n     #...\n\n@workflow.update\nasync def hello(self, greeting: str = hello) -> str:\n     #Bug! helloee could be None!\n     return f\"{greeting}, {self.helloee}!\"\n\nThis will break reliably with Signal-with-Start patterns, but could also occur unexpectedly in other scenarios where a Signal arrived before a Worker ran the first Task in the Workflow.\nTo fix this, in these SDKs, you may now annotate your Workflows constructor and receive the Workflows arguments in it. The constructor is guaranteed to run before your handler here:\n@workflow.defn\nclass MyGoodWorkflow:\n     @workflow.init\n     def __init__(self, helloee: str) -> None:\n         self.helloee = helloee\n\n@workflow.run\nasync def run(self, helloee: str) -> None:\n  #...\n\n@workflow.update\nasync def hello(self, greeting: str = hello) -> str:\n   #Works!\n   return f\"{greeting}, {self.helloee}!\"\n\n\n  We recommend that you use this pattern for any interactive Workflow, though note that you cannot make blocking calls in the constructor.\n  Workflow Init is available today in .NET, Python, and Java, and soon in PHP. Consult our documentation to get started.\n\nDangling Handlers\nBlocking handlers can accidentally be left partially finished when the Workflow completes or continues as new. We call these dangling handlers, and they can cause data inconsistency and leave clients with unmet expectations.\nBefore, for the main Workflow routine to tell when all the handlers are finished, youd need to do your own careful bookkeeping, which is cumbersome and error-prone.\nWeve now added a method, All Handlers Finished, that lets you await any remaining handlers. If you dont, we will warn you, reminding you to wait for this condition before you exit or continue as new. If you really want to abandon an unfinished handler, you may suppress this diagnostic using a Handler Unfinished Policy. See our documentation.\nSummary\nThis suite of concurrency-management primitives makes handling Updates and Signals breezier. We hope that this gives handler styles their day in the sun, while we still acknowledge that queuing is a powerful mechanism for advanced use cases.\nFurther reading\nWeve revamped our docs on message passing. Id like to call particular attention to our new overview of Message Handlers which provide a conceptual overview that will help you code with confidence.\n\n  Weve also built samples showing best practices for handlers in various languages.\n  See the Safe Message Handlers samples in Python, Typescript, .NET, and Go. Java is coming soon.\n\nFeedback?\nWed love your feedback on anything mentioned here, as well as Workflow Update, which is in Public Preview as of this writing. As usual, you can connect to our community via Slack, GitHub, or our forum.",featureImage:{title:"social-card-temporalite-blog",description:"social-card-temporalite-blog",url:"https://images.ctfassets.net/0uuz8ydxyd9p/43c3wR1aXhf2oLpXy8WReZ/b280baada058cdc1d0dc9a4b2aaff37a/social-card-temporalite-blog.jpg"},publishDate:"2024-10-15T09:00-07:00",metaDescription:"Avoid race conditions in Temporal Workflows. Learn how new Signal and Update handler tools improve safety, initialization, and concurrency control. ",metaTitle:"How to Use Temporal Signal Handlers Safely and Effectively",socialCard:{title:"social-card-temporalite-blog",description:"social-card-temporalite-blog",url:"https://images.ctfassets.net/0uuz8ydxyd9p/43c3wR1aXhf2oLpXy8WReZ/b280baada058cdc1d0dc9a4b2aaff37a/social-card-temporalite-blog.jpg"},tags:"Scaling,Security,Temporal Primitives",slug:"robust-message-handlers",contentType:"blogPost",entityId:"2TzLv8NfQ93GivwT9Qa8jZ",authors:[{id:"LS7zQaCnktCD3qgirNPPc",name:"Drew Hoskins",slug:"drew-hoskins",jobTitle:"Staff Product Manager",photograph:{title:"Drew Hoskins",description:"Drew Hoskins",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6GobjHlaiDrKY2bzxlg2Am/da3be8bc14fe893c6db62178b96ce7f1/Drew_Hoskins_Headshot.png"},biography:"Drew Hoskins is a Staff Product Manager at Temporal focusing on improving the developer experience. Hes spent his whole career building developer technology, most recently as a Staff Engineer at Stripe where he founded and built out the Workflow Engine, a popular internal framework built on Temporal. You can follow his writings on software engineering at The Product-Minded Engineer, https://drewhoskins.substack.com/.",website:"https://drewhoskins.substack.com",company:"Temporal",contentType:"person"}],authorsString:"Drew Hoskins",category:"How-To",readingTime:8},{title:"Durable Execution: A better way to build distributed systems",content:"Durable Execution is a concept used by companies such as Stripe, Netflix, HashiCorp, Datadog, and many others to address a variety of challenges in distributed systems. In this post, we look at those challenges, how durable execution can solve them, the new programming possibilities it introduces, and how it makes distributed system patterns easier.\nDistributed Systems\nBefore the rise of cloud computing and microservices in the early 2010s, most applications used a monolithic architecture. In this model, all components were deployed as one unit and shared a single database, usually located in a local datacenter. This approach made development slow and risky because changes in one part could cause problems in others. Scalability was limited by hardware, and adding new servers often took weeks or months.\nWith cloud computing, companies moved to virtualized infrastructure on platforms like AWS, Azure, or GCP. Applications also shifted to microservices, breaking down into smaller, independent components. This made it easier to update and scale parts of the system quickly and safely.\n\n  Today, most applications are distributed systems, where components communicate over networks. This shift brings new challenges, as remote connections introduce potential points of failure, making it harder for developers to keep everything consistent and reliable.\n  Let's say youre working in a distributed system and you need to charge a credit card and update the database at the same time:\n\npublic async Task\u003Cint> HandleRequestAsync()\n{\n    await paymentAPI.ChargeCardAsync();\n    await database.InsertOrderAsync();\n    return 200;\n}\n\nThis post uses C# as an example.\nIf the card is charged but the database update fails, the system ends up in an inconsistent state: the customer is charged, but theres no record of it. You might try to fix this by retrying the database update until it works.\nThis could work if InsertOrderAsync() can safely be retried and the database issue is temporary. But if the process thats retrying crashes before it finishes, the system is still left in an inconsistent state.\nTo avoid this, your application needs to:\n\n  Save order details.\n  Keep track of which steps are completed.\n  Have a worker process to finish any incomplete tasks.\n\nNow imagine that the application has to do even more things, like updating inventory, creating a shipping label, or assigning a delivery driver. Writing the code to handle all the retries, timeouts, and saving state for each step can be overwhelming, and its easy to miss some edge cases or failure scenarios (see the full, scalable architecture. )\nDurable execution helps by automatically handling these complexities, so you can focus on building your application without worrying about all the failure handling details.\nDurable Execution\nDurable Execution guarantees that code runs to completion, regardless of hardware reliability, network stability, or service availability. This means that even if the hardware crashes, the network fails, or downstream services are temporarily unavailable, the code execution continues seamlessly. Timeouts and retries are handled automatically and transparently, and resources are efficiently managed by freeing them up when the system is idle, such as when waiting for a downstream service to become available again.\nThis is possible because Durable Execution systems like Temporal persist each step our code takes. If the process running the code fails, another process takes over, maintaining all the state information, including the call stack and local variables. For example, if an execution is blocked on an external API call and the machine that hosts it crashes, when the API call returns a few days later, the execution is recovered on a different machine still blocked on the same API call. Then, the call returns, and the execution continues to the next line. This ensures that the code execution continues without any loss of progress or data.\nNew Possibilities\nDurable execution is programming on a higher level of abstraction, where we dont have to be concerned about transient faults in our infrastructure or dependencies. It opens up new possibilities like:\n1. Writing code that sleeps for a month.\nWe can realistically have a method that sleeps for an arbitrary length of time, be it weeks, months, or years. Thanks to durable execution, we dont need to be concerned about whether the process can safely be expected to run for that period of timewe can be confident that another process will continue running the method at the specified time. For example, a subscription method can charge the users credit card every 30 days in a loop:\n  public async Task RunAsync(string userId)\n  {\n      while (true)\n      {\n          await Workflow.DelayAsync(TimeSpan.FromDays(30));\n\n          await Workflow.ExecuteActivityAsync(\n              () => MyActivities.Charge(userId),\n              new() { StartToCloseTimeout = TimeSpan.FromMinutes(5) });\n      }\n  }\nAfter it waits 30 days, it calls ExecuteActivityAsync to execute an activity. Activities are methods with normal code. They are the steps that are automatically timed out and retried. Here, if the Charge(userId) activity method fails or times out, it will be re-executed with exponential backoff, unless the error thrown is marked as non-retryable, like a card declined error.\n2. Workflows can receive RPCs and respond to queries.\nA workflow is a single instance of durable code execution. In the below example, a signal can be sent to notify of an order item, a query can be used to get the items, and a signal can be sent to perform checkout which will run an activity and complete the workflow:\n[Workflow]\npublic class ShoppingCartWorkflow\n{\n\tprivate PaymentDetails? paymentDetails;\n\n\t[WorkflowRun]\n\tpublic async Task\u003CCompletedOrder> RunAsync(ShopperInfo shopperInfo)\n\t{\n    \t// Wait for checkout\n    \tawait Workflow.WaitConditionAsync(() => paymentDetails != null);\n\n    \t// Do checkout and return\n    \treturn await Workflow.ExecuteActivityAsync(\n        \t() => OrderActivities.Checkout(shopperInfo, paymentDetails, Items),\n        \tnew() { StartToCloseTimeout = TimeSpan.FromMinutes(5) });\n\t}\n\n\t[WorkflowQuery]\n\tpublic List\u003CItem> Items { get } => new();\n\n\t[WorkflowSignal]\n\tpublic async Task AddItem(Item item) =>\n    \tItems.Add(item);\n\n\t[WorkflowSignal]\n\tpublic async Task CheckoutAsync(PaymentDetails paymentDetails) =>\n    \tthis.paymentDetails = paymentDetails;\n}\n3. Store state in instance variables instead of a database.\nSince a Workflow can be long running, and we can trust that an instance variable will always be there and be accurate, we can send an RPC to get the variables value instead of storing it in a DB:\nvar items = await handle.QueryAsync(workflow => workflow.Items);\nA query is a type of RPC that only returns data and doesn't mutate state.\nDistributed System Design Patterns the Temporal Way\nDurable execution makes it trivial or unnecessary to implement many distributed systems patterns, including event-driven architecture, task queues, sagas, cron jobs, state machines, circuit breakers, and transactional outboxes. For a more in-depth explanation of each of these, you can watch System Design on Easy ,Mode.\nDurable execution makes implementing patterns like event-driven architecture, task queues, and sagas straightforward:\n\n  Event-Driven Architecture: Temporal is event-driven, maintaining loose coupling and simplifying development and debugging.\n  Task queues: Temporal handles task distribution, reducing the need for custom queue management.\n  Sagas: Temporal orchestrates long-running transactions, automatically compensating for failures.\n\nEvent-Driven Architecture\nThe great benefit of Event-Driven Architecture (EDA)using a message bus to communicate between servicesis loose coupling at runtime. A service running step B can go down without losing requests or messing up the service running step A, since service A can keep publishing messages to the bus. When service B comes back up, it can read the messages it missed while it was down.\nHowever, EDA is tightly coupled when implemented at scale: making a breaking change to a message sent to a bus means finding all the other teams that depend on that message and getting them to deploy an update to their code before we can deploy our change.\nDurable execution is loosely coupled at runtime: Temporal is event-driven under the hood, and any piece can go down and come back up without dropping work. But it has a much better developer experience when building and evolving systems. Not only is it easier to code and make changes, but developers are also able to understand the system much better. Instead of studying disparate instances event-handling code to try to figure out what it does with events in which circumstances, or setting up and combing through distributed tracing a diagram, we can:\n\n  read the durable code to see what it does, and\n  view in the Temporal UI the steps every production function execution tookor even the current state of an in-progress execution.\n\nFor more on this topic, check out the keynote from the 2023 Replay conference: The way forward for event-driven architecture.\nTask Queues\nAnything that we would normally use task queues for can instead be accomplished with durable execution. Under the hood, every durable functionand every step the function takesis put on a task queue and distributed across a pool of workers. All we need to do is provide our code to Temporals worker library and ensure were running enough worker processes to get through all the work in the desired time frame.\nSagas\nSagas are long-running transactions that dont hold locks; instead, each step is executed sequentially, and if a step fails, previous steps are undone with compensating steps. This is a common pattern when we need to alter state thats stored across multiple data stores or other systems, and it requires either choreography (event-based) or orchestration (central coordinator) to be accurately implemented. The Microservices Patterns book recommends using orchestration for non-trivial use cases (and I'd argue for all use cases) due to the complexity of choreography (see event-driven architecture above), and durable execution is developer-friendly, automatic orchestrationit orchestrates each step our code takes.\nIn our first example, we can replace this request handler:\npublic async Task\u003Cint> HandleRequestAsync()\n{\n    await paymentAPI.ChargeCardAsync();\n    await database.InsertOrderAsync();\n    return 200;\n}\nwith executing a Workflow:\npublic async Task\u003Cint> HandleRequestAsync(order)\n{\n    await client.ExecuteWorkflowAsync(\n        (ProcessOrder workflow) => workflow.RunAsync(order),\n        new(id: order.OrderId, taskQueue: \"my-store\"));\n    return 200;\n}\nand the Workflow is a saga with two steps:\n[WorkflowRun]\npublic async Task RunAsync(Order order)\n{\n    await Workflow.ExecuteActivityAsync(\n        () => MyActivities.ChargeCardAsync(order.paymentInfo),\n        new() { StartToCloseTimeout = TimeSpan.FromMinutes(5) });\n\n    try\n    {\n        await Workflow.ExecuteActivityAsync(\n          () => MyActivities.CreateOrderAsync(order),\n          new() { StartToCloseTimeout = TimeSpan.FromMinutes(5) });\n    }\n    catch (ActivityFailureException ex)\n    {\n        Workflow.Logger.LogWarning(ex, \"Creating order failed, compensating\");\n            () => MyActivities.RefundCardAsync(order.paymentInfo),\n            new() { StartToCloseTimeout = TimeSpan.FromMinutes(5) });\n        throw;\n    }\n}\nIf the second stepCreateOrderAsynchas a non-retryable failure (like item out of stock), then we compensate by refunding the charge. (If it has a transient failure, like it's unable to reach the database, it will be retried.) The compensation, combined with the guarantee that the method will complete executing, makes this small, simple method a reliable long-running transaction!\nConclusion\nThis blog covered consistency in distributed systems, durable execution, and its benefits: new programming possibilities, and the simplification and acceleration of building distributed systems.\nDurable Execution offers the following advantages:\n\n  It increases development velocity by simplifying the coordination of services, APIs, and data stores, allowing features that once took 20 weeks to be built in just two weeks, with some completed in a day using Temporal.\n  It enhances reliability because a simpler codebase leads to fewer bugs. Durable Execution has been tested at scale by numerous companies, effectively handling much of the complexity for developers.\n  It significantly improves testability by providing a structured environment for testing, which allows developers to simulate various failure scenarios. Temporals Workflow history and replay capabilities ensure comprehensive test coverage and eliminate flakiness.\n  It enhances observability, as every step of the code execution can be tracked and viewed in Temporals UI. This visibility enables quick diagnosis of issues and aids in monitoring system health.\n  It makes debugging easier by providing better visibility, allowing developers to download execution logs and replay them locally. Fast-forwarding time during testing simplifies debugging scenarios.\n  It contributes to a positive user experience when systems operate reliably without failures, resulting in a smoother and more satisfying interaction for users.\n\nDurable execution significantly simplifies software development. There are systems like Temporal, Azure Durable Functions, AWS Simple Workflow Service, and Uber Cadence that provide durable execution. Temporal's founders, Maxim and Samar, have extensive experience with all these technologies. Samar developed the Durable Task Framework, which was later adopted by Azure Durable Functions. Maxim was the tech lead for the public release of AWS Simple Workflow Service. Both of them led the Cadence project at Uber before they founded Temporal in 2019.\nTemporal is open source (MIT license) with a large team of full-time engineers working to improve it. Temporal is used by thousands of companies for critical applications. If youve streamed a show on Netflix, ordered food from DoorDash, or made a payment through Stripe, youve experienced a Temporal Workflow.\nLearn more about the use cases of Stripe, Datadog, Coinbase, and others.\nFor more information, check out the recommended resources:\n\n  Video: Getting to know Temporal\n  Video: The way forward for event-driven architecture\n  .NET SDK:\n    \n      Full code example and more technical details in the launch post\n      Getting started tutorial\n      Docs\n      Samples\n      API reference\n    \n  \n  Course: Temporal 101\n  Community Slack\n  How Durable Execution Works\n\nTemporal also has runtimes for Go, Java, Python, TypeScript, and PHP. You can also use multiple languages, for instance having a .NET Workflow call activities implemented in Go and Java.\n\n  Ask us any questions in the Temporal Community Slack.\n  Get started today by downloading Temporal or signing up for Temporal Cloud.\n\nThank you to Rick Ross, Erica Sadun, Tom Wheeler, Drew Gorton, Chad Retz, and all the other Temporal team members for reviewing this post!",featureImage:{title:"social-card-image",description:"social-card-image",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1NfzbiO64uLGYOtl5hBwnw/8e88e819b8ef01edc766b2fb0f0b35fe/social-card-image.jpg"},publishDate:"2024-10-14T02:08-07:00",metaDescription:"Learn how Durable Execution solves common distributed systems challengesboosting reliability, observability, and development velocity with Temporal.",metaTitle:"Mastering Durable Execution in Distributed Systems",socialCard:{title:"social-card-dark-waves (1) ",description:"social-card-dark-waves (1) ",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7fqbHM7iWOHKJo0GNha3Ou/ca1d6b6c63ab327d9e872eefa5a33627/social-card-dark-waves__1__1.png"},tags:"Durable Execution",slug:"durable-execution-in-distributed-systems-increasing-observability",contentType:"blogPost",entityId:"4EnJbsqHtsQdgGeIdcxf5o",authors:[{id:"1K9fya5I763iDVBnr2WeLw",name:"Loren Sands-Ramshaw",slug:"loren-sands-ramshaw",jobTitle:"Developer Relations Engineer",photograph:{title:"Loren",description:"Loren",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3koq3MoNG4lPucMRTSkEUW/40ba102fafaba8524b8826b345ee55cd/loren-ivy-512-square.png"},twitterUrl:"https://twitter.com/lorendsr",linkedInUrl:"https://www.linkedin.com/in/lorensr/",contentType:"person"},{id:"7GV0xjBamDpDSZZ543r8yX",name:"Irina Belova",slug:"irina-belova",jobTitle:"Product Marketing",photograph:{title:"headshot-irina-belova",description:"headshot-irina-belova",url:"https://images.ctfassets.net/0uuz8ydxyd9p/BJ0w7WeAjw83DatmJ7Fin/a8facdb4b7206afe1e66dc73b216ec09/headshot-irina.png"},contentType:"person"}],authorsString:"Loren Sands-Ramshaw, Irina Belova",category:"Temporal Concepts",readingTime:12},{title:"Spooky Stories: Money transfers on the edge of town",content:"\n  \n\nThe bank on the edge of town was haunted - or at least, that's what folks often said.\nMost days, the bank's software worked just fine. But on nights when the moon was full, and the wind rustled in the leaves, and everything felt not-quite-right, things sometimes went very, very wrong.\nOn one chilly fall evening, the team was wrapping up after a busy day. Susan, one of the developers on the team, had tickets to see a movie at the theater in town. Her final task before leaving was to prepare the account balances file, which had to be uploaded so that transactions could be processed overnight.\nWhen the files were ready, Susan connected to the SFTP server and started the upload.\n\"Need any help?\" one of her colleagues asked.\n\"I'm all set,\" said Susan. \"Just waiting on this file to upload, it shouldn't take more than a few minutes.\"\nAs the last of her colleagues filed out the door, a warning popped up on Susan's monitor.\nUPLOAD FAILED\n\n\"Weird,\" Susan muttered to herself. She double checked the selected file, and tried again.\nUPLOAD FAILED\n\nHer computer was connected to the network, the server was online, and she'd never had an issue with this process before. Susan checked the time and realized with frustration that she'd miss the previews, but might still be able to make it in time for the movie's opening credits.\nUPLOAD FAILED\nA few miles away, previews had ended and the movie was just starting. Although the theater was relatively crowded, Susan's seat sat empty.\nUPLOAD FAILED\n\nA light breeze had picked up outside, rustling dry autumn leaves. Moonlight spilled through the office window.\nUPLOAD FAILED\n\nThe Real Story\nWhile Susan is fictional, her haunting tale is drawn largely from truth. The story is based on a financial institution that migrated its daily sweep process to Temporal.\nThe financial institutionlet's call them Money Co. to keep it simplewas using SFTP file uploads and downloads several times each day to communicate account balances and transfers between accounts with other financial institutions in their network. While this approach met regulatory needs and generally got the job done, a number of issues regularly caused headaches for Money Co. employees, including:\n\n  Uploads and downloads failed frequently, often requiring human intervention to fix.\n  The SFTP server would get overwhelmed with requests regularly, meaning the Money Co. team needed to pause operations until the server recovered.\n  Queries related to these operations could fail if the database was under heavy load.\n  To make matters worse, Money Co.'s own internal systems were not resilient to delays introduced by the above issues, and the engineering team often found themselves scrambling to fix issues in time to meet strict deadlines.\n\nFor a more detailed exploration of this story, please see Increasing Resiliency in a Banking Sweep System: Incremental migration to a Temporal Workflow\nMigrating these operations to Temporal allowed the Money Co. team to take advantage of Temporal's event history to help investigate the cause of any errors going forward. The migration itself was rolled out incrementally, allowing for intentional changes to roll out over time. Ultimately, migrating to Temporal delivered positive impact immediately, and ensured a more stable and resilient foundation for the future.\nReady to try Temporal yourself? Set up your local environment in under 10 minutes with our quick start guide.",featureImage:{title:"social-spooky-crypt",description:"social-spooky-crypt",url:"https://images.ctfassets.net/0uuz8ydxyd9p/53OWeaA3D9yMQjporZuNvC/d720fcb2b660524fd9a5cf6257b4e54d/social-spooky-crypt.png"},publishDate:"2024-10-09T09:00-07:00",metaDescription:"The bank on the edge of town was haunted - or at least, thats what folks often said.",metaTitle:"Spooky Stories: Money transfers on the edge of town",socialCard:{title:"social-spooky-crypt",description:"social-spooky-crypt",url:"https://images.ctfassets.net/0uuz8ydxyd9p/53OWeaA3D9yMQjporZuNvC/d720fcb2b660524fd9a5cf6257b4e54d/social-spooky-crypt.png"},tags:"Finance,Cloud",slug:"spooky-stories-money-transfers-on-the-edge-of-town",contentType:"blogPost",entityId:"aMul8WjJP7lCaFF87T0bO",authors:[{id:"18qI9Klto8BBXF4qObF8ET",name:"Angie Byron",slug:"angie-byron",jobTitle:"Senior Manager, Developer Advocacy & Community",photograph:{title:"Angie Byron",description:"Angie Byron",url:"https://images.ctfassets.net/0uuz8ydxyd9p/lBQUFwdlhhE1sWJ6Hkkyy/f00ae0b4854ad0b750e0f01297cffcc7/IMG_6961.jpeg"},biography:"Angie has been herding open source cats for 20+ years and in her spare time enjoys videos games, doodling silly cartoons, and wakka wakka wakka!",twitterUrl:"https://x.com/webchick",linkedInUrl:"https://www.linkedin.com/in/webchick/",website:"https://webchick.tech/",company:"Temporal",contentType:"person"}],authorsString:"Angie Byron",category:"Community",readingTime:3},{title:"Introducing Temporal Spooky Stories: Terrifying tales from *before* Temporal!",content:"\n  \n\nOctober marks the  spookiest season of the year! Well be honoring this glorious occasion by regaling Spooky Stories throughout the month about life before Temporal. Youll glean best practices and hear harrowing tales from community members, partners, and Temporalites alike!\nSpooky Stories will be added to this page throughout the month, so please watch this space! \n\n\n  Oct 1: Horrors of long-running, unpredictable workloads with Apache Kafka by Gabriel Harris-Rouquette, Senior Software Engineer @ Merit.\n  Oct. 4: Spooky Web Scraping, at Scale by Steve Poole, Developer Advocate for all things Java, Security, DevOps\n  Oct. 8: Money Transfers on the Edge of Town a spooky interpretation of a story by James Heller, Co-Founder and Principal Consultant @ Apartment 304\n  Oct 9: Chilling Temporal Anti-Patterns by Joshua Smith, Staff Solutions Architect @ Temporal\n    \n      See as blog post Anti-Patterns Part 1 and Anti-Patterns Part 2\n    \n  \n  Oct 15: Nightmares of Spiraling Deployment Complexity by Daniel Abraham, Founding Engineer @ autokitteh\n  Oct 16: The Ghosts of Systems Past: Zaq Wiedmann and Sr. Infrastructure Engineer II @ Khan Academy and Kate Pond, Sr. Software Engineer @ Openly\n  Oct 17: The Tale of the Haunted Costume Store: Cecil Phillips, Staff Developer Advocate @ Stripe\n  Oct 29: Eerie Ghosts of Temporal Past by Maxim Fateev, CTO @ Temporal (RSVP here)\n  Oct 29: Silence of the Lambdas and other Spooky Stories from Prod (Oakland, CA meetup with our friends at LaunchDarkly)\n  Oct 31: Terrifying Tales from the Temporal Trenches by Tihomir Surdilovic\nSenior Staff Developer Success Engineer @ Temporal (RSVP here)\n\n\nOur stories will conclude on Halloween (October 31) with the ULTIMATE spooky story from Temporals very own Tihomir Surdilovic, Senior Staff Developer Success Engineer. Youll gain an excellent understanding of the different types of issues that tend to occur, why, and how to troubleshoot them. Youll also pick up tips and best practices around monitoring and metrics. Head off hurdles before they become a problem!\nThis special event will be a version of his standing room-only talk from Replay 2024. If you missed it or if you want to revisit his advice, don't lose out on this opportunity! (RSVP link coming soon.)\nThere is also still time to contribute a Spooky Story of your own! ",featureImage:{title:"Spooky Stories (large size)",description:"Spooky Stories (large size)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3xygenKGoAHroFqkzW5GCP/9f748beebe9aa4804b5f1bc1912a55b6/Slide_16_9_-_2.png"},publishDate:"2024-09-30T03:47-08:00",metaDescription:"Spooky Stories about life before Temporal",metaTitle:"Temporal Spooky Stories",socialCard:{title:"Spooky Stories Announcement (social card)",description:"Spooky Stories Announcement (social card)",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2TqQ0Ftw0KLrQiaNTei91Y/62ae0db936b1d8f495c6b1d351993a64/8.png"},tags:"",slug:"spooky-stories",contentType:"blogPost",entityId:"4bDQoNt8zBPai7rRvMaWnW",authors:[{id:"18qI9Klto8BBXF4qObF8ET",name:"Angie Byron",slug:"angie-byron",jobTitle:"Senior Manager, Developer Advocacy & Community",photograph:{title:"Angie Byron",description:"Angie Byron",url:"https://images.ctfassets.net/0uuz8ydxyd9p/lBQUFwdlhhE1sWJ6Hkkyy/f00ae0b4854ad0b750e0f01297cffcc7/IMG_6961.jpeg"},biography:"Angie has been herding open source cats for 20+ years and in her spare time enjoys videos games, doodling silly cartoons, and wakka wakka wakka!",twitterUrl:"https://x.com/webchick",linkedInUrl:"https://www.linkedin.com/in/webchick/",website:"https://webchick.tech/",company:"Temporal",contentType:"person"}],authorsString:"Angie Byron",category:"Community",readingTime:2},{title:"OMS: A Temporal reference application for Order Management Systems",content:"Temporal provides a wealth of features that enable organizations to build scalable and reliable applications. Through our extensive documentation and SDK code samples, developers can quickly learn what a specific feature does and see an example of how to use it in a given SDK. While concise explanations and usage examples are essential, making Temporal accessible to a growing community requires that we also show them in context.\nThat's why we've recently announced OMS, a reference application that showcases the design and implementation of an order management system on the Temporal platform.\nOMS illustrates how Workflows, Child Workflows, Activities, Timers, Signals, Queries, Custom Data Converters, and several other features work together in the context of a relevant and relatable use case. This, in turn, helps developers and architects map their own business requirements to features provided by the Temporal platform.\nHow to Get Started with OMS?\nThe quickstart offers step-by-step instructions that will help you get the application up and running in just a few minutes.\nWe published a four-part video playlist on YouTube that gives an overview of the OMS and demonstrates how to set up and use it. The project's documentation details what's shown in those videos, including using the OMS with Temporal Cloud and enabling the application's built-in support for encryption. It also provides instructions for deploying the application to a Kubernetes cluster in AWS.\nThe technical description details the system's design and implementation, linking to relevant sections of the code as it walks through the steps involved in processing an order.\n\n  \n\nWhat's Next for OMS?\nThe application implements all of the capabilities we felt were required for the initial release, but there are plenty of opportunities to improve and expand on this in the future. What would you most like to see? Perhaps a new feature, such as email notifications? UI enhancements, such as a more traditional product listing and shopping cart in the web application? Maybe an implementation of the OMS using a different SDK, such as Java or Python? We're interested in your feedback, so feel free to start up a discussion in the #watercooler channel in Temporal's community Slack.",featureImage:{title:"clair-feature-image",description:"clair-feature-image",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41Sp92v0l4764RVqMDivBG/04ac2f7f28ef2e3654bab1b77e4734ba/clair-feature-image.png"},publishDate:"2024-09-26T00:00-04:00",metaDescription:"Our Order Management System (OMS) demo app helps developers learn core platform features in contextfrom Workflows to encryption and Kubernetes deployment.",metaTitle:"New Reference App to Learn Building with Temporal",socialCard:{title:"clair-feature-image",description:"clair-feature-image",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41Sp92v0l4764RVqMDivBG/04ac2f7f28ef2e3654bab1b77e4734ba/clair-feature-image.png"},tags:"Code Samples,Scaling",slug:"oms-a-temporal-reference-application-for-order-management-systems",contentType:"blogPost",entityId:"3HOxtevLWxFb77D4wTCUt0",authors:[{id:"6NFooJhrzJdVAxMRWhgeTl",name:"Tom Wheeler",slug:"tom-wheeler",jobTitle:"Principal Developer Advocate",photograph:{title:"Tom Wheeler",description:"Tom Wheeler",url:"https://images.ctfassets.net/0uuz8ydxyd9p/53ysX1Y47NqQaThXEVUny4/b1d9bbb620188ffc23a6a5098a80cfa5/tomwheeler-2024-headshot-800x800.webp"},biography:"Alternating between software engineering and technical education roles, Tom Wheeler's career spans more than 25 years in the financial, healthcare, defense, and tech industries. Prior to joining Temporal as the founding member of the Education team in 2022, he wrote training courses at Cloudera, developed aerospace engineering software at Object Computing, helped create a distributed system for high-volume data processing at WebMD, and built some of the earliest web applications at brokerage firm A.G. Edwards. When Tom manages to step away from the computer, you can probably find him cooking, traveling, or playing guitar.",company:"Temporal",contentType:"person"},{id:"5bp3Xb1CkUsMsCh2zoTrJA",name:"Paul Nordstrom",slug:"paul-nordstrom",jobTitle:"Principal Software Engineer",photograph:{title:"paul nordstrom",description:"paul nordstrom",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1P1tHSmZnhTIqgr925hGYX/ac05dfc9571b3d0a10f4531c8fc44fae/85532575"},contentType:"person"}],authorsString:"Tom Wheeler, Paul Nordstrom",category:"Announcements",readingTime:2},{title:"Replay 2024 recap: Day 2",content:"Navigating the early stages of my career felt like drifting in currents of space without truly knowing where I was going or what was pulling me forward. Today, I find myself on the edge of a new frontier, with a clear view of where Im headedand the promise of something evolutionary on the horizon.\nTemporal's Keynote\nAt Temporal, Im helping to introduce a concept that's truly out of this world: Durable Execution. I recently attended my second Temporal Replay conference, where I could sense the growing momentumlike the accelerating expansion of the universe. This years attendance jumped by 300, bringing 750 enthusiastic Temporal community members. The energy was electric, and Temporal's growth feels unstoppable. The keynote introduced Ziggy, our space-exploring tardigrade mascot.\nIts the perfect symboljust like the indestructible tardigrade, Temporals Durable Execution framework thrives in the harshest conditions, whether in deep space or mission-critical workflows. Tardigrades survive extreme temperatures, radiation, and the vacuum of spaceproof that Ziggy is durable just like Temporal.\n\n  \n\nA key highlight of the conference was the introduction of Nexus, an integrated feature of the Temporal platform designed to connect durable executions across team, namespace, region, and cloud boundaries.\nNexus solves the challenges of tightly coupled microservice workflows, security, and complexity, making collaboration and integration seamless. The demo sparked excitement among attendees eager to explore its potential.\n\n  \n\nSecond Day\nOn the second day of Replay, I attended a talk given by Rajesh Iyer, Executive Director - Software Engineering, from JPMorgan Chase. The bank handles $10 trillion in transactions daily with a workforce of over 290,000 people. Rajesh shared how Chase is modernizing its infrastructure by transitioning to the cloud and leveraging Temporal to ensure durability and reliability, particularly across payment services. Temporal allows Chase to standardize processes like fraud detection and settlement without the need for major refactoring. The decision to use Temporal Cloud marks a pivotal shift in how JPMC builds applications.\nAnother standout story came from Yum Brands, which has revolutionized their global order management system using Temporal. Before, developers were bogged down by retry logic and debugging, but now, every order at Taco Bell flows through Temporal workflows. This shift led to a 20% increase in digital sales, with 45% of their revenue now coming from online orders. Temporal also plays a key role in their loyalty and promotions services, ensuring processes are resilient and streamlined across 53,000 stores.\nOne of my favorite talks was by Temporal Cloud Principal Engineer Sergey Bykov who reviewed Temporal Cloud's new release process. Temporal Cloud operates on a continuous deployment model with bi-weekly release cycles, ensuring that the latest features from the Temporal open-source platform are promptly available on the cloud. Additionally, Temporal Cloud upgrades avoid introducing breaking changes through a ring deployment modeltested first in non-production environments and then gradually rolled out from the least to the most critical services.\n\n  \n\nBy the end of the conference, after the closing remarks from Temporal CEO Samar Abbas, the excitement in the air felt like a spacecraft preparing for liftoff. The Temporal community is unified and energizedlike weve tapped into something cosmic that similar to Temporal can live forever. I can't wait for Replay 2025 in London.\nIf you havent already, join our Slack community and say hellowe wont bite, but we might just take you on a journey into the stars.\nStay in the loop with more insights, tips, and updates for durable execution by following me on X: @CKielkopf, LinkedIn",featureImage:{title:"Sergey",description:"Sergey",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7sGBLQDBqeC4D1UYPYw96e/7b1c499f254b85df4556e8b5878ddd18/IMG_2693.jpg"},publishDate:"2024-09-20T00:00-04:00",metaDescription:"Get the top highlights and key takeaways from Day 2 of Temporal's annual community conference.",metaTitle:"Replay 2024 recap: Day 2",socialCard:{title:"Sergey",description:"Sergey",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7sGBLQDBqeC4D1UYPYw96e/7b1c499f254b85df4556e8b5878ddd18/IMG_2693.jpg"},tags:"Replay",slug:"replay-recap-day-2",contentType:"blogPost",entityId:"4tG5gEQF8DAPmKgJC90J7X",authors:[{id:"21emNDdyzd4s9srXH8Ase4",name:"Chris Kielkopf",slug:"chris-kielkopf",jobTitle:"Corporate Account Executive",photograph:{title:"Chris",description:"Chris",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1lnk5WaGgiTC3jzTGoEN8D/3feb947248bd18c7676e63d1bfe12cbc/Screenshot_2024-09-20_at_5.29.13_PM.png"},contentType:"person"}],authorsString:"Chris Kielkopf",category:"Community",readingTime:3},{title:"Replay 2024 recap: Day 1",content:"Today was the first day of Replay 2024, Temporals annual conference. In case you couldn't make it, I've compiled the day's top highlights and key takeaways.\nKeynote Session\nSamar Abbas, Co-Founder and CEO of Temporal, opened the keynote by asking, \"How many of these issues are due to non-durable execution?\" It followed with a live demo where participants played a game built using Temporal Workflows. This interactive demo highlighted Temporals ability to ensure Workflows survive in challenging conditions.\n\n  \n\nNext, Maxim Fateev, Co-Founder and CTO, discussed key challenges of distributed systems, and how Temporal, with over 20 years of research and eight years in production, is a trusted solution. Maxim also introduced Nexus, a new feature enabling Workflows to be triggered across Namespaces, which helps simplify system architecture.\nSamar returned to announce key updates: Workflow Update, Worker Auto-Tuning, and Worker Scalingall designed to improve user experience and reduce Worker management costs.\n\n  \n\nPreeti Somal, SVP of Engineering, highlighted Temporal Clouds growth and unveiled a few key announcements: a $1,000 promotion credit, API Keys, Google Cloud as the second cloud provider supported by Temporal Cloud (with Azure coming soon), and a Billing Center. She stressed that Temporal Cloud offers robust security, giving users full control over their environments.\nFinally, the session closed with a call to action: \"Unblock your creativity with Temporal!\"\nHighlights from Additional Sessions\nThere were a wide variety of sessions, presented by customers, partners, and Temporal employees. We will be publishing all the recordings following Replay, but in the meantime, here are top highlights from a few additional sessions I attended.\n\n  Great tech is not enough - building trust to get the most out of Temporal By Cashback App\n  This session highlighted strategies to expand Temporal usage by building an internal platform team. Key steps include collaborating with other teams through design reviews and pair programming, and simplifying Temporal with a custom Workflow SDK that meets most internal needs. Flexibility is important, as Temporal platform teams can operate differently from traditional ones. Celebrating the success of teams using Temporal and quantifying the impact, like reduced development time, are essential to promoting wider adoption.\n\n\n  Mastering Self-Hosted Temporal Clusters By Salesforce\n  The talk focused on managing high availability, scalability, and cost efficiency in self-hosted Temporal clusters. It discussed setting up multi-availability zones, handling unexpected pod disruptions, and addressing certificate expiration to ensure system reliability. On the scalability front, strategies included scaling based on application load, using Aurora for persistent storage, and setting per-Namespace resource limits for multi-tenant clusters, alongside enhanced monitoring and alerting. The session also emphasized the importance of controlling costs by optimizing resource utilizationparticularly compute, storage, and archivalwhile staying within budget.\n\n\n  Temporal Product Feedback | Managing Temporal Cloud Costs: Finance, Visibility\n  Jonathan Lacefield, Temporal Staff Product Manager, took the stage to announce the release of a new feature: the Billing Center. He demonstrated the updated billing platform and introduced the new roles that could be able to access the Billing Center. Additionally, usage APIs will soon be available, allowing users to query and retrieve detailed billing information. Temporal is actively seeking feedback from users on their cost management needs, including the level of granularity they require for cost insights.\n\nGet Ready for Day 2\nDay 2 of Replay 2024 tomorrow promises to be just as engaging and enlightening. Stay tuned for tomorrow's recap.",featureImage:{title:"Replay day 1 photo 2",description:"Replay day 1 photo 2",url:"https://images.ctfassets.net/0uuz8ydxyd9p/57UESmTvW1c7BtF86IVucv/2b7ca2e5d81c14aaae3f99083976f9c1/IMG_8625.jpg"},publishDate:"2024-09-19T00:00-04:00",metaDescription:"Get the top highlights and key takeaways from Day 1 of Temporal's annual community conference.",metaTitle:"Replay Conference 2024 Recap: Day 1",socialCard:{title:"Replay day 1 photo 2",description:"Replay day 1 photo 2",url:"https://images.ctfassets.net/0uuz8ydxyd9p/57UESmTvW1c7BtF86IVucv/2b7ca2e5d81c14aaae3f99083976f9c1/IMG_8625.jpg"},tags:"Replay",slug:"replay-2024-recap-day-1",contentType:"blogPost",entityId:"3oManyrRou879Kx4vy8vza",authors:[{id:"3pQ1pcczaCj0RlcdU6oyQ2",name:"Alice Yin",slug:"alice-yin",jobTitle:"Sr. Software Engineer",photograph:{title:"headshot-alice-yin",description:"headshot-alice-yin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/47jPcdz4dL0RZyi0seC1VC/86dba0aad07b06f3d1f079975d1619af/headshot-alice-yin.png"},contentType:"person"}],authorsString:"Alice Yin",category:"Community",readingTime:3},{title:"Unlock new possibilities with product updates from Replay 2024",content:"This morning, at Replay 2024, we rolled out key updates to help you build, scale, and manage Workflows more efficiently. Heres a summary of everything weve launched.\nElevate Your Developer Experience\n\n  Optimize performance automatically with the much-anticipated Worker Auto-Tuning. It automatically adjusts worker slots based on CPU and memory usage, maximizing efficiency and preventing out-of-memory errors with no manual tuning required.\n  \n    Make informed scaling decisions for your worker fleet based on real-time data with the Worker Scaling feature, and optimize the balance between speeding up workflow executions and managing the size and cost of your worker fleet.\n    These tools help you to focus on what matters most: building the business logic, without the distraction of managing complex infrastructure.\n  \n\n\n  \n\nBoost Productivity Across Your Teams\nIntroducing Temporal Nexus: Durable Execution Across Teams, Namespaces, Regions, and Clouds\nTemporal Nexus is a new feature of the Temporal platform designed to connect durable executions across team, namespace, region, and cloud boundaries. It promotes a more modular architecture for sharing a subset of your teams capabilities via well-defined service API contracts for other teams to use, that abstract underlying Temporal primitives, like Workflows, or execute arbitrary code.\nTemporal Nexus provides an integrated Temporal SDK experience, built-in Nexus Machinery, first-class observability, and enables each team to have their own namespace for improved security, troubleshooting, and blast radius isolation.\nTransform Real-Time Interactions\nWe are announcing Workflow Update - a powerful new feature that enables you to send updates and receive results synchronously - delivering real-time feedback and responsiveness that your users expect.\nWith Workflow Update, you can:\n\n  Build highly interactive applications, like shopping carts or live dashboards, where users instantly see the impact of their actions.\n  Ensure low-latency, real-time updates, even during heavy traffic, keeping your applications fast and reliable.\n  Prevent issues like race conditions with built-in validation and concurrency management, ensuring smooth, secure workflows.\n\nIts designed for developers who want to create seamless, interactive experiences without sacrificing performance or reliability.\nAdopt Temporal Cloud on Google Cloud\nTemporal Cloud on Google Cloud is now available in Public Preview, to give you more options for deploying Temporal Cloud. Based on growing demand, weve partnered with Google to bring this option to our customers. You can now launch a fully-managed Temporal Service on Google Cloud with a few clicks.\nWith Temporal Cloud on Google Cloud, you can:\n\n  Deploy production applications on Google Cloud today with enterprise support, white-glove services, and uptime SLAs.\n  Keep your workload traffic securely inside Google Cloud.\n  Deploy in two regions worldwide, with more regions coming soon. Please reach out to us if you dont see the region you prefer.\n\nThis release makes Temporal Cloud a multi-cloud platform, letting you choose to deploy on GCP or AWS depending on your preferences. You can manage and view your AWS and GCP Namespaces side by side, ensuring a seamless experience across both platforms.\n\n  \n\nEfficiently manage costs and billing in Temporal Cloud\nWeve launched new capabilities to manage your costs and billing more easily in Temporal Cloud:\n\n  Adopt Temporal Cloud with pay-as-you-go pricing through the AWS Marketplace. This is the most efficient way to get started with Temporal Cloud and provides simplified billing through AWS, so your Temporal Cloud usage appears alongside your other AWS services.\n  View and manage billing information with the new Billing Center in the Temporal Cloud UI. Understand and monitor current and historical costs, download invoices, and adjust credits cards.\n  Manage finances more effectively and securely with new roles. FinOps teams can now view and modify information in the Billing Center with the new RBAC role Finance Admin. The recently-added Account Owner role can access all resources within Temporal, including the Billing Center.\n\nThese tools give you the flexibility to deploy Temporal Cloud where you want and the transparency to manage your costs effectively.\nLearn how to build more effective Temporal applications\nWeve launched a new Order Management System (OMS) reference application to help you learn how to solve common development challenges with Temporal, and design and build more effective Temporal applications.\nIt can help you at every stage of your Temporal journey:\n\n  Learn how Temporal simplifies common development tasks with real-life scenarios for compensations, timers, human-in-the-loop and more.\n  Quickly understand how to use key features in Temporal like Workflows, Activities, Child Workflows, Local Activities, Signals, Queries, and more.\n  Incorporate vetted best practices into your applications by repurposing code from the reference application.\n\nCheck out the instructional videos here.\nExperience the Future with Temporal\nThese updates are designed to help you achieve your goals faster, with greater efficiency and control. Were excited for you to explore these updates and see how they can transform your workflows and operations.\n\n  Ask us any questions in the Temporal Community Slack.\n  Get started today by downloading Temporal or signing up for Temporal Cloud.\n",featureImage:{title:"Replay 2024 Product Announcement",description:"Replay 2024 Product Announcement",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2sWUsSbhlv46yAAvtLPoVN/2df04f172c6f7892b14bca01c47b4e28/IMG_2550.jpg"},publishDate:"2024-09-19T00:00-04:00",metaDescription:"Learn what's new in Temporal, with highlights including Nexus and Google Cloud support.",metaTitle:"Product Updates from Replay 2024",socialCard:{title:"Replay 2024 Product Announcement",description:"Replay 2024 Product Announcement",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2sWUsSbhlv46yAAvtLPoVN/2df04f172c6f7892b14bca01c47b4e28/IMG_2550.jpg"},tags:"Replay",slug:"unlock-new-possibilities-with-product-updates-from-replay-2024",contentType:"blogPost",entityId:"6nZJtIO3MMTMHFWNO5EGBI",authors:[{id:"7GV0xjBamDpDSZZ543r8yX",name:"Irina Belova",slug:"irina-belova",jobTitle:"Product Marketing",photograph:{title:"headshot-irina-belova",description:"headshot-irina-belova",url:"https://images.ctfassets.net/0uuz8ydxyd9p/BJ0w7WeAjw83DatmJ7Fin/a8facdb4b7206afe1e66dc73b216ec09/headshot-irina.png"},contentType:"person"},{id:"4dsODPDNXZPwvTMknnOR7N",name:"Meagan Speare",slug:"meagan-speare",jobTitle:"Sr. Manager, Product Marketing",photograph:{title:"headshot-megan-speare",description:"headshot-megan-speare",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4cU6Eil7AyPgQDtc52XeS8/935bb30acca03ba2e011e5cc90be909c/meagan-speare.jpg"},contentType:"person"}],authorsString:"Irina Belova, Meagan Speare",category:"Product News",readingTime:5},{title:"Durable RAG with Temporal and Chainlit",content:"Boosting Conversational AI with Durable RAG, Temporal, and Chainlit\nIn recent years, conversational AI has seen remarkable improvements, thanks to advancements in machine learning models such as Retrieval-Augmented Generation (RAG). RAG models combine the strength of large language models (LLMs) with external knowledge sources, improving the accuracy and relevancy of responses in real-time interactions. However, with the increasing complexity of conversational systems, managing long-running AI tasks, optimizing user interactions, and scaling such solutions have become challenges for developers.\n\n  To address these concerns, Techfabric wrote a detailed blog discussing the integration of Temporal, a workflow orchestration platform, and Chainlit, a framework for building interactive agents, with RAG has emerged as a game-changer. In this post, well explore how these technologies work together to build a Durable RAG\n  system that provides reliable, efficient, and scalable conversational AI.\n\nWhat is Retrieval-Augmented Generation (RAG)?\nRAG is a technique that augments language generation models by incorporating real-time retrieval of external knowledge. Instead of relying solely on pre-trained data, RAG can dynamically query databases, documents, or other knowledge sources to provide more contextually relevant responses. This ability to retrieve and use up-to-date information makes RAG particularly valuable for applications where accuracy and timeliness are crucial, such as customer support, legal services, or business intelligence.\nHowever, while RAG offers the potential for more informed conversations, it also brings new challenges:\n\n  Workflow Orchestration: RAG models involve multiple processes, such as fetching external data and integrating it with language generation. Ensuring these processes run smoothly across long durations is essential.\n  Scalability and Reliability: The model must be able to handle high-demand environments without sacrificing performance or accuracy.\n  User Interaction: Building a system where users can interact smoothly with RAG-based agents requires intuitive tools and interfaces.\n\nThis is where Temporal and Chainlit come into play, providing solutions for these challenges and enhancing the overall RAG experience.\nIntroducing Temporal: Orchestration for Durable Workflows\nTemporal is an open-source platform designed for orchestrating long-running workflows. It helps manage and automate complex processes by breaking them into smaller tasks that can run concurrently or sequentially. With Temporal, developers can handle workflows that involve multiple services and ensure that these services operate smoothly over time.\nIn the context of a Durable RAG system, Temporal plays a critical role in maintaining the efficiency and resilience of the model:\n\n  Durable Execution: Temporal ensures that tasks are not lost due to errors or interruptions. It makes workflows resilient by retrying failed tasks and persisting their state, which is vital for long-running RAG processes.\n  Scalability: Temporal allows RAG workflows to scale effortlessly, accommodating more complex use cases or higher demand without compromising performance.\n  Resource Optimization: By optimizing the way RAG retrieves and processes external data, Temporal helps ensure that resources are used efficiently, reducing operational costs in the long term.\n\nFor example, imagine a customer support bot that uses RAG to answer technical queries. The bot may need to retrieve data from various sources, such as user manuals, product databases, and customer histories. With Temporal, this multi-step workflow can be orchestrated effectively, ensuring that data retrieval, response generation, and error handling are coordinated smoothly.\nChainlit: Enhancing User Interaction in Conversational AI\nChainlit is a framework designed to simplify the development of AI-powered conversational agents. It focuses on creating intuitive user interfaces, making it easier for developers to build and deploy AI agents that are interactive and user-friendly. In combination with RAG and Temporal, Chainlit helps to bridge the gap between complex AI workflows and human users.\nHeres how Chainlit enhances a Durable RAG system:\n\n  Seamless User Experience: Chainlit offers pre-built components for common interactions, such as chatbots, data visualizations, and feedback systems. This allows developers to focus on the AIs core functionality, leaving the user interface (UI) and user experience (UX) to Chainlits highly customizable framework.\n  Rapid Prototyping and Deployment: Chainlit enables faster development of conversational agents. Its framework supports quick iterations, allowing developers to experiment with new features or integrations with minimal hassle.\n  Support for Complex Interactions: RAG-based systems often require multiple steps to generate accurate and useful responses. Chainlits user interface components help present this complexity in a way thats clear and easy for end-users to navigate, improving overall satisfaction.\n\nFor instance, in a legal advice chatbot that leverages RAG to provide accurate legal references, Chainlit can provide a sleek, user-friendly interface where users can input queries, view references, and ask follow-up questionsall while the underlying RAG system works to retrieve relevant documents and generate contextually aware responses.\nBuilding a Durable RAG System with Temporal and Chainlit\nNow that we understand the individual strengths of Temporal and Chainlit, lets explore how these technologies can be integrated to create a Durable RAG system that delivers reliability, efficiency, and scalability.\n1. Defining Long-Running Workflows: A Durable RAG system involves multiple steps such as querying external data sources, processing information, and generating language responses. Temporal enables developers to define these steps as durable workflows, ensuring that each step is completed correctly, even in the face of system failures.\n2. Managing Complex Interactions: RAG systems often involve interacting with multiple databases or external APIs. Temporal handles this complexity by orchestrating these interactions, ensuring that data is retrieved efficiently and responses are generated in a timely manner.\n3. Streamlining User Experience: Chainlit is the front-end solution that allows users to interact seamlessly with the Durable RAG system. With customizable UI components, Chainlit ensures that even complex workflows appear simple and intuitive to end-users.\nEnsuring Scalability and Reliability: Combining Temporals orchestration with Chainlits user-friendly interfaces ensures that the Durable RAG system is not only powerful but also scalable and reliable. Whether youre building a system for a small team or deploying a solution that serves thousands of users, Temporal and Chainlit work together to ensure that your RAG model performs optimally under load.\nConclusion\nBy integrating Temporal and Chainlit with Retrieval-Augmented Generation, developers can build a Durable RAG system that addresses the challenges of complex, long-running workflows and user interaction. Temporals ability to manage durable and scalable workflows complements Chainlits user-friendly interface for building conversational agents, resulting in a powerful AI system that can handle the demands of modern applications.\nThis combination offers a practical and efficient way to scale conversational AI, making it more reliable, cost-effective, and user-friendly. Whether youre building an AI-powered customer support system or an intelligent agent for knowledge retrieval, leveraging these tools can significantly enhance your RAG-based solutions performance and user experience.\nFor more information, visit: https://www.techfabric.com/blog/durable-rag-with-temporal-and-chainlit",featureImage:{title:"TechFabric Social Card",description:"TechFabric Social Card",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4c0OAxKzKjVgfjGbL8WRMj/d1c10640c323147e9439bb538e3c0094/TechFabric_Temporal_RAG_HeaderImage.png"},publishDate:"2024-09-14T05:00-04:00",metaDescription:"Learn about how Temporals durable execution framework can help solve this problem by bringing durability and resiliency into multi-step RAG workflows.",metaTitle:"Durable RAG with Temporal and Chainlit",socialCard:{title:"TechFabric Social Card",description:"TechFabric Social Card",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4c0OAxKzKjVgfjGbL8WRMj/d1c10640c323147e9439bb538e3c0094/TechFabric_Temporal_RAG_HeaderImage.png"},tags:"",slug:"durable-rag-with-temporal-and-chainlit",contentType:"blogPost",entityId:"keqM8V4feQpfhKu6KJlSX",authors:[{id:"3kajGDy7YHoLjGdI2VDJMp",name:"Sergey Ustimenko",slug:"sergey-ustimenko",jobTitle:"VP of Technology",photograph:{title:"Sergey Ustimenko",description:"Sergey Ustimenko",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7K1d21CanXCCESeD1iJbgJ/f2dc7a3716209efcf5ca259a4cc4a681/Sergey_Ustimenko_Headshot.jpeg"},company:"TechFabric",contentType:"person"}],authorsString:"Sergey Ustimenko",category:"How-To",readingTime:6},{title:"Pay-as-you-go pricing for Temporal Cloud on AWS Marketplace",content:"We are excited to announce that Temporal Cloud is now available on AWS Marketplace with pay-as-you-go pricing, offering developers in the AWS ecosystem the most streamlined path to using Temporal Cloud. This is the latest innovation in our ongoing commitment to make it effortless to access Temporal Cloud.\nTo celebrate this release, were offering a 3-month free trial with $1,000 in Temporal Cloud credits for developers who sign up through AWS Marketplace by September 27th.\n\n  \n    It was refreshingly easy to get started with Temporal Cloud with AWS Marketplace; it only took a few clicks and a couple of minutes between finding the listing and having our cloud account setup. The billing and provisioning steps being so simple makes the entire migration to cloud a much less daunting task for my team and me.\n     Jonty Preston, Software Engineer, Cisco\n  \n\nKey Benefits of Pay-as-You-Go Pricing on AWS Marketplace:\n\n  Self Serve, Fast: Start with Temporal Cloud in a few minutes with a few clicks.\n  Simplified Billing: Enjoy the convenience of consolidated billing through AWS - no need for a credit card. Temporal Cloud usage will appear alongside your other AWS services.\n  Free Trial: Get a 3-month free trial with $1,000 in Temporal Credits if you sign up by September 27th.\n  Consumption-Based Pricing: After the free trial, pay only for what you use with no upfront costs. Enjoy the flexibility of pricing that matches your needs.\n\nHow to Get Started:\n\n  Visit the Temporal Cloud pay-as-you-go listing on AWS Marketplace\n  Click View Purchase Options\n  Select Temporal Consumption under contract options\n  Click Create Contract\n  Complete the registration form in order to unlock the 3-month free trial + $1,000 in free credits, with pay-as-you-go billing thereafter\n\nOur new pay-as-you-go listing on AWS Marketplace is the fastest and most frictionless way to start with Temporal Cloudno credit card, no up-front cost and pay-as-you-go billing through AWS.\nReady to get started? Sign up here.\nHave questions? Were here to helpreach out to partners@temporal.io",featureImage:{title:"social-orb",description:"social-orb",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Tk0k2JzNldP4WvVCZzJzA/08592218f1fd8de9b5efd2ee10cf0364/social-orb.jpg"},publishDate:"2024-09-05T00:00-04:00",metaDescription:"Temporal is now available on the AWS Marketplace with flexible pay-as-you-go pricing, making it easier than ever to integrate scalable workflows.",metaTitle:"Temporal now on AWS Marketplace with pay-as-you-go pricing",socialCard:{title:"social-orb",description:"social-orb",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Tk0k2JzNldP4WvVCZzJzA/08592218f1fd8de9b5efd2ee10cf0364/social-orb.jpg"},tags:"Scaling",slug:"introducing-pay-as-you-go-pricing-for-temporal-cloud-on-the-aws-marketplace",contentType:"blogPost",entityId:"5yqS8lHfaLCo9rM1YiZGqj",authors:[{id:"6ZrqOx5rXn6dp0w49g7vDb",name:"Jay Sivachelvan",slug:"jay-sivachelvan",jobTitle:"VP of Partnerships",photograph:{title:"Jay Shivachelvan",description:"Jay Shivachelvan",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3RS0QEY2Zh9mZwIfIRC8jN/bd89483f6b2cbd610e955d9eb30458eb/TT31S6VK5-U05LKSQG753-7b4dcb8eea4b-512"},contentType:"person"}],authorsString:"Jay Sivachelvan",category:"Announcements",readingTime:2},{title:"Temporal expands in India: ap-south-2 (Hyderabad) now available",content:"Today we launched Temporal Cloud in ap-south-2 (Hyderabad), our second AWS region in India. In the past year, since we first launched in India in ap-south-1 (Mumbai), weve seen rapid uptake of Temporal within companies ranging from financial services to technology providers. The new region will allow us to continue serving this growing part of our community.\nWith two regions in India, you can now take advantage of Multi-Region Namespaces while complying with Indias strict data residency regulations. Multi-Region Namespaces lets you achieve a contractual SLA of 99.99% available uptime. The Temporal Service is deployed in a primary region, while a second region is available on standby for immediate failover in case of a primary region outage.\nFinally, our CTO and Co-Founder, Maxim Fateev, and other Temporal members will be in Bangalore the week of August 19th. If you are in Bangalore, wed love to see you at our meetup on August 20th, where you will have the opportunity to hear from Maxim, ask him questions, and learn how the team at Kotak Mahindra Bank is using Temporal.",featureImage:{title:"social-card-temporalite-blog",description:"social-card-temporalite-blog",url:"https://images.ctfassets.net/0uuz8ydxyd9p/43c3wR1aXhf2oLpXy8WReZ/b280baada058cdc1d0dc9a4b2aaff37a/social-card-temporalite-blog.jpg"},publishDate:"2024-08-12T00:00-04:00",metaDescription:"We're announcing a new region for Temporal Cloud in India to support this growing part of our community.",metaTitle:"Temporal expands in India: ap-south-2 (Hyderabad) now available",socialCard:{title:"social-card-temporalite-blog",description:"social-card-temporalite-blog",url:"https://images.ctfassets.net/0uuz8ydxyd9p/43c3wR1aXhf2oLpXy8WReZ/b280baada058cdc1d0dc9a4b2aaff37a/social-card-temporalite-blog.jpg"},tags:"Industry Events",slug:"temporal-expands-in-india-ap-south-2-hyderabad-now-available",contentType:"blogPost",entityId:"1dnuuHPIWZNcBtB3ZeIrsl",authors:[{id:"MCUTFqNLNNgiiy9UUZhtu",name:"Preeti Somal",slug:"preeti-somal",jobTitle:"Senior VP, Engineering",photograph:{title:"Preeti Somal",description:"Preeti Somal",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2rCtGkbfn1AuVq1K9BBbqY/d714dd855d39ed11eed844ded2d8a4fe/861A2388.jpg"},biography:"Preeti is Senior Vice President of Engineering at Temporal. Preeti is passionate about building great products, growing world class organizations and solving complex problems. Prior to Temporal, Preeti led the Platform, Security and IT engineering organizations at HashiCorp.  Her extensive career includes engineering leadership roles at Yahoo!, VMware and Oracle. While at Yahoo! Preeti was VP of Cloud Services in the Platform organization delivering highly scalable services used by engineers across Yahoo to build and operate applications with improved agility, reliability and security. These services power Yahoo!s consumer and advertising business.",company:"Temporal",contentType:"person"},{id:"4dsODPDNXZPwvTMknnOR7N",name:"Meagan Speare",slug:"meagan-speare",jobTitle:"Sr. Manager, Product Marketing",photograph:{title:"headshot-megan-speare",description:"headshot-megan-speare",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4cU6Eil7AyPgQDtc52XeS8/935bb30acca03ba2e011e5cc90be909c/meagan-speare.jpg"},contentType:"person"}],authorsString:"Preeti Somal, Meagan Speare",category:"Announcements",readingTime:1},{title:"Discover Temporals newest tutorials",content:"The Temporal Education team is excited to announce the release of several new tutorials published in July! These tutorials cover a range of topics and languages - from showing you how to build interactive applications such as booking systems or subscription-based services to how to deploy and maintain a Temporal Service. Here are the latest tutorials we have created in July:\nBuild a one-click order application with TypeScript and Next.js\nIn this tutorial, you'll learn how to enhance an e-commerce application using Workflows with Next.js. By integrating Temporal, you ensure that calls to external services like databases and payment gateways are reliable and fault-tolerant. You'll build a back-end API with Nest API Routes to start a Temporal Workflow and create a user interface with React and Tailwind to interact with the API. By the end, you'll have a functional full-stack example of an order processing system within a Next.js application.\nBuild a Work Queue Slack App with TypeScript and deploy it to production on DigitalOcean\nWhen building a TypeScript application, you typically develop and test it locally before deploying it to a public cloud provider for production. In this two-part tutorial, you will first build a Work Queue Slack App with TypeScript and Temporal locally using the Temporal CLI. Then, you will deploy it to production on a DigitalOcean Droplet using Temporal Cloud. By the end, you will have created a Slash command Slack App for managing work requests in a Slack channel, leveraging Workflows to manage state without a traditional database.\nBuild an email drip campaign with Temporal and Java\nIn this tutorial, you'll build an email drip campaign and a subscription web application using Temporal and Java, leveraging the Spring Boot framework. You'll create a web server to handle user requests and use Temporal Workflows, Activities, and Queries to manage the email subscription process without relying on a separate database or Task Queue. Users can provide their email address to start a new Workflow Execution that simulates sending emails at intervals, check their subscription status using Queries, and unsubscribe by canceling the Workflow Execution. The entire process will be monitored through Temporal's Web UI. By the end of this tutorial, you'll understand how to use Temporal to create and manage long-running Workflows within a web application.\nBuild a recurring billing subscription workflow with TypeScript\nIn this tutorial, you'll build backend processes for a phone subscription management application using TypeScript, focusing on the entire subscription lifecycle through command-line programs. Instead of creating a web app or API, you'll interact with Temporal through command-line scripts. You'll define and send Signals to cancel a subscription and update the price. You'll also define and send Queries to retrieve the current state of your subscription details. With these features, you'll be able to write a responsive subscription management application.\nBuild a trip booking application in Python\nWhen dealing with distributed systems, a single service failure can compromise the entire transaction. The Saga pattern solves this by breaking transactions into smaller steps, each with its own compensation logic for failures. Temporal orchestrates these long-running transactions, ensuring data consistency and automatically handling compensations. In this tutorial, you'll build a Flask API that uses Temporal to manage the booking process for cars, hotels, and flights, ensuring that any failure in the booking process triggers a rollback of previous steps to maintain data integrity.\nHow to deploy a Temporal Service using an SQLite backend with Nginx\nIn this tutorial, you'll configure and deploy the Temporal server and UI server binaries, create systemd unit files for automatic management, and set up an Nginx reverse proxy for web traffic ingress. This setup provides a production-ready Temporal Service with options for future scaling or migration to Temporal Cloud.\nHow to deploy a Temporal Service using an SQLite backend with Envoy\nIn this tutorial, you'll configure and deploy the two binaries needed for a complete Temporal Service (the Temporal server and the UI server). You'll create systemd unit files to gracefully run and restart the Temporal Service automatically upon server startup, and you'll deploy an Envoy edge proxy to handle web traffic ingress. This will give you everything you need to run a production Temporal Service, and evaluate how to scale further or migrate to Temporal Cloud.\nHow to configure a Temporal Service without a Proxy\nIn this tutorial, similar to the one above, you'll configure and deploy the two binaries needed for a Temporal Service. However, this approach excludes the use of an additional proxy, and focuses on configuring the Temporal server itself. This will be especially relevant for users wanting to deploy Temporal as part of Kubernetes or another orchestration system.\nWe hope that you enjoy our July tutorials! For more tutorials and courses, make sure to check out learn.temporal.io.",featureImage:{title:"yue-ma-KtEx7LYscXM-unsplash",description:"yue-ma-KtEx7LYscXM-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/66R2v0sappsE9EIPfGDbH5/8afe080b10586bbcecfdd9661de115bf/yue-ma-KtEx7LYscXM-unsplash.avif"},publishDate:"2024-08-02T00:00-07:00",metaDescription:"The Temporal Education team is excited to announce the release of several new tutorials published in July!",metaTitle:"Discover Temporals newest tutorials",socialCard:{title:"yue-ma-KtEx7LYscXM-unsplash",description:"yue-ma-KtEx7LYscXM-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/66R2v0sappsE9EIPfGDbH5/8afe080b10586bbcecfdd9661de115bf/yue-ma-KtEx7LYscXM-unsplash.avif"},tags:"Temporal Primitives",slug:"discover-temporals-newest-tutorials",contentType:"blogPost",entityId:"5GY7NhCHzxvgYaR691IlMl",authors:[{id:"gz6Asa7ycvY1HZz9vcJk0",name:"Angela Zhou",slug:"angela-zhou",jobTitle:"Senior Technical Curriculum Developer",photograph:{title:"headshot-angela-zhou",description:"headshot-angela-zhou",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3FgLhuMJuEASXJmzoNevWN/c115937f066329eb77cd75caa831bfbe/headshot-angela-zhou.png"},contentType:"person"}],authorsString:"Angela Zhou",category:"Announcements",readingTime:5},{title:"Announcing the Temporal Summer Camp 2024 Competition",content:"We are thrilled to announce the Summer Camp 2024 Competition at Temporal Technologies! This year, we are inviting all engineers and enthusiasts to participate in a contest designed to challenge your skills, spark your creativity, and win exciting prizes. We welcome participants of all skill levels to compete.\nThe Task\nYour mission is to create a set of Workflows and Activities using any or all of the Temporal SDKs that output the set of letters A-Z, in any order. You define what \"output\" means  let your imagination run wild!\n\n  \n\nWhy Participate?\n\n  It's fun! Create some smiles :)\n  Explore new ideas, push the boundaries of what's possible, and experiment with Temporal capabilities.\n  Engage in friendly competition with peers, learn from others, and share your knowledge.\n  Win prizes! Participants are eligible to win tickets to our annual Replay conference in Seattle this fall and exclusive Summer Camp swag.\n\nIdeas to Get You Started\nTo spark your creativity, Here are some great starting points:\n\n  Sleep Sort: Implement a sleep sort algorithm using workflows.\n  Races: Create workflows that compete in a virtual race.\n  Chained Workflows: Chain multiple workflows together for complex tasks.\n  Language Switching: Use multiple SDK languages in your workflows.How many can you add!?\n  Error Responses: Flex your error handling muscles. \"Signal not defined!?\" Show us cool and innovative ways to work with errors.\n  Trigger History Events: Generate specific history events and fetch the history.\n\nWeve included two simple Go SDK samples in our repository to help you get started: ./race and ./scavenger.\nHow to Enter\n\n  Visit the competition repository on GitHub\n  Develop Your Workflow. Write your code. Dont forget to include a basic README explaining how to run your workflow.\n  Submit your entry using our event participation form. Sadly, PRs without submission forms can't be considered for the competition prizes\n  Ensure your README includes a brief description of how your entry works. If your workflow has surprising or unintuitive behavior, feel free to keep the outcome a secret!\n\nComplete rules can be found in the README on GitHub.\nDeadline for entries: July 28st. Make sure to submit your code before the deadline to allow time for judging.\nJudging Criteria\nOur judges will look for:\n\n  Complexity with a twist: Charmingly pointless complexity. We love charmingly\n  Experimenting with limits: Push Temporal to its limits. It's okay. We're durable!\n  Novel outputs: Show us unique and unexpected methods of output.\n  Surprising behaviors: Use Temporal in surprising ways.\n  Using AI: Surprise us with innovative and silly ways to add AI to Temporal\n  Mixing SDK languages: Creative use of multiple SDKs.\n\nAnything that makes us smile or think will work in your favor!\nPrizes!\nThe top 3 winners will receive tickets to the Replay conference in Seattle this September, along with Cool Summer Camp swag.\nJoin our Community Slack to stay updated on the competition and connect with fellow participants.\nHappy Coding!",featureImage:{title:"Camp",description:"Camp",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4OTJ04JWhnHY7imqbjrf0t/e305e192f4efe4b219ff52933885a6dd/Screenshot_2024-07-08_at_8.04.58_PM.png"},publishDate:"2024-07-05T09:00-08:00",metaDescription:"We're announcing the Summer Camp 2024 Competition at Temporal Technologies! This year, we are inviting all engineers and enthusiasts to participate in a contest designed to challenge your skills, spark your creativity, and offer exciting prizes. ",metaTitle:"Announcing the Temporal Summer Camp 2024 Competition",tags:"Industry Events,Meetups",slug:"announcing-the-temporal-summer-camp-2024-competition",contentType:"blogPost",entityId:"2ei7rG3l33Nmz3EUJdBeKG",authors:[{id:"7GV0xjBamDpDSZZ543r8yX",name:"Irina Belova",slug:"irina-belova",jobTitle:"Product Marketing",photograph:{title:"headshot-irina-belova",description:"headshot-irina-belova",url:"https://images.ctfassets.net/0uuz8ydxyd9p/BJ0w7WeAjw83DatmJ7Fin/a8facdb4b7206afe1e66dc73b216ec09/headshot-irina.png"},contentType:"person"},{id:"765ncnsHQZyTqc5R3DmGMf",name:"Rob Holland",slug:"rob-holland",jobTitle:"Staff Developer Experience Engineer",photograph:{title:"Rob Holland",description:"Rob Holland",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5TYAt2gPMiffTdA6ZRdgY3/bfcc87ff9e19765d53c736981313889b/9563"},company:"Temporal",contentType:"person"}],authorsString:"Irina Belova, Rob Holland",category:"Announcements",readingTime:3},{title:"Enhancing sweep networks with Temporal Workflows for greater resiliency",content:"At Apartment 304, we're fortunate to work on interesting problems, like stabilizing a financial institution's sweep network system. This client, offering cash management accounts akin to checking and savings, sought to attract customers and mitigate financial risk. Like many financial institutions, they joined a sweep network, allowing them to offer higher interest rates and maximize their FDIC insurance.\nAlthough their initial integration was successful, it came with stability issues and operational hurdles that ideally should be resolved automatically, rather than requiring manual intervention from the engineering team. We worked with their team to prioritize the issues and made a plan to incrementally resolve them, instead of rewriting the whole process from scratch.\nTemporal's flexibility and convenient message passing made it easy to lift and shift workflow steps piece by piece, which reduced the time it took to see impactful stability improvements, and eliminated the risk of a full rewrite's single cut-over event.\nBefore diving in on the technical challenges and how we let Temporal do the heavy lifting, let's explore sweep networks.\nSweep networks in a nutshell\nA sweep network is a group of financial institutions that pool their deposited funds together. This lets them collectively manage their cash flow and balances while increasing financial stability across the network. For example, a financial institution might want to increase their lending business, which requires additional cash on hand. The institution can draw those funds from the sweep network. Conversely, some financial institutions carry a higher cash balance than they need, so they contribute their excess to the network.\nHow does this benefit the people banking at these financial institutions? They get higher interest rates and additional FDIC insurance coverage on their accounts.\nFrom the depositor's point of view, they deposit money into their financial institution like they would normally, but their institution allocates the funds across various institutions in the network.\n\n  \n\nUpon withdrawal, the reverse happens. The depositor withdraws from their account, and the financial institution recalculates the amount they need to withhold in their institution and rebalances the amounts shared across the network.\nChallenges in sweep network operations\nThe sweep process runs daily, sending updated account lists and balances to the network each morning. This sounds simple enough, but there are a few hurdles. As a regulated industry, banks and financial institutions tend to move slowly and sometimes use technologies that a cloud-first approach might otherwise ignore.\nI don't mean that they still move physical money around. It's all digital. No more cowboys and stagecoaches hightailing it through the hills. The money transfers electronically, but, in this case, the sweep network uses SFTP file uploads to communicate with the financial institutions in the network. Specifically, banks and the sweep network use files to communicate in both directions, several times each day.\nUnfortunately, these SFTP uploads and downloads were a primary pain point. At times, the SFTP server, overwhelmed by requests from across the network, needed our system to pause operations until it recovered. Other times, the sweep network's internal processes were slow, cascading to our system, which wasn't resilient to such delays. The SFTP uploads and downloads failed fairly frequently, and, though the issues were usually temporary, they required human intervention by the engineering team.\nThere were also many queries needed to calculate sweep balances, any of which could fail if the database was already under load. Add in a Slack integration and networking issues, and there were a number of intermittent errors.\nTo round it out, the sweep network's strict deadlines had the engineering team rushing to resolve errors, auditing the workflow's progress and manually resuming operations. Before migrating to Temporal, preventable errors needed manual intervention several times each month.\nA new plan\nAfter identifying the issues, we set project goals:\n\n  Resolve stability issues.\n  Minimize the risk of migrating by avoiding a single cutover event.\n  Gracefully handle humans in the loop  aka finance team approval.\n  Improve the workflow's audit trail.\n\nTemporal was a natural fit, especially since the original codebase was in Go, a language we love. Temporal has a Go SDK, which let us reuse code from the existing workflow, saving time and effort while migrating individual workflow steps. It's worth noting that we could have easily switched languages in the migration. Sticking with Go was preferred because we could reuse much of the original code, and, well, we love Go.\nBeing able to incrementally migrate (instead of rewriting the whole legacy process using a more strict workflow system) was a major factor in the project's approval and success. It let us make intentional and methodical changes, testing as we went, while benefiting from early stability improvements.\nWe prioritized migrating the SFTP operations to a Temporal Workflow first, followed by the database intensive operations, and finally migrated the Slack human-in-the-loop integration.\nWe also benefited from Temporal's event history, which tracks all events during a Workflow execution's lifetime. Should future errors occur, we were well positioned to investigate the preceding events.\nOur general approach in the migration was to move decision-making logic to a Temporal Workflow and move external operations, like SFTP file uploads and database queries, into Activities. Temporal Workflows define the overall flow and logic in the process, which it accomplishes by calling Activities. Activities execute a single action, such as calling an external service.\nSweep workflow\nThe workflow was scheduled to run after the daily account balance job finished each morning. After account balances were set, the sweep process would:\n\n  Send account info & changes to the sweep network via SFTP upload\n    \n      Retrieve account info from database and generate the sweep network account file\n      Send the file via SFTP upload\n      Wait for acknowledgement via SFTP response file download\n    \n  \n  Calculate account amounts to reserve at the \"home bank\" and remaining balances to send to the network.\n    \n      Retrieve account balances, calculating the amounts to reserve and send.\n      Generate a balance file\n      Store the file, wait for internal approval\n    \n  \n  Finance team reviews and approves the balances\n    \n      Send Slack message to finance team\n      Finance team reviews and approves. (Disapproval is infrequent and requires additional review from finance and engineering)\n    \n  \n  Send the balance file to the sweep network via SFTP upload\n    \n      Send the balance file via SFTP upload\n      Wait for acknowledgement via SFTP response file download\n    \n  \n\nThis sequence diagram shows how the process used to work.\n\n  \n\nSFTP stabilization\nThe SFTP upload process had multiple steps: Upload the file to the SFTP server, wait for an acknowledgement file to be uploaded by the sweep network, and download the acknowledgement file. The Workflow maintained the decision logic, while each specific operation (SFTP interaction) was implemented in an Activity.\nIf you've used Temporal before, the benefit is obvious: Temporal automatically retries failed Activities. By wrapping the SFTP operations in Activities, any errors caused by finicky SFTP errors would automatically retry, and usually succeed on subsequent attempts. The sweep process's main pain point was resolved simply by using Temporal primitives.\nAs an added benefit of using Temporal's Go SDK, the Activity implementations were copied and pasted from the original process with minimal changes, which saved time and increased confidence in the new implementation.\nOnce the Temporal Workflow was ready to handle the SFTP operations, we updated the legacy process to start the Temporal Workflow and Signal when the SFTP file should upload. It then waited for the account file SFTP upload steps to complete by Querying the Temporal Workflow status. The Temporal Workflow would run, successfully complete the SFTP steps, update its status, and wait for a Signal to send the final balance file.\nAt that point, control returned to the legacy workflow, which would calculate balances, and send a Slack notification to the finance team for approval. After the balances were approved, the legacy workflow sent a second signal to the Temporal Workflow, which triggered the balance file SFTP upload steps.\nThis sequence diagram shows the updated process, with the Temporal Workflow managing the SFTP uploads and downloads.\n\n  \n\nLet's look at the Temporal implementation.\nThe activities manage the SFTP uploads and downloads. UploadFile accepts an S3 file key, referencing the file to upload, and the SFTP upload file path. ReceiveAck downloads the SFTP file stored at the specified path, and verifies that the upload was acknowledged.\ntype sweepActivity struct {\n\tbucket     *blob.Bucket\n\tsftpClient *SFTPHandler\n}\n\ntype UploadRequest struct {\n\tS3FileKey    string\n\tSFTPFilePath string\n}\n\nfunc (sa *sweepActivity) UploadFile(ctx context.Context, req UploadRequest) error {\n\t// Open reader for file\n\tfile, err := sa.bucket.NewReader(ctx, req.S3FileKey, nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer file.Close()\n\n\t// Upload file to SFTP\n\terr = sa.sftpClient.Upload(ctx, req.SFTPFilePath, file)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\ntype FileWaitRequest struct {\n\tSFTPFilePath string\n}\n\nfunc (sa *sweepActivity) ReceiveAck(ctx context.Context, req FileWaitRequest) (bool, error) {\n\tbody, err := sa.sftpClient.Download(ctx, req.SFTPFilePath)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\tif body != \"success\" {\n\t\treturn false, errors.New(\"SFTP ack error\")\n\t}\n\n\treturn true, nil\n}\nYou call these activities from a workflow.\nAfter starting, the Workflow waits to receive an \"upload-account-file\" Signal from the legacy process, which contains a reference to the file that needs uploading. Once received, the Temporal Workflow uploads the file to the SFTP server and waits for acknowledgement. After the file is acknowledged, the Temporal Workflow returns control to the legacy process, and waits for the \"upload-balance-file\" Signal, sent by the legacy workflow. Again, this triggers the SFTP upload and acknowledgement process.\nAfter each of these steps, the Temporal Workflow updates its status. The legacy process Queries the Temporal Workflow status to know when it should resume processing. This Query is handled at the start of the Temporal Workflow, simply returning the current Workflow status, which is stored in the SweepWorkflow struct.\nTemporal Workflows are just code, so we encapsulated the SFTP upload and acknowledgement steps in the function uploadFileAndWait, which handles the account and balance exchanges. Temporal is doing the heavy lifting, automatically retrying failed steps. The retries automatically back off, gracefully handling the common error cases when the SFTP server was overloaded and unable to respond, or the sweep network's own processes were delayed. This alone prevented the most frequent errors in the system.\ntype SweepWorkflow struct {\n\tStatus string // account-uploaded,\n}\n\nfunc RunSweepWorkflow(ctx workflow.Context) error {\n\t// Configure status query\n\twork := SweepWorkflow{Status: \"running\"}\n\terr := workflow.SetQueryHandler(ctx, \"current-status\", func() (string, error) {\n\t\treturn work.Status, nil\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Wait for account file upload signal\n\tuploadAccountFileSig := workflow.GetSignalChannel(ctx, \"upload-account-file\")\n\n\tvar uploadSignalData UploadRequest\n\tuploadAccountFileSig.Receive(ctx, &uploadSignalData)\n\n\terr = uploadFileAndWait(ctx, uploadSignalData)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Update status\n\twork.Status = \"account-file-uploaded\"\n\n\t// Wait for balance file upload signal\n\tuploadBalanceFileSig := workflow.GetSignalChannel(ctx, \"upload-balance-file\")\n\tuploadBalanceFileSig.Receive(ctx, &uploadSignalData)\n\n\terr = uploadFileAndWait(ctx, uploadSignalData)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Update status\n\twork.Status = \"balance-file-uploaded\"\n\n\treturn nil\n}\n\nfunc uploadFileAndWait(ctx workflow.Context, uploadReq UploadRequest) error {\n\t// Upload file\n\tuploadCtx := workflow.WithActivityOptions(ctx, workflow.ActivityOptions{\n\t\tStartToCloseTimeout: 5 * time.Minute,\n\t\tRetryPolicy:         &temporal.RetryPolicy{MaximumAttempts: 5},\n\t})\n\n\terr := workflow.ExecuteActivity(uploadCtx, sweepActivities.UploadFile, uploadReq).Get(uploadCtx, nil)\n\tif err != nil {\n\t\t// Human intervention is needed. Notify finance and engineering stakeholders.\n\t\treturn err\n\t}\n\n\t// Wait for acknowledgement\n\twaitCtx := workflow.WithActivityOptions(ctx, workflow.ActivityOptions{\n\t\tStartToCloseTimeout: 15 * time.Minute,\n\t\tRetryPolicy: &temporal.RetryPolicy{\n\t\t\tMaximumAttempts: 15,\n\t\t\tInitialInterval: 10 * time.Second,\n\t\t},\n\t})\n\n\twaitReq := FileWaitRequest{\n\t\tSFTPFilePath: \"resp-file\",\n\t}\n\tvar success bool\n\terr = workflow.ExecuteActivity(waitCtx, sweepActivities.ReceiveAck, waitReq).Get(waitCtx, &success)\n\tif err != nil {\n\t\t// Human intervention is needed. Notify finance and engineering stakeholders.\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nWe'd prevented the most frequent recoverable errors in the legacy system, but we weren't finished. With a successful Temporal Workflow launch, we were ready to migrate and stabilize the rest of the workflow.\nCalculating sweep amounts\nThe natural next step was to migrate the account and sweep balance queries and calculations, which generated the account and sweep balance files. While the queries themselves were effective and performant, there were many queries, and other intensive jobs would occasionally run simultaneously, leading to query failures. Instead of letting the sweep process halt altogether, we leaned on Temporal's automatic retry backoff to gracefully continue.\nWe lifted and shifted the queries into Temporal Activities, and called them from the Temporal Workflow. The Workflow similarly needed few changes, as the decision logic didn't change.\nAs an added benefit, the account file generation and balance calculations happened before and after the account file SFTP upload. This meant the Temporal Workflow's initial responsibility expanded before handing control back to the legacy workflow. The legacy workflow needed minimal changes  removing the account and balance calculations and changing the Temporal Workflow status it queried for to \"calculation-complete\".\n\n  \n\nHumans in the loop\nWe were moving and grooving. The final step integrated the Slack approval process into the Temporal Workflow. The integration used the Slack API to send daily balance summaries along with an 'approve' button to the finance team. Upon review, clicking the 'approve' button would signal the Workflow to proceed.\n\n  Like the previous migration steps, we moved the decision logic over to the Temporal Workflow, while external Slack API calls moved to Activities.\n  This step showcases a great Temporal benefit  Temporal Workflows are designed to run indefinitely, if you need them to. It makes them well suited for workflows that need input from us slow humans. In this case, we only needed it to run for as long as it took for the finance team to review and respond, and we could easily add subsequent reminders should the approval deadline approach.\n\nAnd with that, the workflow was migrated! We stopped running the legacy workflow, and let the Temporal Workflow drive the process going forward.\n\n  \n\nParting thoughts\nBy transitioning to Temporal, the financial institution not only addressed immediate operational challenges but also established a scalable, resilient, and efficient foundation for future operations. The incremental migration reduced project risks and accelerated the stability improvements. We were able to see the positive impact almost immediately, without waiting for a complete system overhaul. By tackling critical issues first, we ensured that each step delivered substantial benefits.\nSince migrating to Temporal, the need for manual interventions, which were once a frequent necessity, has been virtually eliminated. For me, knowing that our solution has led to a dependable system certainly contributes to a good night's sleep.",featureImage:{title:"hazel-z-45AHiklPJH4-unsplash",description:"hazel-z-45AHiklPJH4-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Potp6G9LHoZ780AhLw3vs/861da43ba6e469417a7a9084b708e71f/hazel-z-45AHiklPJH4-unsplash.jpg"},publishDate:"2024-06-27T00:00-07:00",metaDescription:"Improve the resiliency and scalability of your banking sweep network by migrating to Temporal workflows, ensuring seamless and efficient operations.",metaTitle:"Building Resilient Sweep Networks with Temporal Workflows",socialCard:{title:"hazel-z-45AHiklPJH4-unsplash",description:"hazel-z-45AHiklPJH4-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Potp6G9LHoZ780AhLw3vs/861da43ba6e469417a7a9084b708e71f/hazel-z-45AHiklPJH4-unsplash.jpg"},tags:"",slug:"increasing-resiliency-in-a-banking-sweep-system",contentType:"blogPost",entityId:"5LPEqHSX0AVdW4A2PGPOoo",authors:[{id:"2m4V7y3X8VIVqRduYuN8Ah",name:"James Heller",slug:"james-heller",jobTitle:"Co-founder and Principal Consultant, Apartment 304",photograph:{title:"James Heller",description:"James Heller",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4fufa5ZlY5O3VJC8s1tx9E/0784c2f693f1d6a83147f1b9718713e6/IMG_7681.png"},contentType:"person"}],authorsString:"James Heller",category:"How-To",readingTime:13},{title:"Join us for live hands-on Temporal training at Replay",content:"At Replay 2022, we debuted Temporal 101 with Go as a live hands-on workshop. At Replay 2023, we expanded this to include Temporal 101 and Temporal 102 in Go, Java, and TypeScript.\nThis year, we're going even further, offering all of this fundamental training for Go, Java, TypeScript, and Python plus advanced training that goes beyond the basics. We've organized this into two tracks, allowing you to select the path that best suits you.\nChoose your Own Learning Adventure\nIf you're new to Temporal, choose the Developer Fundamentals track for your preferred SDK. This training focuses the foundational skills you'll need to get started with developing Temporal Applications, such as how to write Workflows and Activities.\nIf you already have experience developing Temporal applications, choose the Beyond the Basics track, which we offer in Go, Java, and TypeScript. This training delves deeper into Temporal, covering Signals, Queries, error handling, and more.\nDeveloper Fundamentals Workshops\nIf you're new to Temporal, sign up for the Developer Fundamentals workshops! These workshops will be offered in Go, Java, Python, and TypeScript. They're intended for developers who have little or no prior experience with Temporal and will provide the fundamental concepts, tools, and techniques used to build, test, and run applications on the Temporal platform. The content is based on Temporal's fundamental training courses: Temporal 101: Introducing the Temporal Platform and Temporal 102: Exploring Durable Execution.\nYou'll begin by learning about the concept of Durable Execution and our basic architecture of the platform. Next, you'll use Temporal's basic building blocks, Workflows and Activities, to develop an application that communicates with an external service. You will then continue by learning how to launch Workflow Executions from both the command line and code, and how to view the progress and result of the execution using the Temporal Web UI.\nThroughout these workshops, you'll explore key concepts and best practices. You'll learn how to develop and run automated tests for your Temporal applications, how to interpret the Event History, and how to debug common problems. Most importantly, you'll gain a deeper understanding of how Temporal works and how to use it effectively.\nBeyond the Basics Workshops\nThe Beyond the Basics Workshops will be offered in Go, Java, and TypeScript. This track is for developers who have completed our foundational Temporal 101 and Temporal 102 training courses. This material is based on our Interacting with Workflows course and exclusive coverage from our upcoming course, Crafting an Error Handling Strategy.\nYou'll begin by learning how to make your Workflows more dynamic, reacting to external events that are triggered by other Workflows, by other systems, or by humans. You'll learn how to use Signals to supply data to Workflow Executions, both new and those already in progress. You'll also learn how to use a Query to access the state of a running or completed Workflow. Additionally, you'll learn how to use other Temporal mechanisms for interacting with your applications, including Search Attributes, Cancellations, and Asynchronous Activity Completions.\nYour journey continues as you learn how to design and implement effective error handling strategies that map your business logic to the Temporal platform. You'll explore the nature of different types of failures and investigate the support that Temporal provides for addressing them. You'll also learn essential concepts and design patterns, such as idempotence, sagas, and heartbeating. They will help you to ensure the correctness and responsiveness of your application.\nGet Your Tickets!\nBoth workshops will run from 9:00 AM until 5:00 PM, with an hour-long break for lunch (provided) and short breaks throughout the day.\nSpace is limited, so don't delay. Get your tickets today! We hope to see you there!",featureImage:{title:"rick-rothenberg-JP-d0V5UBxs-unsplash 1",description:"rick-rothenberg-JP-d0V5UBxs-unsplash 1",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Q3MJsvD1ujCkIoEbicDUD/91e1dc92fa47018f97057873b03ff3c6/rick-rothenberg-JP-d0V5UBxs-unsplash_1.png"},publishDate:"2024-06-25T00:00-07:00",metaDescription:"This year's Replay workshops include both fundamentals and advanced courses for Temporal users of all learning levels!",metaTitle:"Join us for live hands-on Temporal training at Replay",socialCard:{title:"rick-rothenberg-JP-d0V5UBxs-unsplash 1",description:"rick-rothenberg-JP-d0V5UBxs-unsplash 1",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Q3MJsvD1ujCkIoEbicDUD/91e1dc92fa47018f97057873b03ff3c6/rick-rothenberg-JP-d0V5UBxs-unsplash_1.png"},tags:"Replay,Meetups",slug:"join-us-for-live-hands-on-temporal-training-at-replay",contentType:"blogPost",entityId:"4349v9spQrT7GyJeqFlzcs",authors:[{id:"gz6Asa7ycvY1HZz9vcJk0",name:"Angela Zhou",slug:"angela-zhou",jobTitle:"Senior Technical Curriculum Developer",photograph:{title:"headshot-angela-zhou",description:"headshot-angela-zhou",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3FgLhuMJuEASXJmzoNevWN/c115937f066329eb77cd75caa831bfbe/headshot-angela-zhou.png"},contentType:"person"}],authorsString:"Angela Zhou",category:"Community",readingTime:4},{title:"Amazon Bedrock with Temporal: rock solid",content:"tl;dr In this blog we walk through the steps required to build a chatbot powered by Temporal and Amazon Bedrock.\nDeveloping AI-powered applications has never been easier, and with multiple high-quality large language models (LLMs) publicly available, developers have many options. Amazon Bedrock makes it straightforward for developers to access models from leading providers through a single, standardized API, and removes the friction and pain of hosting reliable, scalable models.\nEven with all the benefits that come with Amazon Bedrock, there are still a number of broader challenges that must be addressed when building production-grade Generative AI (Gen AI) applications.\n\n  LLMs are stateless; if the history of interactions with a model are required  which is the case for conversational AI  then the history must be stored securely.\n  LLM conversations may be very long running, and may have large intervals between interactions. Very long running sessions can be tricky to manage;\n    \n      It can be difficult to determine which sessions can remain in memory and which can be persisted to disk, resulting in extra costs where too much memory is left unused, or poor performance due to too little memory.\n      There are two paths for handling user inputs; one for active sessions and another for inactive sessions. Active sessions are simpler as the session is present in memory, whereas inactive sessions are more complicated; the session needs to be restored, additional user requests may arrive during session restoration, and errors during session restoration need to be handled.\n    \n  \n  LLMs are deterministic, but generally we want some randomness (e.g. top-p, top-k. temperature) in the output. For example, to enable users to have the LLM rephrase a result if needed. For debugging and investigation, individual parameters passed to an LLM need to be logged for each and every invocation, and the overall history/sequence of invocations but be able to be rebuilt if needed.\n\nThese are difficult challenges but solvable. Caching/persistence can be added to store the history of conversations, queues can be added to help with rate-limiting calls made to Bedrock, and tracing, observability, and logging tools can be strung together to provide visibility into Gen AI applications. The problem with this approach is all these solutions involve additional developer effort, become complicated quickly, and are yet another resource to monitor and troubleshoot when things inevitably go wrong.\nHow Temporal Solves these Problems\nTemporal enables developers to write workflows that are guaranteed to execute to completion. Temporal manages queues, retries, state management, and more; developers spend less time on scaffolding and build reliable applications faster. By modeling each conversation as a Temporal workflow, the same patterns that Temporal developers use every day can be used to solve the challenges that come with building Gen AI applications powered by Amazon Bedrock.\n\n  The history of each conversation is stored by Temporal within the workflow, and can be used on subsequent calls to Amazon Bedrock to provide history and context for the LLM. As each conversation is a separate workflow, the history of each conversation is stored separately, significantly reducing the risk of accidentally exposing one users chat history to another user.\n  Temporal workflows can run forever, and a workflow that is waiting for an external signal (such as user input) doesnt consume compute resources, meaning a workflow can wait indefinitely.\n  Temporals event history captures the inputs and outputs (including failures) for every step in a workflow, where each step can be almost anything; a write to a database, sending a notification, a request to Amazon Bedrock, etc. This allows for rapid debugging as Temporal provides a single place to view the execution history for a workflow.\n  Temporal provides a straightforward approach to developing processes that execute in parallel, bypassing traditional event-driven constructs like message buses and dead letter queues.\n\nBuilding an AI chatbot with Temporal and Amazon Bedrock\nTo better understand how Temporal and Amazon Bedrock can be used to quickly build resilient AI applications, well walk through building an example chatbot application using the Temporal Python SDK. Well start with a simple workflow to introduce some of the Temporal concepts, and then add additional features to build a more sophisticated conversational AI application. Well show the relevant snippets of code as we progress, and if youd like to run the samples yourself, the full code is available on GitHub.\nPrerequisites\n\n  An AWS account with access to one or more LLMs on Amazon Bedrock.\n  AWS secret access key configured on your local machine\n  Temporal CLI\n  Python >= 3.8\n  Temporal Python SDK\n\nIf you are following along with the code in the GitHub repository, you will also need Poetry to install the dependencies and run the samples.\nA basic Bedrock workflow\nOur first step is to build a workflow that interacts with Amazon Bedrock. In this simple example well accept a prompt from a user and use it to generate a response from Bedrock.\n\n  \n\nUsing the Temporal Python SDK, a workflow is just a function written in standard Python with a decorator to define it as the workflow entry point. For our basic Bedrock workflow, the workflow definition is straightforward; we define a workflow class (SimpleBedrockWorkflow) with a single function (run) that returns the result of the activity that calls Bedrock (prompt_bedrock).\n\n@workflow.defn\nclass BasicBedrockWorkflow:\n    @workflow.run\n    async def run(self, prompt: str) -> str:\n\n        workflow.logger.info(\"Prompt: %s\" % prompt)\n\n        response = await workflow.execute_activity_method(\n            BedrockActivities.prompt_bedrock,\n            prompt,\n            schedule_to_close_timeout=timedelta(seconds=20),\n        )\n\n        workflow.logger.info(\"Response: %s\" % response)\n\n        return response\n\nAn activity is some function or code that might fail and would potentially need to be retried. Temporal can automatically handle retries when an activity fails. How many times to retry, and how often, can be defined by an activity retry policy. By default, when an activity fails, Temporal will continue to retry the activity forever, with an increasing delay between retries (exponential backoff), until the activity is successful. Like the workflow definition, we use a decorator when defining activities.\nThe prompt_bedrock activity invokes an LLM on Bedrock and formats a response to return to the user.\n\nclass BedrockActivities:\n    def __init__(self) -> None:\n        self.bedrock = boto3.client(service_name=\"bedrock-runtime\", config=config)\n\n    @activity.defn\n    def prompt_bedrock(self, prompt: str) -> str:\n        # Model params\n        modelId = \"meta.llama2-70b-chat-v1\"\n        accept = \"application/json\"\n        contentType = \"application/json\"\n        max_gen_len = 512\n        temperature = 0.1\n        top_p = 0.2\n\n        body = json.dumps(\n            {\n                \"prompt\": prompt,\n                \"max_gen_len\": max_gen_len,\n                \"temperature\": temperature,\n                \"top_p\": top_p,\n            }\n        )\n\n        response = self.bedrock.invoke_model(\n            body=body, modelId=modelId, accept=accept, contentType=contentType\n        )\n\n        response_body = json.loads(response.get(\"body\").read())\n\n        return response_body.get(\"generation\")\n\nFinally, we create a worker that is responsible for executing our workflow and activity.\n\nasync def main():\n    # Create client connected to server at the given address\n    client = await Client.connect(\"localhost:7233\")\n    activities = BedrockActivities()\n\n    # Run the worker\n    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as activity_executor:\n        worker = Worker(\n            client,\n            task_queue=\"bedrock-task-queue\",\n            workflows=[BasicBedrockWorkflow],\n            activities=[activities.prompt_bedrock],\n            activity_executor=activity_executor,\n        )\n        await worker.run()\n\nif __name__ == \"__main__\":\n    print(\"Starting worker\")\n    print(\"Then run 'python send_message.py \\\"\u003Cprompt>\\\"'\")\n\n    logging.basicConfig(level=logging.INFO)\n\n    asyncio.run(main())\n\nTo run our workflow, we first start an instance of the Temporal Server using the Temporal CLI with the command temporal server start-dev . The CLI server instance is a great way to quickly test workflows locally, but for higher level environments and production deployments we recommend Temporal Cloud.\nFirst, we need to start our Temporal worker; this is what will process workflows and activities as they are requested.\n$ poetry run python run_worker.py\n\nIn another terminal we can now start the workflow, with the prompt for Bedrock to complete a list of names for dogs, and view its output;\n\n$ temporal workflow execute --type SimpleBedrockWorkflow --task-queue bedrock-task-queue --input '\"Which animals are marsupials?\"'\nRunning execution:\n  WorkflowId  a79dff10-d6c9-4c97-8b2b-25429914b78c\n  RunId       a0e7cb0a-dd3a-4b4d-bf82-cd690bd2cc5f\n  Type        SimpleBedrockWorkflow\n  Namespace   default\n  TaskQueue   bedrock-task-queue\n  Args        [\"Which animals are\n              marsupials?\"]\n\nProgress:\n\nTime elapsed: 4s\n  ID          Time                     Type\n   1  2024-05-22T10:01:37Z  WorkflowExecutionStarted\n   2  2024-05-22T10:01:37Z  WorkflowTaskScheduled\n   3  2024-05-22T10:01:37Z  WorkflowTaskStarted\n   4  2024-05-22T10:01:37Z  WorkflowTaskCompleted\n   5  2024-05-22T10:01:37Z  ActivityTaskScheduled\n   6  2024-05-22T10:01:37Z  ActivityTaskStarted\n   7  2024-05-22T10:01:41Z  ActivityTaskCompleted\n   8  2024-05-22T10:01:41Z  WorkflowTaskScheduled\n   9  2024-05-22T10:01:41Z  WorkflowTaskStarted\n  10  2024-05-22T10:01:41Z  WorkflowTaskCompleted\n  11  2024-05-22T10:01:41Z  WorkflowExecutionCompleted\n\nResult:\n  Run Time: 5 seconds\n  Status: COMPLETED\n  Output: [\"\\n\\nMarsupials are mammals that have a pouch in which they carry their young. Some examples of marsupials include:\\n\\n* Kangaroos and wallabies\\n* Possums\\n* Koalas\\n* Wombats\\n* Marsupial moles\\n* Bilbies\\n* Bandicoots\\n* Dunnarts\\n* Quokkas\\n* Sugar gliders\\n* Tasmanian devils\\n\\nThese are just a few examples of the many different species of marsupials that exist. Marsupials are found primarily in Australia and the surrounding islands, as well as in South America and parts of North America.\"]\n\n\nEven with this very simple workflow we can already see some of the benefits Temporal provides.\n\n  You are guaranteed to get a result from Bedrock. For example, simulate a network fault by disconnecting your local environment from the internet and start the workflow, and after some time reconnect. Simulate a server or cluster fault by terminating your worker, then start the workflow. Restart the worker. In both of these cases your workflow will execute to completion.\n  Using the Temporal UI at http://localhost:8233 we can easily inspect the history of the workflow; which activity was executed, when it was executed, what inputs were passed to it, and what was the result. As workflows grow beyond a simple case such as this one, the ability to easily view a full history of a workflow execution is invaluable.\n\nAdding signals & queries\nNow we can expand on our workflow and begin modeling something that resembles a conversation. Users will now be able to provide follow-up prompts to Bedrock, and Bedrock will receive the prompt, along with the conversation history, which will allow Bedrock to provide a response that makes sense in the context of the conversation. If users dont provide a prompt within a timeout window then the conversation will end, and a summary of the conversation is generated.\n\n  \n\nIn our basic workflow we provided a single input at the start of execution and we received a single response at the end of execution. Well now store prompts as the user provides them, and well also keep track of the conversation history.\n\n@workflow.defn\nclass SignalQueryBedrockWorkflow:\n    def __init__(self) -> None:\n        # List to store prompt history\n        self.conversation_history: List[Tuple[str, str]] = []\n        self.prompt_queue: Deque[str] = deque()\n        self.conversation_summary = \"\"\n        self.chat_timeout: bool = False\n\nWe now need a way to receive user prompts and push them to the queue, and we want to expose the current conversation history to the user should they request it. There are two Temporal primitives that support this;\n\n  Signals allow us to inject data into a running workflow. They can also be used to start a new workflow execution that immediately receives the signal. Well use this feature in our conversation workflow as it reduces how we interact with our workflow to a single path; either our signal adds data to an existing conversation, or it starts a new conversation for us. Signals do not return any data to the original sender of the signal.\n  Queries are used to expose data from a running workflow. Queries cannot mutate the state / internal data of a workflow.\n\nWe use decorators to define our signal and query handlers, which in this case, are straightforward;\n\n@workflow.signal\n    async def user_prompt(self, prompt: str) -> None:\n        # Chat timed out but the workflow is waiting for a chat summary to be generated\n        if self.chat_timeout:\n            workflow.logger.warn(f\"Message dropped due to chat closed: {prompt}\")\n            return\n\n        self.prompt_queue.append(prompt)\n\n@workflow.query\ndef get_conversation_history(self) -> List[Tuple[str, str]]:\n    return self.conversation_history\n\n\nIts important to note that signals and queries can be called any time during the lifetime of a workflow. If you have a case where a signal should not be processed immediately then this must be handled with additional logic, e.g. by adding the signal input to a queue. In our case, we will enqueue user inputs when they are received, and dequeue one each iteration of our main loop.\nNext, we can modify our workflow to allow subsequent prompts from the user. In each iteration of our main loop, our workflow needs to:\n\n  Update the conversation history with the next user input\n  Create a prompt using the conversation history, and process it with our Bedrock activity\n  Add the Bedrock response to the conversation history\n  Check if there are user inputs on the queue, and if the queue is empty and no user inputs are received within a timeout window, finish the workflow\n\n\n@workflow.run\nasync def run(self, inactivity_timeout_minutes: int) -> str:\n    while True:\n        workflow.logger.info(\n            \"Waiting for prompts... or closing chat after \"\n            + f\"{inactivity_timeout_minutes} minute(s)\"\n        )\n\n        # Wait for a chat message (signal) or timeout\n        try:\n            await workflow.wait_condition(\n                lambda: bool(self.prompt_queue),\n                timeout=timedelta(minutes=inactivity_timeout_minutes),\n            )\n        # If timeout was reached\n        except asyncio.TimeoutError:\n            self.chat_timeout = True\n            workflow.logger.info(\"Chat closed due to inactivity\")\n            # End the workflow\n            break\n\n        while self.prompt_queue:\n            # Fetch next user prompt and add to conversation history\n            prompt = self.prompt_queue.popleft()\n            self.conversation_history.append((\"user\", prompt))\n\n            workflow.logger.info(f\"Prompt: {prompt}\")\n\n            # Send the prompt to Amazon Bedrock\n            response = await workflow.execute_activity_method(\n                BedrockActivities.prompt_bedrock,\n                self.prompt_with_history(prompt),\n                schedule_to_close_timeout=timedelta(seconds=20),\n            )\n\n            workflow.logger.info(f\"{response}\")\n\n            # Append the response to the conversation history\n            self.conversation_history.append((\"response\", response))\n\n    # Generate a summary before ending the workflow\n    self.conversation_summary = await workflow.start_activity_method(\n        BedrockActivities.prompt_bedrock,\n        self.prompt_summary_from_history(),\n        schedule_to_close_timeout=timedelta(seconds=20),\n    )\n\n    workflow.logger.info(f\"Conversation summary:\\n{self.conversation_summary}\")\n\n    return f\"{self.conversation_history}\"\n\nAs mentioned earlier, we can use signal with start to simplify how we start workflow execution and signal running workflows. Instead of having two paths, one to signal a running workflow, and one to start a new workflow then signal it, we can just send a signal and Temporal will start a new workflow execution if required.\n\nasync def main(prompt):\n    # Create client connected to server at the given address\n    client = await Client.connect(\"localhost:7233\")\n\n    workflow_id = \"bedrock-workflow-with-signals\"\n    inactivity_timeout_minutes = 1\n\n    # Sends a signal to the workflow (and starts it if needed)\n    await client.start_workflow(\n        SignalQueryBedrockWorkflow.run,\n        inactivity_timeout_minutes,\n        id=workflow_id,\n        task_queue=\"bedrock-task-queue\",\n        start_signal=\"user_prompt\",\n        start_signal_args=[prompt],\n    )\n\nStart the worker with;\n$ poetry run python run_worker.py\n\nIn another terminal we can send inputs to our workflow;\n$ poetry run python send_message.py 'What animals are marsupials?'\n$ poetry python send_message.py 'Do they lay eggs?'\n\nBecause we are sending inputs as signals, there is no Bedrock response returned from sending the signal. In a production deployment we could trigger a webhook or callback to notify the client when a response is available, but for this example, well simply query the conversation history using poetry run python get_history.py or view the output from the worker (the output here has been formatted for readability);\nStarting worker\nThen run 'python send_message.py \"\u003Cprompt>\"'\n\nINFO:temporalio.workflow:Waiting for prompts... or closing chat after 1 minute(s)\n\nINFO:temporalio.workflow:Prompt: What animals are marsupials? INFO:temporalio.workflow: Response: Marsupials are mammals that have a pouch on their belly where they carry their young. They are found primarily in Australia, New Guinea, and nearby islands, although there are also some species found in the Americas and other parts of the world. Some examples of marsupials include kangaroos, wallabies, koalas, opossums, and wombats. Marsupials are known for their unique reproductive system, which involves a short gestation period and the birth of underdeveloped young that then complete their development inside the mother's pouch. \n\nINFO:temporalio.workflow:Waiting for prompts... or closing chat after 1 minute(s)\n\nINFO:temporalio.workflow:Prompt: Do they lay eggs?\nINFO:temporalio.workflow: Response: No, marsupials do not lay eggs. They are mammals, which means they give birth to live young instead of laying eggs like birds or reptiles. After the young are born, they crawl up to the mother's pouch and attach themselves to a nipple, where they continue to develop and grow until they are able to survive on their own.\n\nINFO:temporalio.workflow:Waiting for prompts... or closing chat after 1 minute(s)\n\nINFO:temporalio.workflow:Chat closed due to inactivity INFO:temporalio.workflow:Conversation summary:\nINFO:temporalio.workflow:  Sure! Here is a two sentence summary of the conversation between the user and the chatbot: The chatbot provided information about marsupials, explaining that they are mammals with a pouch that carry their young, and gave examples of marsupials such as kangaroos and koalas. The chatbot also clarified that marsupials do not lay eggs, but instead give birth to live young that develop inside the mother's pouch.\n\n\nThis is a great opportunity to revisit the workflow history and to see that even as the workflow history grows, it is still easy to view the where/what/when of a workflow and its activities even as the history grows. The compact view makes this especially easy to see.\nWe can also see how Temporal makes it simple to keep track of sessions, even as users change devices. After starting the worker and sending several inputs, try opening another terminal and querying the history or sending signals. Because the same workflow id is used, we can easily attach to a running conversation or view its history. In practice we wouldnt hard-code workflow ids, wed either provide unique ids based on some application/user id, or wed let Temporal generate a unique id.\nFurther Improvements\nOur workflow does a decent job of modeling a conversation by allowing users to have an ongoing back and forth exchange with Bedrock, but it currently has two significant limitations;\n\n  Temporal Workflows are unbounded temporally but bounded spatially; they can run forever so long as they dont exceed the maximum number of events in the event history (50,000 events) and the total size of the event history doesnt grow too large (above 50MB). Its possible that, in our previous workflow, a user chats long enough with our workflow that the workflow history limit is exceeded.\n  Our workflow will finish the conversation after some fixed timeout. We could remove this timeout, but then the workflow would never finish. Ideally, we want conversations to last as long as a user wants - potentially forever. A user should be able to end the conversation when theyre ready.\n\nWhen to finish the workflow is simple, and there are many ways to do this; in our case we just add a signal handler that can be used to end the conversation. An alternative would be to end the conversation based on the users prompt, i.e. finish the conversation when the user asks for it to finish.\nHandling the case where we exceed the workflow history limits is an interesting problem, but is beyond the scope of this post. If youre interested in how Temporal solves this challenge, Very Long-Running Workflows covers this in detail. The code for this blog also includes a sample that demonstrates very long running workflows with Bedrock.\nWrapping up\nTo recap, we saw how Temporal makes it easy to build Gen AI applications with Amazon Bedrock.\n\n  We discussed some of the challenges developers face when building Gen AI applications and how Temporal can be used to solve them.\n  We built a simple Temporal wrapper for Amazon Bedrock, and extended it to support signals and queries to allow for richer interactions with LLMs.\n  We extended our workflow to use the Entity Pattern to model entire conversations as entities that may last forever.\n  We saw how workflows provide greater visibility into the history of workflows, and also provide durability guarantees to ensure workflow history and state is always maintained.\n\nWhat next?\nIn this blog we focused on conversational AI, which is just one of the thousands of great uses for Gen AI that Temporal and Bedrock make easy. Other common use-cases you may want to explore are;\n\n  AI Agents, including agents that require long-running external integrations,\n  Generating insights from reports or large datasets,\n  Personalization, including where a customers preferences change over time,\n  Image generation (text2image)\n\nIf youre ready to learn more and start building your own bulletproof Gen AI applications with Temporal and Amazon Bedrock, make sure to check out these great resources;\n\n  Explore the full Gen AI workflow code from this blog\n  Join 10,000 other users in the Temporal Community Slack to get access to experts to help realize your Gen AI use case.\n  Fast-track production by signing up for Temporal Cloud. Startups can take advantage of Temporal Cloud for Startups for $2400 in free Temporal Cloud credits.\n  Our pay-as-you-go listing on AWS Marketplace is the fastest and most frictionless way to start with Temporal Cloudno credit card, no up-front cost and pay-as-you-go billing through AWS. Sign up here.\n",featureImage:{title:"bedrock-shubham-dhage-xzo5T6t2Ymg-unsplash",description:"bedrock-shubham-dhage-xzo5T6t2Ymg-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/21YpOmFDFzPhxpkkhQ9Otk/4272c25cd1c055ab0efd955274cbed70/shubham-dhage-xzo5T6t2Ymg-unsplash.jpg"},publishDate:"2024-06-18T14:00-05:00",metaDescription:"In this blog, we walk through the steps required to build a chatbot powered by Temporal and Amazon Bedrock.",metaTitle:"Amazon Bedrock with Temporal: rock solid",socialCard:{title:"bedrock-shubham-dhage-xzo5T6t2Ymg-unsplash",description:"bedrock-shubham-dhage-xzo5T6t2Ymg-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/21YpOmFDFzPhxpkkhQ9Otk/4272c25cd1c055ab0efd955274cbed70/shubham-dhage-xzo5T6t2Ymg-unsplash.jpg"},tags:"Durable Execution",slug:"amazon-bedrock-with-temporal-rock-solid",contentType:"blogPost",entityId:"5Fi1Ik7Gl6AEaQGvxJ6nnz",authors:[{id:"QawVEGb9aLGZVppfWl0YK",name:"Brendan Myers",slug:"brendan-myers",jobTitle:"Solutions Architect",photograph:{title:"Temporal Symbol light 1@2x",description:"Temporal Symbol light 1@2x",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5kHQtcFCSqkLDH4I6HFmyG/8e75bd66b57696eb0a7866b3cbf8ea30/Temporal_Symbol_light_1_2x.png"},company:"Temporal",contentType:"person"},{id:"1v9PSw1EtI4GSexvsgab2m",name:"Steve Androulakis",slug:"steve-androulakis",jobTitle:"Sr. Staff Solutions Architect",photograph:{title:"Steve Androulakis photo",description:"Steve Androulakis photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3VYCWEfnobcFUrlJCZP6pT/43ca653fceadf513a4663e444906702f/steve-androulakis-2.jpg"},biography:"Steve helps developers at companies like Netflix, Stripe and Airbnb thrive using Temporal. Before that, he worked at Amazon in Sydney and Seattle for more than 5 years. He brings a decade of full stack developer experience helping biomedical researchers process and make sense of their data.",company:"Temporal",contentType:"person"}],authorsString:"Brendan Myers, Steve Androulakis",category:"How-To",readingTime:17},{title:"Ten reasons to attend Replay 2024",content:"Mark your calendars, Replay 2024 is now 100 days away! Replay, our premier conference focused on the latest platforms, practices, and trends in software engineering, is coming to Seattle from September 18-20, 2024. This year, we're excited to bring together hundreds of innovative backend engineers to explore the future of software engineering and maximize the benefits of using Temporal.\nHere are ten reasons why you can't afford to miss Replay 2024:\n10 - Meet some of the best thinkers and builders in backend software engineering\nJoin Temporals newly-minted CEO Samar Abbas and industry leaders from Netflix, Yum! Brands, SpiralScout, Instacart, and more, to learn how theyre innovating in their organizations and driving the future of software engineering. Come away with concrete ideas and strategies to improve the reliability and velocity of your software development.\n9 - Help drive the future of the Temporal Project\nWell share a keynote full of product announcements and have also added a product forum to the agenda where you can interact with our product team, learn more about new capabilities, and give us feedback and input on where the project should go in the future.\nBring your API questions, learn about the future of the SDKs, and chat about all things in your language with the people who help build Temporal.\n8 - Day zero workshops\nKickstart your learning with live, hands-on-keyboard workshops designed to help you get up and running with Temporal in Go, Java, Typescript, and Python in our Developer Fundamentals courses. No prior Temporal experience? No problem. These sessions are designed to get you up to speed quickly.\nHave you already mastered the fundamentals? Our intermediate/advanced level Beyond the Basics courses in Go, Java, and Typescript are a great way to level-up your understanding of more advanced concepts and design patterns. The content of this track is based on our Interacting with Workflows and Crafting an Error Handling Strategy courses.\n7 - Connect with our sponsors!\nThis years Replay conference has FIVE sponsors. Bitovi, TechFabric, Apartment304, Google Cloud, and SpiralScout. Stop by our sponsor booths and connect with them and see how they can help you on your journey to Temporal Cloud! Is your company interested in sponsoring Replay? Email replay@temporal.io for more information.\n6 - Cant afford to attend? We got you!\nIn order to make Replay 2024 accessible to more people from all walks of life, were offering free or heavily-discounted tickets to people from underrepresented groups in the technology sector and/or communities who may not otherwise have the opportunity to attend Replay. These groups include but are not limited to: women, LGBTQ folks, people of color, people affected by poverty, people affected by war, individuals with physical disabilities, and others.\nInclusivity Tickets are available now by filling out the form here. They are awarded based on a combination of need and impact. Awarded recipients will receive a complimentary ticket and/or travel and lodging to the event in September based on need.\n5 - Community connection\nThis years event provides networking opportunities for both extroverts and introverts alike, offering attendees the chance to Choose your own adventure when it comes to interacting with like-minded developers. Meet with peers who are using Temporal at other forward-thinking organizations to swap tips and tricks, share ideas, and get inspired! This is also an excellent opportunity to help others by collaborating with your peers, solving problems, and getting inspiration.\n4 - Oh the themed decor and swag!\nThis years theme, \"Adventurers Wanted,\" promises creative and exciting venue and stage decorations, along with unique swag. Keep an eye out for an email announcing our swag drop!\n3 - Have a question? Ask an Expert!\nNew this year, our The Guide Post offers a chance to ask our experts any burning questions, participate in live demos, or just chat with Temporal team members that work to make our product amazing everyday. No question is too big or too smallour team is here to help.\n2 - Share your own Temporal story\nFor the first time, we're inviting community members to present 15-minute lightning talks on the Replay stage. If you missed our CFP or have a last-minute idea, this is your opportunity. Contact us at replay@temporal.io for more details.\n1 - The official Replay party!\nThe official Replay party is on September 19th at The Forum Social House in Bellevue. Join Replay attendees and Temporal staff for a fun-filled evening with food and beverages, pool, ping pong, mini golf and a Top Golf Swing Suite!\nSo what are you waiting for? Register for your ticket now at replay.temporal.io\nCant make it in person? Subscribe to our YouTube channel to get notified when the sessions get published.",featureImage:{title:"Replay image",description:"Replay image",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1eHxnC50do9W8huV79M4UU/b27931bc2bec243b77cbf3e42ac639ac/papercall-wide.png"},publishDate:"2024-06-09T12:00-04:00",metaDescription:"Mark your calendars! Replay 2024 is 100 days away. Join us in Seattle, Sept 18-20, for top software engineering insights, hands-on workshops, and networking.",metaTitle:"Why You Should Attend Replay 2024",socialCard:{title:"Replay image",description:"Replay image",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1eHxnC50do9W8huV79M4UU/b27931bc2bec243b77cbf3e42ac639ac/papercall-wide.png"},tags:"Replay",slug:"ten-reasons-to-attend-replay-2024",contentType:"blogPost",entityId:"1Ln4OdwgIfWSxGBOMB4MAY",authors:[{id:"4F2aCvt5v9OmxRDThejYNB",name:"Jennifer Bodie",slug:"jennifer-bodie",jobTitle:"Senior Manager, Events and Field Marketing",photograph:{title:"Jennifer Bodie",description:"Jennifer Bodie",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3qDMGNI4rHjktPqloxm5Kh/3824815809dde8cd1513190c180fdd8f/1542399132022.jpeg"},contentType:"person"}],authorsString:"Jennifer Bodie",category:"Community",readingTime:4},{title:"Maximizing availability with Multi-region Namespaces",content:"We are introducing Multi-region Namespaces (formerly known as Global Namespaces), now available in Public Preview.\nCustomers rely on Temporal to power their most critical workloads. While Temporal Cloud offers 99.99% availability for all Namespaces, a Multi-region Namespace offers a contractual service level agreement (SLA) of 99.99% guarantee against service errors.\nThis is achieved through an active-standby setup managed by Temporal. Workflows are replicated by Temporal Cloud to a standby region as defined by the user. If there is an outage or an incident in the active region, the namespace is seamlessly failed over to the standby region, thus minimizing any disruption.\n\n  \n\n\n  \n\nFor workflows in the critical path of revenue or user experience, Multi-region Namespaces offer customers a guarantee and peace of mind, with no additional effort required. Temporal Cloud has automated the process of replication, workflow migration, and failover  allowing customers to rest easy.\nHere is a highlight of the benefits offered by Multi-region Namespaces\n\n  Reduce risk & minimize operational disruption: Ensure that your workloads remain available, even during unexpected outages. Seamless failover shifts workflow executions to a standby region during outages, without the need for any manual synchronization\n  No manual deployment, configuration or code changes needed: Temporal Cloud simplifies the deployment process with push-button operations. This eliminates the need for any changes on your end\n\nA fun fact is that we have been dogfooding our own replication technology in Temporal Cloud for over a year, so it has been battle-tested and is ready to offer high-availability and reliability to our customers!\nTo learn more about the feature, visit\n\n  Documentation\n  Pricing\n  High Availability in Temporal Cloud\n  SLA Definitions\n\nIn our recent webinar we discussed Temporal Cloud's high availability and durability, spotlighting the new Multi-region namespace capability and tips for configuration. \nFor any questions on how to enable this feature, please reach out to your account team or directly at product@temporal.io!",featureImage:{title:"social-orb",description:"social-orb",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Tk0k2JzNldP4WvVCZzJzA/08592218f1fd8de9b5efd2ee10cf0364/social-orb.jpg"},publishDate:"2024-06-03T00:00-06:00",metaDescription:"Now in Public Preview: Multi-region Namespaces (formerly Global Namespaces) enable seamless failover and 99.99% availabilityno manual config required.",metaTitle:"Maximize Uptime with Multi-Region Deployment and Failover",socialCard:{title:"social-orb",description:"social-orb",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Tk0k2JzNldP4WvVCZzJzA/08592218f1fd8de9b5efd2ee10cf0364/social-orb.jpg"},tags:"",slug:"maximizing-availability-with-multi-region-namespaces",contentType:"blogPost",entityId:"79ellsoajm9MFcrqpqMfS8",authors:[{id:"5rRXBv9YX2HZHsbvCIr7ts",name:"Nikitha Suryadevara",slug:"nikitha-suryadevara",jobTitle:"Staff Product Manager",photograph:{title:"headshot-nikitha",description:"headshot-nikitha",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4OACKtdVPmoAygYiRKZnHU/d4033aa0852aae010c69fe249c9e90c0/headshot-nikitha.png"},biography:"Nikitha is a Staff Product Manager at Temporal based in San Francisco. She oversees several areas of the product such as high availability, worker management, and observability. Before Temporal, she worked on Compute Infrastructure (Borg) in Google Cloud. Her introduction to compute and cloud was through being a Product Line Manager at VMware. Nikitha started her career as a software engineer and product manager at various SaaS startups. She got her bachelor's degree in electrical engineering from the Manipal Institute of Technology and an MBA from UCLA Anderson.",company:"Temporal",contentType:"person"}],authorsString:"Nikitha Suryadevara",category:"Announcements",readingTime:2},{title:"Cloud benchmark latency: Temporal Cloud vs. self-hosted",content:"Developers often worry Temporal will add latency to their applications. Temporal provides a variety of features and Workflow design patterns to help you meet the latency requirements of most apps, but ultimately, your minimum latency will depend on the network latency between your Workers and the Temporal Service, and how well the Temporal Service is tuned.\nYou might assume your application latency will be higher if you use Temporal Cloud rather than self-host Temporal. After all, with Temporal Cloud, the Temporal Service will no longer be located on the same infrastructure as your Workers, increasing network latency.\nIn reality, the opposite is true: end-to-end application latency is significantly lower when using Temporal Cloud compared to self-hosted Temporal. Temporal Cloud offers important architectural advancements to reduce latency, including a custom persistence layer. The latency improvements in Temporal Clouds architecture are so effective that they eclipse the cost of the higher network latency incurred when talking to Temporal Cloud.\nWeve frequently noticed latency improvements when customers migrate from self-hosted Temporal to Temporal Cloud. To quantify these observations, we benchmarked application-side metrics against a self-hosted Temporal Service and Temporal Cloud, with application Workers hosted in the same region.\nThe results demonstrate lower latency in Temporal Cloud compared to the self-hosted instance, supporting what we often tell customers: Temporal Cloud is the best choice for internet scale and low latency workloads.\nBenchmark Overview and Setup\nWe measured five application-side SDK metrics, which we chose because they contribute to application latency. Temporals SDKs emit these metrics by default.\nThe benchmarking infrastructure was established using a specialized latency benchmarking framework, which is accessible here. This framework constructs a Kubernetes cluster and deploys Omes, our designated tool for benchmarking and load testing. Omes incorporates Temporal Workers and a scenario runner to simulate an application environment.\nTo evaluate a wide range of SDK metrics we used the throughput_stress Omes scenario, which uses a comprehensive set of Temporal primitives. The activities used by the throughput_stress workflow are lightweight, with little CPU required. As this benchmark is focused on latency, rather than throughput, the scenario was configured to skip sleeps and to only run one workflow at a time. With this configuration, the workflow's end-to-end latency can serve as an effective metric for comparing Temporal Service instances.\nDuring the benchmark, all pods, nodes, and databases were below 80% CPU utilization.\nFor testing of a self-hosted Temporal Service, the tool installs a Temporal Service backed by a MySQL database.\nAll of the measurements in this post were recorded in clusters running in the AWS us-west-2 region.\nMetric 1: WorkflowEndtoEnd Latency\n\n  \n\nWhat it measures: Workflow_EndtoEnd_Latency measures total execution time, from schedule to completion, for a single Workflow Execution.\nWhy we benchmarked it: This metric can be used to quickly compare the performance of instances running the same workload, as it shows the latency of a full Execution.\nResults\n\n  \n    \n      \n      p50 Latency\n      p90 Latency\n    \n  \n  \n    \n      Self-Hosted Temporal\n      750 ms\n      950 ms\n    \n    \n      Temporal Cloud\n      376 ms\n      476 ms\n    \n  \n\nMetric 2: StartWorkflowExecution Latency\n\n  \n\nWhat it measures: the round-trip time for requests to start a Workflow. To start a Workflow your application contacts the Temporal Service. The Temporal Service durably persists records to represent the Workflow, and acknowledges the request with a response to your application. As the request has been durable persisted, the Temporal Service does not have to wait until the Workflow has started executing to respond.\nWhy we benchmarked it: This metric is important because applications tend to start Workflows frequently, often as a result of inline handling of a web request. Keeping this latency low is particularly important to avoid holding up web requests.\nResults\n\n  \n    \n      \n      p50 Latency\n      p90 Latency\n    \n  \n  \n    \n      Self-Hosted Temporal\n      23.8 ms\n      42.6 ms\n    \n    \n      Temporal Cloud\n      17.7 ms\n      23.8 ms\n    \n  \n\nMetric 3: SignalWorkflowExecution Latency\n\n  \n\nWhat it measures: the round-trip time for requests to signal a Workflow. As with Start workflow requests, these must be persisted by Temporal Service to ensure they will not be lost.\nWhy we benchmarked it: Applications use Signals to inform Workflows of external events. These Signals are often delivered as the result of some action in a UI or receiving an event on a message queue. Low latency here helps keep the application responsive and improves message queue efficiency.\nResults\n\n  \n    \n      \n      p50 Latency\n      p90 Latency\n    \n  \n  \n    \n      Self-Hosted Temporal\n      17.5 ms\n      23.5 ms\n    \n    \n      Temporal Cloud\n      7.64 ms\n      9.76 ms\n    \n  \n\nMetric 4: RespondWorkflowTaskCompleted Latency\n\n  \n\nWhat it measures: the response time from Workers to the Temporal Service when a Workflow Task is completed. As Workflows make progress, the Workers must communicate with the Temporal Service, detailing which actions must be taken next. This may be starting a new child workflow, scheduling an Activity, or simply just setting a Timer to wake the Workflow up again later.\nWhy we benchmarked it: Workflow throughput is impacted by how quickly Workers can communicate with the Temporal Service. If the Temporal Service responds more quickly, then Worker performance improves, and subsequently application performance.\nResults\n\n  \n    \n      \n      p50 Latency\n      p90 Latency\n    \n  \n  \n    \n      Self-Hosted Temporal\n      23.9 ms\n      51.5 ms\n    \n    \n      Temporal Cloud\n      17.8 ms\n      24.7 ms\n    \n  \n\nMetric 5: RespondActivityTaskCompleted Latency\n\n  \n\nWhat it measures: the response time from Workers to the Temporal Service when an Activity Task is completed.\nWhy we benchmarked it: Workflow throughput is impacted by how quickly Workers can communicate with the Temporal Service. Activities are used to perform a single, well-defined action such as calling another service or processing data. If the Temporal Service responds more quickly, then Worker performance improves, and subsequently application performance.\nResults\n\n  \n    \n      \n      p50 Latency\n      p90 Latency\n    \n  \n  \n    \n      Self-Hosted Temporal\n      23.9 ms\n      61.7 ms\n    \n    \n      Temporal Cloud\n      17.3 ms\n      30.8 ms\n    \n  \n\nAnalysis of the latency differences\nThis benchmark supports what weve observed anecdotally after customer migrations: Temporal Cloud provides lower application-side latency than self-hosted Temporal. The lower latencies on Temporal Cloud across the board resulted in a reduced end-to-end latency for our test workflow. Temporal Cloud was able to complete the workflow nearly twice as fast as the Self-Hosted Instance, completing the workflow in 50.1% of the time at both p50 and p90.\nThese latency improvements can be attributed to Temporal Clouds custom persistence layer, which includes more efficient sharding, a write-ahead log (WAL), and tiered data storage. We designed this architecture specifically for high throughput and large scale. As is apparent in this benchmark, the benefits of the custom persistence layer far outweigh any incurred network latency when using Temporal Cloud.\nWhat this benchmark means for production applications\nThousands of users currently run applications in production with both self-hosted Temporal and Temporal Cloud. Our recommendation is that you should consider Temporal Cloud for all production workloads due to the service level guarantees and supportespecially for latency-sensitive, large-scale, or business-critical applications.\nA final consideration is that Temporal Cloud provides a lower price per performance than self-hosted Temporal. The self-hosted Temporal Service in this benchmark was well-tuned and never overloaded (it was below 80% CPU at all times). In reality, this is not always the case. It can be labor-intensive to scale the Temporal Service for a high-throughput use case. You must scale your database (Postgres, MySQL, or Cassandra) and manage four additional independent services. The database and all services must be resourced properly: provisioned for peak load to avoid bottlenecks, and deployed in a highly available manner. These infrastructure and operational costs are steep compared to the consumption-based costs of Temporal Cloud.\nLearn more and run the benchmark yourself\nWeve provided details on how to reproduce this benchmark here. As with any benchmark, results may vary depending on your workload and scale.\nHere are some other helpful resources to learn more:\n\n  Blog Post  Higher Throughput and Lower Latency: Temporal Clouds Custom Persistence Layer\n  On-demand Webinar  Custom Persistence Layer of Temporal Cloud\n  Video  Custom Persistence Layer talk from Replay Conference\n  Blog Post  Scaling your self-hosted instance\n",featureImage:{title:"mo-U3Kst7MY4Ok-unsplash",description:"mo-U3Kst7MY4Ok-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1ZjqmPpBtEMbDMdaDRNMZD/1a595161e2cee8f98964c6563cebd210/mo-U3Kst7MY4Ok-unsplash.jpg"},publishDate:"2024-05-22T00:00-06:00",metaDescription:"Compare cloud benchmark results for Temporal Cloud and self-hosted setups. See how latency and performance stack up.",metaTitle:"Cloud Benchmark: Temporal Cloud vs. Self-Hosted",tags:"Cloud,Self-Hosted",slug:"benchmarking-latency-temporal-cloud-vs-self-hosted-temporal",contentType:"blogPost",entityId:"1olNSqYPFnXjPWF5yY2fO7",authors:[{id:"765ncnsHQZyTqc5R3DmGMf",name:"Rob Holland",slug:"rob-holland",jobTitle:"Staff Developer Experience Engineer",photograph:{title:"Rob Holland",description:"Rob Holland",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5TYAt2gPMiffTdA6ZRdgY3/bfcc87ff9e19765d53c736981313889b/9563"},company:"Temporal",contentType:"person"},{id:"4dsODPDNXZPwvTMknnOR7N",name:"Meagan Speare",slug:"meagan-speare",jobTitle:"Sr. Manager, Product Marketing",photograph:{title:"headshot-megan-speare",description:"headshot-megan-speare",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4cU6Eil7AyPgQDtc52XeS8/935bb30acca03ba2e011e5cc90be909c/meagan-speare.jpg"},contentType:"person"}],authorsString:"Rob Holland, Meagan Speare",category:"Temporal Concepts",readingTime:8},{title:"Learn how to interact with Workflows with free hands-on training",content:"Today we announce the availability of four new hands-on training courses. Each course covers the same topichow to interact with Workflowsusing a specific SDK:\n\n  Interacting with Workflows with Go\n  Interacting with Workflows with Java\n  Interacting with Workflows with Python\n  Interacting with Workflows with TypeScript\n\nWhy should I take Interacting with Workflows?\nTemporal application developers need to learn how to build dynamic applications that respond to external stimuli or dynamic data. For example, enabling your Workflows to respond to Signals and Queries allows them to react to external events during execution. In addition, learning about Search Attributes, Asynchronous Activity Completion, and Workflow cancellations will equip you to manage complex Workflows, optimize tasks, and more. This knowledge is essential for developing scalable, maintainable applications that adapt to dynamic changes and user needs.\nWhat Do These Courses Cover?\nWe had four main goals in mind when designing these courses.\nIntegrating Signals and Queries with Workflows\nIntegrating Signals and Queries is an essential skill to learn for developers looking to build responsive applications. Signals allow Workflows to react to events at runtime, while Queries enable on-demand data retrieval from ongoing Workflows without disrupting their execution. Understanding how to work with Signals and Queries allows developers to manage stateful interactions efficiently. This course will guide you on how to define, handle, and send Signals and Queries. Youll also explore common challenges and practical workarounds, how to monitor your Signals in the Event History, and more.\nDeveloping Custom Search Attributes to identify specific Workflow Executions\nTemporal's Search Attributes enable you to locate specific Workflow Executions of interest within the Namespace. In this course, youll begin with learning the difference between default and Custom Search Attributes. These attributes will allow developers to quickly identify and act on specific Workflow Executions with the command-line interface and Web UI. Well then guide you through setting up and querying your Workflow Executions with Custom Search Attributes, giving you insight and allowing you to efficiently track Workflow Executions.\nEvaluating methods to stop Workflow Executions\nUnderstanding how to cancel Workflow Executions is important for managing Workflows under various scenarios, allowing for the cancellation of processes in response to user actions or external conditions. In this course, you will learn how to strategically cancel specific parts of executions and individual Activities, ensuring precise control over your applications behavior and external disruptions.\nDeveloping Asynchronous Activities\nAsynchronous Activities offer the flexibility needed to handle long-running or external tasks effectively, ensuring that your Workflow Executions can continue processing other tasks concurrently. In this course, you will learn what Activity Heartbeats are and how they are used to monitor the progress of your applications Activities. Youll also explore the tradeoffs between Asynchronous Completions and Signals, providing the advantages or disadvantages of both. Additionally, youll learn how to develop Activities asynchronously within your Workflow code.\nWho Should Take this Course?\nThis course is appropriate for any Temporal application developer who understands how to retrieve Workflow output and navigate the Web UI. Since that topic is covered in Temporal 101: Introducing the Temporal Platform, we recommend that you first complete that course, as well as our Temporal 102: Exploring Durable Execution course, which covers the Event History in greater detail, before you begin one of our Interacting with Workflows courses.\nIf you're ready to learn how to interact with Workflows, just follow one of the links below and begin your free hands-on training:\n\n  Interacting with Workflows in Go\n  Interacting with Workflows in Java\n  Interacting with Workflows in TypeScript\n  Interacting with Workflows in Python\n\nWhat's Next for Temporal Training?\nThe Education Team is currently developing a series of courses, each of which focuses on a specific aspect of Temporal application development. Last month, the Education team released the Securing Application Data course, which teaches why and how to secure application data. We will follow the Interacting with Workflows course with a course on crafting an error handling strategy for your Temporal applications in the coming months.\nAnd, if you attend Replay, be sure not to miss out on Wednesday, September 18. That's when members of our Education team and our partner Bitovi will deliver 14 of these courses livewe invite you to participate!",featureImage:{title:"social-card-purple",description:"social-card-purple",url:"https://images.ctfassets.net/0uuz8ydxyd9p/UbL8tEOAIBjMrI6OCSeNN/62aecca8ce16e11e288c1fd7ef4e346d/social-card-purple.jpg"},publishDate:"2024-05-21T00:00-06:00",metaDescription:"Explore four new hands-on training courses from Temporal to learn how to interact with workflows using different SDKs. Start learning today!",metaTitle:"Learn how to interact with Workflows with free hands-on training",socialCard:{title:"social-card-purple",description:"social-card-purple",url:"https://images.ctfassets.net/0uuz8ydxyd9p/UbL8tEOAIBjMrI6OCSeNN/62aecca8ce16e11e288c1fd7ef4e346d/social-card-purple.jpg"},tags:"Code Samples,Go,Java,Python,Typescript",slug:"learn-how-to-interact-with-workflows-with-free-hands-on-training",contentType:"blogPost",entityId:"p0Epn7gxMYRMkzE33EyMB",authors:[{id:"gz6Asa7ycvY1HZz9vcJk0",name:"Angela Zhou",slug:"angela-zhou",jobTitle:"Senior Technical Curriculum Developer",photograph:{title:"headshot-angela-zhou",description:"headshot-angela-zhou",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3FgLhuMJuEASXJmzoNevWN/c115937f066329eb77cd75caa831bfbe/headshot-angela-zhou.png"},contentType:"person"}],authorsString:"Angela Zhou",category:"How-To",readingTime:4},{title:"Introducing: Temporal Summer Camp! ",content:"Coming this July, were kicking off our very first Temporal Summer Camp!\nWe were brainstorming on what we could do this summer that would be both fun and educational for the community. Someone on our team tossed around the words Summer Camp, and it just clicked! We built Summer Camp to bring out the inner kid in you, while still providing educational content to ensure we all use our time wisely, because aint nobody got time for that. \nWhat is it?\nSummer Camp, set to take place in the month of July 2024, is a collection of virtual and in-person activities, such as in-person meetups, lunch-and-learns, webinars, fireside chats, demos, and contests.\nCommunity members can come and observe if they just want to watch or take on a more active role by volunteering to do a lightning talk on their use case, organizing a meetup in their city, or hosting a lunch and learn in their office! Registration for Summer Camp is officially open, so secure your spot today and dont miss out on all of the upcoming activities.\nIf you are interested in presenting at a lightning talk (show and tell), hosting a meetup, or want to request a lunch and learn, email us at : summercamp@temporal.io\nWere still in the planning stages, but heres what you can expect:\nLearn and Build:\nOur Temporal education team is preparing some beginner-friendly training sessions alongside some more advanced topics, if youre looking to level up. Each week of the camp is filled with activities designed to cater to all learning styles and levels.These technical trainings will take you through the fundamentals and advanced nuances of Temporal.\nIn-Person Meetups:\nDisconnected but highly connected. Theres something special about connecting with people who share your passion. Were planning in-person meetups in a variety of cities across the globe. If you are interested in hosting one, make sure to email us at summercamp@temporal.io.\nLunch and Learns:\n\n  Organizing an educational pizza party at your office might just make you the hero at your company and on your team. Technology is constantly changing, and we need to make sure we stay on top of the pulse. Were sending out our field experts to a variety of companies to host lunch and learns! Lunch is on us, of course!\n  To request a lunch a learn, email summercamp@temporal.io. (subject to availability)\n\nLightning Talks:\nHear directly from your peers at our lightning talks, where community members showcase their real-world use cases and workflows using Temporal.\n\n  These quick, insightful presentations are packed with tips, tricks, and lessons learned from actual experiences.\n  If you are considering showcasing your project, please email us at summercamp@temporal.io.\n\nFireside chats:\nJoin us for cozy fireside chats with industry leaders and innovators. These relaxed sessions are perfect for gaining deeper insights into Temporal and the tech world, providing an intimate platform for discussion and questions.\nAMA Sessions:\nGot questions? Get answers in our AMA sessions, where you can ask anything about Temporal, from technical queries to best practices. Its a direct line to the experts and a great way to clear up doubts and gain new knowledge.\nContests and swag!\n\n  Show off your skills and compete with other developers in our exciting contests! Whether it's coding challenges or creative problem-solving, you'll have the chance to win great prizes and gain recognition in the Temporal community.\n  You can also earn great swag by volunteering to be involved. Email us for info!\n\n\n  Were really looking forward to spending the summer learning with you!\n  While we are still building out the official schedule, you can still register today to be involved in the program.\n\nWe will be updating you as things progress to make sure you dont miss a beat!\nSee you soon, campers!\n\n  \n  Temporal Camp Counselors\n",featureImage:{title:"summer camp",description:"summer camp",url:"https://images.ctfassets.net/0uuz8ydxyd9p/MILOGcP4arKr1ogazpdED/a3342dfb9048ddfcdf81a5fa9e0fde77/summer_camp.jpg"},publishDate:"2024-05-20T00:00-06:00",metaDescription:"Coming this July, were kicking off our very first Temporal Summer Camp! ",metaTitle:"Introducing: Temporal Summer Camp! ",socialCard:{title:"summer camp",description:"summer camp",url:"https://images.ctfassets.net/0uuz8ydxyd9p/MILOGcP4arKr1ogazpdED/a3342dfb9048ddfcdf81a5fa9e0fde77/summer_camp.jpg"},tags:"Meetups,Industry Events",slug:"introducing-temporal-summer-camp",contentType:"blogPost",entityId:"33yCAyByBsihdFTjEHDMG1",authors:[{id:"71Gv0D8ql0QQKIIaNItnn0",name:"Karin Wolok",slug:"karin-wolok",jobTitle:"Marketing",photograph:{title:"headshot-karin-wolok",description:"headshot-karin-wolok",url:"https://images.ctfassets.net/0uuz8ydxyd9p/23ElKMBIBVBqbm5uk77FHK/5d95e338ffc39f57b12d0958950a13a9/headshot-karin-wolok.png"},contentType:"person"}],authorsString:"Karin Wolok",category:"Announcements",readingTime:4},{title:"Becoming a Temporalite: Clair Byrd, CMO",content:"Our world is shifting, once again. Macrotrends that impact software at a massive scale, like AI's proliferation, the growth of devops as a practice and profession, containerization, and the continued decentralization of applications in favor of more flexible, SLA-backed, specialized cloud providers has introduced a whole new world of complexitya tangled, often brittle web of hundreds or thousands of microservices, infrastructure providers, state management, rigid orchestration, team-specific processes and preferences, compliance requirements, and security practices.\nComplexity like this requires a new way to think about the fundamentals of how applications get builtour engineering principles have to shift, too.\nI'm thrilled to be joining Temporal to help the brand and our community usher in a new engineering paradigm that simplifies this complexity for developers, reduces their toil, and shores up the brittle nature of our applications.\nI want to start my first public communication to the Temporal community by sharing a few simple beliefs:\nI am a die-hard open-source religious believer. I am a flag-waving supporter of the expanded access to tools that things like \"free forever\" plans have brought to the world. And I believe that the communities of builders that convene around technologies are just as important as the technology itself.\nI'm super privileged to have spent most of my career supporting tools that deliver those things to people building software. And by becoming a Temporalite, I get to live all these beliefs every day.\nBeyond that, I believe all software should also be:\nSimple and intuitive.\nInnovatively integrated into my daily life.\nBug-free and performant.\nThese are the principles my leadership roles at InVision, Twilio, and most recently at Sauce Labs, have taught me.\nAnd now, I'm adding \"durable and failure-proof\" to the list. Software should be reliable as gravity, as my new teammates like to say. And I agree!\nI'm thrilled to have been offered the opportunity to join Temporal as CMO. I know that marketing can be a swear word with developers, and I'm sure the announcement of a leader focusing on this function entirely might raise your eyebrows. My job is not to \"market\" to you. It's to 1) make a market, 2) build communities, and 3) drive revenue for the business.\nTemporal as a brand, OSS project, and cloud company needs to make a new market for all of us to succeed. We need to expand our community exponentially to bring reliability to the world's applications. And, as a business, we need revenue to continuously invest in Temporal's OSS and hosted products and the new engineering paradigm we believe in and all share.\n\n  Make a market: drive the evolution of how developers build applications by designing, documenting, championing, and proving the value of the tenets of durable execution and durability engineering globally to build a category. Identify areas within the SDLC to shift spending from existing IT budgets to projects that deliver durable execution programs. Create new kinds of engineering roles, teams, functions, budgets, and processes for Temporal and other players in our space to address.\n  Build communities: inspire, educate, equip, and enable practitioners around the world with hard-to-get skills, access to information, and opportunities to convene around things that matter to them. Support the ecosystem already in place for application developers, augment with programs that deepen relationships and build bridges between people.\n  Drive revenue: identify and surface opportunities within the market where a deeper commercial relationship makes sense and is deeply mutually beneficial. Make our customers and the people with hands on keyboard wildly successful. Clearly understand Temporal's place in the market and what makes us unique, and drive programs around those qualities.\n\nI wanted to close by sharing publicly and transparently that my marketing mantra is, quite literally, \"don't be gross.\" What that means in practice is this:\n\n  We will not spam you\n  Our work will enhance your experience and not detract from it\n  The things we make will be based on stuff youve asked for\n  We will not unnecessarily limit access to things to force conversion\n  We will strive to live up to the standard you set. Our community creates incredible things every day  if were not meeting that standard, were failing.\n\nI am stoked to be joining a company with such strong alignment to my personal beliefs and core values, as well as a thriving community of builders who seem to mirror those beliefs on a journey to usher in a new way to make applications invincible. I encourage you to get in touch with me at any time to share your feedback, ideas, or comments with meand if I ever don't live up to my commitments above, feel free to call me out! You can find me in the Temporal Slack community or on Twitter!",featureImage:{title:"clair-feature-image",description:"clair-feature-image",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41Sp92v0l4764RVqMDivBG/04ac2f7f28ef2e3654bab1b77e4734ba/clair-feature-image.png"},publishDate:"2024-05-15T00:00-07:00",metaDescription:"Im thrilled to be joining Temporal to help the brand and our community usher in a new engineering paradigm that simplifies this complexity for developers.",metaTitle:"Becoming a Temporalite: Clair Byrd, CMO",socialCard:{title:"clair-feature-image",description:"clair-feature-image",url:"https://images.ctfassets.net/0uuz8ydxyd9p/41Sp92v0l4764RVqMDivBG/04ac2f7f28ef2e3654bab1b77e4734ba/clair-feature-image.png"},tags:"Industry Events",slug:"becoming-a-temporalite-clair-byrd-cmo",contentType:"blogPost",entityId:"1SudFxw5tlB34tELjWxzVi",authors:[{id:"780p8MZSlKh9AuMzW5FrA0",name:"Clair Byrd",slug:"clair-byrd",jobTitle:"CMO",photograph:{title:"Clair Byrd",description:"Clair Byrd",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2ENA9j4df6EfXCLgoWmt46/bb029b33e3f92fb2a7973348c8ccce88/861A2507.jpg"},biography:"Clair Byrd is the Chief Marketing Officer at Temporal, the company defining durable execution in software engineering. Before joining Temporal, Clair held senior marketing and leadership roles at Twilio, InVision, and Sauce Labs, and co-founded the front end builder platform Mason. Her work centers on elevating developer experience, connecting open-source ecosystems, and building brands that inspire technical creativity and trust. Clair is passionate about storytelling that helps engineers build faster, smarter, and with lasting impact.",company:"Temporal",contentType:"person"}],authorsString:"Clair Byrd",category:"Community",readingTime:5},{title:"Temporal in India: My experience in Bengaluru",content:"Although Temporal has previously held meetups in Bengaluru, Mumbai, and Hyderabad, the Great International Developer Summit two weeks ago marks the first time we had a presence at a conference in India. Since I gave a presentation and met hundreds of developers at the Temporal booth there, I wanted to share my impressions on my trip.\n\n  \n  Photo: The Great International Developer Summit banner, just outside the entrance to the JN Tata auditorium\n\nThis was my first time in India, a country Ive dreamed of visiting since childhood. Despite landing at 3:00 AM, Terminal 2 at Kempegowda International Airport in Bengaluru immediately caught my attention with its extensive woodwork, open spaces, and beautiful gardens. Its easy to see why it won multiple awards and has been named as one of the best airports in the world.\n\n  \n  Photo: Terminal 2 - Kempegowda International Airport (credit: Wikimedia Commons user Ananthmohanram18)\n\nMeeting a Longtime Friend\nThe highlight of my trip happened soon after I arrived on Sunday. Through my work in another open source community years ago, I was introduced to Varun, then a CS student at a university in Northern India. Weve stayed in touch through the yearshes since moved to Hyderabad and has a successful career as a senior engineer. Before my trip, I wrote to let him know that although I was finally visiting India, Id be in a different city with little free time and wouldnt be able to meet him during this trip. Varun immediately wrote back to say that hed come to Bengaluru to meet me. Open source truly does bring people together and it was so wonderful to finally meet my friend in person after all these years. Varun was an excellent host and truly exemplified the importance of hospitality in Indian culture.\nConference Organizers Demonstrate Local Pride\nUpon checking into the conference on the first day, I received my badge as well as speakers gifts from the conference organizers. These included an interesting book about the city, a very nice clothbound notebook, and a delicious artisanal chocolate bar made with jaggery in the Dakshina Kannada district of Karnataka, about 300 kilometers west of the conference. It was clear that the conference organizers have a lot of local pride, and after spending a week there, I can certainly understand why.\n\n  \n  Photo: The book and other gifts given to speakers by the conference organizers\n\nA Tough Act to Follow\nMy presentation was on Tuesday, the first day of the conference. After settling in at the Temporal booth, I went to find the room where Id deliver the talk. Im glad that I did, because it was in a separate building across the parking lot. When I arrived, I saw that my presentation was right after one from Dr. Venkat Subramaniama tough act to follow! I remembered that in 2007, we were both speakers at the Gateway Java Symposium in St. Louis, Missouri, USA. This time, we were doing it again on the other side of the world. Fun fact: My manager at Temporal, Brian Hogan, was also the editor for at least two of Dr. Subramaniams books. Its a small world.\n\n  \n  Photo: The sign outside the room where I delivered my presentation\n\nStanding Room Only\nI worried whether others would be able to find the room, but despite the distant location, it quickly filled up. According to the conference organizer, nearly 300 people attended my talk. Not only were the lecture hall's 275 seats filled, there were also people standing on the sides, aisles, and in the back of the room. The warm welcome for my first talk in India made me feel right at home\n\n  \n  Photo: Standing room only for my presentation: Temporal: A Better Way to Build Modern Applications\n\nConversations at the Temporal Booth\nGIDS is a large conference, so for each person who saw my presentation, there were probably 10 more who did not. Fortunately, I was able to introduce hundreds of these developers to Temporal through conversations and demonstrations at our booth. Attendees at GIDS were very technical and able to grasp key Temporal concepts right away.\n\n  \n  Photo: Tom talks to a group of developers at the Temporal booth\n\nOne question that came up repeatedly is one that seldom comes up at other conferences: How much latency does Temporal add? As with most technical questions, the answer is It depends.\nLatency varies based on the design of the application and the infrastructure where it runs, among other factors, so its difficult to generalize. Regardless of whether you use Temporal, ensuring that your business transactions complete requires that you persist application state. Applications built on Temporal do this automatically, while developers writing non-Temporal applications must write their own code for this. Because of caching and other built-in optimizations, the latency and performance of an application built on Temporal is usually the same or better than the equivalent non-Temporal application. In the rare case that latency the custom solution has lower latency, the transformational gains in reliability, scalability, and developer productivity that Temporal provides will likely far outweigh that difference.\nWrapping Up\nIm back home and nearly over the jet lag, but I already miss starting off my day with a masala dosa, idli, sambar, and a cup of Indian filter coffee (which reminded me of the chicory-based caf au lait I have whenever Im in New Orleans).\n\n  \n  Photo: The masala dosa I had for breakfast at the world famous Mavalli Tiffin Room.\n\nThe conference, the food, and the sights were all excellent, but the friendly people I met made my time in Bengaluru so memorable for me. It was my first trip to India, but it certainly wont be my last.",featureImage:{title:"social-waves",description:"social-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1ojf8uswsTwWgcxXdka2tN/c2ee70581685dfc48f11115ec9fb4490/Component_1.png"},publishDate:"2024-05-08T00:00-06:00",metaDescription:"Although Temporal has previously held meetups in Bengaluru, Mumbai, and Hyderabad, the Great International Developer Summit two weeks ago marks the first time we had a presence at a conference in India. ",metaTitle:"Temporal in India: My experience in Bengaluru",socialCard:{title:"social-waves",description:"social-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1ojf8uswsTwWgcxXdka2tN/c2ee70581685dfc48f11115ec9fb4490/Component_1.png"},tags:"Industry Events",slug:"temporal-in-india-my-experience-in-bengaluru",contentType:"blogPost",entityId:"7fdHrNM2X2jZEetYGL8dMp",authors:[{id:"6NFooJhrzJdVAxMRWhgeTl",name:"Tom Wheeler",slug:"tom-wheeler",jobTitle:"Principal Developer Advocate",photograph:{title:"Tom Wheeler",description:"Tom Wheeler",url:"https://images.ctfassets.net/0uuz8ydxyd9p/53ysX1Y47NqQaThXEVUny4/b1d9bbb620188ffc23a6a5098a80cfa5/tomwheeler-2024-headshot-800x800.webp"},biography:"Alternating between software engineering and technical education roles, Tom Wheeler's career spans more than 25 years in the financial, healthcare, defense, and tech industries. Prior to joining Temporal as the founding member of the Education team in 2022, he wrote training courses at Cloudera, developed aerospace engineering software at Object Computing, helped create a distributed system for high-volume data processing at WebMD, and built some of the earliest web applications at brokerage firm A.G. Edwards. When Tom manages to step away from the computer, you can probably find him cooking, traveling, or playing guitar.",company:"Temporal",contentType:"person"}],authorsString:"Tom Wheeler",category:"Community",readingTime:5},{title:"Learn how to secure Temporal application data with free hands-on training",content:"Today we announce the availability of four new hands-on training courses. Each course covers the same topicsecuring application datausing a specific SDK:\n\n  Securing Application Data with Go\n  Securing Application Data with Java\n  Securing Application Data with Python\n  Securing Application Data with TypeScript\n\nWhy should I take Securing Application Data?\nTemporal application developers need to learn how to secure their application data if their payloads contain sensitive information that needs to be encrypted. Defining custom data conversion behavior, using an encryption codec and codec server, allows you to make CLI and SDK calls that encode and decode the data being sent from your application to a Temporal Service.\nWith these training courses, you'll learn when securing application data is necessary and practice applying it using your favorite SDK.\nWhat Do These Courses Cover?\nWe had three main goals in mind when designing these courses.\nExplaining how to customize your Data Conversion behavior\nTemporal provides its own default data conversion logic for serializing input and output as JSON. To implement custom data handling, including data compression or encryption, you can customize this data conversion logic. There are several components to defining custom data conversion: a custom codec, a custom failure converter (for encrypting your error messages), and a custom payload converter (for complex data handling). These courses provide guidance on all three.\nUnderstanding best practices for codecs and encryption\nImplementing a custom codec, for example to encrypt your Temporal Payloads, provides flexibility for your data handling. Selecting an encryption solution for your infrastructure is a significant decision, and Temporal is designed to be as flexible as possible in supporting institutional requirements and existing security infrastructure. These courses provide some best practices and recommendations from our community for implementing encryption.\nExploring the creation and deployment of a Codec Server\nA Codec Server is a standalone server that uses your custom codec logic to decode your data remotely through predefined endpoints. The Temporal CLI and the Web UI in turn provide built-in hooks to call the Codec Server to decode encrypted payloads on demand. These courses provide guidance on how to create, operate, and manage access to your Codec Server in your own environment.\nWho Should Take this Course?\nThis course is appropriate for any Temporal application developer who understands how to retrieve Workflow output and navigate the Web UI. Since that topic is covered in Temporal 101: Introducing the Temporal Platform, we recommend that you first complete that course (and Temporal 102) before you begin one of our Securing Application Data courses.\nIf you're ready to learn how to Secure Application Data, just follow one of the links below and begin your free hands-on training:\n\n  Securing Application Data with Go\n  Securing Application Data with Java\n  Securing Application Data with Python\n  Securing Application Data with TypeScript\n\nWhat's Next for Temporal Training?\nLast month, the Education team followed up on Temporal 101: Introducing the Temporal Platform and Temporal 102: Exploring Durable Execution by releasing a course dedicated to Versioning. That was the first in a series of courses, each of which focuses on a specific aspect of Temporal application development, that were developing this year. Securing Application Data is the second in this series and we will follow it with additional courses in the coming months.\nAnd, if you attend Replay, be sure not to miss out on Wednesday, September 18. That's when members of our Education team and our partner Bitovi will deliver 14 of these courses livewe invite you to participate!",featureImage:{title:"social-card-temporalite-blog",description:"social-card-temporalite-blog",url:"https://images.ctfassets.net/0uuz8ydxyd9p/43c3wR1aXhf2oLpXy8WReZ/b280baada058cdc1d0dc9a4b2aaff37a/social-card-temporalite-blog.jpg"},publishDate:"2024-04-30T00:00-06:00",metaDescription:"Today we announce the availability of four new hands-on training courses. Each course covers the same topicsecuring application datausing a specific SDK:",metaTitle:"Learn how to secure Temporal application data with free hands-on training",socialCard:{title:"social-card-temporalite-blog",description:"social-card-temporalite-blog",url:"https://images.ctfassets.net/0uuz8ydxyd9p/43c3wR1aXhf2oLpXy8WReZ/b280baada058cdc1d0dc9a4b2aaff37a/social-card-temporalite-blog.jpg"},tags:"Security,Go,Java,Typescript,Python",slug:"learn-how-to-secure-temporal-application-data-with-free-hands-on-training",contentType:"blogPost",entityId:"6Sxcxkevo4vKInY0IeJoZA",authors:[{id:"1ixl3MvlJq3HHeOAybbItw",name:"Alex Garnett",slug:"alex-garnett",jobTitle:"Sr. Curriculum Developer",photograph:{title:"headshot-alex-garnett",description:"headshot-alex-garnett",url:"https://images.ctfassets.net/0uuz8ydxyd9p/AQU0azmUuAr68eADoogUJ/63d8023152958926ce5a524b8439c227/headshot-alex-garnett.png"},contentType:"person"}],authorsString:"Alex Garnett",category:"How-To",readingTime:3},{title:"Improving latency with Eager Workflow Start",content:"Eager Workflow Start (EWS) is an experimental latency optimization, currently in Pre-release, with the goal of reducing the time it takes to start a workflow. The start response with EWS includes the initial workflow task when there is a local worker ready to process it.\nThe target use case is short-lived workflows that interact with other services using local activities, ideally initiating this interaction in the first workflow task, and deployed close to the Temporal Server. These workflows have a happy path that needs to initiate interactions within low tens of milliseconds, but they also want to take advantage of server-driven retries, and reliable compensation processes, for those less happy days.\nApplications of this use case include financial transactions that interact with customers in real-time, collaborative apps that need reliable replay, or remote interactions with the physical world, such as configuring drone settings, or controlling factory equipment.\nIn this post, we will first describe how it works, and what performance improvement you can expect. Then, we will discuss some limitations of the current implementation, and finally, wrap up with a \"hello world\" example in Go.\nDiscussion\nThe traditional way to start a workflow decouples the starter program from the worker by sharing a task queue name between them, similar to a publish/subscribe pattern. This has many advantages, for example, we can reliably schedule a workflow execution without a running worker, or separate the worker and workflow implementation from the starter application and host them independently.\nBut decoupling also makes it harder to optimize for latency. Instead, when the starter and worker are collocated and aware of each other, they can interact while bypassing the server, saving a few time-intensive operations.\n\n  \n\nThe above figure shows EWS in action:\n\n  The process begins with the starter setting EnableEagerStart to true in the start workflow options.\n  Then, the SDK will try to locate a local worker that is willing to execute the first workflow task, and reserve an execution slot for it.\n  If successful, the SDK will provide a hint to the server that eager mode is preferred for the new workflow.\n  The server not only registers the start of the workflow in history, it also assigns the first workflow task to the starter, all in the same DB update.\n  The first task is included in the server response, no matching step required.\n  The SDK extracts the task from the response, and dispatches it to the local worker.\n\nTo recover from errors, EWS falls back to the non-eager path. For example, when the first task is returned eagerly, but the local worker refuses to honor the reserved slot, the server retries this task non-eagerly after WorkflowTaskTimeout.\nWhat are the savings? One database update plus the matching operation that associates polling workers with messages in task queues. It can also reduce latency variation because polling worker connections are not always ready when you need them.\nThis translates into significantly lower latency. For example, a few months back we did a test measuring the time it takes to create a workflow and start executing its first task, a local activity. The goal was to estimate the minimum latency to interact with an external service, using a newly-created workflow, and the Temporal Cloud. The starter and worker were in the same AWS region as our Temporal Cloud namespace. The p50 latency was 16.7 ms (eager) vs 29.3 ms (non-eager), a 43% improvement. For p99 latency, we saw 30.9 ms (eager) vs 51.6 ms (non-eager), a 40% improvement.\nNote that these numbers are for illustrative purposes only, just to put EWS potential improvements in perspective.\nLimitations\nThe most intrusive limitation of this implementation is that the worker and the starter need to share a client connection to discover each other. This means that they have to run in the same process, and share a common lifecycle. In the next section, we discuss how to do that with a Go example.\nAlso, the current implementation does not support worker versioning with build IDs, another feature in Pre-release. Our goal is to solve this problem before General Availability.\nCurrently, we are supporting the following Temporal SDKs:\n\n  Go\n  Java\n  Python\n  .Net\n\nWe will not immediately support:\n\n  TypeScript\n\nEWS is enabled with the dynamic configuration server flag system.enableEagerWorkflowStart.\nFor debugging, we can start a local server with EWS enabled using:\ntemporal server start-dev --dynamic-config-value system.enableEagerWorkflowStart=true\nTo enable EWS in your namespace in Temporal Cloud, open a ticket.\nHello World Example\npackage main\n\nimport (\n\t\"context\"\n\t\"log\"\n\n\t\"go.temporal.io/sdk/client\"\n\t\"go.temporal.io/sdk/worker\"\n\n\t\"github.com/temporalio/samples-go/helloworld\"\n)\n\nconst taskQueueName = \"eager_wf_start\"\n\nfunc main() {\n\t// 1. Create the shared client.\n\tc, err := client.Dial(client.Options{})\n\tif err != nil {\n\t\tlog.Fatalln(\"Unable to create client\", err)\n\t}\n\tdefer c.Close()\n\n\t// 2. Start the worker in a non-blocking manner before the workflow.\n\tworkerOptions := worker.Options{\n\t\tOnFatalError: func(err error) { log.Fatalln(\"Worker error\", err) },\n\t}\n\tw := worker.New(c, taskQueueName, workerOptions)\n\tw.RegisterWorkflow(helloworld.Workflow)\n            w.RegisterActivity(helloworld.Activity)\n\terr = w.Start()\n\tif err != nil {\n\t\tlog.Fatalln(\"Unable to start worker\", err)\n\t}\n\tdefer w.Stop()\n\n\tworkflowOptions := client.StartWorkflowOptions{\n\t\tID:        \"eager_wf\",\n\t\tTaskQueue: taskQueueName,\n\n\t\t// 3. Set this flag to true to enable Eager Workflow Start.\n\t\tEnableEagerStart: true,\n\t}\n\n\t// 4. Reuse the client connection.\n\twe, err := c.ExecuteWorkflow(context.Background(), workflowOptions,\n\t\thelloworld.Workflow, \"Temporal\")\n\tif err != nil {\n\t\tlog.Fatalln(\"Unable to execute workflow\", err)\n\t}\n\n\t// 5. Wait for workflow completion.\n\tvar result string\n\terr = we.Get(context.Background(), &result)\n\tif err != nil {\n\t\tlog.Fatalln(\"Unable to get workflow result\", err)\n\t}\n\tlog.Println(\"Workflow result:\", result)\n}\nThe code above is from the samples-go repository, a single-file, EWS-enabled variant of the \"Hello World\" sample, also in the same repository.\nTo share the client between worker and starter, we need to start the worker first in non-blocking mode, i.e., using Start() instead of Run(), and set up a handler for worker errors with the option OnFatalError(). Then, we just need to set the EnableEagerStart to true in the start workflow options, and reuse the previous client.\nConclusion\nEWS is an experimental optimization that reduces the time to start a workflow significantly. The current implementation has some limitations, and it requires changes to the structure of your application, but, if low latency with reliability really matters to you, give it a try, and tell us what you think in our Community Slack!\nAcknowledgments\nRoey Berman is the architect of EWS, and he also implemented the required server-side changes. Quinn Klassen implemented EWS for the Go SDK. Dmitry Spikhalskiy did the Java SDK implementation, and Chad Retz the .Net one. Loren Sands-Ramshaw, Drew Hoskins, Paul Nordstrom, and Tasha Alfano made many insightful comments on this post.",featureImage:{title:"social-card-water-effect",description:"social-card-water-effect",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6k8jGdFtBZEH3ltyuVQKwm/27cd3afdcda2b8032c6e120c5eb67d0f/social-card-water-effect.jpg"},publishDate:"2024-04-29T00:00-06:00",metaDescription:"Discover how Eager Workflow Start (EWS) optimizes latency by reducing workflow start time, now in pre-release with local worker integration.",metaTitle:"Improving latency with Eager Workflow Start in Temporal",socialCard:{title:"social-card-water-effect",description:"social-card-water-effect",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6k8jGdFtBZEH3ltyuVQKwm/27cd3afdcda2b8032c6e120c5eb67d0f/social-card-water-effect.jpg"},tags:"",slug:"improving-latency-with-eager-workflow-start",contentType:"blogPost",entityId:"1oLhVBfdsVV4WiEIrdnxAU",authors:[{id:"1VsdDL6StAL0ss8ChocHDL",name:"Antonio Lain",slug:"antonio-lain",jobTitle:"Software Engineer",photograph:{title:"headshot-antonio-lain",description:"headshot-antonio-lain",url:"https://images.ctfassets.net/0uuz8ydxyd9p/61ToZi7H9PF5TnaVqS29Tc/b18bcbf490f3c856ccc03a41952dde15/headshot-antonio-lain.png"},contentType:"person"}],authorsString:"Antonio Lain",category:"Product News",readingTime:6},{title:"Insights from Workflow History Export on Temporal Cloud",content:"The Temporal Web UI provides a view of workflows and history events within a single workflow execution. Over time, each workflow history contains rich execution metadata such as Workflow Type, Start Time, Close Time, Activity, History Size, Task Queue and so on. Digging into this data can not only provide valuable feedback on operational efficiencies and bottlenecks, but also offer guidance on refining the implementation of workflows and activities.\nIn this post, we will guide you through how to feed workflow history into your choice of data warehouse and a few analyses you can build on top of it.\nIntroducing Workflow History Export\nExport in Temporal Cloud allows users to export closed workflow histories to AWS S3. Once you enable Export, workflow history data lands in your S3 bucket hourly.\nNext, you can start to build data pipelines to analyze closed workflow histories from the past. For more details about Export, please see our documentation.\nCase study for Workflow History Analysis\nData transformation\nWorkflow history is exported in the Protocol Buffer (proto) format, with its schema available at temporalio/api on GitHub. Proto formats are known for their serialization efficiency and their ability to maintain compatibility across different versions. Despite these benefits, proto may not always be the ideal format for data analysis purposes.\nTo bridge this gap, we have developed a convenient workflow that facilitates the conversion of workflow history files from proto to Parquet, making it more amenable to analysis. You can find an example of this conversion process in our cloud_export_to_parquet workflow.\n\n  \n\nWhen transforming data, please keep in mind the following:\n\n  We have transformed the nested proto structure into a flat, tabular format.\n  Each row in the table represents a single history event from a workflow. To preserve their relationship post-conversion, we have included workflowID and runID in every row.\n  If you have enabled codec server, the payload field is encrypted. However, this field may contain characters that are not recognized when loaded into a database. As a result, we have excluded this field from the dataset.\n\nSet up ETL pipeline and feed into datastore\nThe workflow described above is actually a Temporal Schedule which can process data on an hourly basis. You could create a similar Schedule to achieve continuous transformation of exported files from proto to Parquet, which could then land in your data store or directly into Amazon S3. If you use AWS Glue, Lambda or Airflow, you could also reference the Python code in this example and build your own ETL pipeline.\nAfter the data lands, leverage your analytical tool of choice to construct queries and derive valuable insights from workflow history data.\n\n  \n\nConduct data analysis\nAfter converting the nested proto file into Parquet format, upload the file into your data store of choice: AWS Athena, Redshift, Snowflake or Databricks.\nThis particular example uses Big Query as its data store with a dataset comprising a total of 245 columns.\n\n  \n\nHere are a few sample queries to run for useful insights.\n\n  What type of workflow triggered most frequently on my namespace?\n\nSELECT \n    Attributes_WorkflowExecutionStartedEventAttributes_workflow_type_name as workflow_type, \n    COUNT(*) as frequency\nFROM \n    `your table`\nWHERE\n  Attributes_WorkflowExecutionStartedEventAttributes_workflow_type_name is not NULL\nGROUP BY \n    workflow_type\nORDER BY \n    frequency DESC\n\n\n  What type of activities triggered most frequently on my namespace?\n\nSELECT \n    Attributes_ActivityTaskScheduledEventAttributes_activity_type_name as activity_type, \n    COUNT(*) as frequency\nFROM \n    `your table`\nWHERE\n  Attributes_ActivityTaskScheduledEventAttributes_activity_type_name is not NULL\nGROUP BY \n    activity_type\nORDER BY \n    frequency DESC\n\n\n  What is the average execution time of my top 5 workflow types?\n\nWITH RankedWorkflowTypes AS (\n  SELECT \n    Attributes_WorkflowExecutionStartedEventAttributes_workflow_type_name as workflow_type, \n    COUNT(*) AS count\n  FROM \n    `your table`\n  WHERE\n    Attributes_WorkflowExecutionStartedEventAttributes_workflow_type_name is not NULL\n  GROUP BY \n    Attributes_WorkflowExecutionStartedEventAttributes_workflow_type_name\n  ORDER BY \n    count DESC\n  LIMIT 5\n),\nRunIDs AS(\n  SELECT\n    rw.workflow_type,\n    RunId\n  FROM\n    `your table`\n  JOIN \n    RankedWorkflowTypes rw ON Attributes_WorkflowExecutionStartedEventAttributes_workflow_type_name = rw.workflow_type\n),\nRunDurations AS (\n  SELECT\n    rds.workflow_type,\n    r.runId,\n    MAX(CASE WHEN r.event_type = 1 THEN r.event_time_seconds END) AS start_time,\n    MAX(CASE WHEN r.event_type = 2 THEN r.event_time_seconds END) AS end_time,\n    ABS(MAX(CASE WHEN r.event_type = 2 THEN r.event_time_seconds END) - MAX(CASE WHEN r.event_type = 1 THEN r.event_time_seconds END)) AS duration_seconds\n  FROM \n    `your table` r\n  JOIN \n    RunIDs rds ON r.RunId = rds.RunId\n  GROUP BY\n    r.runId, rds.workflow_type\n),\nAverageDurations AS (\n  SELECT\n    workflow_type,\n    AVG(duration_seconds) AS avg_duration_seconds\n  FROM \n    RunDurations\n  GROUP BY \n    workflow_type\n)\nSELECT * FROM AverageDurations;\n\n\n  What are my top 5 longest running activities?\n\n WITH ActivityEvents AS (\n  SELECT\n    runID,\n    event_id, \n    Attributes_ActivityTaskScheduledEventAttributes_activity_type_name as activity_type,\n    event_time_seconds as start_time,\n    LEAD(event_time_seconds) OVER(PARTITION BY runId ORDER BY event_id) AS end_time\n  FROM \n    `your table`  \n  WHERE\n    event_type = 10 or event_type = 12\n  ORDER BY\n    runID, event_id\n ), \n ActivityDurations AS (\n  SELECT\n    runId,\n    activity_type,\n    start_time,\n    end_time,\n    ABS(end_time - start_time) AS duration_seconds\n  FROM\n    ActivityEvents\n  WHERE\n    ActivityEvents.activity_type is not null\n),\nRankedActivities AS (\n  SELECT\n    *,\n    RANK() OVER(ORDER BY duration_seconds DESC) AS rank\n  FROM\n    ActivityDurations\n)\nSELECT\n  runId,\n  activity_type,\n  start_time,\n  end_time,\n  duration_seconds\nFROM\n  RankedActivities\nWHERE\n  rank \u003C= 5;\n\nThere is additional analysis that could be done using workflow history data\n\n  Infer cost from workflow history\n  What values are set for initialInterval and maximumAttempts most often in activity retry policy?\n  What task queues are used most often?\n  Which SDK and which SDK version was used in my namespace?\n  When did workerVersion change in my workflow?\n  Whats the last failure message on different activities?\n\nMetrics or visibility data can help achieve some of this analysis, but if you want all the information in one place, workflow history could be your go-to choice.\nBuild a dashboard to visualize your results\nYou could also build your dashboard to monitor workflow and activity execution over time. Depending on your choice of data warehouse, you could use numerous tools like Grafana, AWS QuickSight, GCP Looker etc. Here is an example powered by Looker Studio.\n\n  \n\nCurrent limitations\nThe case study presented has several identified limitations.\n\n  Export has an at least once guarantee. Thus, please dedupe your data based on runID.\n  The payload field was excluded from our example. Decoding this field with a codec server would enable the extraction of valuable insights from the inputs and outputs of workflows and activities.\n  Given the variability in each hour's workflow history data, the schema of the Parquet files may also change. It is important to ensure that your data warehousing solutions are equipped to manage schema evolution over time.\n\nWhats next on Temporal Cloud?\nImproving the customer experience on Temporal Cloud is our foremost goal. Export is currently in public preview, and we would love to to hear your feedback at product@temporal.io. We plan to support more data types for Export to further streamline data analysis.",featureImage:{title:"social-orb",description:"social-orb",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Tk0k2JzNldP4WvVCZzJzA/08592218f1fd8de9b5efd2ee10cf0364/social-orb.jpg"},publishDate:"2024-04-24T00:00-06:00",metaDescription:"Explore how exporting workflow histories in Temporal Cloud gives you deep insights into execution metadata, events, and performance over time.",metaTitle:"Workflow History Export Insights on Temporal Cloud",socialCard:{title:"social-orb",description:"social-orb",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Tk0k2JzNldP4WvVCZzJzA/08592218f1fd8de9b5efd2ee10cf0364/social-orb.jpg"},tags:"Cloud,Temporal Primitives",slug:"get-insights-from-workflow-histories-export-on-temporal-cloud",contentType:"blogPost",entityId:"7b4GppTNl8CbuJrpBBhDhE",authors:[{id:"3pQ1pcczaCj0RlcdU6oyQ2",name:"Alice Yin",slug:"alice-yin",jobTitle:"Sr. Software Engineer",photograph:{title:"headshot-alice-yin",description:"headshot-alice-yin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/47jPcdz4dL0RZyi0seC1VC/86dba0aad07b06f3d1f079975d1619af/headshot-alice-yin.png"},contentType:"person"}],authorsString:"Alice Yin",category:"Product News",readingTime:6},{title:"Improving the Workflow experience: A look at Temporals new UI",content:"What makes Temporal challenging for building UIs is the same reason its so valuable; the flexibility and durability of Workflows. Temporal can be leveraged for so many different use cases that creating an interface for everyone that is also specific to each unique Workflow is a tall task. There may be a handful of Events, or tens of thousands. Events can be completed, canceled, failed, timed out, or terminated at any time. Workflows may last milliseconds or take years to complete. How can you boil down all of those situations plus everything in-between and create a simple, performant, beautiful, and most importantly, highly valuable user experience? With a lot of iterations, designs, feedback and some dark magic .\nOur goal was to improve the Workflow Execution UI so that you could look at any Workflow and understand whats happening, right now. All the details you need are at your fingertips, but that initial experience should be enough to get a good mental map of a Workflow without needing to interact with the full Event History. We think weve accomplished this while giving a snappy and visually pleasing experience. If you would like to experience a live demonstration, you can watch this UI Showcase webinar, now available on demand.\nDefining the UI\nWhen talking about Events in Temporal, one term we use to help simplify the Event History is the Event Group. An Event Group is a small collection of related events. For example ActivityTaskScheduled, ActivityTaskStarted, and ActivityTaskCompleted are an Activity group and a TimerStarted and TimerFired are a Timer group. Events in an Event Group are associated by Ids, such as the ScheduledEventId and StartedEventId or TimerId for the above examples.\n\n  The combined information of each Event in an Event Group that is filtered for high value user data provides a useful summary. Instead of looking at every field on every Event in the Event History, you can view the collection of Event Groups and their summaries to get a fast yet accurate picture of a Workflow. This is where the Compact and Timeline views excel.\n  If you want to deeply understand and debug a Workflow, you want the ability to dig through the entire Event History, including Workflow Tasks. This is what the Full History view is for. Understanding the flow of Events and their context with each other for the duration of a Workflow.\n\nBefore we dive into each view, lets talk about some of the things they all share: Lines, Dots, Icons, Colors and Liveness. Yes all very deep technical terms, but I shall try to explain:\n\n  A dot represent an Event.\n  Lines are used to represent the connection of Events. In the Compact view, a thick line represents an Event Group. In the Timeline view, a line connects each Event dot in its Event group. In the Full History view, a thin line connects Event dots in its Event group and also connects back to the main line that represents the Workflow and its Workflow Tasks. When an Event is pending - awaiting on another Event - the line is dashed and animates forward to indicate its pending status.\n  Icons are used to represent the category of Event: Activity, Child Workflow, Command, Local Activity, Marker, Signal, Timer, Update, Workflow.\n  Colors are used primarily to indicate the classification - or status - of an Event and secondarily as another indication of category. When you see color, it should jump out as an indication of what happened. Red means failure, dashed red means retrying, dashed purple is pending, green means completion.\n  Liveness means the Workflow updates in real-time. As new Events return from the Temporal cluster, every view is updated to show the current state of the Workflow. Liveness also means that Pending Activities are directly associated with their associated Activity in the UI, not as a separate entity in a different area.\n\nLets take a look at each view in detail along with screenshots to give you a visual of the explanation.\nCompact\nThe Compact view is the simplest view which represents a linear progression of Event Groups. The first scheduled Event Group is on the left, the latest scheduled group is furthest to the right. Event Groups that are scheduled at the same time are stacked on top of each other vertically. If more than one of the same type of Event group - say 20 SendNotification Activities are scheduled at once - the Compact view will group them under a single line with a count. You can expand that line to view each individual Event Group, and clicking on an Event Group will open the summary details. Lets take a look below at some screenshots that show this in action.\n\n  \n\n\n  \n\n\n  \n\nThe Compact view does not take clock time into consideration. Simply what happened, in what order. This view is very helpful for consolidating complex Workflows and giving a quick understanding of what happened.\n\n  \n\nTimeline\nWeve taken the work of our current Timeline and improved upon it. Event Groups are stacked vertically, with clock-time durations as the length of each line connecting Events. The time axis and positions of lines and dots are updated in real-time for running Workflows. All Event Group labels are adjusted for readability depending on the position of the Event Group. You can open multiple Event Group summary details to compare Event Groups.\nLets take a look at the same Workflow as the first three screenshots above. Here you can see the duration of each Event Group and at what time each Event occurs. Its also clear that two Activities are still pending and one Timer has yet to fire.\n\n  \n\nNow lets start looking at some more complex Workflows. Here you can see the latency between each Event in its Event Group, with some showing greater latency between Scheduled and Started, while others have higher latency between Started and Completed Events. The time axis labels gives you a sense of relative duration between Events. All lines and dots are green to show everything has completed without issue.\n\n  \n\nIn the next Workflow its immediately clear that something is wrong, red lines and dots pepper the screen due to failing Child Workflows and Activities. You can use the zoom out functionality to get a better big picture view of the Workflow as well.\n\n  \n\n\n  \n\nOne of the most useful new features with this UI is the ability to see the Timeline view of Child Workflows without having to navigate away. You can open a Child Workflow Event Group and in the summary details view its Timeline. This ability is available in both the Compact and Timeline view summary details.\n\n  \n\nFull History\nThe Full History view is for when you need all the low-level details, including Workflow Tasks. In the style of a git tree, the view shows all Events in the Event History and connects Events in the same Event Group.\nAgain lets take a look at the same Workflow as the first three screenshots but in the Full History view. You can see colored dots indicating the status of the Event and lines connecting related Events. The thicker main line represents the Workflow - Workflow Tasks and Workflow Execution Events (all non-Event Groups) with Event Groups branching out from it.\n\n  \n\nWhen you click on a row in the Full History view, not only will you get the full details of that Event, but also the details of the other Events in the Event Group. The dots and lines of the unopened Event Groups will fade to make opened Event Groups stand out.\n\n  \n\nYou can start to see patterns of the Event Groups in relation to the Workflow Tasks that started them.\n\n  \n\nFilters and Tabs\nYou can filter by multiple Event Types in all the views to only see the things you care about. Weve also moved Relationships (Children, Parent, Next, Previous Workflows) to its own tab, and added the Metadata tab to show Search Attributes and Memo fields of the Workflow. This clears up the initial History tab to show only vital information.\n\n  \n\n\n  \n\n\n  \n\nAccessing the New UI\nStarting today, the new Workflow Execution UI with Compact/Timeline/Full History views will be available to everyone in Cloud and Open Source. With change of this magnitude, we want to give you the ability to access the old UI if you so desire. To switch on and off the new UI, you click the Labs Mode icon in the bottom left navigation. By default Labs Mode will be turned off.\nDark Mode\nAnother much-requested feature weve added is Dark Mode! Weve added Day and Night themes for all pages within the UI to ease eye strain when you need to debug Workflows late at night.\nTo try out Dark Mode, turn on Labs Mode to get the Day / Night icon in the bottom left navigation. Dark Mode is only available in Open Source right now, but will be coming to Cloud soon.\n\n  \n\n\n  \n\nChild Workflows\nAnother new feature to highlight is the ability to hide Child Workflows in the Workflow List. By default Child Workflows are listed, but when toggled off all Workflows with a ParentWorkflowId will be removed. You can still view Child Workflows for a Workflow by clicking the Child Workflow icon button in the row. A tooltip will give a count of the number of Child Workflows as well. This is available today for both Cloud and Open Source and you will not need to turn on Labs Mode to access it.\n\n  \n\n\n  \n\n\n  \n\nWe hope you find these new updates helpful, and as always, feedback is very much appreciated!",featureImage:{title:"Timeline1",description:"Timeline1",url:"https://images.ctfassets.net/0uuz8ydxyd9p/doPsSF91cViXecigmt1NA/6bd5f861ba65966266a28e6605ed8a17/Timeline1.png"},publishDate:"2024-04-23T11:00-05:00",metaDescription:"Explore how Temporals new UI transforms the workflow experience with intuitive views, real-time updates, and a cleaner, faster path to workflow clarity.",metaTitle:"Redesigning Workflow experience with Temporals New UI",socialCard:{title:"Timeline1",description:"Timeline1",url:"https://images.ctfassets.net/0uuz8ydxyd9p/doPsSF91cViXecigmt1NA/6bd5f861ba65966266a28e6605ed8a17/Timeline1.png"},tags:"Temporal Primitives",slug:"the-dark-magic-of-workflow-exploration",contentType:"blogPost",entityId:"5EKROAwSH4mOxlN0MHgC68",authors:[{id:"6CycG5a057YIpHYbBjKEzV",name:"Alex Tideman",slug:"alex-tideman",jobTitle:"Staff Software Engineer",photograph:{title:"Alex Tideman",description:"Alex Tideman",url:"https://images.ctfassets.net/0uuz8ydxyd9p/F1Q03VGnLE5lUXwWpRHe3/bc05ec1aa31c4dcf38c56f87e3f5bc9d/alex-tideman.jpg"},company:"Temporal",contentType:"person"}],authorsString:"Alex Tideman",category:"Product News",readingTime:9},{title:"AI, ML, and data engineering Workflows with Temporal",content:"AI and ML developers bump into the same rough edges of system orchestration that nearly every developer encounters. Whether it's management of complex data pipelines, job coordination across GPU resources, failure handling, or deploying a model, the challenges are real.\nWhat might be a little different for the AI/ML developer is the pressure to deliver. The space is active, and it seems a new AI company is born every week. Velocity is critical as these companies seek to out-innovate each other in a land grab for attention. In this environment, speeding up your teams ability to iterate and learn is a meaningful advantage.\nTemporal and AI\nTemporal provides a code-first approach to tackle these orchestration challenges head-on. It allows you to not only build more reliable services, but also to build them faster, which is probably why we see Temporal being used by so many AI companies today. As of this writing, we have over 90 companies with a .ai domain using Temporal Cloud, and we know that there are many, many more running Temporal on their own.\nBroadly speaking, we see two patterns across these teams for their workloads being built with Temporal:\n\n  Orchestration of End-to-End AI/ML Processes\n  Management of AI/ML Data Flows\n\nOrchestration of End-to-End AI/ML Processes\nMany of our AI and ML customers use Temporal in place of coding state machines and writing complex rollbacks or retries when things fail. Weve seen many examples of this, including this Document Processing Pipeline example and this Context Injection example. Descript is another AI platform using Temporal in this way.\nDescript\nDescript uses AI to apply enhancements to video, to obtain transcripts and build out AI-generated voice libraries. With Descript, you can remove \"ums' and \"ahs\" from a video, and add sentences with your own personal AI-generated voice. Processing the video, training the voice, inserting the sentence and then processing the final video is orchestrated by a Temporal Workflow. When the Descript team needs to iterate on this process, they simply update the Workflow code.\n\n  \n\nTemporal guarantees this process executes successfully by automatically retrying failures until they succeed, and handling long-running tasks.\nManagement of AI/ML and Data Engineering flows\nAnother common pattern we see with AI use cases is the management of complex data pipelines. Ultimately, the fuel for AI/ML workflows and LLMs is data. While RAG and other approaches may help fine tune what we ask, systematic training of models and the reliable collection of data is critical. Temporal is a great fit for automating data engineering processes, and we see it often used for data flows. One such Temporal customer is Neosync.\nNeosync\nNeosync uses Temporal to automate, anonymize and generate data as well as synchronize databases. Temporal makes data engineering tasks easier for Neosync by abstracting away the complexities of process management. Developers can write an entire data pipeline as a Temporal Workflow, making it much less complex to run and understand.\n\n  \n\n\n  Temporal makes a lot of this easier. (With Temporal), youre not building it all from scratch. Temporal is the event system that abstracts away the complexities of process management. - Nick Zelei from Neosync\n\nTemporal abstracts away the status tracking, retries, and complexity of running a fleet of data pipelines.\nTemporal Makes AI/ML Easier\nTemporal's Workflow and Activity model is designed specifically for developers dealing with complex orchestration tasks. Heres what stands out:\nWorkflows and Activities\nWorkflows in Temporal define the sequence of operations or steps in your process and run exactly once. Theyre dynamic and can execute steps based on data and results of previous steps, which is critical in the AI/ML domain as the next steps often depend on the data.\nActivities represent the individual tasks within your Workflow. They're the workhorses, designed to handle the unreliable bits of your process, like calls to external services or computations. Activities help you manage risk; Temporal automatically retries failed Activities, and you can configure these retries, along with timeouts, to fit your needs.\nExample: Training and Testing Models\nHere is a sample of a Python Workflow that trains, tests, and deploys a model.\n@workflow.defn\nclass TrainTestDeploy:\n   @workflow.run\n   async def run(self, input: ModelInfo) -> str:\n       await workflow.execute_activity(\n           train, input, start_to_close_timeout=timedelta(hours=5)\n       )\n       await workflow.execute_activity(\n           test, input, start_to_close_timeout=timedelta(minutes=50)\n       )\n       await workflow.execute_activity(\n           deploy, input, start_to_close_timeout=timedelta(seconds=15)\n       )\n\n       return \"successfully trained, tested, and deployed!\"\n\nYou define what needs to happen and Temporal ensures it gets done, retrying tasks as needed and providing a clear record of the Workflows execution.\nVisibility, Resilience and Flexibility\nWith Temporal, you can focus more on the logic of your application and less on the boilerplate around job management, retries, and failure handling. Temporal handles the heavy lifting, making your processes more reliable and easier to manage.\n\n  Visibility: Temporals UI gives a clear view of your Workflow's progress and status.\n  Resilience: Failures in one step? Temporal's retry logic and state management let you pick up where things left off without starting over.\n  Flexibility: Support for multiple programming languages means you can work in the environments youre most comfortable with.\n\nBeyond the Basics\nTemporal isn't just for procedural Workflows. It can handle long-running jobs, complex nested Workflows, and interact with other systems through signals for multistep processes. You can also build entity lifecycle workflows that represent a digital twin of a ML model, a data pipeline, or a dataset. This flexibility is invaluable whether you're automating data pipelines, coordinating microservices, or anything in between.\nCoordinating Jobs Across GPU Resources\nWith Temporal, you can define what work should be done where, so if you need to execute some steps of a process on ordinary infrastructure, such as a Kubernetes pod running on typical hardware, you can do that. But you can also define activities that are restricted to other infrastructure, such as a high-powered GPU server, through the use of Task Queues. This allows for orchestration of complex tasks without always using intense resources - instead using them only when necessary. We see teams use this ability to fire up a GPU node, run models, and then tear down the node, which can be a huge cost savings.\nChaining Workflows\nYou can orchestrate Workflows with other Workflows to manage your whole fleet of processing. For example, the model training Workflow you saw earlier could be part of a bigger Workflow that orchestrates multiple similar processes, or even uses this process multiple times with different inputs.\nIf you need to interact with other systems, such as gathering user input and taking the next step in a process, you can use Signals. This is especially helpful in orchestrating a multistep interactive process, like working with a chatbot powered by AI.\nTLDR: Temporal Helps AI/ML Teams Deliver Results\nTemporal provides a robust, developer-friendly platform for orchestrating complex workflows. Its focus on code-first design, reliability, and flexibility makes it a valuable tool in the developers toolkit, especially for teams in the AI, ML, and data engineering fields.\nGive Temporal a try for your processes and see how it can streamline your workflows, reduce operational complexity, and let you focus on building great software.",featureImage:{title:"social-waves",description:"social-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3VcwELyHT8XrKJCFB6yfht/552f942de9f308def0df62fe24787dcb/image-3D-waves.jpg"},publishDate:"2024-04-22T00:00-04:00",metaDescription:"Learn how Temporal optimizes ML workflows, addressing challenges like data pipeline management, job coordination, and failure handling for AI and ML developers.",metaTitle:"ML Workflows with Temporal: Optimizing AI & Data Engineering",socialCard:{title:"social-waves",description:"social-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3VcwELyHT8XrKJCFB6yfht/552f942de9f308def0df62fe24787dcb/image-3D-waves.jpg"},tags:"AI/ML",slug:"ai-ml-and-data-engineering-workflows-with-temporal",contentType:"blogPost",entityId:"3i082EtoLzRfoQCJjDmz9y",authors:[{id:"6SCT7ktnc7C7malyJV3UsQ",name:"Joshua Smith",slug:"joshua-smith",jobTitle:"Staff Solutions Architect",photograph:{title:"Josh Smith photo",description:"Josh Smith photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2DHNWCAITAPlTgzovWEEyW/1e105a12a16a24ca6db7f3c7ae0ef44b/1678726677795.jpeg"},contentType:"person"}],authorsString:"Joshua Smith",category:"Temporal Concepts",readingTime:6},{title:"Automating Temporal Cloud with Terraform: Introducing the Terraform Provider",content:"We are excited to announce the Public Preview of the Temporal Cloud Terraform Provider. This provider allows developers to automate the management of their Temporal Cloud infrastructure using Terraform, an infrastructure as code tool created by HashiCorp.\nWhat is Terraform?\nTerraform is an open-source tool created by HashiCorp that allows developers to define their infrastructure using declarative configuration files. These files can be shared among team members, treated as code, and subjected to the same processes as application code, such as editing, reviewing, and versioning.\nWhy a Terraform Provider for Temporal Cloud?\nThe motivation for creating a Terraform Provider for Temporal Cloud came directly from your feedback. Many of you already use Terraform to manage your infrastructure and expressed a strong interest in managing Temporal Cloud resources similarly. With the introduction of the Terraform Provider, you can now automate the creation, management, and lifecycle of Temporal Cloud resources, Namespace and User to start. We plan to support more resources in future updates, expanding your management capabilities within the Temporal Cloud environment.\nUse Cases\nThe Public Preview release supports Namespace and Users management through the Namespace, Search Attribute , and Users resources and a Namespace and Regions data source. These resources allow you to automate:\n\n  Namespace Creation | Update | Delete\n  User Creation | Update | Delete\n    \n      With the ability to manage User Account-level roles and Namespace-level permissions\n    \n  \n  Rotate Namespace Certificates\n\nGetting Started\nTemporal Cloud users can get started using Terraform provider right away. If you dont have an account with Temporal, sign up here. You will also need to choose and setup the right Terraform infrastructure. HashiCorp provides excellent documentation to help you get started with Terraform. Finally, the Terraform provider uses Temporal Cloud API Keys for authentication. Make sure your Temporal Cloud account allows for API Key use and generates an API Key to use with the Terraform provider.\nOnce you have a Temporal Cloud account, a Terraform environment and API Key, you are ready to start managing Temporal Cloud resources with Terraform. Use case-specific documentation for the Temporal Cloud provider is located in Temporals documentation. We recommend starting with creating and deleting a new Namespace in your Temporal Cloud Account to get a feel for the Temporal Cloud Terraform provider.\nHeres a quick look at the Terraform configuration file, .tf file, included in the Create Namespace example. This example shows how easy it is to define the desired state of a Namespace, in this example a Namespace named terraform. Once the namespace is defined in the .tf file, Terraform will detect changes to the configuration values defined in this file and update Temporal Cloud with the Namespace changes automatically.\nterraform {\n  required_providers {\n    temporalcloud = {\n      source = \"temporalio/temporalcloud\"\n      version = \">= 0.0.6\"\n    }\n  }\n}\n\nprovider \"temporalcloud\" {\n\n}\n\nresource \"temporalcloud_namespace\" \"namespace\" {\n        name               = \"terraform\"\n        regions            = [\"aws-us-east-1\"]\n        accepted_client_ca = base64encode(file(\"ca.pem\"))\n        retention_days     = 14\n}\nThe Temporal examples use Terraforms CLI and the terraform apply command to execute configuration changes. Terraform provides success messages, like the following, when a Namespace is successfully created for the first time with Terraform.\ntemporalcloud_namespace.namespace: Creation complete after 2m17s [id=\u003Cyournamespace>]\nSee the Temporals Terraform provider documentation for detailed, step-by-step guides for managing Temporal Cloud Namespaces, CA certificates and Users with Terraform.\nUsing an Infrastructure as Code tool like Terraform assumes all changes to resources occurs through Terraform. This means, you should import existing Temporal Cloud Namespace and Users into Terraform using Terraforms import capabilities to manage these resources with Terraform. The Temporal Cloud Terraform provider supports import for Namespaces and Users.\nLooking Ahead\nThe Terraform Provider for Temporal Cloud is just the beginning of our journey toward fully automated Temporal Cloud resource management. Your feedback during this Public Preview is crucial as we plan to support more resources and enhance the provider's capabilities.\nWe look forward to seeing how you use the Terraform Provider to automate and streamline your Temporal Cloud operations. Share your experiences, suggestions, and issues on our GitHub repository or through our community channels. Let's shape the future of cloud resource management together.",featureImage:{title:"social-card-newsletter",description:"social-card-newsletter",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3k9UpZsjFZDXElTHI4BCLz/3a72dd7f1c60ada1f5bd28f46f684810/social-card-newsletter.jpg"},publishDate:"2024-04-18T00:00-04:00",metaDescription:"We are excited to announce the Public Preview of the Temporal Cloud Terraform Provider. This provider allows developers to automate the management of their Temporal Cloud infrastructure using Terraform, an infrastructure as code tool created by HashiCorp. ",metaTitle:"Automating Temporal Cloud with Terraform: Introducing the Terraform Provider",socialCard:{title:"social-card-newsletter",description:"social-card-newsletter",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3k9UpZsjFZDXElTHI4BCLz/3a72dd7f1c60ada1f5bd28f46f684810/social-card-newsletter.jpg"},tags:"CI/CD",slug:"automating-temporal-cloud-with-terraform-introducing-the-terraform-provider",contentType:"blogPost",entityId:"3MDvRK5YZTbUh5hPM7craW",authors:[{id:"3bJXEq1bXhpV9wSFvuAWMS",name:"Jonathan Lacefield",slug:"jonathan-lacefield",jobTitle:"Product - Cloud",photograph:{title:"jonathan lacefield",description:"jonathan lacefield",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1yYV96FcXmeY7aoEREwwio/77d94fcd95ab40bdf939a6a4261fb4d3/TT31S6VK5-U04CKJZEHUG-baf79c6b51fa-512"},linkedInUrl:"https://www.linkedin.com/in/jlacefield/",contentType:"person"}],authorsString:"Jonathan Lacefield",category:"Product News",readingTime:4},{title:"How to migrate your self-hosted service to Temporal Cloud",content:"Temporal Cloud offers an improved experience over self-hosted Temporal, such as greater scale, higher availability, lower latency, and consumption-based costs. If youre currently self-hosting Temporal and considering migrating to Temporal Cloud, you might think a migration sounds daunting. In this post, well provide an overview of what goes into a migration.\nWhat we mean when we talk about migrations\nWith Temporal Cloud, our team manages the Temporal Service and dependencies, while you still manage your Workflow code and Workers (see diagram below). When migrating to Temporal Cloud, a member of our team will guide you through each step.\n\n  \n\nA migration involves routing new executions to start in the Temporal Cloud namespace. It also requires you to resume existing executions in that namespace while gracefully completing them in the self-hosted instance, under load.\nAs of today, migrations occur at the application-level, not the database-level. Theres no straightforward way to migrate data (e.g. Event Histories) from your self-hosted Temporal Service to your Temporal Cloud Namespace. The good news is this means you dont have to manage a complex database migration. Instead, migrations typically require a few minimal code changes. If you need to continue accessing Event Histories from your self-hosted Service for reporting or compliance, there are strategies to do so.\nAn overview of tasks required to migrate\nTo migrate to Temporal Cloud, here are the key tasks you must complete and considerations you should keep in mind:\n\n  Introduce a new Temporal Client to your application. With Temporal Cloud your application must point to a different endpoint. The Temporal Cloud Client connects your new Workflow Executions to Temporal Cloud. Until you fully switch to Temporal Cloud, you can run the old Client and the new Client in tandem. You must also secure that connection, which you can do using API Keys and mTLS.\n  Decide on a data encryption strategy. Your application will pass Workflow-related data to Temporal Cloud. Many Temporal Cloud customers choose to use a Data Converter, a simple form of middleware, to encrypt this data on the wire.\n  Choose the lifetime strategy of your Workflow Executions. To migrate Workflow Executions that are open (i.e. in progress), you must decide whether to let them run to completion or whether to migrate them while theyre in progress. The former strategy is more straightforward, because once the Workflow Execution completes, you can simply point it to Temporal Cloud to start again. But oftentimes, customers have migration deadlines. Your Workflow Executions may not complete before your deadline. In these situations, you must refactor your Workflow Code so it passes the state to Temporal Cloud. Our team can provide guidance and help with your code to accomplish this type of migration safely. Ultimately, you should evaluate each Workflow and their individual requirements to decide which strategy is appropriate.\n  Update code calling your Workflows. Your application has code that calls Workflows; you need to make some minimal changes to this code to route the requests to your Temporal Cloud Namespace.\n  Create a test and verification plan. Like with any migration, you should plan out how youll test your new deployment before turning it live.\n\nSo how long does a migration take?\nMigrating to Temporal Cloud is generally straightforward. It may take a day or so of creating a plan for each Workflow, to understand whether you can drain them or must make code changes. Most Workflows can be drained and easily restarted on Temporal Cloud. Longer running or mission-critical Workflows that cannot be drained will require more work.\nMost importantly, our team will guide you through every step of your migration, for no extra fee. Weve migrated thousands of Namespaces and will help you successfully migrate yours.\nNext steps to migrate\nTo learn more, we recommend watching the webinar recording on this topic. You can also check out the docs. If youre considering migrating, contact us to start working with a member of our team, or drop a question into our community Slack.\nThis post is part of a series about Temporal Cloud. Check out the other posts below:\n\n  Higher throughput and lower latency with Temporal Cloud custom persistence layer\n  Exploring Temporal Cloud Automation Features\n  High availability and disaster recovery with Temporal Cloud\n  Estimating the cost of Temporal Cloud\n",featureImage:{title:"social-card-brandon",description:"social-card-brandon",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1oX4jNjimgeS45r7uoaMha/d54d7043f6f959dc26a493a2e74d98c7/social-card-brandon.jpg"},publishDate:"2024-04-17T00:00-04:00",metaDescription:"Learn how migrating to Temporal Cloud enhances scalability, availability, and reduces latency, offering a more efficient, consumption-based solution.",metaTitle:"How to Migrate to Temporal Cloud from Self-Hosted",socialCard:{title:"social-card-brandon",description:"social-card-brandon",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1oX4jNjimgeS45r7uoaMha/d54d7043f6f959dc26a493a2e74d98c7/social-card-brandon.jpg"},tags:"Cloud,Self-Hosted",slug:"how-to-migrate-your-self-hosted-service-to-temporal-cloud",contentType:"blogPost",entityId:"2Y3rSzUOBevhWHjCQwFdog",authors:[{id:"4dsODPDNXZPwvTMknnOR7N",name:"Meagan Speare",slug:"meagan-speare",jobTitle:"Sr. Manager, Product Marketing",photograph:{title:"headshot-megan-speare",description:"headshot-megan-speare",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4cU6Eil7AyPgQDtc52XeS8/935bb30acca03ba2e011e5cc90be909c/meagan-speare.jpg"},contentType:"person"}],authorsString:"Meagan Speare",category:"How-To",readingTime:4},{title:"Temporal Cloud: 1,000 customers, 1,000 thank yous",content:"We're thrilled to announce that Temporal Cloud has surpassed 1,000 customers in just under a year and a half! And we're incredibly humbled and proud to serve such a diverse group of use cases, with companies of all sizes across all industries, and everywhere on this planet, adopting the service. This includes industry leaders like Snap, Nvidia, Comcast, Brex, Turo, Alaska Airlines, Qualtrics, and over a thousand more, but it's just a glimpse of the broader community we're building.\nThis milestone is a testament to the vision for Durable Execution that Samar and I had almost two decades ago. We're deeply grateful to our customers for entrusting us with their workloads, and we are overwhelmed by all the work that has been accomplished by our exceptional team. Every day, they go above and beyond to drive the project forward, ensure user success, and innovate in ways that continue to inspire us.\nIt is also important to note that this moment wouldn't be possible if it wasn't for the vibrant open-source community that underpins our success. While its difficult to know how many people are using an open source project, we estimate that there are over 200,000 developers using our SDKs to build Temporal Workflows! You are believers in Durable Execution, and we thank you.\nTemporal Cloud is not just another OSS-as-a-service\nTemporal, the project, is offered under the permissive MIT open-source license, which grants users freedom to use, modify, and distribute the code. Temporal, the company, remains committed to ongoing investment in the open source project. Over the last year we have had 88 releases and merged over 1750 PRs across Temporal Server and the SDKs. And will continue to devote time and resources to improving the value that Temporal delivers to our users. We are dedicated to improving the lives of developers everywhere.\nFrom the beginning, Temporal was architected such that an operator of the platform has choice in how they deploy, manage and scale their implementation. We recognize the value of options and this level of control, but also understand that many may not want this responsibility, may not want to manage and scale the server, or may be cost sensitive.\nOur philosophy with Temporal Cloud is to offer a service with ALL the capabilities of the open source project and to use its extensibility to create an efficient, reliable control plane and custom data store that allow the service to reliably scale and deliver unrivaled latency. We not only take the challenges of self-hosting off your plate, but make it easy to adopt and cost-effective to run.\nTemporal Cloud Innovations\nWith over 1,000 customers now, Temporal Cloud manages over 7,000 namespaces and we count over 15 billion actions on average, every day, managed by the service. This scale has required a focus on reliability, and ultimately driven us to provide a fundamentally better Temporal experience through these key areas of innovation:\n\n  \n    Control plane\n    The Temporal Cloud control plane allows you to not only get up and running quickly, but it also extends a \"serverless\" like ability to scale the service to meet your workload demands so you don't have to over provision and pay for any excess capacity.\n    \n      This delivers efficient, cost effective scale because it scales only when you need to scale\n      You get better security out of the box because our team applies best practices and ensures all software is up to date.\n    \n  \n  \n    Custom persistence\n    Temporal is backed by a database that stores your durable state and its performance, directly impacts your experience. With Temporal Cloud, we built a custom persistence layer on the same API that allows you to use Cassandra, Postgres or other. With this design we eliminated what we didn't need from a database and delivered a store that is optimized explicitly for Temporal. It allows for:\n    \n      Scale beyond any level you can get with a off the shelf database scale\n      Lower latency as the database is now streamlined for Temporal\n    \n  \n\nWe deliver all of this in a service that not only allows you to be up and running in minutes, but also allows for easy migration from self-hosted to this Temporal Cloud, and we offer fair consumption based pricing so that you only pay for what you consume.\nOver 1,000 customers are now getting these benefits of Temporal Cloud today.\nA thousand thank yous\nAs developers, Samar and I have grappled with the complexities of system failures and infrastructure intricacies in our code for quite some time and Temporal emerged from this frustration. Now, we are deeply honored that thousands of developers and organizations now believe in it and rely on it to deliver more reliable systems, but more importantly to improve their lives.\nWe are still in the project and active in the community every day. Please stop by and say hello. We look forward to hearing from you.",featureImage:{title:"blog-feature-card",description:"blog-feature-card",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2cK7gW4MwK7MtkBBd46lx3/5ee4f4fd0effe5fb1ee78c75b85fe70e/blog-feature-card.png"},publishDate:"2024-04-16T00:00-04:00",metaDescription:"We're thrilled to announce that Temporal Cloud has surpassed 1,000 customers in just under a year and a half!",metaTitle:"Temporal Cloud: 1,000 customers, 1,000 thank yous",socialCard:{title:"blog-feature-card",description:"blog-feature-card",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2cK7gW4MwK7MtkBBd46lx3/5ee4f4fd0effe5fb1ee78c75b85fe70e/blog-feature-card.png"},tags:"Cloud",slug:"temporal-cloud-1-000-customers-1-000-thank-yous",contentType:"blogPost",entityId:"1f7l71SBtMECyxXkGeA4Md",authors:[{id:"1X8y9RWlP8D5TPrughvFd2",name:"Maxim Fateev",slug:"maxim-fateev",jobTitle:"CTO and Co-Founder",photograph:{title:"Maxim Fateev",description:"Maxim Fateev",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7EdtHMKPMc4iH2gcwIzp8U/1909c8a7ab0fb81b122afe6810bb58c1/861A2412.jpg"},biography:"Max is CTO and co-founder of Temporal. He is a 20-year veteran of AWS, Google, and Uber, engineering leadership, having led the development of the SQS replicated message store and the Simple Workflow service at AWS, and then co-creating Cadence (Temporals predecessor) at Uber. Today, millions of Temporal workflows are run daily for high reliability and high scalability workloads from Stripe to Datadog to Snapchat.",twitterUrl:"https://twitter.com/mfateev",company:"Temporal",contentType:"person"}],authorsString:"Maxim Fateev",category:"Announcements",readingTime:5},{title:"How to convert your job scheduling system to Temporal Schedules",content:"Temporal Schedules offer a major improvement in reliable and efficient scheduling systems. This feature is designed not only as an alternative to traditional Cron jobs but also as a replacement for scheduling systems like systemd timers and Celery.\nMore explicitly, Temporal Schedules:\n\n  Allow developers to execute workflows at specific times or intervals, and enhance control and observability over these tasks. This approach eases management of task operations, such as starting, pausing, resuming, backfilling, deleting, describing, listing, triggering, and updating scheduled workflow executions.\n  Implifies workflow management and provides a durable and more informed solution for task scheduling, treating tasks as independent entities with detailed specifications for each schedule.\n\nSupport systematic and efficient workflow management. From limiting runs and configuring overlap policies to enabling pause-on-failure.\nThe good news is, switching to Schedules is quite straightforward. If you are looking to convert your cron jobs into Schedules, check out this blog post.\nIntegration of Temporal Schedules with Non-Temporal Scripts\nIntegrating Temporal Schedules with existing non-Temporal scripts can be achieved by wrapping your current code in an Activity, which is then placed within a single-activity Workflow. This strategy allows for a straightforward transition to using Temporal as a Cron replacement without extensive code rewrites. It's essential to ensure the activity is idempotent or to disable the retry policy to prevent any potential issues, enabling a straightforward application of Temporal Schedules to your existing workflows.\nMigration Preparation\nThe first step is to understand your existing scheduled jobs and how they are triggered.\n\n  What is their schedule now? Is it per time interval, like day or hour, or does it run on a specific day of the week or month?\n  Can your jobs overlap?\n  Do they need to backfill if the schedule is interrupted?\n  Should they pause the schedule if a job fails?\n\nThe second step is to write a Temporal Workflow that executes the existing batch job. You can start by wrapping an existing job task in a single-Activity Workflow as mentioned above. Alternatively, you can implement a job as a Temporal Workflow, to take advantage of Temporal Workflow capabilities, like retries for individual steps.\nThe final step is to deploy your workflow in a Temporal Worker that will allow it to execute on the schedule you specify. Youll need the task queue name, Workflow ID, and Workflow Type (Name). One good practice is to deploy the job as a shadow to make sure it runs how you want. Implement a feature flag to have it log that it has started and run as expected on your schedule, and then when you are ready activate it and disable your old schedule.\nExample: Migration from Kubernetes CronJobs to Temporal\nOnce you have your workflow deployed, you can schedule it as desired. Review your Kubernetes Cron schedule and implement it in Temporal. Lets say you have a Kubernetes Cron job that takes a database backup every Friday at 12:15PM. Heres a YAML snippet:\napiVersion: batch/v1\n\nkind: CronJob\n\nmetadata:\n\n name: rdb-backup\n\nspec:\n\n schedule: \"15 12 * * 3\"\n\nIt will run at 12:15 PM every Friday.\n\n  Temporal Schedules are much simpler to understand:\n  \n  \n\nYou can also create them using any of the SDKs or via the command line. Here is an example using the command line:\n    temporal schedule create \\\n--schedule-id 'friday-rdb-database-backup' \\\n--calendar '{\"dayOfWeek\":\"Fri\",\"hour\":\"12\",\"minute\":\"15\"}' \\\n--overlap-policy 'BufferAll' \\\n--workflow-id 'rdb-backup' \\\n--task-queue 'rdb-backup-task-queue' \\\n--workflow-type 'RDB-Backup'\n\nTemporal Schedules are similar to Kubernetes Cron but far more powerful. With Schedules, you can do additional things, such as backfill, describe, list, pause, trigger, and update a Workflow Execution schedule with ease. You can also set an interval if you desire:\n     --interval '5h/15m' \\\n\n\n  The interval parameter defines at what interval the Schedule runs.\n  The only thing left to do is disable the Kubernetes Cron job once you have enabled the Schedule in Temporal. Then you can benefit from the power of Temporal Schedules and Workflows as mentioned above. Because Workflows are implemented in code, you can manage them like applications, with a full software development life cycle, versioning, testing, and change management, enabling strong DevOps patterns.\n\nExample: Migration from systemd Timers to Temporal\nAs with Kubernetes Cron jobs, once you have your workflow deployed, you can schedule it in Temporal as desired. Review your systemd schedule and implement it in Temporal. Lets say you have a systemd schedule that takes a database backup every Friday at 12:15PM:\n    $ sudo cat /etc/systemd/system/rdb-backup.timer\n    [Unit]\n    Description=Timer to run rdb-backup.service\n\n    [Timer]\n    Unit=rdb-backup.service\n    OnCalendar=Fri *-*-* 12:15:*\n    Persistent=True\n\n    [Install]\n    WantedBy=timers.target\n\nIt will run at 12:15 PM every Friday.\nAs above, you can implement this schedule in the Temporal UI or using the command line. systemd jobs run on specific hosts, and your Temporal Workflows can run on specific hosts, or across a fleet of hosts. Its important to note that when implementing Temporal Workflows to replace systemd jobs, you must make sure that the Temporal Workflow has access to the host you want to run automation on. You can also run workers on the hosts that formerly ran the systemd jobs.\nOnce you have implemented the Temporal Schedule, you will have much better visibility for the automation - you can see every run in the Temporal UI, and you dont have to be logged into the host to see automation logs.\nThe only thing left to do is disable the systemd job once you have enabled the Schedule in Temporal. At this point you can benefit from the power of Temporal Schedules and Workflows as mentioned above. Because Workflows are implemented in code, you can manage them like applications, with a full software development life cycle, versioning, testing, and change management, enabling strong DevOps patterns.\nExample: Migration from Quartz to Temporal\nQuartz schedules are implemented in Java code, such as with the simple schedule definition below:\nJob Definition:\n    // A simple job\n    public class HelloJob implements Job {\npublic void execute(JobExecutionContext arg0) throws JobExecutionException {\n    System.out.println(\"Hello! It's been a few hours!\");\n}\n    }\nGroup Definition:\n    // add job to a group\n    JobDetail job = JobBuilder.newJob(HelloJob.class)\n      .withIdentity(\"helloJob\", \"jobGroup1\")\n      .build();\nTrigger Definition:\n    Trigger trigger = TriggerBuilder.newTrigger()\n      .withIdentity(\"myTrigger\", \"jobGroup1\")\n      .startNow()\n      .withSchedule(SimpleScheduleBuilder.simpleSchedule()\n.withIntervalInHours(10)\n.repeatForever())\n      .build();\n\nThis job prints Hello! It's been a few hours! every ten hours, forever.\n\n  There are many other options for Quartz jobs, such as CronTriggers that map well to the calendar based jobs discussed above. There is also Quartz misfire configuration that maps in functionality to Temporals catchup window.\n  For this blog post, well work with this simple example. As mentioned above, once you have your workflow deployed, you can schedule it as desired. Schedules can be implemented in the Temporal UI or using the command line. Here is a command line example for this ten hour interval schedule:\n\n    temporal schedule create \\\n--schedule-id 'helloJob' \\\n--interval '10h' \\\n--overlap-policy 'BufferAll' \\\n--workflow-id 'helloJob' \\\n--task-queue 'hello-job-task-queue' \\\n--workflow-type 'HelloJob'  \n\nHere is an example for this ten hour interval schedule set up with Java:\n    Schedule schedule =\nSchedule.newBuilder()\n    .setAction(\n        ScheduleActionStartWorkflow.newBuilder()\n            .setWorkflowType(HelloSchedules.GreetingWorkflow.class)\n            .setOptions(\n                WorkflowOptions.newBuilder()\n                    .setWorkflowId(\"helloJob\")\n                    .setTaskQueue(\"hello-job-task-queue\")\n                    .build())\n            .build())\n    .setPolicy(SchedulePolicy.newBuilder()\n        .setOverlap(ScheduleOverlapPolicy.SCHEDULE_OVERLAP_POLICY_BUFFER_ALL)\n        .build())\n    \t // Run the schedule every 10 hours\n    .setIntervals(Collections.singletonList(new ScheduleIntervalSpec(Duration.ofHours(10))))\n        .build();\n\n    // Create a schedule on the server\n    ScheduleHandle handle =\nscheduleClient.createSchedule(\"helloJob\", schedule, ScheduleOptions.newBuilder().build());\n\nTo convert to Temporal Schedules, you can keep the core of the job in Java, or use any of the other languages supported by Temporal, such as Go or Python. The configuration of the Quartz job management can be removed from your Java code when you are ready to disable the Quartz version.\nAt this point you can benefit from the power of Temporal Schedules and Workflows as mentioned above. Conversion will be familiar in some ways, because Temporal Workers are applications, just like your Quartz job applications. The key difference is job configuration is external as part of the Temporal platform.\nExample: Migration from Celery to Temporal\nCelery beat is a scheduler for python. Heres a sample job:\n    from celery import Celery\n    from celery.schedules import crontab\n\n    app = Celery()\n\n    @app.on_after_configure.connect\n    def setup_periodic_tasks(sender, **kwargs):\n#calls hello every hour \nsender.add_periodic_task(3600.0, hello.s('hello i am alive'), name='task every hour')\n\n#calls hello every Tuesday 5:30 p.m.\nsender.add_periodic_task(\n    crontab(hour=17, minute=30, day_of_week=2),\n    hello.s('Time for Tuesday Dinner!'),\n)\n\n    @app.task\n    def hello(arg):\nprint(arg)\nThese two jobs have different schedules - one periodically by time and one on a crontab schedule. They could be implemented as one Temporal Workflow with two different schedule configurations.\nOnce you have your workflow created and deployed, you can schedule it as desired. Schedules can be implemented in the Temporal UI or using the command line. Here is a command line example for the one hour interval schedule:\n    temporal schedule create \\\n--schedule-id 'helloHour' \\\n--interval '1h' \\\n--input '\"hello i am alive\"' \\\n--overlap-policy 'BufferAll' \\\n--workflow-id 'helloHour' \\\n--task-queue 'hello-job-task-queue' \\\n--workflow-type 'HelloJob'  \n\nHere is a command line example for the Tuesday schedule:\n    temporal schedule create \\\n--schedule-id 'helloTuesday' \\\n--calendar '{\"dayOfWeek\":\"Tue\",\"hour\":\"17\",\"minute\":\"30\"}' \\\n--input '\"Time for Tuesday Dinner!\"' \\\n--overlap-policy 'BufferAll' \\\n--workflow-id 'helloTuesday' \\\n--task-queue 'hello-job-task-queue' \\\n--workflow-type 'HelloJob'  \n\nHere is a Python SDK example for creating the every hour schedule:\n    #...\n    async def main():\nclient = await Client.connect(\"localhost:7233\")\n\nawait client.create_schedule(\n    \"helloHour\",\n    Schedule(\n        action=ScheduleActionStartWorkflow(\n            HelloJob.run,\n            \"hello i am alive\",\n            id=\"helloHour\",\n            task_queue=\"hello-job-task-queue\",\n        ),\n        spec=ScheduleSpec(\n            intervals=[ScheduleIntervalSpec(every=timedelta(hours=1))]\n        ),\n        policy=SchedulePolicy(\n            overlap=ScheduleOverlapPolicy.BUFFER_ALL\n        )\n    ),\n)\nTo convert python jobs to Temporal Schedules, you can keep the core of the job in python, or use any of the other languages supported by Temporal, such as Go or Java. The configuration of the Celery job management can be removed from your code when you are ready to disable the Celery version.\nAt this point you can benefit from using Temporal Schedules and Workflows as mentioned above. Conversion will be familiar in some ways, because Temporal Workers are applications, just like your Celery job workers might be. The key difference is job configuration is external as part of the Temporal platform.\nOther Job Schedulers\nTemporal Schedules provide a framework for many kinds of background processing. Conversion of your code to Temporal makes it more durable, and Temporal Schedules provide an easy way to execute repeating processes clearly. There are other job schedulers not mentioned here that Temporal could replace.\nTemporal also can facilitate complex job streams, with many layers of nested job processing orchestration and complex dependencies. Temporal Workflows can be as complex as needed to process your work streams.\nLearn more\n\n  Schedules Documentation\n  Ask questions in the Temporal Community Slack\n  Watch Schedules webinar: Simplifying and Scaling Cron Jobs with Temporal Schedules\n  How Temporal works\n  Subscribe to Temporal newsletter\n",featureImage:{title:"social-card-image",description:"social-card-image",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1NfzbiO64uLGYOtl5hBwnw/8e88e819b8ef01edc766b2fb0f0b35fe/social-card-image.jpg"},publishDate:"2024-04-15T00:00-04:00",metaDescription:"Temporal Schedules offer a reliable, efficient alternative to traditional job schedulers, replacing Cron, systemd timers, and task queues like Celery.",metaTitle:"Convert Your Job Scheduler to Temporal Schedules",socialCard:{title:"social-card-image",description:"social-card-image",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1NfzbiO64uLGYOtl5hBwnw/8e88e819b8ef01edc766b2fb0f0b35fe/social-card-image.jpg"},tags:"Temporal Primitives",slug:"how-to-convert-your-job-scheduling-system-to-temporal-schedules",contentType:"blogPost",entityId:"5cv2izWDKSrs22qsMKgnlB",authors:[{id:"6SCT7ktnc7C7malyJV3UsQ",name:"Joshua Smith",slug:"joshua-smith",jobTitle:"Staff Solutions Architect",photograph:{title:"Josh Smith photo",description:"Josh Smith photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2DHNWCAITAPlTgzovWEEyW/1e105a12a16a24ca6db7f3c7ae0ef44b/1678726677795.jpeg"},contentType:"person"},{id:"7GV0xjBamDpDSZZ543r8yX",name:"Irina Belova",slug:"irina-belova",jobTitle:"Product Marketing",photograph:{title:"headshot-irina-belova",description:"headshot-irina-belova",url:"https://images.ctfassets.net/0uuz8ydxyd9p/BJ0w7WeAjw83DatmJ7Fin/a8facdb4b7206afe1e66dc73b216ec09/headshot-irina.png"},contentType:"person"}],authorsString:"Joshua Smith, Irina Belova",category:"How-To",readingTime:9},{title:"Estimating the cost of Temporal Cloud",content:"If youre evaluating Temporal for a key workload, an important step in the process is to understand the total cost to operate your application and Temporal. In this post, we break down which costs you should consider for self-hosting Temporal versus Temporal Cloud. We also provide cost estimation strategies for Temporal Cloud.\nWhat we cover in this post\nBefore we dive into costs, we should clarify which costs were referring to. Temporal is comprised of two parts: the Workers that host your application and the Service. In this post, we break down the costs of the Service only. Thats because your Worker costs remain the same regardless of whether you self-host or use Temporal Cloud. Your Workers are an integral part of your own applicationalways hosted, deployed, and managed by you.\nSelf-hosting Temporal requires running all the components of the Temporal Service (a minimum of seven components) in addition to the Workers. Temporal Cloud delivers a fully-managed Temporal Service, packaged with a custom persistence layer for optimized performance, services, and support.\nCost considerations for self-hosting Temporal\nFor self-hosting Temporal, you need to account for the costs of compute infrastructure, a sophisticated tech stack, hardware, and operational resources. Heres a breakdown of what goes into a self-hosted Temporal Service:\n\n  \n    Sophisticated tech stack: The Temporal Service is composed of a collection of distinct services: History, Matching, Frontend, Internal Worker, and Web Tier. Each service must be scaled, tuned, and optimized correctly. Underlying all the services is a data persistence layer. You can use Postgres or MySQL for the data persistence, or if you require greater scale, Cassandra. Customers often choose to run Elasticsearch in the cluster as well. For each service, you must provision network security, authentication, encryption, integration into your IDP, and so on. You should factor in the costs of running and supporting each service.\n  \n  \n    Hardware: You must procure and pay for the hardware for each service. The services are all horizontally scalable to handle extremely large workloads. You need to account for the size, memory, CPU, and IO of each.\n  \n  \n    Operational resources: To estimate operational costs, we recommend starting with your SLA. What uptime does your business require of your applications? How does the platform need to behave to deliver on that SLA? Then you can break down the costs as follows:\n    \n      Cost of downtime based on the SLA: If your SLA is 99%, factor in the cost to the business if the use case is down 1% of the time. For some use cases like order management, downtime causes lost revenue. For other use cases, revenue is not impacted.\n      Infrastructure and testing required ro reach the SLA: you must factor in the redundancy, planning, testing, and continuous optimization as you bring more workloads to production. Include the infrastructure for non-production environments as well.\n      Updates: its critical to keep on top of security updates and software patches. Remember to consider operating systems, platform, and Temporal updates.\n      Disaster recovery: consider cloud service disruptions and whether you need a strategy to maintain uptime.\n      24/7 operational center: you must have an on-call team to handle issues across the stack.\n    \n  \n\nCost considerations and pricing for Temporal Cloud\nTemporal Clouds pricing is consumption-based, so you pay only for what you use, as well as a support fee. All the hardware, infrastructure, and operational costs are abstracted away, and you just need to think about what your Workflows are doing.\nHeres how pricing breaks down:\n\n  \n    Actions: actions are the smallest units of \"durable execution\" that make up your Workflows. An action is recorded each time an event happens like starting a Workflow, starting a Timer, and sending a signal. Actions are priced at $25 per million, rated as you consume them. You can tune your Workflow code to increase efficiency, and our services team often works with customers to accomplish this and optimize costs.\n  \n  \n    \n      Storage: storage is generally a very small percentage (3-5%) of the total bill. There are two types of storage with different pricing:\n      Active storage: storage for running Workflows that are continuing to grow and add more events, priced at $1 GB-day.\n      Retained storage: closed storage, stored in a colder and less expensive way, priced at $0.01 GB-day.\n    \n  \n  \n    Support: the minimum support fee is $200 per month. This covers break/fix support, but it also covers unlimited services. That means a dedicated Solutions Architect and unlimited access to: onboarding, design reviews, code optimization, best practices, and more.\n  \n\nEstimating the cost of Temporal Cloud\nWe can provide a relatively accurate estimate of cost based on your use case. Use cases can be bucketed by size, into the following categories. Note that in addition to the costs below, you will pay a fixed monthly support fee starting at $200 per month.\n\n  Small, \u003C$25 per month: modest to transient throughput use cases like development and testing, automation and orchestration, and human-in-the-loop. The cost equates to 1 million actions per month or less.\n  Medium, \u003C$1,000 per month: use cases with steady or burst throughput like transaction and order systems, infrastructure automation, CI/CD, and batch processing. The cost equates to \u003C40 million actions per month.\n  Large, \u003C$10,000 per month: use cases with sustained throughput like data processing, national retail order systems, KYC, and fraud detection. The cost equates to \u003C400 million actions per month.\n  Extra Large, $20,000+ per month: use cases with web scale, like social media, some SaaS platforms, and global applications. The cost equates to 1 billion or more actions per month.\n\nThe logical next question is: how do you know how many actions per second your workload will produce?\nIf youre currently self-hosting version 1.17 or later, you can access the Actions metrics associated with your self-hosted Service through the metrics endpoint. The Temporal Service produces Actions metrics that can be reported or queried by Prometheus. An example PromQL command to capture Actions metrics for the past 30 days is:\nSum (increase(action{service_name=\"frontend\"}[30d]))\nIf your application isnt running with Temporal, you must break down the processes. How many steps does it have? How long does a single execution take? Does it sleep and wake up later? You can use this pricing calculator for a general estimate. Ultimately, you should reach out to us for the most accurate estimate. We can test your workload in Temporal Cloud and give you a highly accurate number.\nAdditional considerations: upfront costs and scaling\nIn addition to costs, you should consider the timing of your investments and how your expenses will change as your workload grows.\nWhen self-hosting Temporal, you must invest a large sum upfront to set up your infrastructure. As a result, you must get budget approval sooner. When your workload grows, you need to increase capacity on a stepwise basis. Often, you must over-provision your infrastructure to accommodate potential spikes in traffic or future growth.\nThe investment curve looks different for Temporal Cloud. Due to the consumption-based pricing model, the upfront investment is zero, and you only pay for the capacity and storage you use. Your costs increase directly in proportion to your usage, and you dont need to over-provision or pay for idle capacity.\nNext steps\nFor a more detailed discussion on pricing, we recommend watching the cost estimation webinar. If you have any questions or would like an estimate, you can contact our team here.\nThis post is part of a series about Temporal Cloud. Check out the other posts below:\n\n  Higher throughput and lower latency with Temporal Cloud custom persistence layer\n  Exploring Temporal Cloud Automation Features\n  High availability and disaster recovery with Temporal Cloud\n  How to migrate your self-hosted service to Temporal Cloud\n",featureImage:{title:"social-card-purple-waves",description:"social-card-purple-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2nvZtGhubV6XKQbGrFwUmH/c7c8144ccbc2a70cc9d1274206d26593/social-card-purple-waves.jpg"},publishDate:"2024-04-03T00:00-06:00",metaDescription:"If youre evaluating Temporal for a key workload, an important step in the process is to understand the total cost to operate your application and Temporal.",metaTitle:"Estimating the cost of Temporal Cloud",socialCard:{title:"social-card-purple-waves",description:"social-card-purple-waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2nvZtGhubV6XKQbGrFwUmH/c7c8144ccbc2a70cc9d1274206d26593/social-card-purple-waves.jpg"},tags:"Cloud,Temporal Primitives",slug:"estimating-the-cost-of-temporal-cloud",contentType:"blogPost",entityId:"seywWMzJcC2iyPABkpi1r",authors:[{id:"4dsODPDNXZPwvTMknnOR7N",name:"Meagan Speare",slug:"meagan-speare",jobTitle:"Sr. Manager, Product Marketing",photograph:{title:"headshot-megan-speare",description:"headshot-megan-speare",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4cU6Eil7AyPgQDtc52XeS8/935bb30acca03ba2e011e5cc90be909c/meagan-speare.jpg"},contentType:"person"}],authorsString:"Meagan Speare",category:"Temporal Concepts",readingTime:7},{title:"Durable Digest: March 2024",content:"This blog post is a public copy of our monthly newsletter sent on March 29th. If youd like to receive upcoming updates by email, you can subscribe to our newsletter here.\nWe're excited for another year of Replay, and tickets are on sale now! Check out some of the scheduled workshops here. We're also still accepting CFPs, so if you'd like to submit a talk, you can find more details here.\nFor more information on other things we've been working on, just keep reading! And as always, we'd love to hear from youfeel free to share feedback in our Community Slack, or on Twitter (@temporalio).\nNotable New Technology Features\n\n  Server version 1.23.0 released: Changes with this release are a proto library, new reserved search attributes, and a few depreciations.\n  Temporal published a Terraform provider (Public Preview) to help users create/manage Temporal Cloud Namespaces.\n  Workflow History Export is now publicly available as a Public Preview.\n\nIf you have questions about Temporals release stages, then please see our new release stages documentation.\nSDK Updates\nPHP SDK 2.8 and 2.8.1 are now available, with support for our new, experimental Workflow Update feature. The PHP API docs are now published online at https://php.temporal.io/namespaces/temporal.html.\nGo SDK 1.26 is now available, with support for Typed Search Attributes. This release includes a few small breaking changes, including changes to how gRPC protobufs are serialized, so please read the release notes before upgrading.\nJava SDK 1.23 is now available, with bugfixes and some improved defaults. This release also includes changes to use the new history JSON format; please read the release notes for details before upgrading.\nTemporal Cloud's Automation Features: Learn how companies are transforming how they deploy, manage, and scale their operations with the new automation features in Temporal Cloud.\nUpcoming Meetups & Events\nQCon | April 8-10\n\n  Join Temporal for the SuperBowl of technology conferences at QCon London. Stop by booth #1 at the QEII Center to say hi to the Temporal team! Register here.\n\nDevNexus | April 9-11\n\n  The Temporal team will be at DevNexus, the largest Java platform conference in the US. Join the \"devolution\" and stop by Booth #15 at the Georgia World Congress Center to say hello to the team! Register here.\n\nGreat International Developer Summit | April 23-26\n\n  The Temporal team is landing in India! Please join us at the Great International Developer Summit in Bengaluru. Stop by Booth #18 at the J N Tata Auditorium to meet the Temporal team! Register here.\n\nOn Demand Webinar Series: Check out our recent webinar series where we deep dive into \"Building with Temporal Cloud\".\nResources\nUnderstanding when and how to apply versioning is an essential skill for Temporal application developers. We've just released four new hands-on training courses where you can learnand practicehow to do this with our most popular SDKs. Theres no cost, so register today and learn how to version your Workflows in Go, Java, Typescript, and Python.\nCommunity Favorites\n\n  FireHydrant and Temporal Signals: Read about how FireHydrant rigorously tested our Temporal Signals feature and what they discovered.\n  Cloud Disaster Recovery: See how Temporal Cloud removes challenges of managing applications at scale.\n  Custom Persistence Layer: Learn how Temporal Cloud provides better performance and lower latency than self-hosted clusters.\n",featureImage:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},publishDate:"2024-03-29",metaDescription:"Explore Temporals latest developer updates: questions from the field, new releases, builder spotlights, learning resources, and ways to connect with our team.",metaTitle:"Durable Digest: March 2024",socialCard:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},tags:"",slug:"durable-digest-march-2024",contentType:"blogPost",entityId:"7gUtJyOisCqrHtGgukdyYo",authors:[{id:"17hGmNrCwtXdBh7fhsLUnZ",name:"Temporal Technologies",slug:"temporal-technologies",photograph:{title:"temporal technologies logo",description:"temporal technologies logo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3g56zRXtFQYMeJxBBkVBIZ/7771670e5fc7da59f555837b086c35d6/temporal_technologies_logo.avif"},company:"Temporal Technologies",contentType:"person"}],authorsString:"Temporal Technologies",category:"Announcements",readingTime:3},{title:"Learn Temporal Workflow Versioning with free hands-on training",content:"Today weve made four new hands-on training courses available. Each of these courses covers the same topicVersioningusing a specific SDK:\n\n  Versioning Workflows with Go\n  Versioning Workflows with Java\n  Versioning Workflows with Python\n  Versioning Workflows with TypeScript\n\nWhy Should I Learn Versioning?\nVersioning is an essential skill for Temporal application developers to learn, especially as they near the production deployment of their first application. Versioning allows you to successfully make changes to your application code, even when Workflow Executions that were started with the original code are still running when you deploy the updated code.\nBy completing one of these training courses, you'll learn when Versioning is necessary and practice applying it using your favorite SDK.\n\n  \n\nWhat Do These Courses Cover?\nWe had three main goals in mind when designing these courses.\nExplaining when and why you need to use Versioning\nBuilding on the coverage of determinism from our Temporal 102: Exploring Durable Execution course, we begin by explaining how a modification to your application can result in errors after deployment. During the hands-on exercise in this course, youll experience it firsthand by introducing an incompatible change, deploying it, and then observing a non-deterministic error that prevents your Workflow from making progress. Youll then use Versioning to correct the problem by preserving both the old and new execution paths in your Workflow Definition.\nExploring two techniques for Versioning in Temporal\nThese courses cover multiple approaches to Versioning in Temporal: Workflow Type Versioning and the GetVersion / Patching APIs. It explains how they work and how to use them when developing and deploying your applications.\nComparing and contrasting these techniques\nThe courses summarize the advantages and disadvantages of each approach, helping you to understand which one is most appropriate for a given situation.\nWho Should Take this Course?\nThis course is appropriate for any Temporal application developer who understands how Temporal uses History Replay to achieve durable execution. Since that topic is covered in Temporal 102: Exploring Durable Execution, we recommend that you first complete that course (for your selected SDK) before you begin one of our Versioning courses.\nIf youre ready to learn Versioning, just follow one of the links below and begin your free hands-on training:\n\n  Versioning Workflows with Go\n  Versioning Workflows with Java\n  Versioning Workflows with Python\n  Versioning Workflows with TypeScript\n\nA note for those already enrolled in Temporal 102 with Go: Exploring Durable Execution\nThe original release of this course contained a chapter on Versioning. Since this content has now been moved to the new Versioning Workflows with Go course, we have now published a new revision of Temporal 102 with Go that eliminates the duplication. All new enrollments will use the latest revision of Temporal 102, but to ease the transition for those currently working through the course, anyone already enrolled will have access to the older revision through May 1, 2024.\nWhats Next for Temporal Training?\nLast year, the Education team followed up the original Temporal 101: Introducing the Temporal Platform course in Go by releasing versions of this course that covered our Java, TypeScript, and Python SDKs. We also released Temporal 102: Exploring Durable Execution for Go, TypeScript, Java, and Python, as well as our Introduction to Temporal Cloud training.\nYou can expect us to continue delivering new hands-on training courses in 2024. And, if you attend Replay, be sure not to miss out on Wednesday, September 18. Thats when members of our Education team and our partner Bitovi will deliver 14 of these courses livewe invite you to participate!",featureImage:{title:"social-card-purple",description:"social-card-purple",url:"https://images.ctfassets.net/0uuz8ydxyd9p/UbL8tEOAIBjMrI6OCSeNN/62aecca8ce16e11e288c1fd7ef4e346d/social-card-purple.jpg"},publishDate:"2024-03-28T00:00-06:00",metaDescription:"Today were excited to announce the immediate availability of four new hands-on training courses.",metaTitle:"Learn Temporal Workflow Versioning with hands-on training",socialCard:{title:"social-card-purple",description:"social-card-purple",url:"https://images.ctfassets.net/0uuz8ydxyd9p/UbL8tEOAIBjMrI6OCSeNN/62aecca8ce16e11e288c1fd7ef4e346d/social-card-purple.jpg"},tags:"Versioning,Typescript,Python,Java,Go",slug:"learn-temporal-workflow-versioning-with-free-hands-on-training",contentType:"blogPost",entityId:"5hwVgCoPme2Nd4vIzlp5kH",authors:[{id:"6NFooJhrzJdVAxMRWhgeTl",name:"Tom Wheeler",slug:"tom-wheeler",jobTitle:"Principal Developer Advocate",photograph:{title:"Tom Wheeler",description:"Tom Wheeler",url:"https://images.ctfassets.net/0uuz8ydxyd9p/53ysX1Y47NqQaThXEVUny4/b1d9bbb620188ffc23a6a5098a80cfa5/tomwheeler-2024-headshot-800x800.webp"},biography:"Alternating between software engineering and technical education roles, Tom Wheeler's career spans more than 25 years in the financial, healthcare, defense, and tech industries. Prior to joining Temporal as the founding member of the Education team in 2022, he wrote training courses at Cloudera, developed aerospace engineering software at Object Computing, helped create a distributed system for high-volume data processing at WebMD, and built some of the earliest web applications at brokerage firm A.G. Edwards. When Tom manages to step away from the computer, you can probably find him cooking, traveling, or playing guitar.",company:"Temporal",contentType:"person"}],authorsString:"Tom Wheeler",category:"How-To",readingTime:3},{title:"High availability and disaster recovery with Temporal Cloud",content:"Temporal makes your applications more reliable. But from an operational perspective, any complex software is hard to run reliably at scale. In this post, well give a brief overview on the challenges with self-hosting Temporal at scale, and the ways in which Temporal Cloud provides high availability. For more details, you can watch our webinar recording on this topic.\nChallenges of maintaining high availability when self-hosting Temporal\nThe core challenge of achieving high availability with Temporal is that the Service is composed of multiple independently scalable components. You must tune each and maintain their availability:\n\n  A database, typically Cassandra or Postgres, which is usually sharded and deployed in a highly available way, preferably across multiple availability zones.\n  Four independent services that make up the Temporal Server. These services must be resourced properly so there are no bottlenecks in the critical path of serving requests.\n  As with any distributed system, failures are inevitable, and understanding how to operate under different failure conditions is necessary to keep the service stable and available at all times. Some failures are relatively easy to deal with (a machine going down), while some are subtle and require careful attention (a network partition).\n\nManaging each of these services at smaller scales is straightforward. But to run them at scale in production, you must have a lot of expertise. Thats not to say its impossible. Many developers successfully self-host Temporal. But they may have difficulty meeting high availability SLAs, and often spend significant time and resources operating Temporal. For mission-critical applications and high-scale use cases, we always recommend evaluating Temporal Cloud.\nHigh availability with Temporal Cloud\nWith Temporal Cloud, our team delivers Temporal-as-a-service. We properly tune the supporting database and services for your load, and ensure theyre highly available. Because our team has deep Temporal expertise and manages thousands of namespaces, we can provide better service reliability, higher availability, lower latency, and we have a higher buffer of resources reserved for unexpected events.\nAs a Temporal Cloud customer, you're only responsible for deploying and managing your Workers and Workflows in your applications, and connecting your application to your managed Temporal Service.\nHere are the details of the high availability guarantees Temporal Cloud provides:\n\n  Fault tolerance - Temporal Cloud namespaces are deployed across three availability zones for fault tolerance by default. So any AZ failure would be a non-event for your namespace.\n  99.99% service level objective (SLO) - As a service, Temporal Cloud regularly provides four 9s of availability; in other words, thats the availability of the endpoint.\n  99.9% service level agreement (Contractual SLA) - the Temporal Cloud Contractual SLA is based on the average number of gRPC service errors over five minute intervals for the month. Contractually, if we do not meet this objective, we will issue back Cloud credits based on the outage.\n\nFor disaster recovery, Temporal Cloud provides the following:\n\n  RTO/RPO for availability zone failures: the RTO/RPO are zero for availability zone failures, due to Temporal Cloud being replicated across multiple availability zones\n  RTO/RPO for region failures: the RTO/RPO are eight hours at maximum, which is two backup periods for Temporal Cloud.\n  COMING SOON: Multi-Region Namespaces: currently in pre-release, this capability will provide failover capabilities to mitigate service outages due to regional failures. It will also extend our contractual SLA to 99.99%. With Multi-Region Namespaces, your cloud service will be defined by a primary cloud region and a standby cloud region. History events automatically ship into the standby region asynchronously. In the event of the primary region failure, you can manually switch traffic to the standby region without disrupting ongoing Workflows. We recommend this capability if disruption of your workflow will cause loss of revenue, poor end-user experience, or issues with regulatory compliance.\n\nThis is just a brief overview of the topic of high availability in Temporal Cloud. For more details, we recommend watching the webinar:\nThis post is part of a series about Temporal Cloud. Check out the other posts below:\n\n  Higher throughput and lower latency with Temporal Cloud custom persistence layer\n  Exploring Temporal Cloud Automation Features\n  Estimating the cost of Temporal Cloud\n  How to migrate your self-hosted service to Temporal Cloud\n",featureImage:{title:"social card - green waves",description:"social card - green waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4GBHZR0vUnoRSbPtSTCH4s/daf7308a10e469059827e2169065d7ea/social_card_-_green_waves.jpg"},publishDate:"2024-03-27T00:00-06:00",metaDescription:"Learn how Temporal Cloud supports high availability and disaster recovery to keep your applications reliable at scale.",metaTitle:"High Availability & Disaster Recovery with Temporal Cloud",socialCard:{title:"social card - green waves",description:"social card - green waves",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4GBHZR0vUnoRSbPtSTCH4s/daf7308a10e469059827e2169065d7ea/social_card_-_green_waves.jpg"},tags:"Durable Execution",slug:"high-availability-and-disaster-recovery-with-temporal-cloud",contentType:"blogPost",entityId:"4VxV6nP8wMLRcFdQxYZH9P",authors:[{id:"4dsODPDNXZPwvTMknnOR7N",name:"Meagan Speare",slug:"meagan-speare",jobTitle:"Sr. Manager, Product Marketing",photograph:{title:"headshot-megan-speare",description:"headshot-megan-speare",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4cU6Eil7AyPgQDtc52XeS8/935bb30acca03ba2e011e5cc90be909c/meagan-speare.jpg"},contentType:"person"}],authorsString:"Meagan Speare",category:"Temporal Concepts",readingTime:4},{title:"9 ways to use Temporal for AI Workflows",content:"For Temporal, AI workflows are not that different from the countless others in which we are applied and there are dozens of startups and large organizations using Temporal to help build these workflows.\nTemporal can significantly benefit AI workflows in several ways due to its inherent capabilities around durability, scale, and failure handling. Specifically, AI and machine learning workflows often involve complex, long-running processes that can benefit from Temporal's workflow orchestration and state management features.\nA few key areas in which Temporal can be helpful for your AI workloads include the following:\n\n  \n    Workflow Orchestration for AI Pipelines - AI applications often involve complex pipelines consisting of data collection, preprocessing, training, evaluation, and inference stages. Temporal orchestrates these stages reliably across distributed systems. By managing dependencies and task execution order, Temporal ensures that your AI pipeline progresses smoothly, even in the event of failures.\n  \n  \n    Scalable and Reliable Machine Learning Model Training - Training machine learning models can be a resource-intensive and time-consuming process, especially with large datasets. Temporal workflows can manage long-running training jobs, automatically retrying failed tasks and resuming interrupted jobs from their last checkpoint. This durability (source) ensures that training processes are resilient to transient issues, such as network outages or resource constraints.\n  \n  \n    Distributed Data Processing - Data preprocessing, a critical step in the AI pipeline, often requires processing large datasets distributed across multiple nodes. Temporal can coordinate complex data preprocessing workflows, handling failures gracefully and ensuring data consistency and reliability throughout the process. The ability to manage state across distributed systems enables Temporal to optimize resource allocation and processing efficiency.\n  \n  \n    Continuous Learning and Model Deployment - AI models frequently need to be retrained and updated as new data becomes available. Temporal workflows can automate the continuous learning process, orchestrating the cycle of data collection, model retraining, evaluation, and deployment. This ensures that AI models remain accurate and up-to-date without manual intervention.\n  \n  \n    Experimentation and Versioning - Experimenting with different models and configurations is vital for developing effective AI applications. Temporal workflows can manage experimentation processes, tracking the performance of various models and configurations. This makes it easier to compare results, revert to previous versions, and iterate rapidly.\n  \n  \n    Efficient use of GPUs - Temporal allows you to efficiently distribute work across limited resources. Many use limited-activity-slot workers as a way to limit work given to GPU powered machines. The Temporal work-pulling model allows a central workflow to give work to explicit workers that has available resources.\n  \n  \n    Scaling AI operations - As AI models move from development to production, they often require operational support for tasks like model updating, monitoring, and adjusting to new data. Temporal workflows make it possible to automate these tasks reliably, ensuring that AI systems remain effective and up-to-date.\n  \n  \n    Event-Driven and Asynchronous Execution - AI workflows often need to react to external events (ie. new data availability) and execute tasks asynchronously. Temporal's support for event-driven workflows allows you to design AI systems that are both reactive and resilient.\n  \n  \n    Observability and Debugging - Managing complex AI workflows requires insight into what's happening at each stage of the process. Temporal allows you to investigate each execution and get insight into any issues that may be blocking a function. These tools help developers monitor workflow execution, optimize performance, and quickly identify issues.\n  \n\nGetting Started with Temporal\nUnderstanding Temporal and starting to develop with it can be approached through a series of guided steps and resources.\nDive Into the Getting Started Guide\nThe Getting Started with Temporal guide is a great place to start. It introduces you to the range of SDKs available and provides direct links to get started with each.\n\n  Temporal Go SDK\n  Temporal Java SDK\n  Temporal PHP SDK\n  Temporal Python SDK\n  Temporal TypeScript SDK\n\nExperiment and Build\nThe best way to learn is by doing. Start experimenting with the sample projects and try to modify them or build your own simple applications. As you encounter challenges or have questions, the Temporal documentation and community are valuable resources.\nTemporals sample repos:\n\n  Go\n  TypeScript\n  Java\n  Python\n  .NET\n  PHP\n\nThe Temporal Community Slack is active and helpful for discussions and questions.",featureImage:{title:"Social card - Temporal",description:"Social card - Temporal",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3A4UpeAUYabwGjkyPPHEC4/f695115bb2ed3d2ff5cf3ae05aad1bb5/Twitter_Card.png"},publishDate:"2024-03-26T00:00-06:00",metaDescription:"Explore how Temporal enhances AI workflows, helping startups and large organizations build scalable, reliable, and efficient AI systems.",metaTitle:"9 ways to use Temporal in your AI Workflows",socialCard:{title:"Social card - Temporal",description:"Social card - Temporal",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3A4UpeAUYabwGjkyPPHEC4/f695115bb2ed3d2ff5cf3ae05aad1bb5/Twitter_Card.png"},tags:"AI/ML",slug:"nine-ways-to-use-temporal-in-your-ai-workflows",contentType:"blogPost",entityId:"4eY71b9dDgBS0oaRO8CeuG",authors:[{id:"1SCcHs5wmwt6kjoR3qMuGZ",name:"Jim Walker",slug:"jim-walker",jobTitle:"VP of Product Marketing",photograph:{title:"headshot-jim-walker",description:"headshot-jim-walker",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3tZdemozlmoJ8a4leDbfGX/ae3233e372bb29e7d3918b9b0d2c4bfc/Screenshot_2023-10-20_at_2.08.33_PM.png"},contentType:"person"}],authorsString:"Jim Walker",category:"Temporal Concepts",readingTime:4},{title:"Exploring Temporal Cloud automation features",content:"Temporal Cloud Automation capabilities are transforming the way companies deploy, manage, and scale their operations in the Cloud.\nIn our recent webinar, we discussed how Temporal Cloud users can automate the management of namespaces and users, including the provisioning/deprovisioning of users, user access management, onboarding new teams to Temporal, and implementing best practices such as automated mTLS certificate rotation.\nIntroducing our newly added Cloud Automation features\nWe've introduced a suite of Cloud Automation features in Temporal Cloud, aimed at simplifying cloud management while enhancing security. These features allow for the straightforward setup and management of users, namespaces, and account settings. By leveraging APIs, the Terraform provider, and the Temporal Cloud CLI (tcld), coupled with API Keys for Cloud Operations, users gain the ability to automate crucial tasks, such as the rotation of mTLS certificates. These features ensure secure authentication across various interfaces, making cloud operations more secure and less prone to errors.\nCore Features of Temporal Cloud Automation:\n\n  Temporal Cloud API Keys: Provides secure access, ensuring that only authorized users can manage resources.\n  Temporal Cloud CLI (tcld): Facilitates direct, command-line automation, streamlining Temporal Cloud operations.\n  Terraform Provider for Cloud: Enables efficient management via infrastructure-as-code, allowing for scalable cloud environments.\n\nThese tools not only tighten security, they also provide operational efficiency gains across the board freeing you up to focus on what matters, building user value, instead of managing infrastructure.\nUse Cases\n\n  Centralized Cloud Operations: In large organizations, Temporal Cloud users often employ a platform team to centralize the management and governance of Temporal Cloud across all teams. The Cloud Automation features enable this use case by providing automation capabilities for Platform Teams with governance controls.\n  Certificate Rotation: mTLS is a highly secure method for service communication. A best practice for mTLS involves regularly rotating the certificates that enable mTLS encryption. The Cloud Automation features assist users in creating automated certificate rotation capabilities, regardless of their choice in infrastructure management tools, such as Kubernetes environments, Terraform, etc.\n  User and Access Management: Ensuring that Temporal Cloud remains secure, compliant, and responsive to enterprise user and access management changes can be challenging when working across cloud services. The Cloud Automation features simplify this process, ensuring that Temporal Cloud stays in sync with your Enterprise Identity Provider (IdP).\n  Team Onboarding: When new teams adopt Temporal Cloud, they are provided with Namespaces, Permissions, and other resources. The Cloud Automation features help users encapsulate all the resource provisioning for a new team into a single automated routine, reducing the time it takes for new teams to start coding in Temporal.\n\nDiscover More About Cloud Automation:\nTo explore Temporal Cloud Automation further, we provide a range of resources and community links:\n\n  API Keys documentation\n  Temporal Terraform Hashicorp Registry\n  Cloud Ops API documentation\n  GitHub Repository for Cloud Ops API\n  GitHub Repository for Terraform Provider\n\nStay Tuned:\nThis post is part of a series about Temporal Cloud. Check out the other posts below:\n\n  Higher throughput and lower latency: Temporal Clouds custom persistence layer\n  How to migrate your self-hosted service to Temporal Cloud\n  Higher throughput and lower latency with Temporal Cloud custom persistence layer\n  Estimating the cost of Temporal Cloud\n",featureImage:{title:"social-sphere",description:"social-sphere",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4DWjFPWLbTSnteonueNbg7/3b31c73c03bfa544469db528e918a4cd/dynamic-wang-KZuZAaEojq4-unsplash.jpg"},publishDate:"2024-03-25T00:00-06:00",metaDescription:"Temporal Cloud Automation capabilities are transforming the way companies deploy, manage, and scale their operations in the Cloud. ",metaTitle:"Exploring Temporal Cloud automation features",socialCard:{title:"social-sphere",description:"social-sphere",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4DWjFPWLbTSnteonueNbg7/3b31c73c03bfa544469db528e918a4cd/dynamic-wang-KZuZAaEojq4-unsplash.jpg"},tags:"CI/CD,Cloud",slug:"exploring-temporal-cloud-automation-features",contentType:"blogPost",entityId:"7a26LK0dz7csHgwtJe5DKZ",authors:[{id:"7GV0xjBamDpDSZZ543r8yX",name:"Irina Belova",slug:"irina-belova",jobTitle:"Product Marketing",photograph:{title:"headshot-irina-belova",description:"headshot-irina-belova",url:"https://images.ctfassets.net/0uuz8ydxyd9p/BJ0w7WeAjw83DatmJ7Fin/a8facdb4b7206afe1e66dc73b216ec09/headshot-irina.png"},contentType:"person"}],authorsString:"Irina Belova",category:"Temporal Concepts",readingTime:3},{title:"Temporal Clouds custom persistence: Higher throughput, lower latency",content:"Latency drives decisions when evaluating managed services like Temporal Cloud. Many developers assume application latency will increase when they migrate from a self-hosted Temporal Cluster to Temporal Cloud. We see the opposite: Temporal Cloud provides better performance and lower latency than most self-hosted clusters.\nThese performance improvements stem from our teams effective management and scaling of Temporal Cloud, and Temporal Clouds custom persistence layer. This architecture helps our managed service handle high throughput with lower, more stable, request latencies.\nThis post provides an overview of Temporal Clouds custom persistence layer.\nWhy we built a custom persistence layer\nTemporal Cloud is multi-tenant: multiple Namespaces sharing the same compute and persistence layer. Customers pay for consumption instead of entire sets of hardware, a cost-effective solution. Multi-tenancy ensures extra capacity is available for all customers during traffic spikes. Multi-tenancy also means handling the challenge of noisy neighbors, which is when high-traffic tenants consume excess resources, causing slower performance for other tenants.\nThe noisy neighbor problem is especially difficult to address in the database. Because databases are stateful, and take longer to scale, capacity cannot be added quickly to handle spikes in load. Temporal uses a write-heavy workload; changes in execution state are constantly written to the persistence layer. This lets Workflows execute durably, even when failures occur. The database for Temporal Cloud must support reliably high throughput with low latency for multiple customers, concurrently and fairly.\nTo address these challenges, our team built a custom persistence solution on top of Temporal Clouds existing architecture. Our design includes three pillars:\n\n  Better sharding\n  Write-ahead log\n  Tiered storage of Workflow Event History\n\nBetter sharding in Temporal Cloud\nThe first thing we did to improve scalability of Temporal Cloud was to shard the persistent state and store it across multiple databases. We can dynamically add databases and resize them independently depending on the needs of different Namespaces. This architecture helps Temporal Cloud handle high scale on a daily basis and scale Namespaces for high-traffic events such as Black Friday.\nWrite-ahead log in Temporal Cloud\nTemporals write-heavy nature means every event must be written to the database. A high write rate can cause high latency and require a larger database to support. We addressed this by building a write-ahead log (WAL).\nOur write-ahead log stores writes in an append-only log. This allows the server to accumulate multiple updates in the WAL before writing a single aggregated update to the database. If a failure occurs before updates are written to the database, the updates can be read and recovered from the log.\nAfter implementing the write-ahead log, we saw an immediate impact on Temporal Cloud. This enhancement significantly reduced both latency and the size of the databases in Temporal Cloud.\nTiered storage of Workflow Event History\nThe Temporal persistence layer stores the ongoing writes for every event in a Workflow and the Workflow Event History. The Event History is fundamental to the recovery and replay processes in Temporal. It also lets developers debug past executions or export data for compliance and further analysis. Event Histories consume storage in the database and may slow down performance.\nTo address this, we built a system that moves Workflow Event History to an object store when the corresponding Workflow Execution completes. Customers can still access Event Histories as normal, while on the backend we reduce demands on the database, improving efficiency and lowering the latency of starting and running Workflows.\nThe result: higher scalability and lower latency\nWeve helped many customers move from self-hosted Temporal Clusters to Temporal Cloud. We regularly witness decreases in latency as a result of the custom persistence layer. When youre running at large scale, we always recommend evaluating Temporal Cloud for the best possible performance. From small to large, Temporal Cloud saves you time and resources, and gives you a more reliable service.\nFor more details, watch our webinar recording: Custom Persistence Layer of Temporal Cloud. You can learn more about Temporal Clouds latency Service Level Objective (SLO).\nAlso, check out this talk from last years Replay Conference: What's cloud got to do with it? A novel persistence layer for Temporal Cloud.\nThis post is part of a series about Temporal Cloud. Check out the other posts below:\n\n  Exploring Temporal Cloud Automation Features\n  High availability and disaster recovery with Temporal Cloud\n  Estimating the cost of Temporal Cloud\n  How to migrate your self-hosted service to Temporal Cloud\n",featureImage:{title:"social-card-dark-waves (1) ",description:"social-card-dark-waves (1) ",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7fqbHM7iWOHKJo0GNha3Ou/ca1d6b6c63ab327d9e872eefa5a33627/social-card-dark-waves__1__1.png"},publishDate:"2024-03-20T00:00-06:00",metaDescription:"Learn how Temporal Clouds custom persistence layer boosts throughput and reduces latency when migrating from self-hosted clusters.",metaTitle:"Faster Throughput & Lower Latency with Temporal Cloud",socialCard:{title:"social-card-dark-waves (1) ",description:"social-card-dark-waves (1) ",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7fqbHM7iWOHKJo0GNha3Ou/ca1d6b6c63ab327d9e872eefa5a33627/social-card-dark-waves__1__1.png"},tags:"Cloud",slug:"higher-throughput-and-lower-latency-temporal-clouds-custom-persistence-layer",contentType:"blogPost",entityId:"64HcTLRiJiH8mwl187tK9G",authors:[{id:"4dsODPDNXZPwvTMknnOR7N",name:"Meagan Speare",slug:"meagan-speare",jobTitle:"Sr. Manager, Product Marketing",photograph:{title:"headshot-megan-speare",description:"headshot-megan-speare",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4cU6Eil7AyPgQDtc52XeS8/935bb30acca03ba2e011e5cc90be909c/meagan-speare.jpg"},contentType:"person"}],authorsString:"Meagan Speare",category:"Temporal Concepts",readingTime:4},{title:"Announcing our new partnership with AWS Activate to help more startups build reliable apps",content:"Its more difficult than ever for startups to balance growth and spend, while building an MVP and finding product-market fit. Our program, Temporal Cloud for Startups, helps early-stage companies get to market more quickly without draining their resources. Having seen the positive impact of this program on hundreds of customers, were always looking for ways to expand its reach.\nThats why we recently partnered with AWSs startup program to provide an exclusive offer for AWS Activate customers that will help them grow their businesses from the ground up with AWS. With our partnership, we hope to add your company to that list.\nIf you are an AWS Activate customer, you can now access an exclusive offer of $3,000 USD in free Temporal Cloud credits that you can use for:\n\n  Temporal Cloud Usage. Temporal Cloud delivers namespace-as-a-service. Our team manages your Temporal Server instance and all provisioning, sharding, maintenance, and uptime.\n  Support & Services. Standard support SLAs and critical services like technical onboarding, code design reviews, pre-production meetings, and worker tuning to optimize performance.\n\nAWS Activate customers can redeem this exclusive offer by navigating to the Exclusive Offers tab in their Activate Console, and clicking on the Temporal offer in the Engineering or Productivity sections.\nReady to get started with Temporal on AWS? Our pay-as-you-go listing on AWS Marketplace is the fastest and most frictionless way to start with Temporal Cloudno credit card, no up-front cost and pay-as-you-go billing through AWS. Sign up here.",featureImage:{title:"social-orb",description:"social-orb",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Tk0k2JzNldP4WvVCZzJzA/08592218f1fd8de9b5efd2ee10cf0364/social-orb.jpg"},publishDate:"2024-03-19T00:00-06:00",metaDescription:"Learn how Temporal Cloud for Startups combined with AWS helps early-stage companies get to market quickly.",metaTitle:"Temporal & AWS Partnership",socialCard:{title:"social-orb",description:"social-orb",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Tk0k2JzNldP4WvVCZzJzA/08592218f1fd8de9b5efd2ee10cf0364/social-orb.jpg"},tags:"Industry Events",slug:"announcing-our-new-partnership-with-aws-activate-to-help-more-startups-build",contentType:"blogPost",entityId:"5tCrGoApJVfUpKxYRKNgol",authors:[{id:"6ZrqOx5rXn6dp0w49g7vDb",name:"Jay Sivachelvan",slug:"jay-sivachelvan",jobTitle:"VP of Partnerships",photograph:{title:"Jay Shivachelvan",description:"Jay Shivachelvan",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3RS0QEY2Zh9mZwIfIRC8jN/bd89483f6b2cbd610e955d9eb30458eb/TT31S6VK5-U05LKSQG753-7b4dcb8eea4b-512"},contentType:"person"},{id:"4dsODPDNXZPwvTMknnOR7N",name:"Meagan Speare",slug:"meagan-speare",jobTitle:"Sr. Manager, Product Marketing",photograph:{title:"headshot-megan-speare",description:"headshot-megan-speare",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4cU6Eil7AyPgQDtc52XeS8/935bb30acca03ba2e011e5cc90be909c/meagan-speare.jpg"},contentType:"person"}],authorsString:"Jay Sivachelvan, Meagan Speare",category:"Announcements",readingTime:2},{title:"Community threads: Is it possible to write a single Workflow with different languages?",content:"Community Threads: Is it possible to write a single Workflow with different languages?\nIn Community Threads, we dig into some of the most frequent and insightful questions that appear in our Temporal Community.\nThe question\nToday's Thread focuses on a question asked by a Temporal user who wants to know:\nIs it possible to write a single Workflow in multiple languages?\n\n  \n\nThe answer\nWhile a single Workflow Definition should be consistent in one language, that Workflow can include Activities written in other languages. For each Activity written in separate languages, you will need a separate Worker and different task queue names for the Activities in each language.\nTip: Even when using the same function in different programming languages, use a distinct name for each task queue so that the Worker can identify the appropriate Activity to run. If you use the same name, then the Worker Entity will be unable to identify which queue to execute. Be sure to define a separate Worker initialization for each programming language you intend to use in your Workflow.\nIf you want to have the Workflow continue the task execution in another language in the case of failure, then you would use the same Workflow (including the type and method name) to complete the Workflow in the secondary language. Use the data types for your programming language of choice when writing the Workflow or Activity code. The Temporal SDK automatically converts the language types for interoperability with other SDKs. For example, a bool value returned from an Activity written in Python will appear as a boolean value in the Java Workflow that calls the Activity in Python.\nThe context\nYou can use any of the available Temporal SDKs as you write an Activity Task. Activity names in the Task Queue should be unique. When dealing with multiple languages, supply unique task names so the Worker Entity (the individual Worker within a Worker Process that listens to a specific Task Queue) can identify which Activities to select from the queue.\nTip: We recommend appending the language to the Activity name so you can keep track of the language-specific Activities.\nTo combine two different actions written in different languages for your Workflow, each of these actions will require a distinct Activity Type that will be called during the Workflow Execution by the language-specific Worker Entity.\nEach task in a Workflow should be well-defined to accomplish a single action. That enables the Worker to perform the operation efficiently as specified by the Activity Definition. When the Temporal Worker finds the specified name in the Task Queue, it will begin the task execution until either the operation is completed or an error is returned. When you define Activities in different languages (assuming that each task has a distinct name for the queue), then each Worker can identify and run those operations concurrently. The Activities will be executed according to your timeout and retry policies.\nThe Temporal Polyglot and Temporal Pendulum applications illustrate how to use multiple languages with Temporal. The Polyglot app demonstrates Temporals orchestration capabilities between applications in different languages, whereas the Pendulum app calls Workflows written in different programming languages through visual representations in a graphical interface.\n\n  The Pendulum game is written primarily in Java that calls activities written in PHP, Go, and Node (and their corresponding Workers) to populate the user interface and interactive elements. The WorkflowUtils.java file uses the WorkflowUtils class to specify the ID and task queue name for the Workflow in each programming language. As a result, the application, written primarily in Java, can call Workflows in each language to move the position of the pendulum.\n  \n  \n\nLearn the basics with Temporal 101\nStill not sure how Workflows and Activities interact? Temporal 101 introduces these concepts alongside the Temporal SDKs, so you can learn how to configure and environment and manage your application lifecycle with Temporal's execution model and event history features.\nIf youve already completed Temporal 101 and youre ready to delve deeper, try Temporal 102.\nJoin the Temporal user community in Slack\nIf you found this thread helpful or if you have your own questions about using Temporal, join us in Slack to connect with other Temporal users and team members.",featureImage:{title:"li-zhang-ZvVydsVkyTI-unsplash",description:"li-zhang-ZvVydsVkyTI-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3WwtmBoVCX8MFqaV2ZTQUq/fc4fc75dd2e1d75a6a36d292827b8d80/li-zhang-ZvVydsVkyTI-unsplash.jpg"},publishDate:"2024-03-05T00:00-08:00",metaDescription:"Today's Thread focuses on a question asked by a Temporal user who wants to know:  Is it possible to write a single Workflow in multiple languages?",metaTitle:"Community threads: Is it possible to write a single Workflow with different languages?",tags:"Code Samples",slug:"community-threads-is-it-possible-to-write-a-single-workflow-with-different",contentType:"blogPost",entityId:"5H7abYG7Q1MNF98PutjgWu",authors:[{id:"4QvD4O6zJRUA16EVxNN2Sg",name:"Caz Michaels",slug:"caz-michaels",jobTitle:"Technical Writer",photograph:{title:"caz michaels",description:"caz michaels",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5lpwtrmbaFZk9wUi15TLQI/051f555c942bfb73c18ff905abc254e3/caz.jpg"},contentType:"person"}],authorsString:"Caz Michaels",category:"Community",readingTime:4},{title:"Introducing Workflow History Export",content:"Workflow History Export in Temporal Cloud allows users to export closed workflow histories on a per-namespace basis to an AWS S3 cloud storage bucket.\nToday in Temporal Cloud, the default retention period for workflow history data is 30-days. While users are able to extend this limit up to 90-days, those looking for longer-term data storage can take advantage of the workflow history export feature. By doing so, users can retain and preserve historical workflow data for compliance, auditing, and further analysis.\nThis feature has been available to a select group of users in Pre-release and we have already exported millions of workflows. Heres what Betashares, a leading Australian provider of exchange-traded funds and Temporal Cloud customer, had to say about the feature.\nWeve actually needed this feature for a long time. The 90-day retention window has been a real issue for us. I was really surprised to see how easy it was to set up, I went in and launched the AWS CloudFormation stack installer, created the role and it was ready to go.\nOne of the nice advantages with this feature is that two years from now we could re-run code in the debugger that would have run two years prior, and find out what went wrong! Given were a financial institution, the ability to have code-line level audit trails is something that gives us a great degree of safety and accountability.\nWere excited to announce that as of today, this feature is now available to all users of Temporal Cloud in Public Preview, which means you can safely use the feature in production with data delivery guarantees.\nThere is a cost associated with this feature. Each workflow exported will accrue a single action, which will be rolled up and shown on your invoice as a separate line item per namespace.\nTo set up workflow export, users must first create an AWS S3 bucket in the same region as the namespace. Then through the Temporal Cloud UI or CLI, users grant Temporal permission to write data to their S3 bucket via AWS CloudFormation.\n\n  \n  The image above is an example of setting up Workflow History Export in the Temporal Cloud UI\n\nOnce everything is set up correctly, Temporal will export history data from your namespace to S3 on an hourly basis. Thats pretty much it!\nHere are some other useful resources for more details about the feature.\n\n  Documentation\n  Pricing\n  Changelog\n\nIf you have any feedback, questions or concerns, please reach out to product@temporal.io!",featureImage:{title:"social-card-water-effect",description:"social-card-water-effect",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2KTpNohgF4VK8RxG2r4vlT/500df86e294043f8d19983961e4c2a0c/social-card-water-effect.jpg"},publishDate:"2024-03-01T00:00-07:00",metaDescription:"Workflow History Export in Temporal Cloud allows users to export closed workflow histories on a per-namespace basis to an AWS S3 cloud storage bucket.",metaTitle:"Introducing Workflow History Export",socialCard:{title:"social-card-water-effect",description:"social-card-water-effect",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2KTpNohgF4VK8RxG2r4vlT/500df86e294043f8d19983961e4c2a0c/social-card-water-effect.jpg"},tags:"Temporal Primitives",slug:"introducing-workflow-history-export",contentType:"blogPost",entityId:"6Oeb1g2KM3OTqMQkwSwjs6",authors:[{id:"5rRXBv9YX2HZHsbvCIr7ts",name:"Nikitha Suryadevara",slug:"nikitha-suryadevara",jobTitle:"Staff Product Manager",photograph:{title:"headshot-nikitha",description:"headshot-nikitha",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4OACKtdVPmoAygYiRKZnHU/d4033aa0852aae010c69fe249c9e90c0/headshot-nikitha.png"},biography:"Nikitha is a Staff Product Manager at Temporal based in San Francisco. She oversees several areas of the product such as high availability, worker management, and observability. Before Temporal, she worked on Compute Infrastructure (Borg) in Google Cloud. Her introduction to compute and cloud was through being a Product Line Manager at VMware. Nikitha started her career as a software engineer and product manager at various SaaS startups. She got her bachelor's degree in electrical engineering from the Manipal Institute of Technology and an MBA from UCLA Anderson.",company:"Temporal",contentType:"person"}],authorsString:"Nikitha Suryadevara",category:"Product News",readingTime:3},{title:"Understanding idempotency in distributed systems",content:"Life Without Idempotency\nHave you ever been working on a feature, or fixing a bug, and when you got to the bottom of it, duplicate records were being created in a database, or duplicate charges or orders were sent out? If so, idempotency is an important topic for you.\nIdempotency is a property of functions or operations in programming, and its a crucial property when working with durable execution systems such as Temporal. In this post, well explain what it means to be idempotent and how idempotency can make your software systems easier to work with. Well show examples and get into some complex cases that can be managed with Temporal.\n\n  \n\nWhat is Idempotency and Why Does It Matter?\nIt's a fact of life that no system is perfectly reliable, and when things fail, we need to retry what we were doing. Wouldn't it be nice if we could retry safely without causing unintended duplicate effects? Idempotency is what lets us do this! Idempotency is defined as a request that produces the same result, regardless of how many times it is made.\nIf an idempotent request is sent once, it will produce the desired result. If it is sent multiple times, it still produces the desired result.\n\n  An example idempotent operation is updating a customers address in a table in the database because no matter how many times it is called, the final address is always the same in the database.\n  On the other hand, an example non-idempotent operation is foo += 3 because the value of foo changes based on the number of times it is called.\n\nA simple, real-life example of idempotency is the stop button in a media player app. You tap the stop button, and the player stops playing. If you tap it again, the player is still stopped. The result is the same: the player stops. You could hit it a hundred times, and it will still be stopped. Therefore, tapping the stop button is idempotent.\n\n  \n  \n\nCompare this to a play/pause button: you tap it and the media starts, and then you tap it again and the media pauses. The play/pause button doesnt always result in the same state, so it is not idempotent.\nIdempotency matters because systems are not perfect, and it is nice to be able to retry things safely without causing unintended duplicate effects. In an ideal world, you could call:\nchargeCard(paymentInfo, orderId) \nmultiple times with the same inputs and only make one charge for the order.\nIf every operation were idempotent, dealing with transient failures could have a simpler developer experiencejust keep calling the operation until it succeeds. Because some operations are not inherently idempotent, we have to consider the complexities of duplicate calls, especially if something fails without an obvious complete success or failure.\nTemporal and At Least Once Execution\nTemporal allows developers to avoid coding for infrastructure nuances and other inevitable failures, focusing on what matters: coding the process they are trying to implement. It would be nice if you could code up the high-level process, but not worry about the underlying or external systems, right? Except you have to at some point interact with those systems. So we separate out those two concerns into Workflows and Activities respectively.\nWorkflow code concerns itself with the higher-level business logic of the application. Activity code focuses on more granular functions such as writing to a database, calling a service, or processes that could be longer running or even blocking in nature.\nTemporal is an event-sourced system and each Workflow has its own event history. Temporal will maintain the state of the Workflow and continually progress each Workflow to completion regardless of any failures. In addition, Temporal provides built-in retry logic for Activities, and since Activities are just events in the Workflow history, Temporal is able to guarantee at least once execution.\nWhy the specificity around at least once?\nTemporal is a distributed system. The Temporal server orchestrates and maintains state, while Temporal worker(s) execute Workflows and Activities. Part of what is great about using Temporal is that by default, Activities are retried until they run successfully. But Activity execution is not atomic due to factors such as failures, timeouts, environment failure, or other conditions that lead to partial success. Temporal recommends Activities be idempotent, or at least if they arent, that executing an Activity more than once does not cause any unexpected or undesired side effects.\nPractices for Idempotency With Temporal\nTemporal can provide a guarantee for at least once or at most once Activity execution, depending on configuration. By default, Activity retries are unlimited, meaning at least once execution, but practically speaking, it means as many times as needed. However, limiting maximumAttempts to 1 and using normal Activities (not Local Activities) will guarantee at most once execution, meaning zero times is also possible. There are several practices to help make your Activities idempotent.\nIdempotency Keys\nUsing idempotency keys provides a mechanism to understand if an Activity is called more than once, and if so, take the necessary action, for example, skipping execution if it already occurred. Consider this example SubmitOrder Activity:\nActivity Code Example\nfunc SubmitOrder(ctx context.Context, orderId int) (Order, error) {\n\torder, err := ExternalAPI.SubmitOrder(orderId)\n\tif err != nil {\n\treturn Order{}, err\n\t}\n\n\treturn order, nil\n}\nIf ExternalAPI.SubmitOrder doesnt do anything when receiving duplicate order IDs (for example, if the first thing it attempts is inserting a record into a database with a uniqueness contraint on the order ID, no database data will be changedit will just return an error), then orderId serves as the idempotency key.\nIf your use case doesnt already have a value that can be used as an idempotency key, you can use workflowRunId + - + activityId. For example, in the TypeScript SDK, it would be this Activity code:\nimport { info } from @temporalio/activity\n\n \n  const idempotencyKey = `{info.workflowRunId}-${info.activityId}`\nThis value will be constant across Activity retries, and unique among all Workflows.\nSQL Example\nIf your data model doesnt have a natural place to use the idempotency key, you can create an operations table with a uniqueness constraint:\nCREATE TABLE operations (\n    idempotency_key VARCHAR(255) UNIQUE NOT NULL\n);\n\n-- Example transaction:\nBEGIN;\n\n-- Assuming variable declarations are adapted to your SQL dialect\nDECLARE @account_id INT = 1;\nDECLARE @debit_amount DECIMAL(10,2) = 100.00;\nDECLARE @idempotency_key VARCHAR(255) = 'unique-key-123';\nDECLARE @operation_inserted BIT = 0; -- Default to not inserted\n\n-- 1. Attempt to insert the operation first, to check for idempotency early\nINSERT INTO operations (idempotency_key)\nVALUES (@idempotency_key)\nON CONFLICT (idempotency_key) DO NOTHING\nRETURNING 1 INTO @operation_inserted;\n\n-- If the operation was inserted, then check balance and proceed\nIF @operation_inserted = 1\nTHEN\n    IF EXISTS (\n        SELECT 1 FROM accounts\n        WHERE account_id = @account_id AND balance >= @debit_amount\n    )\n    THEN\n        -- 2. Update the account balance since this is a new operation\n        UPDATE accounts\n        SET balance = balance - @debit_amount\n        WHERE account_id = @account_id;\n\n        -- Commit if update is successful\n        COMMIT;\n        -- Return or indicate success here, if needed\n    ELSE\n        -- Insufficient balance, rollback and indicate the issue\n        -- Note: Since the operation was new, it's appropriate to indicate insufficient balance\n        ROLLBACK;\n        RAISE 'Insufficient balance for debit.';\n    END IF;\nELSE\n    -- Operation was a duplicate, consider it a success\n    -- No need to update balance or check it, just end transaction gracefully\n    -- Return a success indicator since this is a repeated but originally successful operation\n    COMMIT; -- Or simply end transaction if COMMIT is not required here\n    RETURN 1; -- Adjust based on how you handle return values or success indicators\nEND IF;\nIn step 1, if the operation has already run, it will be unable to insert the idempotency key into the operations tableinstead, it will throw something like:\nERROR: duplicate key value violates unique constraint\n\nThis is a simple short example. In a production use case, youd likely want to prevent the table from growing forever by:\n\n  adding a timestamp field to the operations table, with an index on it, and\n  periodically prune entries from operations that are old enough that theres no longer a risk of duplicate requests arriving.\n\nCheck Pre-existing Results\nAn alternative to idempotency keys is checking for pre-existing results. If a CreateUser Activity inserts a user record into a database, the Activity could start out by checking whether a user record already exists with the given email address. If it does, then you know the Activity has already successfully run, and you can return without inserting.\nfunc CreateUser(ctx context.Context, userData UserInput) (User, error) {\n\t// Check if user was already created\n\tif ExternalAPI.UserExists(userData.Email) {\n\t\treturn User{}, temporal.NewApplicationError(\"Cant create user: email already exists\", \"UserAlreadyExists\")\n\t}\n\n\t// Create user\n\tuser, err := ExternalAPI.CreateUser(userData)\n\tif err != nil {\n\t\treturn User{}, err\n\t}\n\n\treturn user, nil\n}\nThere unfortunately is a race condition with this codeit still is possible for a duplicate user to be created. (This is assuming that ExternalAPI.CreateUser isnt idempotent by itselflike, the underlying user database doesnt have a unique email constraint. If it did, we wouldnt need to check whether it exists at allwe could just attempt creation as we did in SubmitOrder above.)\nIf the first attempt takes a long time to run ExternalAPI.CreateUserfor example, longer than the Start-To-Close Timeoutthen a second attempt will be run, and if the second attempt gets past the UserExists() check before the first attempts CreateUser() completes, then both the first and second attempts could successfully run CreateUser().\nThe likelihood of the race condition can be reduced by:\n\n  Setting a longer interval between Activity retries.\n  Responding to Activity Cancellation by closing the current API request and returning.\n  Setting a timeout on each API request.\n\nThe risk of duplication could be removed if there were a way to get a lock on user operations with a given email. If the API had such a GetLock() function, we could use itbut we should really just get them to accept an idempotency key as input .\nOn the other hand, if we knew we were the only users of the API, we could implement the lock on our end with a lock workflow:\n\n  UserLock Workflow is an entity Workflow that runs forever, receives get-lock and release-lock Signals, and sends pass-lock Signals.\n  Before running the CreateUser Activity, the UserOnboarding Workflow requests a lock on me@email.coms user operations by sending this request:\n\nSignal-With-Start:\n  WorkflowType: UserLock\n  WorkflowId: me@email.com\n  Signal: get-lock\n\n\n  The UserLock Workflow keeps a queue of lock requests, and sends pass-lock to the Workflow that made the first request, telling it that it now has the lock.\n  When the UserOnboarding Workflow receives the give-lock Signal, it runs the CreateUser Activity. Once the Activity completes, it sends the release-lock Signal to UserLockWorkflow.\n\nFor a similar code sample, see samples-typescript  mutex.\nStateless Activities\nWhenever possible, activities should be stateless meaning only rely on inputs and outputs, rather than any inter-activity state for example global variables or shared memory within activity. Intra-activity state can be shared across activity retries using activity heartbeat with data in the heartbeat details.\nActivity inputs and output are stored in the workflows event history. Temporal uses the event history to reconstruct state in the event of certain failures. During replay, activities that have already been executed are not re-executed. Instead Temporal simply takes activity input and output from its event history while continuing with Workflow progression. If activities were to store some internal state, it would be lost during Workflow replay as already completed activities would never be re-executed.\nIf activity state needs to be stored it is recommended to rely on a database, context propagation or a Custom Search Attribute for storing simple state, where eventual consistency is tolerable.\nIdempotent Workflows\nActivities arent the only thing in Temporal that might be executed twice! Its possible to unintentionally create two Workflow Executions with the same input, unless:\n\n  Both Workflows have the same ID, and the second start request is received by the Server while the first is still running.\n  Both Workflows have the same ID, and while the first Workflow completed before the second started, the Workflow Id Reuse Policy is set to Reject Duplicate, and the first Workflow hasnt exceeded its Retention Period.\n\nIn both of these two cases, the Workflow Id acts as an idempotency key, and the Server will return a duplicate error instead of creating the second Workflow.\nAn example scenario in which a duplicate Workflow will be created is:\n\n  A user double-clicks a submit order button on a website.\n  The website doesnt disable the button after the first click, and sends two order requests to the backend.\n  For each request, the backend generates a random Workflow Id and starts the CreateOrder Workflow.\n\nOne way to address this is:\n\n  On the backend, deterministically generate the Workflow Id from the input.\n  Set a Reject Duplicate Reuse Policy. (Unless you're not concerned about such a slow double click that the first Workflow has completed by the time the second starts.)\n\nThe input could include the user, the address, the item, and the quantity. The problem with this is that the user won't be able to make this order again until the retention period is up, even if they wanted to. Imagine not being able to find the amazing scissors you just bought, and then you keep getting an error when you try to reorder them! We could try to fix this by adding the current date to the Workflow Id generation, but then what if the user double clicks right before and after midnight? \nThis demonstrates the benefit to the idempotency key being generated as close as possible to the origination of a request. In this case, it's best for the browser to generate an idempotency key when the cart is created, and to send it to the backend with the checkout request, so the backend can use it as the Workflow Id.\nAvoiding duplicate Workflows is one reason why we recommend using business meaningful IDs for Workflow Ids. If there's already a record in a database with an ID, and you're starting a Workflow with knowledge of that ID, and there should only be one Workflow running related to that record, then use the record ID as the Workflow Id! It will be guaranteed unique and easy to look up .\nIdempotency Code Samples\nMany services already implement idempotency. Temporals Go starter application uses ReferenceID as an idempotency key. In our charging a credit card example, Stripes API supports idempotency keys for POST requests: stripe.com/docs/api/idempotent_requests\nFinally, here is a sample application that implements a simple form of idempotency:\nOrder Management Sample\nIf you attempt to process multiple orders with the same order ID, it only processes the first request:\n\n  \n\nThe idempotency check is done in the process order function.\nDealing with non-idempotent functions\nWhat happens when you have to deal with operations that are not idempotent and dont support idempotency keys or check-then-set? Such questions may lead to many other reflections:\n\n  Is it impossible to retry these operations?\n  Are we doomed to sometimes create duplicate orders/requests/charges?\n  Are these functions incompatible with Temporals programming model?\n  Should we just assume these operations always work, or have a human take over this part of the process if their execution is unreliable?\n\nThese are great questions that might lead to feeling like operations that arent idempotent cant be used in durable systems like Temporal. But there is hope.\nOne strategy is to configure Temporal to execute Activities at most once. You can do this by setting the max attempts for an Activity to be 1. There are ways in Temporal to manage this situation easily, through taking an alternative path if the Activity fails or running a compensating Activity.\nTemporal Retry Policy Example\nao := workflow.ActivityOptions{\n\tStartToCloseTimeout: 2 * time.Minute,\n\tRetryPolicy: &temporal.RetryPolicy{\n\t\tMaximumAttempts:    1,\n\t},\n}\n\n  You can build on the at most once strategy is to create an idempotent process that retries until it succeeds for an operation that writes data and also supports a read operation:\n  The existing process:\n\n\n  Calls an operation that is not idempotent (and hope it always works or always fails completely)\n\nWrap the non-idempotent operation in a function that:\n\n  Calls an operation that is not idempotent\n  Verify it succeeded with a read operation (that is idempotent)\n  If the read shows it was not successful, try again at #1\n\nIdempotency by Validation Example (simplified)\nfor ticketFound := false; !ticketFound; {\n\tticketCreateErr := workflow.ExecuteActivity(ctx, activities.CreateTicket, order.OrderID, reservation, token).Get(ctx, &order.Ticket)\n\tif ticketCreateErr != nil {\n\t\tworkflow.Sleep(ctx, time.Duration(15)*time.Second)\n\t}\n\terr = workflow.ExecuteActivity(ctx, activities.ValidateTicket, order.OrderID, reservation, token).Get(ctx, &order.Ticket)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif len(order.Ticket) > 0 {\n\t\tticketFound = true\n\t\tbreak\n\t}\n}\nWorking with failures in computer programming is challenging. Temporal Activities make this easier by automatically retrying things that fail. Idempotent operations produce the same result, regardless of how many times they are called. Combine automatic retries with idempotency, and dealing with failures gets much, much easier.\nBy following the practices outlined above, we hope that you can have confidence that your application will have no unintended consequences from non-idempotent operations, and that you will enjoying coding and supporting critical systems knowing that their operations are idempotent and automatically retried - so they just work, with Temporal.\nLinks and Further Reading:\n\n  Temporal Docs: Activities and Idempotency\n  Temporal Context Propagation Go Sample\n  Temporal Workflows: Side Effects\n  Temporal Custom Search Attributes\n  Temporal Go Sample - First Program In Go\n  Order Management Sample With Simple Idempotency\n  Order Management Sample With Non-Idempotent Activity\n  Temporal Activity Retry Limits Documentation\n  Temporal Non-Retryable Errors Documentation\n  Idempotency By Validation Sample\n",featureImage:{title:"social-card-temporalite-blog",description:"social-card-temporalite-blog",url:"https://images.ctfassets.net/0uuz8ydxyd9p/43c3wR1aXhf2oLpXy8WReZ/b280baada058cdc1d0dc9a4b2aaff37a/social-card-temporalite-blog.jpg"},publishDate:"2024-02-27T00:00-08:00",metaDescription:"Learn what idempotency means in programming and distributed systems. Discover how Temporal helps manage retries and durability with real-world examples.",metaTitle:"What Is Idempotency? Why It Matters for Durable Systems",socialCard:{title:"social-card-temporalite-blog",description:"social-card-temporalite-blog",url:"https://images.ctfassets.net/0uuz8ydxyd9p/43c3wR1aXhf2oLpXy8WReZ/b280baada058cdc1d0dc9a4b2aaff37a/social-card-temporalite-blog.jpg"},tags:"Architecture",slug:"idempotency-and-durable-execution",contentType:"blogPost",entityId:"738N6lgAFqZWL45igAEdrn",authors:[{id:"pivTTQQOf37Vyz64iYJP4",name:"Keith Tenzer",slug:"keith-tenzer",jobTitle:"Solutions Architect",photograph:{title:"Keith Tenzer Headshot",description:"Keith Tenzer Headshot",url:"https://images.ctfassets.net/0uuz8ydxyd9p/FZ8rhzxrQJc9Aw9x1VufK/424b5080e52f23f7cf72fd7319236701/Keith-Tenzer.png"},twitterUrl:"https://twitter.com/keithtenzer",linkedInUrl:"https://www.linkedin.com/in/keithtenzer/",contentType:"person"},{id:"6SCT7ktnc7C7malyJV3UsQ",name:"Joshua Smith",slug:"joshua-smith",jobTitle:"Staff Solutions Architect",photograph:{title:"Josh Smith photo",description:"Josh Smith photo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2DHNWCAITAPlTgzovWEEyW/1e105a12a16a24ca6db7f3c7ae0ef44b/1678726677795.jpeg"},contentType:"person"}],authorsString:"Keith Tenzer, Joshua Smith",category:"Temporal Concepts",readingTime:15},{title:"Durable Digest: February 2024",content:"This blog post is a public copy of our monthly newsletter sent on February 23rd. If youd like to receive upcoming updates by email, you can subscribe to our newsletter here.\nThe Replay Conference is coming back to Seattle for a third year - and Super Early Bird tickets are now on sale for only $99 until March 6th! We hope you can join us for Replay 2024 which will take place September 18-20 at the Hyatt Regency Bellevue on Seattle's Eastside. Our CFP is also open, and we'd love to hear from you. Check out details on what we're looking for and how to submit, here.\nFor more information on these updates and other things we've been working on, just keep reading! And as always, feel free to share your feedback in our Community Slack, or on Twitter (@temporalio).\nNew Cloud Updates\n\n  The default Actions Per Second (APS) limit for all Namespaces has now been raised to 400, up from the earlier 200. Users can track their APS limit directly through the Cloud UI, which also issues alerts if a Namespace experiences throttling within the past 5 minutes. This adjustment simplifies the process for customers migrating their workloads to Temporal Cloud, significantly reducing concerns over throttling.\n  \n  \n\nNotable New Technology Features\nTemporal Schedules are a replacement for traditional Cron jobs for task scheduling which allows a durable way to execute tasks, gain insight into their progress, enable observability of schedules and workflow runs, and let you start, stop, and pause them. In this demo video, we show Temporal Schedules in action.\n\n  Learn how to convert Cron jobs to Schedules through clear examples in this blog post.\n\nSDK Updates\nThe .NET SDK is a full-featured SDK, that provides high performance, good resource utilization, and high-quality type-safe APIs. Check out the GitHub Repo and also see how workflows are written with Temporals new .NET SDK in our on-demand webinar.\nOn Demand Webinar: Hear from ANZ Lead Architect Homeloans Chris Gavin on how the company has used Temporal to automate several key financial services, and their lessons learned.\nUpcoming Meetups & Events\nDevWorld | February 29 - March 1\n\n  Join Temporal for the Ultimate Developer Experience at the Dev World Conference in Amsterdam on February 29 and March 1. Stop by booth C7 at the RAI Amsterdam to say hi to the Temporal team!\n\nVS Live! | March 3-8\n\n  Join Temporal at VS Live! in Las Vegas - we'll be around in the expo hall on March 5th and 6th. This top .NET developer conference will take place at the Paris Las Vegas Hotel & Casino. Find more information and register here.\n\nExplore DDD | March 12-15\n\n  Join Temporal at Explore DDD Conference in Denver. Stop by our booth on March 14th and 15th to say hi, and catch Temporals Principal Curriculum Developer, Tom Wheelers session titled: Building Resilient Distributed Systems Through Event Sourcing. Find more information and register here.\n\nCommunity Favorites\n\n  Temporal Cloud is HIPAA compliant: Read more about this update and our privacy standards.\n  To be or not to be: Read about how anyone can be a Durable Execution Service Provider with Temporal.\n  Technical Guide: Learn how to build more reliable applications using durable execution.\n",featureImage:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},publishDate:"2024-02-23",metaDescription:"Explore Temporals latest developer updates: questions from the field, new releases, builder spotlights, learning resources, and ways to connect with our team.",metaTitle:"Durable Digest: February 2024",socialCard:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},tags:"",slug:"durable-digest-february-2024",contentType:"blogPost",entityId:"4MGawZjQhz7LbVneK3In2s",authors:[{id:"17hGmNrCwtXdBh7fhsLUnZ",name:"Temporal Technologies",slug:"temporal-technologies",photograph:{title:"temporal technologies logo",description:"temporal technologies logo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3g56zRXtFQYMeJxBBkVBIZ/7771670e5fc7da59f555837b086c35d6/temporal_technologies_logo.avif"},company:"Temporal Technologies",contentType:"person"}],authorsString:"Temporal Technologies",category:"Announcements",readingTime:3},{title:"To be or not to be a Durable Execution Service Provider",content:"Consider the term Durable Execution Service Provider.\nThat is what anyone can become thanks to Temporal.\nWhen I say anyone, I mean any team of software engineers willing to take it on, can use Temporal Technologies open source software (collectively called Temporal) to become a Durable Execution Service Provider.\n\n  \n  The image above was generated by an AI tool.\n\nIt is possible that you are a developer with experience building your own Durable Execution Service Provider. Many large companies that operate applications at massive scale have invested lots of money building and maintaining such systems. And there are several well known pieces of technology that have spun out from those efforts.\nAnd so you may be asking, what is different about Temporal Technologies version of such a system?\nThe short answer is that it boils down to the right iteration at the right time.\n\n  \n  The image above was generated by an AI tool.\n\nIn other words, the software engineers who built Temporal have done this before. They applied their knowledge and experience to make a better version than the ones we have seen previously. And they made it open source at a time when many of the other systems were clearly at their limits, creating a flood of early adopters.\nThe longer answer is that, this version (Temporal) is so good that it eventually became obvious that they hadnt just created a production level system that is great for large scale distributed applications, they uncovered a new software development abstraction: Durable Execution.\nDurable Execution is the guarantee that the main function of your application and all the steps defined in it, will effectively execute just once and to completion.\nAnd because Temporal provides that as an abstraction so clearly, this is ultimately what sets it apart from other systems intended to provide a similar experience.\nTemporal Workflow Execution = Durable Execution\nDurable Execution is the generic abstraction that the distributed systems community has been yearning for.\nWorkflow Execution is the same abstraction by a different name which has been baked into the components of Temporal.\nIn the context of Temporal (Temporal Technologiess version of a Distributed Service Provider) the term Durable Execution is more or less synonymous with Workflow Execution.\nIf you dive into Temporal Technologies technical content, you tend to see a lot more about Workflow Executions than Durable Executions. But you can think of a Workflow Execution as Temporal Technologies proprietary name for the Durable Execution abstraction.\nThe market is converging around Durable Execution as the name for this abstraction. This emphasizes the result, rather than the implementation, and also avoids associations with the less effectual Workflow engines from the past.\nEvolution can be a little bit tricky like that. At what point do you stop calling something one thing, and call it something else?\nFor example, at what point does an application become a distributed system?\nNote: that the following diagram is meant to illustrate the evolution of a system - this is not a portrayal of a Durable Execution Service Provider architecture.\n\n  \n  The diagram above was created for this article.\n\nThat is exactly the situation that Temporal Technologies finds itself in.\nOn one hand, the system that is now Temporal evolved from the idea of distributed event-driven workflow engines.\nOn the other hand, it is different enough that a refreshing world of application architecture is being unearthed, offering a new fundamental unit for applications to revolve around; i.e., the Durable Execution.\nSDK + supervisor = Temporal\nSo, how does a Durable Execution Service Provider provide Durable Execution to its customers?\n\n  SDK\n  Supervisor service\n\nIn the case of Temporal, our users are other software engineers who are building applications to serve a specific use case. These could be any number of a wide range of use cases, such as a payment portal, a browser shopping cart and checkout flow, a web crawler, a file processing pipeline, and so on.\nSo, the first thing that Temporal provides is a software development kit (SDK). There is an SDK for many popular languages. In the simplest of terms, SDK packages are added as dependencies to your application project. But really, the SDK is both an API library and a framework for the software engineers to write their business logic in. They can also use the SDK components to run their application on any servers they want.\nThe second thing that Temporal provides is a supervisor service.\nConsider if each and every time the business logic was invoked it executed to completion and there were never any issues, no matter how many times it needed to execute. You might not ever need the supervisor service.\nBut thats not the reality, and hardware components fail at weird times, a network request can time out, a server somewhere along the way could be restarting, and every now and then, that business logic could be in jeopardy of failing to complete. Imagine if a step in the process to charge your credit card failed. Was it charged already? Will you be double charged if something retries? Are refunds built in if the process? Was it not charged at all?\n\n  \n  The diagram above was created for this article.\n\nThe supervisor service is responsible for being the source of truth for those applications, such that if they run into trouble, they can chat with their supervisor to remember exactly where things left off and continue on from there. Because the application is written using the SDK, it strategically communicates with the supervisor and becomes durable in the face of many types of platform level and application level failures.\nEven if both the applications server crashes and the supervisor crashes, whatever the application was processing will resume where it left off once both are back online.\nChoose your supervisor\nIn the case of Temporal, Temporal Technologies went one step further.\nNot only did they build all the publicly available software you need to become a Durable Execution Service Provider yourself (use it for your own applications or offer it as a service to other software teams).\nThey also made a software-as-a-service (SaaS) supervisor which works with any application written using a Temporal SDK: Temporal Cloud.\n\n  \n  The diagram above was created for this article.\n\nOnce you learn some key points about the SDK, it can be relatively easy to get the hang of the development pattern and build a lot of stuff. But the truth is that, running the supervisor can be harder. The supervisor is actually a set of scalable services and databases that needs to be monitored and tuned to ensure the optimal performance of the system.\nTemporal Cloud is run by folks who have many years of experience building and running these types of supervisor systems at a very large scale.\nThis means that you can get started building a durable application completely on your own, free of charge, anywhere you want and run your application anywhere you want.\nAnd then when you need to operate at a large-scale production level, you can choose to self-host the supervisor service or use Temporal Cloud.\nIf you want the Service Level Objectives (SLOs) of Temporal Cloud without the heavy overhead of running your own supervisor, just point your applications at Temporal Cloud.\nNamespace as a service\nWant to become a Durable Execution Service Provider, but dont want to self-host all of the software?\nGreat, Temporal Cloud does that too!\nUsing Temporal Cloud and its associated tools, you can offer Namespaces to software teams inside your organization. A single Temporal Cloud Account empowers you to offer the Durable Execution abstraction as a service to feature teams, infra teams, storage teams, data teams, etc through a Namespace, which provides a level of isolation for Workflow Executions, enabling multi-tenancy for metrics, cost, and more.\nConclusion\nAdopting Temporal, whether that is by self-hosting or via Temporal Cloud enables you to offer your applications a new core abstraction: Durable Execution. Become your own Durable Execution Service Provider using publicly available software or use a SaaS supervisor that makes it even easier to adopt and run your durable applications.\nSkip the part where you build your own Durable Execution provider and jump right into building durable applications.\nGet started today by checking out the Temporal Production deployment docs at docs.temporal.io.",featureImage:{title:"social-card-service-provider",description:"social-card-service-provider",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6ucpftSXVqIL4wcPXvAHZa/8108b0fc0e968c8c664670c9ee02c838/blog-image-to-be-1.png"},publishDate:"2024-02-22T00:00-07:00",metaDescription:"Explore the concept of durable execution and how Temporal enables anyone to become a Durable Execution Service Provider.",metaTitle:"What it means to be a Durable Execution Service Provider",socialCard:{title:"social-card-service-provider",description:"social-card-service-provider",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6ucpftSXVqIL4wcPXvAHZa/8108b0fc0e968c8c664670c9ee02c838/blog-image-to-be-1.png"},tags:"Durable Execution",slug:"to-be-or-not-to-be-a-durable-execution-service-provider",contentType:"blogPost",entityId:"6N17pQY521uMdJqgUm2hdb",authors:[{id:"3OTgMXY0lh84MTxGyif7A5",name:"Cully Wakelin",slug:"cully-wakelin",jobTitle:"SDE Technical Writer",photograph:{title:"cully wakelin",description:"cully wakelin",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4q9VPTjs2cfZSom6Krmmca/c47495568e52f16cb43816d6c3877bc8/34380806"},contentType:"person"}],authorsString:"Cully Wakelin",category:"Temporal Concepts",readingTime:7},{title:"Temporal Cloud is now HIPAA compliant",content:"Temporal Cloud has achieved compliance with HIPAA, the national privacy and security standard for health-related information. Organizations across a wide variety of industries have experienced the benefits of Temporal Cloud since it launched in late 2022 and we can now provide that same experience for Temporal users working in the healthcare space, who can now take advantage of our reliable managed service, while maintaining legal compliance required by the industry.\nTemporal Cloud provides a number of capabilities that support the protection and transmission of sensitive health information and ensure data security. This includes integration with identity management systems and access controls, as well as flexible encryption settings. With the Temporal Data Converter, users can choose default settings to encode data or add custom logic for encoding, ensuring that Payload data passed to or from the Temporal Server will only exist in un-encrypted original format while on hosts that the user controls.\nHIPAA (or the Health Insurance Portability and Accountability Act of 1996) is United States legislation that provides data privacy and security provisions for safeguarding medical information. Compliance with these regulations is mandatory and requires organizations to take a proactive approach in managing and safeguarding protected health information (PHI).\nFor applications that deal with PHI either directly or indirectly, achieving and maintaining HIPAA compliance is mandatory, and now organizations subject to HIPAA regulations can now enjoy the benefits of durable execution with Temporal Cloud.\nIf you have questions or would like to discuss how Temporal Cloud can support faster and more reliable applications at your organization, please reach out to our team to get a conversation started!",featureImage:{title:"social-card-purple",description:"social-card-purple",url:"https://images.ctfassets.net/0uuz8ydxyd9p/UbL8tEOAIBjMrI6OCSeNN/62aecca8ce16e11e288c1fd7ef4e346d/social-card-purple.jpg"},publishDate:"2024-02-05T09:00-07:00",metaDescription:"Temporal Cloud has achieved compliance with HIPAA, the national privacy and security standard for health-related information. ",metaTitle:"Temporal Cloud is now HIPAA compliant",socialCard:{title:"social-card-purple",description:"social-card-purple",url:"https://images.ctfassets.net/0uuz8ydxyd9p/UbL8tEOAIBjMrI6OCSeNN/62aecca8ce16e11e288c1fd7ef4e346d/social-card-purple.jpg"},tags:"Security",slug:"temporal-cloud-is-now-hipaa-compliant",contentType:"blogPost",entityId:"5u24Fa6KGHb0rjPExmfpe0",authors:[{id:"1SCcHs5wmwt6kjoR3qMuGZ",name:"Jim Walker",slug:"jim-walker",jobTitle:"VP of Product Marketing",photograph:{title:"headshot-jim-walker",description:"headshot-jim-walker",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3tZdemozlmoJ8a4leDbfGX/ae3233e372bb29e7d3918b9b0d2c4bfc/Screenshot_2023-10-20_at_2.08.33_PM.png"},contentType:"person"}],authorsString:"Jim Walker",category:"Product News",readingTime:2},{title:"Durable Digest: January 2024",content:"This blog post is a public copy of our monthly newsletter sent on January 26th. If youd like to receive upcoming updates by email, you can subscribe to our newsletter here.\nThis year, we're excited for even more meetups, more conferences, and new technical updates! Thanks to you, our community of developers is ever growing, and we wanted to take a look back at some of the highlights in this 2023 Year in Review blog post as we look forward to an exciting 2024.\nFor more information on updates and other things we've been working on, just keep reading! And as always, we'd love to hear from youfeel free to share feedback in our Community Slack, or on Twitter (@temporalio).\nNew Cloud Updates\nThe Temporal Cloud Operations API is now available as a Public Preview. You can now automate user, namespace, certificate rotation, and account management activities.\nView Ops docs.\nAPI Keys for use in the Cloud Operations API and Temporal Cloud CLI (tcld) are now available as a Public Preview. Global Administrators can opt their organizations into this feature to afford users the ability to generate API Keys for Cloud operations and automation purposes.\nView API Key docs.\nSDK Updates\n\n  PHP 2.7 includes support for Schedules, Workflow Start Delay, and Interceptors, and PHP 2.7.4 includes some performance and memory-usage optimizations.\n  TypeScript 1.9 includes the experimental new Workflow Update feature, and enables reuseV8Context by default, which significantly reduces RAM and CPU usage\n\nWebinar Series: Temporal Cloud: In this series of 5 half-hour webinars, the Temporal technical team will explain how weve built Temporal Cloud to deliver world-class latency, performance, and availability for the smallest and largest workloads.\nUpcoming Meetups & Events\nTemporal @ Chicago JavaScript Meetup Group | Feb 20\n\n  Join us for an evening of technical talks, snacks and drinks, and meet with Bitovi and Temporal users and experts, including Kevin Phillips, Director of Backend Engineering at Bitovi, and Peter Sullivan, Solutions Architect at Temporal. Register here.\n\nTemporal Meetup: Melbourne | Feb 22\n\n  Temporal is co-hosting a meetup with Airwallex in Melbourne. Hear from engineers and product experts with Airwallex and Temporal. Register here.\n\nDevWorld Conference | Feb 29\n\n  Join us and 7,500+ developers at RAI Amsterdam for talks, tracks, and demos involving Javascript, Full Stack, PHP, DevOps & Cloud, AI - ChatGPT, Blockchain and more. Well be at booth C7 - come say hi! Purchase tickets here.\n\nNew Technical Guide: Deep dive into Saga patterns, their challenges, and how Temporal can help automate the process.\n2024 Replay Conference\nReplay 2024 will take place September 18-20th at the Hyatt Regency Bellevue on Seattle's Eastside.\nSuper early bird tickets for Replay 2024 are on sale NOW for only $99 until March 6th. Get your ticket today.\nCommunity Favorites\n\n  Application Reliability on Infrastructure Unreliability: Learn how to build applications on top of unreliable infrastructure.\n  Convert my Cron into a Schedule: Leave traditional Cron jobs behind and learn how to switch them to Temporal Schedules.\n  Very Long Running Workflows: In this guide, learn what to expect when building long-running workflows.\n",featureImage:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},publishDate:"2024-01-26",metaDescription:"Explore Temporals latest developer updates: questions from the field, new releases, builder spotlights, learning resources, and ways to connect with our team.",metaTitle:"Durable Digest: January 2024",socialCard:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},tags:"",slug:"durable-digest-january-2024",contentType:"blogPost",entityId:"2o1uKdmp9eplBEHCMBBc4P",authors:[{id:"17hGmNrCwtXdBh7fhsLUnZ",name:"Temporal Technologies",slug:"temporal-technologies",photograph:{title:"temporal technologies logo",description:"temporal technologies logo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3g56zRXtFQYMeJxBBkVBIZ/7771670e5fc7da59f555837b086c35d6/temporal_technologies_logo.avif"},company:"Temporal Technologies",contentType:"person"}],authorsString:"Temporal Technologies",category:"Announcements",readingTime:3},{title:"Managing very long-running Workflows",content:"Long-Running Workflows\nWhen you hear \"workflow,\" you're likely to imagine processes or state machines: a collection of tasks to accomplish a goal like processing a loan, building out some infrastructure, or ordering some food. These Workflows can take a long time, but they generally have an end. But what if they didn't?\nThere's no rule or even guideline that determines whether a Workflow is long-running or short-running. But, the Workflows we'll talk about here are distinguished by not having a definite end. Workflows in this pattern could run for less than a second or many years and in both cases, depending on the application, be considered \"long-running.\"\nWe often call this pattern \"Entity Workflows.\" This pattern is similar to an Actor Model, where a Workflow Execution represents one occurrence of some kind of entity, like a customer's lifecycle through their purchasing journey, a customer's cart, a product inventory, or a bank account.\nThis guide assumes that you have a basic working knowledge of Temporal, including Workflows, Activities, Signals, and Queries. Reading this guide will help you understand many of the situations and Temporal features you may encounter while building your own long-running Workflows.\nPrerequisite Terminology\nThe following additional terms and concepts will be helpful in understanding the remainder of this guide:\nEntity Workflow\nThough not an SDK primitive or core Temporal concept, we'll use the term \"Entity Workflow\" in this guide to refer to Workflows that are used to represent something (an \"entity\") that potentially lives forever. Examples include customers, an inventory of items, an account, and more. These contrast with Workflows that are used for processes with a definite end, like placing a food order or waiting for a Timer to finish.\nLong-Running\nThere's no rule that determines if a given Workflow is long or short-running. There's no \"if runtime > N seconds\" threshold a Workflow must pass for it to be dubbed long-running; it could run for fractions of a second or many years, depending on your application. Here, we'll define \"long-running\" as Workflows that run for an indefinite amount of timethat is, you dont know in advance when theyll complete. For example, if you have a Workflow that maintains a customers loyalty points, you dont know until the customer decides to close their account that youll be completing the Workflow Execution representing their account.\nEvent and Event History\nTemporal ensures the durability of Workflows by recording the state of a Workflow throughout its life. These state changes are dubbed \"Events\" and the log \"Event History.\" By receiving and \"replaying\" a Workflow's Event History, a Worker is able to resume executing the Workflow at the appropriate place with the appropriate state.\nThe Event History has a hard limit of 50K (51,200) Events or 50MB in total size. To continue a Workflow past these limits, Temporal has Continue-As-New.\nContinue-As-New\nContinue-As-New is a feature allows you to keep a Workflow running but with a new Run ID and a new Event History. Continue-As-New completes the current Workflow instance and atomically starts a new one with the same Workflow ID without having to worry about race conditions from manually closing and restarting a Workflow Execution.\nNote: Some of the Temporal SDK's APIs for Continue-As-New are defined or implemented as some kind of \"error\" (for example, in Go, you would create a NewContinueAsNewError). Despite being named as such, it's not really an \"error,\" in the commonly understood sense. Rather, it's an artifact of how these SDKs handle a Workflow Execution's completion for Continue-As-New versus successful completion.\nAdditional Background on Entity Workflows\nThere are two main types of \"long-running Workflows\" that we'll discuss here:\n\n  Some kind of process that takes a long time (see the definition of \"long-running\" above)\n  A Workflow that represents something (see the definition of \"Entity Workflow\" above)\n\nThe difference is in concept only: both could run quickly or forever, both may need to interact with systems outside the Workflow, and both might do so much work as to require Temporal's Continue-As-New.\nFor example, these two Workflows could have very similar implementations:\n\n  \n\nThe Workflow on the left (A) represents a customer's subscription to a service, with periodic billing. The Workflow on the right (B) represents a server provisioning process. Both start something they must wait for  (A) a time period to pass; (B) a server to finish booting  then send a message to an external system, and then periodically take a related action  (A) charge the customer the subscription fee; (B) enable traffic to the server.\nWhile distinctly different from each other, these two Workflows must both:\n\n  Sleep/wait for a potentially very long time, possibly running Activities concurrently with a Timer\n    \n      (checking if the customer's information has changed, or checking if the server is up yet)\n    \n  \n  Indefinitely repeat an Activity, waiting for some time between invocations\n    \n      (billing the customer; validating server is still up)\n    \n  \n  Canceling that loop based on some external condition\n    \n      (customer has cancelled; server is down)\n    \n  \n\nSimilarly, they both have similar refinements and edge cases. Both also need to:\n\n  Handle Signals or Updates to break the loop and end the Workflow or update internal state\n  Handle Queries to report status to the outside world\n  Track the Workflow Execution's Event History to not exhaust Temporal's limits\n  Make code fixes or updates while there are actively running Workflows\n\nTo simplify, we'll cover these in two categories:\n\n  How to keep a Workflow Execution running indefinitely\n  How to interact with these Workflow Executions\n\nThe last point, applying updates to Workflow code, is covered in a separate guide on Workflow Versioning.\nThis guide also does not cover long-running Activities. For that, consult the documentation on Activity Heartbeats.\nHow to Keep a Workflow Running Indefinitely Long\nThere are two limits in Temporal that keep a single Workflow execution from actually running forever: 50Ki (51,200) Events in the Event History and an Event History size of 50MB. If either limit is reached, the Workflow is Terminated with an error of, \"Workflow history size / count exceeds limit.\"\nThese limits are in place to address how much work a Worker needs to do when it encounters a Workflow it doesn't know anything about. This happens when either the Workflow Execution doesn't exist in cache (either it never was there, or it was evicted) or the Worker crashed and restarted. When a Worker is looking to resume running a Workflow, it needs to replay the prior history to resume at the right point. Let's consider an example.\nImagine we have designed a Workflow to run infinitely long and that this Workflow does a fair amount of work: say, a Workflow that acts as a proxy between a temperature sensor floating in the ocean and the rest of the internet. This Workflow must be able to handle a large number of Signals and Queriesin order to push updates or get the latest data, respectivelyand a large number of Activitiesto actually make the network call to retrieve the real data from the sensor in question.\nEach of these Signals and Activities (among other things, like their inputs and outputs) adds to the Workflow's Event History. Doing so means that, in the scenario where a Worker crashes and subsequently restarts, it can \"replay\" the history to be able to resume from exactly where it left off with exactly the state it previously had.\nReplaying that history takes time. When small, it's usually an acceptable delay. On the opposite end, if the Event History were very large, replaying it to get back to doing real work could take so long as to cause unacceptable delays in a Workflow Execution making forward progress.\nContinue-As-New\nThe situation described above is why Continue-As-New exists. It allows a Workflow to clear its Event History and start anew, but have the same Workflow ID. Continue-As-New is like a stackless recursion: call the same function with different parameters to keep processing data, but without the baggage of a call stack risking a stack overflow.\nThere are a few considerations when incorporating Continue-As-New into your Workflow:\n\n  \n    Since \"continuing as new\" means there's an empty Event History, your Workflow function is starting from a completely clean state. Its inputs and initialization need to be designed such that your implementation can distinguish (or wont need to distinguish) between a continuation of a previous Workflow instance versus a brand-new one.\n    For example, in a monthly billing or subscription Workflow, the pseudocode for handling this might look like this:\n    func BillingSubscription(subscription) -> error:\n\tif subscription.trialExpirationDatetime > workflow.now():\n\t\tworkflow.sleep(subscription.trialExpirationDatetime\n\t\t\t\t- workflow.now())\n\n\twhile not subscription.canceled:\n\t\tworkflow.sleep(subscription.nextBillingCycleDatetime\n\t\t\t\t- workflow.now())\n\t\tChargeCustomer(subscription.customerInfo)\n\n\t\tif workflow.eventHistoryLength > 25K:\n\t\t\treturn workflow.continueAsNew(BillingSubscription, subscription)\n\n\treturn null\n\n    That is, the inputs to the function  in this example, the options within the subscription objectare designed such that it doesn't matter whether it's called for a new subscription or the continuation of an existing one.\n    Note that the exact SDK calls into workflow will differ for each language. For example, the above workflow.continueAsNew call in Go would be\n  \n\n  return workflow.NewContinueAsNewError(ctx, BillingSubscription, subscription)\nwhereas [in Python it would be](https://python.temporal.io/temporalio.workflow.html#continue_as_new)\n\n    workflow.continue_as_new(subscription)\n\n  \n    Because Continue-As-New starts a new run of the current Workflow, you will lose any pending Signals when doing Continue-As-New unless you drain and/or process them first. Because handling Signals also generates Events (see below), you will need to drain any outstanding Signals before calling Continue-As-New: waiting until the Event History length is extremely close to 50K could result in the Events created by handling pending Signals leading to a Workflow Termination. The Temporal Server emits warnings after every 10K Events; if you see those warnings, it's a good time to Continue-As-New.\n    Using the Go SDK, Signal draining might look like this:\n    // Drain signal channel asynchronously to avoid signal loss\nfor {\n\tvar signalVal string\n\tok := signalChan.ReceiveAsync(&signalVal)\n\tif !ok {\n\t\tbreak;\n\t}\n\tworkflow.GetLogger(ctx).Info(\"Received signal!\", \"signal\", signalName, \"value\", signalVal)\n\t// PROCESS SIGNAL\n}\nreturn workflow.NewContinueAsNewError(....)\n    That is, receive and process any and all pending Signals until none are remaining. Since this snippet immediately calls Continue-As-New when there are no more Signals, any future Signals that come in will be handled by the new instance of this Workflow.\n    Its possible for Signals to come in faster than your Signal draining happens because a workflow is not designed to process a high constant rate of signals. In this case if a workflow is not able to call continueAsNew before hitting the max signal limit, new signals will be rejected until continueAsNew is executed.\n  \n  \n    Similarly, because Continue-As-New results in a new execution, any pending Activities are lost and sent a cancellation if they are not awaited. This can happen in cases where your Workflow asynchronously starts Activities, but does not await them or otherwise block on their results. Consider the following Go example:\n  \n\n// error handling removed for brevity\nfunc Workflow(ctx Context) error {\n    _ = workflow.ExecuteActivity(ctx, Activity)\n    return workflow.NewContinueAsNewError(ctx, Workflow)\n}\nIn this example, an Activity is started but the Workflow does not block on its result, instead immediately Continuing-As-New. Besides resulting in an infinite loop of new Workflow Executions, the results of the Activity are never able to be retrieved.\n\nNote that in this example, the Worker only ever gets a single Task from the server; since these Tasks (Workflow Tasks specifically) are what include Events such as ActivityTaskScheduled to inform the Worker to run Activities, the Activity in the above code snippet will never even run, let alone finish. In some cases, depending on what your Workflow does (for example sleeping between ExecuteActivity calls thus yielding to the Temporal Server and allowing new Activity Tasks to be picked up by the Worker) these Activities may still run even though the results are never retrieved.\n\n4. Similarly, since Continue-As-New closes the current Workflow Execution, it affects how Child Workflows behave. By default, all Child Workflows will be terminated when the Parent closes (including with Continue-As-New). To override this  for example, to allow Child Workflows to continue as if nothing happened  set a ParentClosePolicy. This example snippet in Go will allow the Child to continue running after the Parent calls Continue-As-New:\n  cwo := workflow.ChildWorkflowOptions{\n    // ...\n    ParentClosePolicy: enums.PARENT_CLOSE_POLICY_ABANDON,\n  }\n  ctx = workflow.WithChildOptions(ctx, cwo)\n  childWorkflowFuture := workflow.ExecuteChildWorkflow(ctx, ChildWorkflow)\nNote that as a result of this, even though the Child Workflow will continue to run, the direct parent-child relationship is broken. However, since with Continue-As-New there will still be an instance of the Parent, the Child and Parent can still interact with each other via the usual Signal and Query operations (see below for discussion on Run IDs and Workflow IDs),\n\n5. Since Continue-As-New is necessary when a Workflow's Event History risks getting near the limits, deciding when to call Continue-As-New depends on how your Workflow generates Events. Principally (a) how many and how often Events get added to the Event History (e.g., through Activity executions or Timers); and (b) how much data is included with each Event (e.g., what are your Activities returning). Recall that the Temporal Server will terminate your Workflow if its Event History goes beyond 50k Events or 50MB in size.\nNote that in many cases you can determine if you should Continue-as-New by using the `GetContinueAsNewSuggested` method on a Workflow's Info. For example, [`info.GetContinueAsNewSuggested()`](https://pkg.go.dev/go.temporal.io/sdk@v1.25.1/internal#WorkflowInfo.GetContinueAsNewSuggested) in Go, or  [`info.is_continue_as_new_suggested()`](https://python.temporal.io/temporalio.workflow.Info.html#is_continue_as_new_suggested) in Python (similar methods exist in every other SDK as well). This call is only supported with Temporal Server versions starting with version 1.20.\n\nShould you need to estimate for yourself, here are some heuristics for measuring how close your Workflow is to hitting the History limits and, therefore, determining when to call Continue-As-New:\nLength of Event History\n\n  A Workflow with no Activities, Timers, Markers, or other event-generating operations will generate five events: one for Workflow started, one for completed, and three for a single Workflow task being scheduled, started, and completed.\n  A Workflow with only a single Activity execution will generate an Event History of length 11. The Activity itself results in three Events (Activity Scheduled, Started, and Completed), there are Workflow Tasks before and after the Activity which result in six Events (Workflow Scheduled, Started, and Completed), and every Workflow has a WorkflowExecutionStarted and WorkflowExecutionCompleted at the beginning and end respectively.\n  A Workflow with a single Activity in a loop will generate an Event History of length 5 + 6 * i (where i is the number of loop iterations). That is, each Activity effectively results in six Events.\n  A Workflow with a single Timer and nothing else (e.g., only a workflow.Sleep or workflow.Timer) will generate 10 events. Timers themselves generate two Events, TimerStarted and TimerFired. When the Workflow waits for the time to expire, it yields back to the Server, generating three more Events for the subsequent Workflow Task after the timer fires in addition to the three Events corresponding to the Workflow Task that started the Timer.\n  A Signal itself only generates a single Event and in normal situations, it also generates a Workflow Task for it to be handled. However, whether there are Workflow Tasks associated with it depends on the nature of the Signal. Consider a Workflow that starts and then immediately blocks waiting for a Signal (and then completes successfully once a Signal is received). There are two scenarios in which this Workflow could run:\n    \n      Signal-With-Start will include the Signal information as part of the Workflow's starting and will trigger the signal handler immediately. The result is a Workflow with 6 Events.\n      If the Workflow progresses as far as it can (therefore allowing the Worker to move on to other Workflows or just waiting for more Tasks), for example by blocking on waiting for incoming Signals, then for the Signal to be handled a new Workflow Task needs to be issued to the Worker, resulting in three additional Events. This Workflow  one that does nothing but blocks until a single Signal is received  completes with 9 Events.\n    \n  \n\nSize of Event History\n\n  The primary determinate factor for Event History size is your Activities' parameters and returns and a Signal or Update's input arguments. All inputs and returns of Activities are recorded in the Event History. For example, if you have an Activity that takes no parameters but returns 500KB of data (measured in its serialized form), you'll be able to run well under 100 of these Activities, as the history size limit is 50MB. (Since there are other Events and metadata on Events that contribute to the History size, you won't be able to run exactly 100 of them.)\n  If your Workflow's Activities need to be able to take in or return a lot of data (defined as more than 1-2MB), consider either compressing via a Data Converter or storing the actual data in a blob store like AWS S3 and instead passing the URL of the uploaded blob.\n    \n      For performance-sensitive applications, it may also be worth caching data on Worker hosts and routing Activities that need to use the data to the same host.\n    \n  \n\n\n  \n    Since Temporal only allows one actively running (\"Open\") Workflow instance per Workflow ID the Run ID exists to distinguish between invocations. One of the things Continue-As-New does for you is to atomically create a new run of the same Workflow ID. (If you did this on your own, without Continue-As-New  that is, complete the Workflow and then start another  there would be a time gap between the two runs, thereby risking Signal loss.)\n    The side effect of this is to consider how you interact with this Workflow. Signals and Queries, for example, need to be able to identify a specific instance of the Workflow. The default behavior for the Temporal SDKs is that when a Run ID is not given, the currently running (or most recent, in the case of Queries) instance is used.\n    As an example, consider the function signature for the Go SDK's client.SignalWorkflow:\n  \n\nSignalWorkflow(ctx context.Context, workflowID string, runID string, signalName string, arg interface{}) error\nWith `runID` as a \"required\" parameter, it may be tempting to conclude that you need to retrieve and specify a Run ID for every Signal sent. And if that's the case, why not cache that Run ID to avoid the query time cost for updating it? (In fact, Run IDs aren't deterministic and so you should never cache them.)\n\nAs per the above, the problem with this is that Continue-As-New closes the current Workflow Execution and starts a new one with a new Run IDand, signaling a closed Workflow results in a \"workflow execution already completed\" error.\n\nInstead, SignalWorkflow allows an empty Run ID. In this case, the Workflow Signaled will be the currently open execution of the given Workflow ID.\n\nThe other SDKs have similar behavior. For example, in Python, if you call a method like `signal` or `describe` on a [Workflow Handle](https://python.temporal.io/temporalio.client.WorkflowHandle.html) that doesnt have a Run ID, it will go to the most recent Run.\n\nHow to Interact with Indefinitely Long-Running Workflows\nAside from the above considerations for Continue-As-New, interacting with a long-running Workflow is not meaningfully different from interacting with any other Temporal Workflow. That said, here are a few things to keep in mind when interacting with such Workflows:\n\n  \n    Signals are your way to get application-specific data into a Workflow. Signals can update Workflow state and so,\n    \n      They can reliably alter the Workflow's behavior as necessary (e.g., to update the credit card information for a monthly billing subscription).\n      They can start Activity executions (e.g., in a sensor proxy use case, to call out to the sensor to update its data collection rates).\n      They can only be sent to Open (running) Workflows. See above for discussion on Run IDs vs Workflow IDs. (An alternative to Signal is Signal-With-Start, which will start a Workflow if its not already running.)\n    \n    Note that Signals in rare cases may be duplicated. Though unlikely, if having a repeat Signal is a problem for your application, be sure to make your Signal handler idempotent (e.g., through the use of idempotency keys).\n    You can read more about Signals and learn how to use them in our Documentation.\n  \n  \n    \n      Queries are the opposite of Signals: they allow you to get application-specific data _from _a Workflow. They do not modify Workflow state and do not get added to the Event History. As such,\n      4. They will return the current state within the Workflow. While this can be any application-specific information, it cannot result in a change in state.\n      5. They will return that state even if the Workflow is Closed.\n    \n    You can read more about Queries and learn how to use them in our Documentation.\n  \n  \n    \n      Updates are a way to combine a Signal (sending data into a Workflow) and a blocking Query (waiting for data to come back from a Workflow) into a single operation. Updates can both update Workflow state and receive data back, and so,\n      6. They can be validated before being handled. This allows you to determine if an Update request is valid (e.g., deny the Update request if it wants to change the Workflow into an erroneous state).\n      7. They can run handler code, similar to a Signal. And, just like a Signal or any other Workflow code, the Update handler must be deterministic, but can otherwise start Activities, run Child Workflows, or use any other Workflow features.\n    \n    You can read more about Updates and learn how to use them in our Documentation.\n  \n\nConclusion\nThis guide outlined the primary considerations when designing Temporal Workflows to run for an indefinitely long time. Temporal allows you to create Workflows that can trivially last a long time  a Workflow sleeping and then waking up once a year to increment a counter will reliably run. But to get a Workflow that can truly run forever while accomplishing \"real work\"  as in examples like monthly billing subscriptions or sensor proxies  requires a bit of extra consideration. Principally:\n\n  To avoid having your Workers stuck in an endless process of reading and Replaying long Event Histories, you'll need to \"Continue-As-New\" these Workflows to reset the Event History. Note that this not only applies to long-running Workflows, but also to Workflows containing many Activities or Activities with large inputs and returns.\n  Interacting with such Workflows from outside the Workflow is really no different from interacting with other Workflows, except for how you identify them: Continue-As-New creates a new Run ID for the Workflow instance. This means that when you use APIs like Signal and Query that optionally take a Run ID, you need to take care to either not specify the Run ID (thus automatically using the latest run) or otherwise ensure that you're using the correct one.\n\nWhile the practices described in this guide apply generally to long-running Workflows, they're particularly well suited for applications implementing patterns like the Actor Model: Workflow instances that represent an \"Actor\" or \"Entity\" will typically need to run for a very long time and handle an innumerable amount of incoming messages.\nSee Also\n\n  Programming Model Limits\n  Actors and Workflows, Part 1\n  Actors and Workflows, Part 2\n  Signals\n  Queries\n  Updates\n",featureImage:{title:"yue-ma-KtEx7LYscXM-unsplash",description:"yue-ma-KtEx7LYscXM-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/66R2v0sappsE9EIPfGDbH5/8afe080b10586bbcecfdd9661de115bf/yue-ma-KtEx7LYscXM-unsplash.avif"},publishDate:"2024-01-25T00:00-07:00",metaDescription:"Discover how Temporal supports long-running workflows, enabling reliable execution of complex processes like infrastructure automation and loan processing.",metaTitle:"Managing very long-running Workflows with Temporal",tags:"Architecture",slug:"very-long-running-workflows",contentType:"blogPost",entityId:"3OOuiwHgPyveQt0FN7Jaem",authors:[{id:"1V2nWXuO9AHzYzI4qmqAJ5",name:"Fitz",slug:"fitz",jobTitle:"Developer Advocate",photograph:{title:"Fitz",description:"Fitz",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5rtdEzcJFPLV5Ce29uPyFb/951227c4a68cb13b1bd03c8856b1f740/fitzface_shadowed_blue-2.jpg"},contentType:"person"}],authorsString:"Fitz",category:"How-To",readingTime:20},{title:"Building application reliability on top of infrastructure unreliability",content:"What do you do when you know, with absolute certainty, that the infrastructure you're running something on is unreliable? Hardware always fails eventually, networks go down, or software needs to be patched.\nEven under perfectly ordinary operation, your runtime environment could drop out from under the running process: traffic drops, causing the autoscaler to downscale and, unless you've tied into the termination lifecycle, the process is forcibly killed. But whether purposeful or not, it's a computing fact that processes can abruptly end and be restarted.\nFor many kinds of services, that's perfectly acceptable; give the process a chance to drain outstanding requests, and then new requests will land on other nodes. Or, if that process unexpectedly dies or is forcibly ended, the client can retry and have its request handled elsewhere.\nPut another way, things can be made \"effectively reliable\" from an infrastructure perspective: for example, Kubernetes helps ensure that nodes and processes exist to run application code, and Istio improves network reliability and performance. Things still fail, but we can make it tolerable with well-known tools.\nBut perhaps a more important question is: what's actually being run? As in, what is the full application trying to accomplish?\nAn Example Application\nBuilding something from the bottom up is a natural way to go; assume that things will fail (always a safe assumption), and design the system from there. But this makes it hard to build and keep track of a multi-step application, like an e-commerce store. Let's take a look.\nConsider how this application might look from the customer's perspective. It's a relatively short series of steps:\n\n  Add item to cart\n  Input payment\n  Input shipping address\n  Confirm and checkout\n  Track order\n  Receive item\n\nSoftware engineering over the past couple of decades has taught us that nothing is simple. Namely, because we've made our infrastructures effectively reliable through tools like Kubernetes and patterns like stateless services, a \"simple\" workflow like the above ends up being composed of dozens of microservices (or more).\n\n  \n  Caption: A hypothetical but realistic microservices connection graph for placing an e-commerce order.\n\nThat's not all, though, because behind and in between these microservices also ends up being a complex mix of databases, caches, event streams, and message queues. While these services all have unique functions, they're all dealing with the same orders, and hopefully each order's details and status are appropriately picked up by the appropriate next service.\nThus, tracing a single order through this dizzying system becomes a daunting or even impossible task. While this is necessary for tasks like ensuring orders aren't dropped, providing customer service, or auditing for regulatory compliance, it's also important to answer a more fundamental question: How reliable is our application?\nApplications Need Reliability Too\nAt some point, that question will come up. And I'm sure you've had the experience of trying to calculate some kind of overall reliability number, only to find that a single number like 99.99% doesn't adequately represent the full story of the application.\nLet's take a look at a simplified example.\n\n  Suppose you have a two-step process, with each step handled by separate microservices. For the sake of example, let's say the process is painting a bike shed, and the two steps are (1) choose and reserve a paint color and (2) apply paint to the shed. Step 2 cannot happen without Step 1 occurring first. But if we have two sheds, the microservices pattern allows the application to handle the two sheds independently from each other: Step 1 could be working on picking a paint color for Shed B without affecting Step 2's painting of Shed A.\n  \n  \n\nReasoning about the reliability of this application is really asking: What is the likelihood of a given shed successfully making it through both steps?\nFor a serial system like this, the success probability is calculated as the product of the success probabilities for each individual step. So, if Step 1 has a 98% chance of success and Step 2 has a 99% chance, the overall probability of success (i.e., the \"reliability\" of the application) would be 0.99 * 0.98 = 0.9702, or ~97%.\nYou might note that this is actually worse than \"the weakest link.\" You can think of the product here as a logical and: both microservices must succeed in order for an overall success to occur. Even though we have a 98% chance of successfully painting the shed, the overall process could still fail if the committee deadlocks on making a decision in Step 1.\nAside: This then effectively proves what most of us intuitively know to be true. If you add more components to a system, its overall reliability goes down, even if each individual component has a success probability of \"five nines.\" Said system would have an overall chance of success of .99999 ^ n, where n is the number of services (assuming they're in serial). Meaning, just adding a third service to our example (say, splitting out choosing the paint color versus procuring the actual paint) reduces the chance of success to four nines, about .99997 or the equivalent of one failure out of every 33,333. 1\n\n  You can make the story a little bit better by adding redundancy to each step.\n  \n  \n\nEven if the backup services are wildly unreliable, it still improves the overall reliability, which is calculated as:\nReliability of step 1 (R1) = 1 - (1 - .99) * (1 - .5) = 0.995\nReliability of step 2 (R2) = 1 - (1 - .98) * (1 - .6) = 0.992\nOverall reliability = R1 * R2 = .98704\n\nThat 98.7% chance of success is certainly better than our 97% chance from earlier, but it does come with the extra operational cost of running secondary services.\nWhy is this important?\n\n  Part of the reason for splitting things out into microservices in the first place is to allow Step 1 to process as many requests as it can independently of Step 2 and vice-versa. To scale this, you might replicate each service as many times as needed, such that you have N instances of Step 1's service, and M instances of Step 2's.\n  \n  \n\nWhile this improves our overall reliability number, we've introduced a new complication.\nWhen the application was just two services wired in serial, once Step 1 was finished it could directly notify Step 2 and then move on to the next incoming request. Each service could maintain its own queue of requests (with possible persistence) and very little other coordination would be needed.\nUnfortunately, that pesky little parenthetical tucked in there is the culprit of our complications. The \"possible persistence\" of a request queue is helpful if you want to not lose requests in the face of, e.g., process restarts. But, it's absolutely required once you scale out beyond n = 1 instances of the service so that each request can be handled effectively once.\n\n  For short-lived requests, this could be handled by some kind of load balancer in front of each step:\n  \n  \n\nThe load balancers act as the request queues, divvying requests out to workers as appropriate.\nThe side effect is that we've now doubled the number of components in the system. Load balancers can fail just like any other service, and so the system reliability becomes\nR LB1 * R 1 * R LB2 * R 2\nAs discussed in the aside earlier, if all four of these services have a five-nines (99.999%) chance of successfully processing a given request, then the overall reliability is .999994 = 0.99996 or an equivalence of one out of every 25,000 requests failing. That may not seem too bad, but without those load balancers, the success rate would have been .999992 = .99998 or a failure rate of one per 50,000. Doubling the number of services in the sequence also doubled our failure rate.\n\n  So, naturally, let's remove one of the load balancers and instead put a cache, database, or message queue in between:\n  \n  \n\nThis intermediate queue provides a central place for keeping track of where your various sheds are in their painting lifecycles. That lifecycle is still somewhat disjointed though, and your components (Steps 1 and 2 and the Queue) are still very much wired in serial in a way that one outage affects an untold number of shedswhich ones and how is anyone's guess.\nAnswering the Bigger Questions\nThis brings us, finally, back to the original question, \"How reliable is the application?\" The previous section described how to calculate the reliability of an overall system. Being able to say that the combined success rate of all services in the system is X% sort of answers the application-reliability question, but only does so from a fairly conceptual level.\nMore specifically, while it tells you how often any one random request will fail, it doesn't answer questions like \"Where is this request?\" or \"Where did this request fail?\" or \"Is this request going to eventually unstick itself or does a human need to step in?\"\nThat is to say, if you're looking at the aforementioned collection of microservices in an e-commerce system and wondering where a particular order is in its lifecycle (footnote: because, for example, you're building a frontend for customer service agents), well.... good luck.\nBuilding Reliable Applications With Temporal\n\n  Having a single number representing the reliability of a system isn't nearly as important as understanding what to do when unexpected things happen (as they always will). And, seeing all green across a status dashboard feels delightful.\n  \n  \n\nSuppose one of your services is backed by a load-balanced cluster of nodes. What's the impact on customer experience if a misconfiguration in your autoscaler causes a repeated up-then-down scaling?\n\n  \n\nSure, it's a problem worth investigating, but with Temporal you don't have to worry too much about the end-user impact: each user request could match to a Temporal Workflow, which is automatically resumed on another process where it left off if something interrupts the original process its running on.\nSo for example, consider a simplified user flow through your system that looks like:\n\n  Check fraud\n  Validate inventory\n  Process payment\n  Dispatch / Ship\n\nIf each of these is a separate microservice, and one of them is having infrastructure problems, you might be tempted to declare, \"Oh no! This whole application is unreliable now!\" After all, we saw earlier in this post that the weakest link in the chain tanks your overall reliability numbers.\nWith Temporal, instead of coming in with the assumption that each individual service needs to be made as reliable as possible, we take it a level higher. What if we assumed that dependent services will always fail, and we instead work to make the application reliable?\n\n  \n  Caption: Four graphs of a demo Temporal application. Top left: the number of active Kubernetes replicas for the Worker fleet; randomly re-sized between 0 and 10. Top right: Workflow successes per second for this application. Bottom left and right: Workflow timeouts and failures, respectively, both flat at zero.\n\nIn these example graphs, depicting a demo Workflow running a simulated load (upper right graph), the Kubernetes cluster (upper left) responsible for actually running the Workflow (as in, the Worker fleet) is concurrently being randomly scaled up or down. This random scaling is to simulate unreliable infrastructure.\nMeasuring the uptime of this application from the infrastructure perspective  for example, how often are there no Workers available  leads to a pretty bleak number. Roughly calculated, the graph above represents an hour-long window. For a total of eight minutes during that hour, the cluster had no replicas available. 52 / 60 * 100 = 86.666% uptime, or in other words: zero nines.\nBut, take a closer look at the other graphs. While the rate of Workflow successes dipped to zero during the infrastructure downtime, they did still continue to succeed: Workflow timeouts and Workflow failures remained flat at zero.\nWith a Workflow as the thing we're measuring the reliability of, the calculation of reliability over the hour looks much nicer:\n\tsum(timeouts_per_second) (T) = 0\n\tsum(failures_per_second) (F) = 0\n\tsum(successes_per_second) (S) = 685\n\n\tApplication reliability = 1 - (T + F) / S = 1 = 100%\n\nThat is to say, even with much worse reliability than you'd like, Temporal gives you better overall application reliability.\nSummary\nPerhaps obviously, the example used here is contrived, but it's not that far from reality with Temporal. Microservices and external dependencies will always fail at some point. Working to make them as reliable as possible is necessary and important work, but no service will ever truly hit 100% reliability over a sufficiently long period of time.\nTo mitigate that, consider why services exist in the first place: to provide a, well, servicea self-contained piece of functionalityto a bigger application. When you take a step back and consider the reliability of the bigger picture, rather than service-by-service, your whole application can be reliable while underlying services are inconsistent.\nFor more on Temporal, head over to our documentation and courses:\n\n  https://docs.temporal.io\n  https://learn.temporal.io\n\n\n\n  Footnotes\n  \n    \n      Which, to be fair, is still a heck of a lot of successfully painted sheds. \n    \n  \n",featureImage:{title:"social-card-machine",description:"social-card-machine",url:"https://images.ctfassets.net/0uuz8ydxyd9p/ixYNBwZoX1wu8VwLSDFmS/35e58aea31546f1b0dc42311f8f1de98/social-card-machine.jpg"},publishDate:"2024-01-12T00:00-07:00",metaDescription:"What do you do when you know, with absolute certainty, that the infrastructure you're running something on is unreliable? Hardware always fails eventually, networks go down, or software needs to be patched.",metaTitle:"Building application reliability on top of infrastructure unreliability",socialCard:{title:"social-card-machine",description:"social-card-machine",url:"https://images.ctfassets.net/0uuz8ydxyd9p/ixYNBwZoX1wu8VwLSDFmS/35e58aea31546f1b0dc42311f8f1de98/social-card-machine.jpg"},tags:"Industry Events",slug:"building-application-reliability-on-top-of-infrastructure-unreliability",contentType:"blogPost",entityId:"4z6WrsBLY38fBGZSaasb8X",authors:[{id:"1V2nWXuO9AHzYzI4qmqAJ5",name:"Fitz",slug:"fitz",jobTitle:"Developer Advocate",photograph:{title:"Fitz",description:"Fitz",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5rtdEzcJFPLV5Ce29uPyFb/951227c4a68cb13b1bd03c8856b1f740/fitzface_shadowed_blue-2.jpg"},contentType:"person"}],authorsString:"Fitz",category:"How-To",readingTime:12},{title:"Temporal: 2023 year in review",content:"At Temporal, we fundamentally believe that Durable Execution will improve the developer experience for everyone and as we look back on 2023, we feel we made some headway on making this a reality. It was a big year for us, but more importantly for our customers and community, and we are delighted that you have been on this road with us.\nLet's take a look back at 2023\nOur raison detre  the Temporal community and customers\nTemporal is an open-source company and active member of the open-source community. Since our inception, our Github repo has maintained steady growth, and today has collected over 8.8k stars. Over the last year, we also saw our community Slack workspace grow to over 10,000 members. And all the while, Max, our co-founder as well as many of our key engineers remain active and helpful in this important channel.\n\n  \n\nWe spent a lot of our time out on the road last year, and we were humbled by the excitement and engagement thousands of you gave us at meetups around the world. This last year we got together at meetups in New York, Singapore, Tel Aviv, San Francisco, Melbourne, Chicago, Dallas, Bengaluru, Mumbai, Hyderabad, Sydney, Seattle, Raleigh, London, and Paris, and we look forward to spending time with you in more places next year  stay tuned.\n\n  \n\nLike many of you, we too, are building a company and also celebrate some of our commercial success. So many of you trust us to run mission-critical workloads on Temporal Cloud. In fact, last year, we welcomed over 800 new customers and deployed thousands of namespaces. We are thankful to our team that worked nights and weekends to provide this rock-solid service, but more importantly we appreciate ALL of our customers large and small.\nThis was also the year we launched a Startups program (which provides $2400 in free cloud credits) and we've had over 100 of you join the program. Also, our Temporal Partner Ecosystem rolled out in 2023 and our partners have already delivered services to help users successfully navigate getting their Temporal apps to prod.\nA new primitive, so many features and SDKs!\nThe Temporal project has come a long way and we continue to innovate in and around it so that it is more approachable and applicable. Whether this means adding new features to the core project, making improvements to our managed service or delivering wholly new SDKs, we've been pretty busy.\nWe worked a lot on the core capabilities of Temporal, but three key highlights include:\n\n  Workflow Update is our first new primitive that combined two previous operations (signals and queries) into a single synchronous blocking call. This feature allows users to drastically simplify their Temporal logic for updating ongoing workflows.\n  Temporal Schedules are a replacement for traditional Cron jobs for task scheduling. Schedules allow users to durably execute tasks, get insight and visibility into their progress, and start, stop and pause them arbitrarily!\n  The timeline view is one of the most well-loved features we shipped this year. Users rave about how easy this view makes it to understand and visualize workflows from start to finish, whether youre running your own cluster or using the Temporal Cloud service!\n\nWe learned a whole lot about running the Temporal service in 2023 as we onboarded thousands of namespaces on Temporal Cloud, and we are blown away by the positive feedback and constructive input you all have provided. The offering has matured a lot and some of the highlights from the last year are:\n\n  New Regions - We added three new available regions for Temporal Cloud (sa-east-1, ap-south-1, and us-east-2) to bring the total to 12 regions around the world.\n  Enhanced automation capabilities - We streamlined Temporal Cloud for power users with the introduction of our Cloud Operations API which allows you to automate management of Users, Namespaces, and Accounts. We also added support for secure programmatic access to Temporal Cloud through API Key Authentication.\n\nFinally, in 2023 we also added two fully supported SDKs to bring our total to six. Back in the spring we added Python and more recently we added the .NET SDK. While these major milestones are important, there was also a massive amount of work put into making all our SDKs more feature complete. If you want to get started building with any of our SDKs, head to our dev guide in docs.\nYou can find a full list of the features and launches in our changelog.\nReplay Replay 2023\n2023 also saw the second installation of our Replay Conference, our flagship event in Seattle. This year we tripled the number of talks and nearly doubled the amount of attendees. It was an exciting, fun-filled three days and we were delighted that so many of you joined us, and are thankful for all our speakers who joined us from a wide range of companies, including: AfterPay, AirWallex, Autokitteh, AWS, Better, Bitovi, Bright Machines, Cosmonic, Datadog, Grab, Hashicorp, Hasura, Instacart, JP Morgan Chase, Linus Health, Logikcull, Logixboard, Maersk, Microsoft, MongoDB, Netflix, Retool, Rippling, SoFi, Stripe, Turo, Twilio, Will Bank and Yum Brands WOW!\nYou can \"replay\" all the talks on our Replay site right now if you like. A few highlight talks include:\n\n  Distilling Durable Execution - In this keynote, Temporal founder and CEO, Maxim Fateev provided a clear and easy to understand explanation of Durable Execution and how to think about using Temporal.\n  Temporal: A year later - In this followup to the 2022 event, Mat McDole from Yum Brands! (Taco Bell, KFC, Pizza Hut, Habit Burger) walked through how they've now rethought their ecommerce order system on Temporal. This talk is FULL of great advice.\n  From Monolith to Workflows - Sai Pragna Etikyala from Twilio walked through how the messaging team is breaking down their monolith and reworking it into Temporal workflows.\n  Deploying SaaS using Temporal - Chris Ludden and Anthony Davis from the Hashicorp team demonstrated their code generation approach that allows internal users to be more productive.\n  DAGs on Temporal? - Roberto Fernandez discussed the patterns Retool is using to improve the performance of executing DAGs of code blocks for their users.\n  Managing Kafka - Patroklos Stefanou walked us through Stripes experience using Temporal for managing Kafka Clusters, including a great use of signals.\n\n\n  The product keynote also provided amazing demos of some of the features we mentioned above and is super valuable. If you're interested in the 2024 event, super early bird registration is open now ;)\n  \n  \n\nA more approachable Temporal\n2023 was also the year we invested heavily in training, support, and content to help developers learn Temporal with more ease, and we think we did alright! Here are some content highlights that you might find helpful:\n\n  We released Temporal 101 and Temporal 102 courses in four different programming languages, making it possible to get started with Temporal in hours, rather than weeks and saw over 6000 course enrollments.\n  Our most viewed webinar was \"What is a Saga\".\n  Our most visited blog was \"Introducing Temporal .NET\".\n  We published a hefty 815 changes to our Documentation.\n  Our Developer Success team delivered over 500 sessions right from onboarding to code/design reviews and worker tuning.\n\nAnd in case you missed it, we completely revamped our website to improve how viewers can think about and explain Temporal.\n\n  \n\nWe ended 2023 with a bang seamlessly supporting our customers through their busiest and most critical periods over Black Friday and New Years Eve, and received this kind shoutout from The Pragmatic Engineer.\n\n  \n\nSneak peek into 2024\n2024 is already shaping up to be a great year and our team is excited to deliver on some of the key product investments we made over the last year. Stay tuned for upcoming launches of new capabilities such as multi-region availability, self-serve signup and Google Cloud Platform options for Temporal Cloud, as well as some secret project work around the simplification of workers, cross-namespace communications and maybe a new SDK.\nThanks again for joining us in 2023 and we look forward to a great 2024 with you all. To keep up to date on news and events, please join our community on Slack and register to receive our monthly newsletter.",featureImage:{title:"blog post replay",description:"blog post replay",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1cVP7MLfyQAJcjtPgaLT1e/cecdbd6c74b1d1b71e6535a6a99e5d4e/blog_post_replay.png"},publishDate:"2024-01-11T09:00-07:00",metaDescription:"2023 was a big year for Temporal, but more importantly for our customers and community. Let's look back on the year with Durable execution",metaTitle:"Temporal: 2023 year in review",socialCard:{title:"blog post replay",description:"blog post replay",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1cVP7MLfyQAJcjtPgaLT1e/cecdbd6c74b1d1b71e6535a6a99e5d4e/blog_post_replay.png"},tags:"Industry Events",slug:"temporal-2023-year-in-review",contentType:"blogPost",entityId:"5dbaP7rtCOV0ptRgdhbuyT",authors:[{id:"1SCcHs5wmwt6kjoR3qMuGZ",name:"Jim Walker",slug:"jim-walker",jobTitle:"VP of Product Marketing",photograph:{title:"headshot-jim-walker",description:"headshot-jim-walker",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3tZdemozlmoJ8a4leDbfGX/ae3233e372bb29e7d3918b9b0d2c4bfc/Screenshot_2023-10-20_at_2.08.33_PM.png"},contentType:"person"}],authorsString:"Jim Walker",category:"Community",readingTime:8},{title:"How do I convert my Cron into a Schedule?",content:"Overview\nTemporal Schedules are a replacement for traditional cron jobs for task scheduling because this Schedules provide a more durable way to execute tasks, allow insight into their progress, enable observability of schedules and workflow runs, and let you start, stop, and pause them.\nNow that Temporal Schedules are GA, its time to convert those cron jobs into Schedules. In this article we will step through the process and show some examples.\nBy converting to Schedules, you can immediately take advantage of the benefits which include:\n\n  Enhanced workflow control and visibility\n  Flexible and extensible scheduling\n  Elimination of external dependencies\n\nFor more information about Schedules, check out this blog post.\nConverting to Schedules\n\n  Thankfully the process of converting to Schedules is very simple. The Temporal SDKs provide new primitives for Schedule CRUD operations. In addition to the SDKs, the CLI and UI are also able to perform Schedule CRUD operations.\n  First, setup and test your new Temporal Schedule using the interface of your choice. Then once your Schedule is working and you are comfortable, turn off your old cron job. That is it!\n\nFor more information, you can refer to the Temporal documentation.\nTypescript Example\nimport { Connection, Client } from '@temporalio/client';\nimport { temporalCommunityWorkflow } from './workflows';\n\nasync function run() {\n  const client = new Client({\n    connection: await Connection.connect(),\n  });\n\n  // https://typescript.temporal.io/api/classes/client.ScheduleClient#create\n  await client.schedule.create({\n    action: {\n      type: 'startWorkflow',\n      workflowType: temporalCommunityWorkflow,\n      workflowId: \"temporal-community-workflow\",\n      taskQueue: 'schedules-task-queue',\n    },\n    scheduleId: 'top-stories-every-mon-at-noon',\n    spec: {\n      cronExpressions: ['0 12 * * MON'],\n    },\n  });\n\n  await client.connection.close();\n}\n\nrun().catch((err) => {\n  console.error(err);\n  process.exit(1);\n});\nSee also the Schedules sample application.\nGo Example\nDev guide  Go  Features  Schedules\npackage main\n\nimport (\n\t\"context\"\n\t\"log\"\n\n\t\"example.com/myworkflows\"\n\t\"go.temporal.io/sdk/client\"\n)\n\nfunc main() {\n\tctx := context.Background()\n\t// The client is a heavyweight object that should be created once per process.\n\tc, err := client.Dial(client.Options{\n\t\tHostPort: client.DefaultHostPort,\n\t})\n\tif err != nil {\n\t\tlog.Fatalln(\"Unable to create client\", err)\n\t}\n\tdefer c.Close()\n\n\t_, err := c.ScheduleClient().Create(ctx, client.ScheduleOptions{\n\t\tID: \"top-stories-every-mon-at-noon\",\n\t\tSpec: client.ScheduleSpec{\n\t\t\tCronExpressions: []string{\"0 12 * * MON\"},\n\t\t},\n\t\tAction: &client.ScheduleWorkflowAction{\n\t\t\tID:        \"temporal-community-workflow\",\n\t\t\tTaskQueue: \"schedules-task-queue\",\n\t\t\tWorkflow:  myworkflows.SampleScheduleWorkflow,\n\t\t},\n\t})\n\tif err != nil {\n\t\tlog.Fatalln(\"Unable to create schedule\", err)\n\t}\n}\nJava Example\nDev guide  Java  Features  Schedules\npackage io.temporal.samples.hello;\n\nimport io.temporal.client.WorkflowOptions;\nimport io.temporal.client.schedules.*;\nimport io.temporal.serviceclient.WorkflowServiceStubs;\nimport io.temporal.serviceclient.WorkflowServiceStubsOptions;\nimport java.util.Collections;\n\npublic class HelloSchedules {\n  public static void main(String[] args) {\n    // Get a Workflow service stub.\n    WorkflowServiceStubs service = WorkflowServiceStubs.newServiceStubs(WorkflowServiceStubsOptions.newBuilder().setTarget(\"localhost:7233\").build());\n\n    /*\n     * Get a Schedule client which can be used to interact with schedule.\n     */\n    ScheduleClient scheduleClient = ScheduleClient.newInstance(service);\n\n    /*\n     * Create the workflow options for our schedule.\n     * Note: Not all workflow options are supported for schedules.\n     */\n    WorkflowOptions workflowOptions =\n        WorkflowOptions.newBuilder().setWorkflowId(\"temporal-community-workflow\").setTaskQueue(\"schedules-task-queue\").build();\n\n    /*\n     * Create the action that will be run when the schedule is triggered.\n     */\n    ScheduleActionStartWorkflow action =\n        ScheduleActionStartWorkflow.newBuilder()\n            .setWorkflowType(HelloActivity.GreetingWorkflow.class)\n            .setOptions(workflowOptions)\n            .build();\n\n    // Define the schedule spec\n    ScheduleSpec spec = ScheduleSpec.newBuilder().setCronExpressions(Collections.singletonList(\"0 12 * * MON\")).build();\n\n    // Define the schedule we want to create\n    Schedule schedule =\n        Schedule.newBuilder().setAction(action).setSpec(spec).build();\n\n    // Create a schedule on the server\n     scheduleClient.createSchedule(\"top-stories-every-mon-at-noon\", schedule, ScheduleOptions.newBuilder().build());  }\n}\n.NET Example\nusing Temporalio.Client;\nusing Temporalio.Client.Schedules;\nusing MyWorkflows;;\n\n// Create a client to localhost on default namespace\nvar client = await TemporalClient.ConnectAsync(new(\"localhost:7233\"));\n\nvar action = ScheduleActionStartWorkflow.Create\u003CMyWorkflow>(\n    wf => wf.RunAsync(),\n    new()\n    {\n        Id = \"temporal-community-workflow\",\n        TaskQueue = \"schedules-task-queue\",\n    });\n\nvar spec = new ScheduleSpec\n{\n    CronExpressions = new List\u003Cstring> { \"0 12 * * MON\" },\n};\n\nvar schedule = new Schedule(action, spec) { };\nawait client.CreateScheduleAsync(\"top-stories-every-mon-at-noon\", schedule); \nSee also the Schedules sample application.\nPython Example\nDev guide  Python  Features  Schedules\nTo convert your cron job into a Schedule using Python with Temporal, you can use the create_schedule() function provided by Temporal's Python SDK. Here's a step-by-step guide:\n\n  First, create a new file, for example, schedule_workflow.py.\n  Import the necessary modules and your workflow. Here's an example:\n\nimport asyncio  \nfrom datetime import timedelta  \n\nfrom temporalio.client import (  \n    Client,  \n    Schedule,  \n    ScheduleActionStartWorkflow,  \n    ScheduleIntervalSpec,  \n    ScheduleSpec,  \n    ScheduleState,  \n)  \n\nfrom activities import TASK_QUEUE_NAME  \nfrom your_workflow import TemporalCommunityWorkflow\n\n  Define your main function and connect to the Temporal client:\n\nasync def main():  \n    client = await Client.connect(\"localhost:7233\")\n\n  Use the create_schedule() function on the Client and pass a unique identifier for the Schedule. This identifier can be a business process identifier, for example, temporal-community-workflow. It's crucial for each Schedule to have a unique identifier to avoid conflicts and ensure clear identification.\n  Use the Schedule class on the Client to set the Schedule action and spec. The Schedule provides a solution to running your actions periodically. The spec determines when the action is taken.\n  In create_schedule, set an cron expression, for example, 0 12 * * MON. While this tutorial uses a cron expression, you can set an interval, calendars, and more to run your Workflow.\n\nHere's an example of how to do this:\nasync def main():\n    client = await Client.connect(\"localhost:7233\")\n\n    await client.create_schedule(\n        \"top-stories-every-mon-at-noon\",\n        Schedule(\n            action=ScheduleActionStartWorkflow(\n                TemporalCommunityWorkflow.run,\n                id=\"temporal-community-workflow\",\n                task_queue=\"schedules-task-queue\",\n            ),\n\t    \tcron_expression=[\"0 12 * * MON\"],\n    )\n\n  Finally, run the following command to start the Schedule:\n\npython schedule_workflow.py\n\nAdditional resources:\n\n  Join nearly 10,000 fellow engineers on our Community Slack\n  How Temporal works\n",featureImage:{title:"social-card-water-effect",description:"social-card-water-effect",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2KTpNohgF4VK8RxG2r4vlT/500df86e294043f8d19983961e4c2a0c/social-card-water-effect.jpg"},publishDate:"2023-12-18T00:00-05:00",metaDescription:"Converting a Cron into a Temporal schedule will will improve the durabililty of task execution and the visibility of schedule and workflow runs.",metaTitle:"Cron to Schedule Conversion",socialCard:{title:"social-card-water-effect",description:"social-card-water-effect",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2KTpNohgF4VK8RxG2r4vlT/500df86e294043f8d19983961e4c2a0c/social-card-water-effect.jpg"},tags:"Temporal Primitives",slug:"how-do-i-convert-my-cron-into-a-schedule",contentType:"blogPost",entityId:"5aPYfksgs3EttfXdfwGTtN",authors:[{id:"2S9VxKoLsmgeogWHXpwJsQ",name:"Patrick Rachford",slug:"patrick-rachford",jobTitle:"SDE Technical Writer",photograph:{title:"Temporal Symbol light 1@2x",description:"Temporal Symbol light 1@2x",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5kHQtcFCSqkLDH4I6HFmyG/8e75bd66b57696eb0a7866b3cbf8ea30/Temporal_Symbol_light_1_2x.png"},company:"Temporal",contentType:"person"},{id:"7GV0xjBamDpDSZZ543r8yX",name:"Irina Belova",slug:"irina-belova",jobTitle:"Product Marketing",photograph:{title:"headshot-irina-belova",description:"headshot-irina-belova",url:"https://images.ctfassets.net/0uuz8ydxyd9p/BJ0w7WeAjw83DatmJ7Fin/a8facdb4b7206afe1e66dc73b216ec09/headshot-irina.png"},contentType:"person"},{id:"6arqyRjoPr2qsFRjA16P0I",name:"Quinn Klassen",slug:"quinn-klassen",jobTitle:"Sr. Software Engineer",photograph:{title:"Temporal Symbol light 1@2x",description:"Temporal Symbol light 1@2x",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5kHQtcFCSqkLDH4I6HFmyG/8e75bd66b57696eb0a7866b3cbf8ea30/Temporal_Symbol_light_1_2x.png"},company:"Temporal",contentType:"person"}],authorsString:"Patrick Rachford, Irina Belova, Quinn Klassen",category:"How-To",readingTime:5},{title:"Durable Digest: December 2023",content:"This blog post is a public copy of our monthly newsletter sent on December 8th. If you'd like to receive upcoming updates by email, you can subscribe to our newsletter here.\nThis will be our last newsletter of 2023, so it's filled with tons of updates like the Temporal .NET SDK is now Generally Available!\nWe will also be hosting a webinar next week to discuss how workflows are written with the new .NET SDK and the interesting challenges encountered during the development of SDKs.\nFor more information on these updates and other things we've been working on, just keep reading! And as always, we'd love to hear from youfeel free to share feedback in our Community Slack, or on Twitter (@temporalio).\nNotable New Technology Features:\n\n  Schedules, a flexible and durable replacement for traditional Cron jobs, are now Generally Available.\n  The Temporal .NET SDK is now Generally Available and can be leveraged by all Temporal users. Learn more in this blog post.\n  The preview feature Workflow Update is now available in the Python SDK and .NET SDK.\n\nSDK Updates:\n\n  The .NET SDK 1.0.0 release brings General Availability support to users.\n  Python SDK 1.4.0 adds support for Typed Search Attributes and advanced metrics, and the experimental API for Workflow Update. Note there are a couple small breaking changes for search attributes and telemetry  see the release notes for more information.\n\nDecember Webinar: Our webinar from December 14th is now available to watch on demand.\nUpcoming Meetups & Events\nHappy Hour: Melbourne, AUS | December 13\n\n  Join us for a happy hour in Melbourne with Temporal staff and users.\n\nMeetup: Mumbai, IND | December 13\n\n  Join us for an evening of technical talks, snacks and drinks, and meet with Temporal users and experts, including Vijay Narayanan, Senior Executive Vice President at Kotak Mahindra Bank and Preeti Somal, Senior Vice-President of Engineering at Temporal.\n\nMeetup: San Francisco, CA | December 13\n\n  Join us at our new San Francisco office for an evening of technical talks, snacks and drinks, and meet with Temporal users and experts, including engineers from Turo and Instacart.\n\nMeetup: Hyderabad, IND | December 23\n\n  Temporal is co-hosting a meetup with CNCF in Hyderabad. Hear from engineers with Salesforce and DragonflyDB as well as Temporal. Register here.\n\n2023 Replay Conference\nWe are excited to announce that the talks from the 2023 Replay Conference were recorded and all 39 videos are now available to watch on Youtube. Revisit talks like the ones from Datadog, Netflix, JPMC, and more.\nYou can also find the full catalogue of videos on our Replay website.\nTemporal at Yum! Brands: Matt McDole gives an update on their journey with Temporal and how over 80% of all orders are now a Temporal Workflow.\nTemporal at Instacart: Hear how Instacart started with Temporal, the use cases and platforms they have built on top of it, and some key takeaways they've learned.\nResources\nWe have new Temporal 102 courses available in several SDK languages:\n\n  Python\n  TypeScript\n  Java\n\nVisit learn.temporal.io/courses to see our current offerings, and sign up for our waiting list to be notified when we release new courses.\nCommunity Favorites\nCommunity Threads: Learn if it's possible to create event - based Workflows and how to make Activities within a Workflow wait for these events.\nTemporal Cloud for Startups: Read about the top 5 ways users say Startups can benefit from Temporal Cloud and who qualifies.\nTemporal Partner Ecosystem: Learn more about our quest to make Durable Execution a reality for for our customers and community.",featureImage:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},publishDate:"2023-12-15T00:00-07:00",metaDescription:"Explore Temporals latest developer updates: questions from the field, new releases, builder spotlights, learning resources, and ways to connect with our team.",metaTitle:"Durable Digest: December 2023",socialCard:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},tags:"",slug:"durable-digest-december-2023",contentType:"blogPost",entityId:"1d7ZZWN2jpvdc8MHhBFTTi",authors:[{id:"17hGmNrCwtXdBh7fhsLUnZ",name:"Temporal Technologies",slug:"temporal-technologies",photograph:{title:"temporal technologies logo",description:"temporal technologies logo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3g56zRXtFQYMeJxBBkVBIZ/7771670e5fc7da59f555837b086c35d6/temporal_technologies_logo.avif"},company:"Temporal Technologies",contentType:"person"}],authorsString:"Temporal Technologies",category:"Announcements",readingTime:4},{title:"Introducing Temporal .NET  deterministic Workflow authoring in .NET",content:"\n  \n\n\n  A Temporal workflow is code that is executed in a durable, reliable, and scalable way. Today Temporal allows you to\n  write workflows in Go, Java, Python, TypeScript, and more. You can now add .NET to that list with the release of the .NET SDK. While this post will focus on C#, any .NET language will work.\n\n\n  Different language runtimes have different trade-offs for writing workflows. Go is very fast and resource efficient due\n  to runtime-supported coroutines, but that comes at the expense of type safety (even generics as implemented in Go are\n  limited for this use). Java is also very fast and type safe, but a bit less resource efficient due to the lack of\n  runtime-supported coroutines (but virtual threads are coming). It might sound weird to say, but our dynamic languages of\n  JS/TypeScript and Python are probably the most type-safe SDKs when used properly; however, as can be expected, they are\n  not the most resource efficient. .NET provides the best of all worlds: high performance like Go/Java, good resource\n  utilization like Go, and high quality type-safe APIs.\n\nWebinar recording - Introducing Temporal .NET and how it was built.\n\n  This post will give a high-level overview of the .NET SDK and some interesting challenges encountered during its\n  development. To get more info about the SDK, see:\n\n\n  \n    GitHub Repository  The README here provides the most comprehensive docs\n    for .NET at the moment\n  \n  NuGet Package\n  \n    Temporal Documentation  Contains general-purpose Temporal documentation with\n    .NET-specific content coming soon\n  \n  API Documentation\n  Samples\n\nContents:\n\n  Introduction to Temporal with C#\n    \n      Implementing an Activity\n      Implementing a Workflow\n      Running a Worker\n      Executing a Workflow\n    \n  \n  How It Works  Workflow Determinism\n  Future of the .NET SDK\n\nNOTE: A previous version of this post used a Ref pattern to invoke workflows, activities, signals, and queries. This has been updated to use the latest lambda expressions supported in current .NET SDK versions.\nIntroduction to Temporal with C#\n\n  To give a quick walkthrough of Temporal .NET, we'll implement a simplified form of one-click buying in C# where a\n  purchase is started and then, unless cancelled, will be performed in 10 seconds.\n\nImplementing an Activity\n\n  Activities are the only way to interact with external resources in Temporal, such as making an HTTP request or accessing\n  the file system. In .NET, all activities are just delegates which are usually just methods with the [Activity]\n  attribute. Here's an activity that performs a purchase:\n\nnamespace MyNamespace;\n\nusing System.Net;\nusing System.Net.Http;\nusing System.Net.Http.Json;\nusing Temporalio.Activities;\nusing Temporalio.Exceptions;\n\npublic record Purchase(string ItemID, string UserID);\n\npublic class PurchaseActivities\n{\n    private readonly HttpClient client = new();\n\n    [Activity]\n    public async Task DoPurchaseAsync(Purchase purchase)\n    {\n        using var resp = await client.PostAsJsonAsync(\n          \"https://api.example.com/purchase\",\n          purchase,\n          ActivityExecutionContext.Current.CancellationToken);\n\n        // Make sure we succeeded\n        try\n        {\n            resp.EnsureSuccessStatusCode();\n        }\n        catch (HttpRequestException e) when (resp.StatusCode \u003C HttpStatusCode.InternalServerError)\n        {\n            // We don't want to retry 4xx status codes, only 5xx status codes\n            throw new ApplicationFailureException(\"API returned error\", e, nonRetryable: true);\n        }\n    }\n}\nThis activity makes an HTTP call and takes care not to retry some types of HTTP errors.\nImplementing a Workflow\nNow that we have an activity, we can implement our workflow:\nnamespace MyNamespace;\n\nusing Temporalio.Workflows;\n\npublic enum PurchaseStatus\n{\n    Pending,\n    Confirmed,\n    Cancelled,\n    Completed\n}\n\n[Workflow]\npublic class OneClickBuyWorkflow\n{\n    private PurchaseStatus currentStatus = PurchaseStatus.Pending;\n    private Purchase? currentPurchase;\n\n    [WorkflowRun]\n    public async Task\u003CPurchaseStatus> RunAsync(Purchase purchase)\n    {\n        currentPurchase = purchase;\n\n        // Give user 10 seconds to cancel or update before we send it through\n        try\n        {\n            await Workflow.DelayAsync(TimeSpan.FromSeconds(10));\n        }\n        catch (TaskCanceledException)\n        {\n            currentStatus = PurchaseStatus.Cancelled;\n            return currentStatus;\n        }\n\n        // Update the status, perform the purchase, update the status again\n        currentStatus = PurchaseStatus.Confirmed;\n        await Workflow.ExecuteActivityAsync(\n            (PurchaseActivities act) => act.DoPurchaseAsync(currentPurchase!),\n            new() { ScheduleToCloseTimeout = TimeSpan.FromMinutes(2) });\n        currentStatus = PurchaseStatus.Completed;\n        return currentStatus;\n    }\n\n    [WorkflowSignal]\n    public async Task UpdatePurchaseAsync(Purchase purchase) => currentPurchase = purchase;\n\n    [WorkflowQuery]\n    public PurchaseStatus CurrentStatus() => currentStatus;\n}\nWorkflows must be deterministic, and we use a custom task scheduler (explained later in this post).\n\n  Notice the Workflow.DelayAsync call there? That is a durable Temporal timer. When a cancellation token is not provided\n  to it, it defaults to Workflow.CancellationToken so that cancelling the workflow implicitly cancels the tasks being\n  awaited. Workflows must use Temporal-defined timing and scheduling, so something like Task.DelayAsync cannot be used.\n  See the Workflow Determinism section below for more details.\n\nRunning a Worker\nWorkflows and activities are run in workers like so:\nusing MyNamespace;\nusing Temporalio.Client;\nusing Temporalio.Worker;\n\n// Create a client to localhost on \"default\" namespace\nvar client = await TemporalClient.ConnectAsync(new(\"localhost:7233\"));\n\n// Cancellation token to shut down worker on ctrl+c\nusing var tokenSource = new CancellationTokenSource();\nConsole.CancelKeyPress += (_, eventArgs) =>\n{\n    tokenSource.Cancel();\n    eventArgs.Cancel = true;\n};\n\n// Create an activity instance since we have instance activities. If we had\n// all static activities, we could just reference those directly.\nvar activities = new PurchaseActivities();\n\n// Create worker with the activity and workflow registered\nusing var worker = new TemporalWorker(\n    client,\n    new TemporalWorkerOptions(taskQueue: \"my-task-queue\").\n        AddActivity(activities.DoPurchaseAsync).\n        AddWorkflow\u003COneClickBuyWorkflow>());\n\n// Run worker until cancelled\nConsole.WriteLine(\"Running worker\");\ntry\n{\n    await worker.ExecuteAsync(tokenSource.Token);\n}\ncatch (OperationCanceledException)\n{\n    Console.WriteLine(\"Worker cancelled\");\n}\nWhen executed, the worker will listen for Temporal server requests to perform workflow and activity invocations.\nExecuting a Workflow\nusing MyNamespace;\nusing Temporalio.Client;\n\n// Create a client to localhost on \"default\" namespace\nvar client = await TemporalClient.ConnectAsync(new(\"localhost:7233\"));\n\n// Start a workflow\nvar args = new Purchase(ItemID: \"item1\", UserID: \"user1\");\nvar handle = await client.StartWorkflowAsync(\n    (OneClickBuyWorkflow wf) => wf.RunAsync(args),\n    new(id: \"my-workflow-id\", taskQueue: \"my-task-queue\"));\n\n// We can update the purchase if we want\nvar signalArgs = new Purchase(ItemID: \"item2\", UserID: \"user1\");\nawait handle.SignalAsync(wf => wf.UpdatePurchaseAsync(signalArgs));\n\n// We can cancel it if we want\nawait handle.CancelAsync();\n\n// We can query its status, even if the workflow is complete\nvar status = await handle.QueryAsync(wf => wf.CurrentStatus());\nConsole.WriteLine(\"Purchase workflow status: {0}\", status);\n\n// We can also wait on the result (which for our example is the same as query)\nstatus = await handle.GetResultAsync();\nConsole.WriteLine(\"Purchase workflow result: {0}\", status);\n\n  This is a tiny taste of the many features offered by Temporal .NET. See the\n  .NET SDK README for more details.\n\nHow It Works  Workflow Determinism\n\n  In Temporal, workflows must be deterministic. This means in addition to disallowing all the obvious stuff like random\n  and system time, Temporal must also have strict control over task scheduling and coroutines in order to ensure\n  deterministic execution.\n\n\n  While Python and others allow full control over the event loop (see\n  this blog post), .NET does not. We make a custom\n  TaskScheduler to order all created tasks deterministically, but we cannot control timers and many Task management\n  calls in .NET (e.g. simple overloads of Task.Run) use TaskScheduler.Default implicitly instead of the preferred\n  TaskScheduler.Current. Even\n  some analyzer rules\n  discourage use of calls that implicitly use TaskScheduler.Current though that is exactly what needs to be used in\n  workflows. Sometimes it's not even obvious that something internal will\n  use the default scheduler unexpectedly.\n\n\n  In order to solve this and prevent other non-deterministic calls, we would run in a sandbox. But recent versions of .NET\n  have done away with some of this tooling (specifically \"Code Access Security\" and \"Partially Trusted Code\" features).\n  These same issues also appear in Temporal Go and Java SDKs where we ask users not to do any platform threading/async\n  outside of our deterministic scheduler.\n\n\n  So, we ask users to make sure all task calls are done on the current task scheduler and not to use timers. See the\n  .NET SDK README for more details on what we limit.\n\n\n  We found it so hard to know which calls use threading and system timers in .NET that we are trying to eagerly detect\n  these situations at runtime and compile time. At runtime, by default, we enable a tracing\n  EventListener that intercepts\n  a select few info-level task events to check whether, if we are running in a workflow, all tasks are being performed on\n  the proper scheduler. Technically this event listener listens for all of these specific task events regardless of\n  whether a workflow is executing, but our check to disregard non-workflow events is very cheap (basically just a thread\n  local check). But we do allow the listener to be disabled if needed. This listener will suspend the workflow (i.e. fail\n  the \"workflow task\") when invalid task scheduling is encountered. The workflow will resume when code is deployed with a\n  fix.\n\n\n  In the future, there are two things that can help here. First, we want to create analyzers to find these mistakes at\n  compile time (see \"Future\" section below). Second for timers, the\n  new TimeProvider API recently merged will allow modern .NET versions\n  to let us control timer creation instead of falling back to system timers.\n\nFuture of the .NET SDK\nThe .NET SDK is a full-featured SDK on par with the others. There are three things we may add in the future.\n\n  First, we want to add source generation. We have the shape of activities and workflows, and therefore we can generate\n  idiomatic caller-side structures to make invocation safer/easier. Source generation will always be optional, but may\n  become the preferred way to call activities and workflows.\n\n\n  Second, we want to create a set of analyzers. We know what you can and can't call in a workflow, so static analysis to\n  catch these invalid calls should be fairly easy to develop. This would work like any other .NET analyzer and is\n  something we want to develop soon. Then again, maybe our approaches/investments in AI to find Temporal workflow mistakes\n  will be completed first .\n\n\n  Finally, the new TimeProvider API will allow us to intercept timers\n  in a much more transparent way for users. Granted, it will only work on the newest .NET versions.\n\n\n  The .NET SDK will be supported like other SDKs. Therefore, Temporal features like workflow\n  updates will be added to the .NET SDK as they are added to other SDKs.\n\n\n  Try it out today! We want all feedback, positive or negative! Join us in #dotnet-sdk on Slack or\n  on the forums.\n\nWebinar recording - Introducing Temporal .NET and how it was built.",featureImage:{title:"dotnet-feature",description:"dotnet-feature",url:"https://images.ctfassets.net/0uuz8ydxyd9p/CT03sHlCvlQHcPBtLv9Gd/2c6e7844cefbe13e6a7b5783464a780c/dotnet-blog.png"},publishDate:"2023-12-05T09:00-04:00",metaDescription:"A high-level overview of Temporal's new .NET runtime, and some interesting challenges encountered during its development.",metaTitle:"Introducing Temporal .NET  Deterministic Workflow Authoring",socialCard:{title:"dotnet-social",description:"dotnet-social",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2fJelvJo3Dqa4fbZUewYev/e7bb00aa572541c89aa39f67824d97b4/dotnet-social.png"},tags:"Code Samples,.NET",slug:"introducing-temporal-dotnet",contentType:"blogPost",entityId:"dWmQLZNte56i99wax375n",authors:[{id:"54HCUkZ1FzXSVjuPgLdbrm",name:"Chad Retz",slug:"chad-retz",jobTitle:"Language Runtime Engineer",photograph:{title:"chad avatar",description:"chad avatar",url:"https://images.ctfassets.net/0uuz8ydxyd9p/466YHdnNYWtGFCOMR3is5J/29dfa0790135812058d2b0e458ccc524/chad-avatar.png"},company:"Temporal",contentType:"person"}],authorsString:"Chad Retz",category:"Product News",readingTime:8},{title:"Announcing Temporal 102: Exploring Durable Execution with Python",content:"I'm excited to announce the general availability of our latest training course Temporal 102: Exploring Durable Execution with Python. This represents the next step for Python developers who have completed the Temporal 101: Introducing the Temporal Platform with Python course, released earlier this year. It also fulfills our commitment to offer both courses in four languages: Go, Java, TypeScript, and Python. All of them are self-paced and available online, so you can improve your skills as a Temporal developer when and where you like. Best of all, they're completely free.\nThe Next Step for Temporal Developers\nTemporal 101 introduces developers to Temporal, explaining what it is, its key features, and the fundamentals of how it works. In short, it covers how to build and run a basic Temporal application.\nTemporal 102 builds on this foundation, but from a different perspective than you might expect. Instead of covering additional features, it focuses on the best practices and key concepts that a developer should understand before deploying their first Temporal application to production. In other words, it's not about learning to create a more complex application; it's about learning how to test, debug, and deploy applications that you already know how to create.\nShould You Take Temporal 102 with Python?\nThe examples and hands-on exercises for this course are written in Python. If youve taken Temporal 101 and have basic proficiency with Python, I would definitely recommend taking this course.\nWhats Next?\nWe will release a course that focuses on Versioning within the coming month. The course is currently in development and we expect the delivery of this new course in all four of our primary languages (Go, Java, TypeScript and Python) very soon.\nIf you sign up for early access to our courses, well let you know as soon as theyre available.",featureImage:{title:"python-social",description:"python-social",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5aFzBgpUrTfznk9RPvLmG1/4c4e8a013656618663cbe68d6c7b9715/python-social2.jpg"},publishDate:"2023-12-01T00:00-05:00",metaDescription:"I'm excited to announce the general availability of our latest training course Temporal 102: Exploring Durable Execution with Python.",metaTitle:"Announcing Temporal 102: Exploring Durable Execution with Python",socialCard:{title:"python-social",description:"python-social",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5aFzBgpUrTfznk9RPvLmG1/4c4e8a013656618663cbe68d6c7b9715/python-social2.jpg"},tags:"Python",slug:"announcing-temporal-102-exploring-durable-execution-with-python",contentType:"blogPost",entityId:"6dO450DpTFMrk3LiWVO06X",authors:[{id:"1VQRqr0fVS9svnoX57cPKm",name:"Mason Egger",slug:"mason-egger",jobTitle:"Sr. Technical Curriculum Developer",photograph:{title:"mason egger",description:"mason egger",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7ouhODOdbYXBCMY8wynrGa/a184aa85abb1880f8857a60dc99ca825/11214847"},contentType:"person"}],authorsString:"Mason Egger",category:"How-To",readingTime:2},{title:"5 ways Temporal Cloud can help startups",content:"Weve frequently heard from developers at startups that Temporal Cloud would provide substantial benefits for their projects, but remains just out of reach of their limited budgets. To help these developers, we recently launched Temporal Cloud for Startups, which provides startups with free credits and the support they need to make their projects a success.\nThe early results have been really positivealmost two hundred startups have signed up over the past two months, and were already working closely with many of them.\nBut were also hearing some questions. How does Temporal Cloud help startups specifically? Isnt Temporal meant for applications operating at large scale?\nWe talked to a few startups to learn how Temporal Cloud helps them, and here are the top five reasons.\n1. Deliver new features faster to reach product-market fit.\nTemporals core value proposition is it lets you focus on building your business logic rather than engineering for state management. Temporal is a programming model that abstracts away state management and automatically handles state in the background. This abstraction saves you from hours of writing retry policies, exponential backoffs, cron jobs, and the list goes on.\nThe result is ridiculously faster development. Startups using Temporal have reported 2-10x faster development velocity. That means faster time to market, faster iteration, faster product-market fit, and a competitive advantage. As one developer put it, Were a speedboat driving circles around the ocean liners.\n2. Win the trust of early customers with good reliability.\nIts hard to overstate how critical it is to keep early adopters satisfied. One easy way to lose customers is to provide an unreliable service.\nTemporal operates with a durable execution model, meaning it guarantees all programs execute to completion, even when failures happen. It accomplishes this by autosaving state at every step in the system, so processes can pick up where they left off in the event of a machine failure, an API timeout, a plugged up queue, and so on.\nCompanies we spoke with reported as close to 100% reliability as possible since adopting Temporal, and other stats like 50% reduced downtime.\n3. Build distributed systems without having distributed systems expertise.\nDesigning and building distributed systems with a small engineering team can be a challenge, especially if not everyone has experience with it. One or two experts on the team end up teaching everyone else, and the other developers spend their time learning instead of building.\nBecause Temporal abstracts away and automatically handles distributed system complexities like durability and availability, the startups we spoke to were able to hire developers with less experience and operate with leaner teams. Developers are able to code with Temporal in the programming language they already know (Go, Java, Typescript, Python, PHP, and .NET), instead of learning a new one. They also gain visibility in the state of their entire system and can access that information from the UI.\n4. Set up systems for scale without sacrificing agility.\nAt a startup, you often need to make design compromises to deliver your MVP more quickly. That can result in accruing technical debt during feature development, especially related to reliability or performance. The system works well for the time being, but when you grow and reach product-market fit, things can start to go wrong. Your on-call engineers are burdened with manually intervening to resolve production issues that could be prevented with reliability built into the system.\nTemporal lets you set up your systems for scale from the start, so you dont need to redesign in the future. It scales out horizontally to handle millions of concurrent processes; our largest customers operate at internet scale. As a result, the customers we spoke to didnt have to take time and effort to deal with reliability issues or redesigning, and instead could focus on building new features to win even more customers.\n5. Get advice about whats worked well for other startups and how to optimize systems.\nFinally, startups have appreciated the access to our services team, which comes with a Temporal Cloud subscription. Our services team is staffed with engineers who have extensive experience with distributed systems. They can provide code reviews, pre-production checks, and more. Their knowledge has helped our startup customers learn whats worked well for other similar use cases, and ultimately build more effective applications.\nIf youre part of a startup and want to experience the benefits your peers have gained from Temporal Cloud, you can request $2,400 in free Temporal Cloud credits.\nIf you have any questions, you can take a look at our Temporal Cloud for Startups FAQs on this page or contact us at incubator@temporal.io. Wed love to hear from you!\nAnd finally, to hear how Nuon, an infrastructure startup, is building with Temporal, check out this webinar.",featureImage:{title:"social-orb",description:"social-orb",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Tk0k2JzNldP4WvVCZzJzA/08592218f1fd8de9b5efd2ee10cf0364/social-orb.jpg"},publishDate:"2023-11-28T00:00-05:00",metaDescription:"Weve frequently heard from developers at startups that Temporal Cloud would provide substantial benefits for their projects, but remains just out of reach of their limited budgets. To help these developers, we recently launched Temporal Cloud for Startups",metaTitle:"5 ways Temporal Cloud can help startups",socialCard:{title:"social-orb",description:"social-orb",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2Tk0k2JzNldP4WvVCZzJzA/08592218f1fd8de9b5efd2ee10cf0364/social-orb.jpg"},tags:"",slug:"5-ways-temporal-cloud-can-help-startups",contentType:"blogPost",entityId:"6WfwpiLhvxdvwNSbYPdzFN",authors:[{id:"4dsODPDNXZPwvTMknnOR7N",name:"Meagan Speare",slug:"meagan-speare",jobTitle:"Sr. Manager, Product Marketing",photograph:{title:"headshot-megan-speare",description:"headshot-megan-speare",url:"https://images.ctfassets.net/0uuz8ydxyd9p/4cU6Eil7AyPgQDtc52XeS8/935bb30acca03ba2e011e5cc90be909c/meagan-speare.jpg"},contentType:"person"}],authorsString:"Meagan Speare",category:"How-To",readingTime:4},{title:"Community threads: Is it possible to create an event-based Workflow?",content:"In Community Threads, we dig into some of the most frequent and insightful questions that appear in our Temporal Community.\nThe question\nIn todays Thread, I will look at a question from a Temporal user who wants to know:\nIs it possible to create event-based Workflows; and, if so, how do I make Activities within a Workflow wait for these events?\n\n  \n\nThe context\nThe full anatomy of a Workflow is out of the scope of this article, but as a durable, reliable, and scalable function execution, a Workflow Execution is the main unit of a Temporal application. Workflow Executions are instances of Workflow Definitions; think of a Workflow Definition as a series of expected steps or processes, and a Workflow Execution as a single run of that series of steps from start to finish.\nWorkflows use Signals to communicate between Workflow Execution instances, and Activities to communicate with the external environment.\nThe following diagrams shows the two ways Workflow Executions interact with the Temporal Platform: they can issue Commands, such as ScheduleActivityTask or StartTimer; and they can wait on Awaitables.\n\n  \n\nA Workflow Execution may only ever block progress on an Awaitable that is provided through a Temporal SDK API. Awaitables are provided when using APIs for the following:\n\n  Awaiting: Progress can block using explicit \"Await\" APIs.\n  Requesting cancellation of another Workflow Execution: Progress can block on confirmation that the other Workflow Execution is canceled.\n  Sending a Signal: Progress can block on confirmation that the Signal sent.\n  Spawning a Child Workflow Execution: Progress can block on confirmation that the Child Workflow Execution started, and on the result of the Child Workflow Execution.\n  Spawning an Activity Execution: Progress can block on the result of the Activity Execution.\n  Starting a Timer: Progress can block until the Timer fires.\n\nIn the context of this users question, each of their Activities require waiting on either a handshake, an acknowledgment, or some other type of Awaitable before proceeding to the next Activity. As shown above, this event-based flow is in the DNA of Temporal Workflows.\nThe Answer\nThe question came from the Python SDK forum, so the example code for the response will most closely resemble a Python implementation.\nThe short answer is: yes! Because of the magic of Temporal and the Temporal-backed asyncio event loop in Python, you can combine variables and wait conditions to create async Activities within your Workflow Definitions. Executing Activities requires a start_to_close_timeout. The main purpose of this param is to detect when a Worker crashes after it has started executing an Activity Task.\nYou can then set up a signal handler within your Workflow, using set() for each event to send a signal to the Workflow to trigger the subsequent Activity.\nHere is a sketch implementation:\n@workflow.defn\nclass MyWorkflow:\n    def __init__(self):\n        self.stage = 0\n\n    @workflow.run\n    async def run(self) -> None:\n        workflow.logger.info(\"Executing activity 1\")\n        await workflow.execute_activity(my_activity_1, start_to_close_timeout=timedelta(seconds=45))\n        workflow.logger.info(\"Finished activity 1\")\n        await workflow.wait_condition(lambda: self.stage > 0)\n\n        workflow.logger.info(\"Executing activity 2\")\n        await workflow.execute_activity(my_activity_2, start_to_close_timeout=timedelta(seconds=30))\n        workflow.logger.info(\"Finished activity 2\")\n        await workflow.wait_condition(lambda: self.stage > 1)\n\n        workflow.logger.info(\"Executing activity 3\")\n        await workflow.execute_activity(my_activity_3, start_to_close_timeout=timedelta(minutes=15))\n        workflow.logger.info(\"Finished activity 3\")\n        await workflow.wait_condition(lambda: self.stage > 2)\n\n        workflow.logger.info(\"Executing activity 4\")\n        await workflow.execute_activity(my_activity_4, start_to_close_timeout=timedelta(hours=2))\n        workflow.logger.info(\"Finished activity 4\")\n\n    @workflow.signal\n    def advance_stage(self, stage: int) > None:\n        self.stage = stage\nThis is a very normal Workflow and will work as expected even if it has to wait for weeks between events, the Worker crashes, etc. Thanks to Temporals replay functionality, to recover a Workflow you simply need to send a signal with the Activity number from a client anywhere, in any language as needed.\nJoin the Temporal user community in Slack\nIf you found this helpful, or if you have your own questions about Temporal that youd like to see answered, you can join us in Slack to connect with other Temporal users and team members.",featureImage:{title:"li-zhang-ZvVydsVkyTI-unsplash",description:"li-zhang-ZvVydsVkyTI-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3WwtmBoVCX8MFqaV2ZTQUq/fc4fc75dd2e1d75a6a36d292827b8d80/li-zhang-ZvVydsVkyTI-unsplash.jpg"},publishDate:"2023-11-27T00:00-05:00",metaDescription:"Handling event-based signals is one of the core components of Temporal Workflows. In this Community Threads post, a new Temporal user asks: How do I create an event-based Workflow with Temporal?",metaTitle:"Community threads: Is it possible to create an event-based Workflow?",tags:"",slug:"community-threads-is-it-possible-to-create-an-event-based-workflow",contentType:"blogPost",entityId:"V8CkMebP94KdJaL6LAbbz",authors:[{id:"7avHorknbM2zXYHMO2JxAn",name:"Eric O'Rear",slug:"eric-orear",jobTitle:"Technical Writer",photograph:{title:"eric-orear",description:"eric-orear",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5cqDRjGCTB1Z1T5q55KIWQ/593f467071430c43fe57d0c04058b217/eric-orear.png"},contentType:"person"}],authorsString:"Eric O'Rear",category:"Community",readingTime:4},{title:"Nuon gets 36x increase in developer velocity with Temporal long-lived Workflows",content:"We hear over and over again that customers are rebuilding their software stack with Temporal, often starting by augmenting parts of their stack and sometimes replacing it all. It gives an interesting comparison - you can measure the development velocity before/after Temporal.\nWe were joined by Jon Morehouse and Jordan Acosta from Nuon for a webinar last week to share how they completely rebuilt their API using Temporal, the best practices for long-lived workflows, and how Temporal is helpful for startups.\nNuon is an infrastructure company that enables software companies to create a BYOC (Bring Your Own Cloud) version of their app. Software companies connect existing tooling to create a fully managed version of their app that runs in the customer's cloud account.\nNuon started with two teams- one working on the external-facing API and the other working on infrastructure automation for CRUD software deployments. They had a three-person team building the API using traditional event-sourcing patterns. Nuon was using Temporal for the infrastructure automation and had one person working on it. Infrastructure automation is a typical Temporal use case. The API was perpetually slow and buggy, whereas the infrastructure automation was reliable and fast to develop.\nWatch the Hashicorp talk on infrastructure automation.\nNuon customers often had to step in when there was an error during deployment. They had to manually run commands to fix provisioning issues because the Nuon API was not declarative.\nNuon wondered if they could rebuild their API with Temporal.\nComing from a distributed systems background using event sourcing, Jordan was skeptical. Still, Jordan soon realized that Temporal Workflows could manage objects in the database and all interactions with those objects. Temporal Workflows could create a queue per object, allowing more efficient and scalable data management.\nNuon decided to dedicate a sprint to explore rebuilding the API with Temporal. In a single sprint, they replicated their existing API functionality entirely and, with a second sprint, took that code to production. In one developer month, they achieved what theyd failed to do in the 36 developer months theyd dedicated using event sourcing and queues.\nNot only did they get significantly improved developer velocity, but they also got significant improvements in reliability and insights. The Temporal UI is now used to track the lifecycle of objects in the database, providing a detailed view of object creation, updates, and more.\nCheck out the webinar to learn how Temporal's event loop model simplifies programming by handling side effects and workflows asynchronously, allowing for a lightweight and scalable architecture. Heres the accompanying blog post from Nuon with the code shared in the webinar.\n",featureImage:{title:"parrish-freeman-4rF9RftX4XA-unsplash",description:"parrish-freeman-4rF9RftX4XA-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3QK4OrL4Fct40ix4igrERX/c276ab1c5217e7abb928fd3e58ef7677/parrish-freeman-4rF9RftX4XA-unsplash.jpg"},publishDate:"2023-11-22T00:00-05:00",metaDescription:"We were joined by Jon Morehouse and Jordan Acosta from Nuon for a webinar last week to share how they completely rebuilt their API using Temporal, the best practices for long-lived workflows, and how Temporal is helpful for startups.",metaTitle:"Nuon gets 36x increase in developer velocity with Temporal long-lived Workflows",socialCard:{title:"parrish-freeman-4rF9RftX4XA-unsplash",description:"parrish-freeman-4rF9RftX4XA-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3QK4OrL4Fct40ix4igrERX/c276ab1c5217e7abb928fd3e58ef7677/parrish-freeman-4rF9RftX4XA-unsplash.jpg"},tags:"Industry Events",slug:"webinar-recap-nuon-gets-36x-increase-in-developer-velocity-with-temporal",contentType:"blogPost",entityId:"1PQNgoCDgXkNYCTYGTaJEs",authors:[{id:"5wU3ZwIOHTexKiFw1WVHwS",name:"Justin Pirie",slug:"justin-pirie",jobTitle:"Director of Product Marketing",photograph:{title:"justin-pirie-headshot",description:"justin-pirie-headshot",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7tlJfRA5m1ZEItrc2pMe3c/332eeabac7a4b7be2d12db997441d2e2/justin-pirie-headshot.png"},contentType:"person"}],authorsString:"Justin Pirie",category:"How-To",readingTime:3},{title:"Temporal Schedules: Reliable, scalable, and more flexible than Cron jobs",content:"Temporal Schedules are a replacement for traditional Cron jobs for task scheduling because this capability provides a more durable way to execute tasks, gain insight into their progress, enable observability of schedules and workflow runs, and lets you start, stop and pause them.\nWebinar recording - Simplifying and Scaling Cron Jobs with Temporal Schedules, Presented by Engineers from Watershed and Temporal.\nChallenges with Cron\nTraditional cron schedulers are a standard, but they often struggle with complex scheduling needs in modern environments, lacking features like job pausing and detailed monitoring for long-running tasks. In addition, traditional cron schedulers rely on databases and have scalability issues.\nDistributed Cron solutions, such as Kubernetes CronJobs, offer more scalable job scheduling by distributing workloads across a cluster. However, this scale comes at the cost of increased complexity and a steeper learning curve associated with Kubernetes.\nIntroducing Temporal Schedules\nWe're now announcing the general availability of our new Schedules feature. This enables you to execute Temporal Workflows at specified times or intervals, similar to Cron but far more powerful. And with Schedules, we now provide developers with controls to start, backfill, delete, describe, list, pause, trigger, and update a scheduled Workflow Execution with ease.\nSchedules enhance the flexibility of scheduling Workflows within the Temporal platform, streamlining the process and providing a more powerful toolset for time-based Workflow management. More explicitly, they are better than Cron because of the following:\n\n  Enhanced Workflow control and observability: Schedules improve the manageability of Workflows and allow for better monitoring, making it easier to track scheduled Workflow runs and address any issues swiftly.\n  Flexible and extensible scheduling: Schedules are more adaptable and facilitate the definition of Tasks with varied schedules and intervals. This adaptability allows for more sophisticated scheduling needs, such as handling overlapping runs.\n  Elimination of external dependencies: For Temporal users, Schedules remove the need to integrate external scheduling systems. This simplifies the Workflow process and reduces complexity.\n\n\n  Temporal allows us to orchestrate all our tasks, so we are able to focus on the business case and less on plumbing. Schedules extend the value of Temporal. With it, the cost of maintaining healthy time precision & traceability is becoming more and more like the job of a watchmaker. - Frederic Tu, at Airwallex, a Fintech company\n\nHow to use Schedules\nOur Solution Architect, Keith Tenzer, wrote a great overview about how to create and view Schedules.\nSchedules can be configured either by using the SDK or tctl. Schedules can be viewed using tctl or the Web UI. In this example, we demonstrate using tctl to configure a Schedule and the Web UI to display it.\nCreating Schedule\nFirst we use tctl to simply get a list of Workflows that have run. Note: the new Temporal CLI also supports Schedules. More information in our docs.\n\n  \n\nNext we schedule the preceding Workflow to run every 5 minutes. In addition to the information gathered by tctl, we also need to provide a Schedule ID (sid).\n\n  \n\n\n  \n\nViewing Schedule\nUsing the new Schedule widget in the UI navigation bar, we can see Schedules listed by their corresponding Schedule ID.\n\n  \n\nFrom here we can drill into a schedule to see its details. We can also see the result of recent runs and even schedule time for future upcoming runs.\n\n  \n\n\n  In addition, the Schedule can be paused or resumed.\n  All of this is also possible with the tctl command.\n\n\n  \n\nLearn more - Join us for a webinar and Q&A session on 11/30 at 9:30 AM PT to discuss the Schedules with the Engineering team from Temporal.\nWe will soon be adding a video demonstration to showcase the capabilities of Temporal Schedules. Stay tuned for this exciting addition!\nSchedules: Like Cron but better\nThe release of Temporal Schedules is a significant advancement in workflow scheduling. This feature transforms traditional Cron jobs into reliable, flexible Temporal Workflows that are easier to manage and monitor. Developers can now enjoy a clear view of their schedules and runs, with the added ability to perform a variety of operations such as start, backfill, pause, and update workflows seamlessly. Each Schedule has a unique id and can be managed independently; providing a structured and adaptable scheduling system, free from the complexities and rigidities of traditional Cron. The introduction of Schedules streamlines time-based workflow management, eliminates the need for external dependencies and enhances overall control and observability for developers within the Temporal platform.\nAs with all other Temporal capabilities, the Schedule feature is also available in Open Source. Support for Schedules has been added to the CLI and the Web UI, and APIs support has been added to the Go SDK, the TypeScript SDK (see sample), the JAVA SDK, the .NET SDK, and the Python SDK. Also, check out the Schedules docs.\n\nWebinar recording - Simplifying and Scaling Cron Jobs with Temporal Schedules, Presented by Engineers from Watershed and Temporal.\nAdditional Resources:\n\n  Join nearly 10,000 fellow engineers on our Community Slack\n  How we built Schedules - blog post by Temporal engineer\n  How Temporal works\n",featureImage:{title:"social-card-dark-waves (1) ",description:"social-card-dark-waves (1) ",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7fqbHM7iWOHKJo0GNha3Ou/ca1d6b6c63ab327d9e872eefa5a33627/social-card-dark-waves__1__1.png"},publishDate:"2023-11-15T00:00-07:00",metaDescription:"Replace traditional Cron jobs with Temporal Schedules for durable task execution, progress insights, and enhanced scalability.",metaTitle:"Temporal Schedules: More Reliable & Scalable than Cron Jobs",socialCard:{title:"social-card-dark-waves (1) ",description:"social-card-dark-waves (1) ",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7fqbHM7iWOHKJo0GNha3Ou/ca1d6b6c63ab327d9e872eefa5a33627/social-card-dark-waves__1__1.png"},tags:"Temporal Primitives",slug:"temporal-schedules-reliable-scalable-and-more-flexible-than-cron-jobs",contentType:"blogPost",entityId:"4bOYnIKu99nFwsrbHuCauY",authors:[{id:"7GV0xjBamDpDSZZ543r8yX",name:"Irina Belova",slug:"irina-belova",jobTitle:"Product Marketing",photograph:{title:"headshot-irina-belova",description:"headshot-irina-belova",url:"https://images.ctfassets.net/0uuz8ydxyd9p/BJ0w7WeAjw83DatmJ7Fin/a8facdb4b7206afe1e66dc73b216ec09/headshot-irina.png"},contentType:"person"}],authorsString:"Irina Belova",category:"Product News",readingTime:5},{title:"Announcing Temporal 102: Exploring Durable Execution in TypeScript",content:"I'm excited to announce that our latest training course, Temporal 102: Exploring Durable Execution with TypeScript, is now generally available. Like Temporal 101 with TypeScript, it is self-paced and available online, so you'll have the opportunity to improve your skills as a Temporal developer when and where you like. Best of all, its free.\nThe Next Step for Temporal Developers\nTemporal 101 introduces developers to Temporal, explaining its key features and the fundamentals of how it works. In short, it covers how to build and run a basic Temporal application.\nTemporal 102 builds on this foundation by focusing on the best practices and key concepts that a developer should understand before deploying their first Temporal application to production. In other words, it's not about learning to create a more complex application; it's about learning how to test, debug, and deploy applications that you already know how to create.\nA Departure from Temporal 102 in Go\nTemporal 102: Exploring Durable Execution in TypeScript is a slight departure from our current Temporal 102 in Go course. After teaching Temporal 101 and Temporal 102 live at Replay this past year in Go, Java, and TypeScript, we identified some areas where we could make improvements to the course. If youve already taken Temporal 102 in Go you will notice a different ordering for the material, as well as the removal of certain sections. We also migrated a few pages from the previous Temporal 102 courses into the relevant Temporal 101 courses and removed the section and exercise on Versioning from Temporal 102. This Versioning material is being split off and will be the topic of our next course, Temporal 103. While this course and any future Temporal 102: Exploring Durable Execution courses in different languages will not contain this material, it will be available by the end of 2023. We will leave the Temporal 102 in Go course in its current state until we have released our Versioning course in Go.\nShould You Take Temporal 102 with TypeScript?\nThe examples and hands-on exercises for this course are written in TypeScript. If youve taken Temporal 101 and have basic proficiency with TypeScript, I would definitely recommend taking this course.\nWhats Next?\nWe plan to finish porting this Temporal 102 course to use the Python SDK and releasing it before the end of 2023. Temporal 102 has already been released in Java and Go.\nWe also will be releasing a course just on Versioning very soon. The course is currently in development and we expect the delivery of this new course in at least two languages by the end of 2023.\nIf you sign up for early access to our courses, well let you know as soon as theyre available.",featureImage:{title:"Social card - Temporal",description:"Social card - Temporal",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3A4UpeAUYabwGjkyPPHEC4/f695115bb2ed3d2ff5cf3ae05aad1bb5/Twitter_Card.png"},publishDate:"2023-11-09T00:00-07:00",metaDescription:"I'm excited to announce that our latest training course, Temporal 102: Exploring Durable Execution with TypeScript, is now generally available.",metaTitle:"Announcing Temporal 102: Durable Execution in TypeScript",socialCard:{title:"Social card - Temporal",description:"Social card - Temporal",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3A4UpeAUYabwGjkyPPHEC4/f695115bb2ed3d2ff5cf3ae05aad1bb5/Twitter_Card.png"},tags:"Typescript",slug:"announcing-temporal-102-durable-execution-in-typescript",contentType:"blogPost",entityId:"4bDdMsYg6Y6JVNMnm23XbP",authors:[{id:"gz6Asa7ycvY1HZz9vcJk0",name:"Angela Zhou",slug:"angela-zhou",jobTitle:"Senior Technical Curriculum Developer",photograph:{title:"headshot-angela-zhou",description:"headshot-angela-zhou",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3FgLhuMJuEASXJmzoNevWN/c115937f066329eb77cd75caa831bfbe/headshot-angela-zhou.png"},contentType:"person"}],authorsString:"Angela Zhou",category:"How-To",readingTime:3},{title:"Announcing the Temporal Partner ecosystem",content:"We are on a quest to make durable execution a way of life for backend engineers. Many of you have joined us on this journey, and there are millions more who stand to benefit from a better developer experience, with more durability, less code, and higher feature velocity.\nToday, we are announcing the Temporal Partner Ecosystem as a new pillar in our quest to make Durable Execution a mainstream reality for our customers and community. Our partners share our developer-first ethos and are dedicated to helping you shorten the time it takes to get from where you are today, to where you want to be with Durable Execution and Temporal.\nThe Growing Demand for Temporal Services\nWe regularly hear from engineering teams that they want to move faster and do more with Temporal. In response, we have made Temporal more approachable, expanded our documentation, and grown our training programs and course catalog. However, we also hear that injecting engineering expertise from partners is more impactful.\nThe types of services weve heard demand for include:\n\n  Modernizing existing applications with Temporal\n  Migrating applications from legacy workflow and orchestration tools or self-managed Temporal to Temporal Cloud\n  Building new features or applications with Temporal\n\nOur curated partners are optimally suited to deliver these services to help our customers succeed and scale with Temporal, and weve already seen over 20 partner engagements arise in the early days of the ecosystem.\n\n  \n    Were writing in Temporal, a code-first workflow service, and it elevates that code one level of abstraction up from us. And we wanted to build our own teams, but we wanted to augment those teams with people we could trust, that had the quality bar at our level, and Bitovi knocks that out of the park.\n    Matt McDole - Senior Director, Yum! Brands\n  \n\nIntroducing our First Cohort of Partners\nWe were deliberate in selecting our initial cohort of partners, and evaluated them using the following criteria:\n\n  A shared developer-first philosophy\n  Strong subject matter expertise, and a commitment to a high bar for enablement and certification\n  Breadth of geographic representation to benefit as much of the community as possible\n\nWere proud to highlight our initial cohort of partners:\n\n  \n    \n      Partner\n      Geography\n      Website\n    \n  \n  \n    \n      \n        \n      \n      Americas\n      Learn more\n    \n    \n      \n        \n      \n      United Kingdom\n      Learn more\n    \n    \n      \n        \n      \n      Americas\n      Learn more\n    \n    \n      \n        \n      \n      France\n      Learn more\n    \n    \n      \n        \n      \n      Americas\n      Learn more\n    \n    \n      \n        \n      \n      Asia\n      Learn more\n    \n    \n      \n        \n      \n      Americas\n      Learn more\n    \n    \n      \n        \n      \n      DACH\n      Learn more\n    \n    \n      \n        \n      \n      Eastern Europe\n      Learn more\n    \n  \n\n\n  \n    Formula.Monks is thrilled to announce our collaboration with Temporal. Durable Execution is the future of backend development, and were excited to collaborate with customers to usher in this paradigm shift for application development and modernization.\n    Felicia Schwartz - Managing Partner, Formula.Monks\n  \n\nGet in Touch\nIf you need help implementing Temporal and would like to get connected to the right partner, please let us know at temporal.io/partners.\nIf youd like to be a partner and help build the future of event driven architectures, please reach out to partners@temporal.io.",featureImage:{title:"social-card-newsletter",description:"social-card-newsletter",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3k9UpZsjFZDXElTHI4BCLz/3a72dd7f1c60ada1f5bd28f46f684810/social-card-newsletter.jpg"},publishDate:"2023-11-07T06:00-07:00",metaDescription:"Today, we are announcing the Temporal Partner Ecosystem as a new pillar in our quest to make durable execution a mainstream reality for our customers and community.",metaTitle:"Announcing the Temporal Partner ecosystem",socialCard:{title:"social-card-newsletter",description:"social-card-newsletter",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3k9UpZsjFZDXElTHI4BCLz/3a72dd7f1c60ada1f5bd28f46f684810/social-card-newsletter.jpg"},tags:"Industry Events",slug:"announcing-the-temporal-partner-ecosystem",contentType:"blogPost",entityId:"3WD07PHnuuf2ztziCyQd3v",authors:[{id:"6ZrqOx5rXn6dp0w49g7vDb",name:"Jay Sivachelvan",slug:"jay-sivachelvan",jobTitle:"VP of Partnerships",photograph:{title:"Jay Shivachelvan",description:"Jay Shivachelvan",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3RS0QEY2Zh9mZwIfIRC8jN/bd89483f6b2cbd610e955d9eb30458eb/TT31S6VK5-U05LKSQG753-7b4dcb8eea4b-512"},contentType:"person"}],authorsString:"Jay Sivachelvan",category:"Announcements",readingTime:3},{title:"Announcing Temporal 102: Exploring Durable Execution with Java",content:"I'm excited to announce that our latest training course, Temporal 102: Exploring Durable Execution with Java, is now generally available. Like Temporal 101 with Java, it is self-paced and available online, so you can improve your skills as a Temporal developer when and where you like. Best of all, its free.\nThe Next Step for Temporal Developers\nTemporal 101 introduces developers to Temporal, explaining what it is, its key features, and the fundamentals of how it works. In short, it covers how to build and run a basic Temporal application.\nTemporal 102 builds on this foundation, but from a different perspective than you might expect. Instead of covering additional features, it focuses on the best practices and key concepts that a developer should understand before deploying their first Temporal application to production. In other words, it's not about learning to create a more complex application; it's about learning how to test, debug, and deploy applications that you already know how to create.\nA Departure from Temporal 102 with Go\nTemporal 102: Exploring Durable Execution with Java is a slight departure from our current Temporal 102 with Go course. After teaching Temporal 101 and Temporal 102 live at Replay this past year in Go, Java, and TypeScript, we identified some areas where we could make the course better. If youve already taken Temporal 102 with Go, youll notice a different ordering for the material, as well as certain sections removed. We migrated a few pages into the relevant Temporal 101 courses and removed the section and exercise on Versioning. The Versioning material is being split off and will be the topic of our next course. Although this course and any future Temporal 102: Exploring Durable Execution courses in other languages wont contain this material, it will be available by the end of 2023. We will leave the Temporal 102 with Go course in its current state until we have released our Versioning course in Go.\nShould You Take Temporal 102 with Java?\nThe examples and hands-on exercises for this course are written in Java. If youve taken Temporal 101 and have basic proficiency with Java, I would definitely recommend taking this course.\nWhats Next?\nWe plan to finish porting this course to other SDKs, including TypeScript and Python. These ports will be landing before the end of 2023, so if youre holding out for Temporal 102 in your favorite language you might want to wait. Theyll be here soon.\nWe also will be releasing a course just on Versioning very soon. The course is currently in development and we expect the delivery of this new course in at least two languages by the end of 2023.\nIf you sign up for early access to our courses, well let you know as soon as theyre available.",featureImage:{title:"Temporal Java SDK",description:"Temporal Java SDK",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1k7xt6Oyeg8rwsvaZMdcL0/2dbb127aa814915ee084bd006c22df32/Temporal_java_social_card_2x.png"},publishDate:"2023-11-06T00:00-07:00",metaDescription:"I'm excited to announce that our latest training course, Temporal 102: Exploring Durable Execution with Java, is now generally available.",metaTitle:"Announcing Temporal 102: Exploring Durable Execution with Java",socialCard:{title:"Temporal Java SDK",description:"Temporal Java SDK",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1k7xt6Oyeg8rwsvaZMdcL0/2dbb127aa814915ee084bd006c22df32/Temporal_java_social_card_2x.png"},tags:"Java",slug:"announcing-temporal-102-exploring-durable-execution-with-java",contentType:"blogPost",entityId:"1um42E0nOgP4cxgaehAUr0",authors:[{id:"1VQRqr0fVS9svnoX57cPKm",name:"Mason Egger",slug:"mason-egger",jobTitle:"Sr. Technical Curriculum Developer",photograph:{title:"mason egger",description:"mason egger",url:"https://images.ctfassets.net/0uuz8ydxyd9p/7ouhODOdbYXBCMY8wynrGa/a184aa85abb1880f8857a60dc99ca825/11214847"},contentType:"person"}],authorsString:"Mason Egger",category:"How-To",readingTime:3},{title:"Replay replay: Temporal product announcements ",content:"At Replay this year we hosted over 40 talks, and one of the most anticipated was our Product Keynote, which was presented by Samar (our CTO and co-founder) and Preeti (our SVP of Engineering). The video of this talk is now available to view on our Replay Rewind site.\nWe rolled out a few product updates during the keynote. Some of which are previews of upcoming releases and some generally available. Regardless of release availability, each was accompanied by a working demo from Yimin and Liang from our engineering team. The features we spoke through are below.\nNative Temporal Monitoring in Datadog\nWe welcomed our friends at Datadog to join us during the keynote to roll out a (yet another) new feature that provides native monitoring of Temporal within Datadog. They now provide an out of the box dashboard and a handful of recommended monitors that give you a great starting point for running your own Temporal servers. They also announced the release and spoke through a native Datadog tracing library for our Go SDK.\n\n  \n\nTemporal Updates: Versioning, Schedules, Workflow Update, Multi-region cloud and more.\nWe continued the keynote with some of our own product announcements and demos, rolling out five new features across the project and within our managed service, Temporal Cloud. The key updates included:\n\n  \n    Workflow Update (public preview)\n    Workflow Update is the first new primitive added to Temporal in quite a while. This key capability eliminates development friction and reduces latencies for your responsive applications. In the past, if you wanted to interact with a Workflow, you would send data to it and then you would have to query the Workflow to get a response. With Workflow Update you can now simply send a request and get data back synchronously. This eliminates blocking on the response and helps you build interactive apps.\n  \n\n\n  \n\n\n  \n    Schedules (public preview)\n    The Schedules capability of Temporal is applicable against two challenges; it is an upgrade to traditional Cron utilities and also replaces the existing Temporal Cron Jobs feature. The new Schedules feature provides granular controls for you to schedule Temporal Workflows and run them reliably and on a specified schedule, interval or calendar. It also allows you to manage these workflows with controls to start, backfill, delete, describe, list, pause, trigger, and update their execution.\n  \n\n\n  \n\n\n  \n    Worker Versioning\n    Have you ever had to modify logic within a Temporal Workflow in production? Until now, this task was quite complicated and required manual control over versions deployed on explicit workers. With this feature update, Temporal now automates control over Worker Versioning. You simply change your code, and then deploy your Workflow with a new version number. Under the cover, Temporal will direct all new workflow executions to Workers that have the new version and all previous versions will continue on the existing workers.\n  \n\n\n  \n\n\n  \n    Programmatic and Automated User and Account Management\n    Over the past few months, we have been busy rethinking and simplifying how you manage and authenticate users within Temporal Cloud. We introduced API Keys and updated the tcloud CLI so that you can automate and programmatically manage user, accounts and namespaces within Temporal Cloud. It allows you to perform a single update or execute these in batch. In the demo,we even showed how you can do all of this as a reliable Temporal Workflow.\n  \n\n\n  \n\n\n  \n    Multi-Region Temporal Cloud: Global Namespaces\n    Our final announcement was Global Namespaces for Temporal Cloud. This deployment option, allows you to get a managed service for workloads that need 99.99% availability or global access. If you want to do this with a self-hosted Temporal Server, it requires fairly complex setup and management for replication and traffic failover. With this new feature, this is as simple as choosing a secondary region for Temporal Cloud and we take care of all the complexity. Don't believe us? Check out the demo!\n  \n\n\n  \n\nThis was a feature packed keynote and highlighted some of the biggest advances we've made over the past few months. Ultimately, We are pretty happy that all the demos went off without a hitch and that much of this is available for you to use now.\nIf you'd like to see the demos and hear from the team directly, you can check out the video on our Replay Rewind site and join the discussion about these new features in our community slack.",featureImage:{title:"blog post replay",description:"blog post replay",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1cVP7MLfyQAJcjtPgaLT1e/cecdbd6c74b1d1b71e6535a6a99e5d4e/blog_post_replay.png"},publishDate:"2023-10-30T00:00-06:00",metaDescription:"At Replay this year we hosted over 40 talks, and one of the most anticipated was our Product Keynote, which was presented by Samar (our CTO and co-founder) and Preeti (our SVP of Engineering).",metaTitle:"Replay replay: Temporal product announcements ",socialCard:{title:"blog post replay",description:"blog post replay",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1cVP7MLfyQAJcjtPgaLT1e/cecdbd6c74b1d1b71e6535a6a99e5d4e/blog_post_replay.png"},tags:"Replay",slug:"replay-replay-temporal-product-announcements",contentType:"blogPost",entityId:"3s4DMUMFMsenSahgDaMkI4",authors:[{id:"1SCcHs5wmwt6kjoR3qMuGZ",name:"Jim Walker",slug:"jim-walker",jobTitle:"VP of Product Marketing",photograph:{title:"headshot-jim-walker",description:"headshot-jim-walker",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3tZdemozlmoJ8a4leDbfGX/ae3233e372bb29e7d3918b9b0d2c4bfc/Screenshot_2023-10-20_at_2.08.33_PM.png"},contentType:"person"}],authorsString:"Jim Walker",category:"Community",readingTime:4},{title:"Upcoming changes to Temporal Cloud metering",content:"A few weeks ago at the Replay developer conference we announced a number of new features that are coming to Temporals open source platform for durable execution. Some of these new features such as schedules and workflow update are new abstractions for Temporals programming model that simplify the implementation and lower the latency for backend services.\nTemporal Cloud is a stateful serverless service where customers only pay for what their application uses. Temporal Clouds usage model is based on three core principles:\n\n  Customers should only pay for the value they consume - i.e. Temporal only succeeds when our customers succeed.\n  Customers should have full control over their costs based on the transparency we provide and their own implementation decisions.\n  Customers should not be tempted to make sub-optimal implementation decisions in order to manage costs.\n\nTo stay consistent with these principles, the new additions to our SDK's functionality require an update to Temporal Cloud's metering. Were making two additional metering corrections at the same time. Our updates will change how Temporal cloud meters the usage of:\n\n  Schedules\n  Workflow updates\n  Child workflows\n  Local activities\n\nSchedules are new to the Temporal platform. Temporal Cloud metering will count the triggering of a Schedule as 2 actions, not including the start of the Workflow itself which is already counted as an action. This is essentially the same number of actions if a user manually implemented the equivalent of a Schedule.\nWorkflow Updates are new to the Temporal platform. Temporal Cloud metering will count a workflow update as 1 action. This is a potential savings for applications as today the equivalent implementation would count as 2 actions for a Query and a Signal.\nChild Workflows are currently metered so that every child workflow execution from StartChildWorkflowInitiated to WorkflowExecutionStarted to WorkflowExecutionCompleted is metered as 1 action. This is inconsistent with the way Temporal Cloud meters an equivalent implementation where an Activity starts a new Workflow (2 actions). With this metering update we will count the parent workflow spawning a child workflow as 1 action and the execution of the child workflow as 1 action.\nLocal Activities are currently metered so that every Local Activity execution is metered as 1 action. This can result in over-counting of Local Activities and unsustainable costs for these implementations. Local Activities also have weaker guarantees than regular Activities (less value-added). With this metering update, all Local Activities associated with one Workflow Task will count as 1 action, significantly reducing the number of Local Activities metered when used as appropriately. Each additional workflow task heartbeat after that is counted as an additional action. Also, Local Activities retried following a Workflow Task heartbeat will count as 1 action. I.e. the more a Local Activity gets used like a regular Activity, the more it will get counted that way too.\nThese updates to our metering are staged to take effect November 1st, midnight UTC. They do not alter Temporal Clouds pricing, credits or any special terms a customer might have today. They also do not affect how Temporal Cloud rate limits namespaces. Weve analyzed the cost implications of these metering updates for our customers and they are effectively net-neutral across the hundreds of services and applications backed by Temporal Cloud. Most applications will be completely unaffected and the applications that are affected should not see their action count increase or decrease by more than 15%.",featureImage:{title:"social-card-brandon",description:"social-card-brandon",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1oX4jNjimgeS45r7uoaMha/d54d7043f6f959dc26a493a2e74d98c7/social-card-brandon.jpg"},publishDate:"2023-10-26T00:00-07:00",metaDescription:"A few weeks ago at the Replay developer conference we announced a number of new features that are coming to Temporals open source platform for durable execution.",metaTitle:"Upcoming changes to Temporal Cloud metering",socialCard:{title:"social-card-brandon",description:"social-card-brandon",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1oX4jNjimgeS45r7uoaMha/d54d7043f6f959dc26a493a2e74d98c7/social-card-brandon.jpg"},tags:"Cloud",slug:"upcoming-changes-to-temporal-cloud-metering",contentType:"blogPost",entityId:"d0x93yxunF9FFSF1jLevz",authors:[{id:"7F3KZ7fZZ8qsrNC5JCH9jj",name:"Charles Zedlewski",slug:"charles-zedlewski",jobTitle:"CPO",photograph:{title:"charles zedlewski",description:"charles zedlewski",url:"https://images.ctfassets.net/0uuz8ydxyd9p/2zXHcMwt6Lgw5HXk9KI7FZ/201c4c83cc5a1b91e61888618c76d60d/charles-2016_1.png"},twitterUrl:"https://twitter.com/zedlewski",contentType:"person"}],authorsString:"Charles Zedlewski",category:"Product News",readingTime:3},{title:"Durable Digest: October 2023",content:"This blog post is a public copy of our monthly newsletter sent on October 27th. If you'd like to receive upcoming updates by email, you can subscribe to our newsletter here.\nIf you couldnt make it to Replay 2023, or attended but couldnt see every talk, weve got good news: The first line of talks are now available for you to watch and share! Check out our blog post for more information on how you can rewind Replay.\nFor more information on these updates and other things we've been working on, just keep reading! And as always, we'd love to hear from youfeel free to share feedback in our Community Slack group, or on Twitter (@temporalio)\nTemporal Cloud\nWe have several features that are available as a part of a pre-GA preview and are listed below. Please reach out to Temporal if you would like to try out any of this functionality.\n\n  Global Namespace is available as a private preview for users who would like to increase availability of Temporal to 4 9s through multi-region Namespace replication.\n  For users who purchased Temporal Cloud Credits, we have a private preview available, so you can manage credit burn down in the Temporal Cloud UI.\n  Workflow History Export is available for users who would like to receive automated exports of closed Workflow Histories in a private preview.\n  For users looking to automate Temporal Cloud operations, like user invites or Namespace permissions, the Cloud Operations API is in a private preview and public GitHub repo.\n\nSeveral small enhancements have also been made to the Temporal Cloud CLI to afford users the ability to specify a Codec Server endpoint during Namespace creation and see accurate Regions using tcld account list-regions with user permissions applied.\nSDK Updates\n\n  The Go SDK release v1.25.0 provides a built in integration with the standard slog package.\n  The latest Temporal CLI release has updates to recent Temporal Server and UI versions, including the experimental Timeline view shown during Replayturn on Labs to try it out!\n\nUpcoming changes to Temporal Cloud metering: See the new features and updates to Temporal Cloud's metering that will take affect on November 1st.\nUpcoming Meetups & Events\nDenver Dev Day | October 27\n\n  Temporal is sponsoring the community led Denver Dev Day where our very own Steve Kinney will be presenting A World Without Failure: Building Reliable Systems with Temporal. This event is SOLD OUT, but if youre attending, be sure to stop by and talk to our Temporal team.\n\nPycon Sweden | November 9-10\n\n  We are so ready to meet the Python community in Sweden in just a few weeks! Temporals Raphal Beaumont is giving the talk \"What if your code could be as simple as your business logic, and crashes were nothing but a minor inconvenience?\" Tickets on sale here.\n\nNYC Python Meetup | November 15\n\n  Temporal and MongoDB are excited to host a joint NYC Python and PyData NYC meetup! Join for an evening of technical talks, grab some pizza and drinks, and meet fellow Pythonistas. Register here.\n\nJS Conf Colombia | November 17-18\n\n  The 10th and final JS Conf Colombia will take place in Medellin and Temporal is a Gold sponsor. The conference is SOLD OUT, and if youre attending we cant wait to celebrate with you!\n\nUpcoming Community Meetup: Chicago Java Users Group (CJUG): We're partnering with Kin + Carta for a meetup in Chicago on November 16th. See how to join us and network with other local users.\nResources\nWhether you're onboarding to Temporal Cloud, or just interested in seeing what Temporal Cloud is all about, check out the new free course, Introduction to Temporal Cloud.\nCommunity Favorites\nIntroduction to Worker Tuning: Learn about performance tuning and other factors that have the biggest impact on Worker performance.\nThe Distributed Machine: Read about Temporal and why we think its natural progression is a new kind of computing machine.\nLet's Visualize a Workflow: See the latest UI update, available in both Temporal Cloud and OSS, which allows users to easily visualize a Workflow in the UI.",featureImage:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},publishDate:"2023-10-26",metaDescription:"Explore Temporals latest developer updates: questions from the field, new releases, builder spotlights, learning resources, and ways to connect with our team.",metaTitle:"Durable Digest: October 2023",socialCard:{title:"Durable Digest",description:"Durable Digest",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3fYFwJscrBjaOGT5EZeKaD/f4a6230742b9282b5471c58a1f3d939a/Durable-digest-linkedin_1280x720-x2__1_.png"},tags:"",slug:"durable-digest-october-2023",contentType:"blogPost",entityId:"3lNND8LAkpvFHFu8luM8PG",authors:[{id:"17hGmNrCwtXdBh7fhsLUnZ",name:"Temporal Technologies",slug:"temporal-technologies",photograph:{title:"temporal technologies logo",description:"temporal technologies logo",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3g56zRXtFQYMeJxBBkVBIZ/7771670e5fc7da59f555837b086c35d6/temporal_technologies_logo.avif"},company:"Temporal Technologies",contentType:"person"}],authorsString:"Temporal Technologies",category:"Announcements",readingTime:4},{title:"Replay replay: Durable Execution, the way forward for event-driven architectures",content:"At Replay 2023, our CEO and co-founder, Max provided an enlightening keynote talk that outlined how Durable Execution is the future of event-driven architectures.\nWhether you are working within a monolith, breaking one down into services, or starting a new application from scratch, an event-driven architecture is considered the way forward for backend development. It allows engineers to deliver scalable and resilient applications that are easy to build and operate. It's great at runtime.\nHowever, the scale and resilience of an event-driven architecture is offset by the horrendous developer experience.\nTemporal and Durable Execution encapsulates most of the complexities of event-driven architecture so that developers can focus on what matters: business logic. The traditional approach of designing these systems around events holds us back and shifting your point of view to execution centered design creates a fundamentally better developer experience.\nMany of you love the dev experience allowed by Durable Execution and have already built, deployed and run dozens, and possibly hundreds of Temporal workflows. Many of you see workflows everywhere. Some of you are new to Temporal and see it can be valuable but aren't sure where to start. In this talk, Max talks through how Temporal can fit into your current architectures and where Durable Execution may be a good fit or not for your applications.\nAs only Max can, he distills these complex concepts into a more consumable set of primitives that make it fairly simple to understand and explain to your peers. You can view the talk now at our Replay Rewind site, and while you are there maybe check out talks from our product team or some of your peers!\n\n  \n",featureImage:{title:"blog post replay",description:"blog post replay",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1cVP7MLfyQAJcjtPgaLT1e/cecdbd6c74b1d1b71e6535a6a99e5d4e/blog_post_replay.png"},publishDate:"2023-10-24T00:00-06:00",metaDescription:"At Replay 2023, our CEO and co-founder, Max provided an enlightening keynote talk that outlined how Durable Execution is the future of event-driven architectures. ",metaTitle:"Replay replay: Durable Execution, the way forward for event-driven architectures",socialCard:{title:"blog post replay",description:"blog post replay",url:"https://images.ctfassets.net/0uuz8ydxyd9p/1cVP7MLfyQAJcjtPgaLT1e/cecdbd6c74b1d1b71e6535a6a99e5d4e/blog_post_replay.png"},tags:"Replay",slug:"replay-replay-durable-execution-the-way-forward-for-event-driven",contentType:"blogPost",entityId:"1hsga5V46I5dQwvUgzwpmg",authors:[{id:"1SCcHs5wmwt6kjoR3qMuGZ",name:"Jim Walker",slug:"jim-walker",jobTitle:"VP of Product Marketing",photograph:{title:"headshot-jim-walker",description:"headshot-jim-walker",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3tZdemozlmoJ8a4leDbfGX/ae3233e372bb29e7d3918b9b0d2c4bfc/Screenshot_2023-10-20_at_2.08.33_PM.png"},contentType:"person"}],authorsString:"Jim Walker",category:"Community",readingTime:2},{title:"An introduction to Worker tuning",content:"An Introduction to Worker Tuning\nWhen you were first learning Temporal, Workers probably seemed pretty simple:\n// err handling omitted for brevity\nfunc main() {\n\tc, err := client.NewClient(client.Options{})\n\tdefer c.Close()\n\n\tw := worker.New(c, \"task-queue\", worker.Options{})\n\tw.RegisterWorkflow(app.Workflow)\n\tw.RegisterActivity(app.GreetingActivity)\n\terr = w.Run(worker.InterruptCh())\n}\nThat is, register your Workflow and Activities, and then run until canceled. Is it really that simple? Regardless of whats happening behind the scenes, you inevitably grow to a point where one Worker is not enough to handle the number of new Workflows.\nWhether youre self-hosting or using Temporal Cloud, you need a pool of Workers to actually run your Workflows and Activities. This guide discusses a few Worker deployment patterns and some of the configurations that have the biggest impact on Worker performance.\nNote that, as in all production settings, performance tuning is a much more involved process than what can be covered in a single general-purpose article. This guide hopefully gives you a starting point for what to look for, but you should expect Worker tuning to be a nuanced and ongoing process.\nSetup\nThis guide assumes that youre familiar with Temporal concepts and that you have written a proof of concept Workflow or have run one or more of the sample Workflows.\nAt the end of this guide, you will have the foundational knowledge necessary for deploying and managing your own Worker Pool.\nThis guide focuses on the Workers themselves and the strategies for performance tuning Worker-side code. For server-side tuning (in the case of a self-hosted deployment of the Temporal Cluster), see this article.\nBackground Terminology\nFirst, some concepts you should be familiar with before we dive deeper.\nWorkers\nThe term \"Worker\" is used to refer to the entity that actually runs your code and makes forward progress on your Workflows and Activities. A single process can have one or many Workers.\nMost of your first Worker code is minimal: create a client, register Activities and a Workflow, and then run until shut down. But a lot happens behind the scenes, including maintaining long-poll connections to the server, caching and batch-sending Events and Commands, receiving new Tasks from the Server, emitting metrics, streaming Event Histories when necessary, and more.\nTask Queues\nTask Queues are the entities that Workers poll for more work, and its more than just a string you need to make sure is identical in multiple places. Task Queues serve as a logical separation of work, such as different types of Workflows or Activities with different functional requirements.\nTasks\nTask Queues contain Tasks created by the Temporal Server. Tasks represent and contain the context needed for a Worker to make progress. There are two types of tasks: Workflow Tasks, which include the type of the Workflow and the Event history. And Activity Tasks, which specify the Activity to run.\nCommands\nCommands are sent from Workers to the Temporal Server to indicate what needs to happen next, such as starting a Timer or scheduling an Activity to run.\nEvents\nEvents are the records of your Workflows progress and include, among other things, results of completed Commands. Events, rather than Commands, are what you see in the Workflow Execution Event History. You may commonly reference Events to see the results of an Activity: when a Worker successfully completes an Activity, it sends the results to the Temporal Server, which adds an ActivityTaskCompleted Event with those results to the Workflows history.\nThe other common use for Events is in the Worker: included in every Workflow Task is the history of events known by the server to have already completed.\nHow Workers Work\nWorkers are responsible for making progress on your Workflow and they do so by picking up Tasks from a Task Queue. These Tasks are either Workflow or Activity tasks, depending on the state of the Workflow Execution.\nWhen Workers start, they open asynchronous long-polling connections to the server to get new tasks on the specified Task Queue. In the simplest form, when a Worker receives a Task, it does the following:\n\n  Validate that the Task is not malformed (e.g., missing the Event History when it should be non-zero length)\n  Check that this Worker can run the requested work (i.e., that the Workflow or Activity types are known and valid)\n  If a Workflow Task, validate that the unseen portion of the Event History in the Task matches the known Workflow Definition (i.e., check for determinism)\n    \n      Then, run the Workflow code as far as possible (i.e., until all coroutines have yielded and are waiting on the Server)\n    \n  \n  If an Activity Task, run the Activity with the given arguments\n  Send Task Completed back to the Server and any results (e.g., an Activitys return values)\n\nAt this point, the Temporal Server records the relevant updates to this Workflow instances Event History and generates new Tasks as necessary.\nAside: Why two different types of Tasks?\nIf both Workflow and Activity Tasks follow the same patterncheck that the type is registered, then run the matching codewhy are they different?\nRecall why the concept of Activities exists in the first place: to ensure that unreliable work is isolated and doesnt cause unnecessary failures of the overall system. For many categories of unreliability, such as API or network timeouts, simply retrying until successful is all thats necessary to effectively remove that unreliability.\nThis conceptual separation between unreliable work and deterministic work necessitates the two different Task types. This allows the Activity Tasks to be substantially simpler than Workflow Tasks. It doesnt matter whether its the first time this Activity has run, the Nth time, or happening after a long Timer. The Workers job is to run the Activity specified in the Task using the provided inputs and return the results.\nA Workflow, meanwhile, must be deterministic. If its not, Temporal cannot guarantee that the Worker is running the same Workflow implementation that the Server thinks it should be. The Tasks that facilitate this, Workflow Tasks, must therefore include the information needed for the Worker to validate determinism. It cant simply execute (or, like with Activities, re-execute) the next step in the Workflow. The Worker must check that how it thinks that step is reached is how the Server thinks it was reached. This is done by comparing the Event history given in the Workflow Task to what the Worker thinks the history would be if it re-ran the Workflow. We call this process Replay.\nHow many Workers do you need?\nWhen to know you need more\nAs your application grows, it's inevitable that a single Worker won't be enough to complete all your Workflow or Activity Executions, as well see below (in fact, best practice is to always have more than one). To keep up with the increased demand, you'll need to scale up your Workers. But as it always is with capacity planning, whats the minimum number of Workers needed?\nReduced ability of Workers to start new Tasks\n\n  \n\nAbove: An example graph of the workflow_task_schedule_to_start_latency metric. At around timestamp 11:55 the number of incoming Workflows increased dramatically, causing a sizable (and growing) backlog in Workflow Tasks. At 12:05, the number of Workers was increased and the schedule_to_start latency started falling (this could also happen with an increase in the number of pollers).\nYour Workflows only make progress when Tasks are dequeued by Workers and the associated work is run. The Schedule-To-Start metric represents how long Tasks are staying, unprocessed, in the Task Queues. If its increasing or high, and your hosts are at capacity, add Workers. If your Workflow Schedule-To-Start is increasing or high and your hosts still have capacity, increase the Workers max concurrent Workflow Task configuration.\nReduced ability of Workers to run Tasks\n\n  \n\nAbove: A contrived example where Activities have started coming in too fast for the number of Worker slots to handle. Configured at 5, but drops to 0 with heavy load. (Note: this graph and the previous occurred on different days and exemplify different scenarios. They are not occurring concurrently; they should be considered as entirely distinct from each other.)\nWorker Task Slots represent how much capacity Workers have to actually do the work. When a Worker starts processing a Task, a Slot is filled. So when there are zero slots available, your Worker pool is unable to start new Tasks.\nThe worker_task_slots_available metric should always be >0. If its not, add more Workers or increase the max concurrent execution size, according to whats reported in the metrics worker_type label:\nw := worker.New(client, \"task_queue\", worker.Options{\n\t\tMaxConcurrentActivityExecutionSize:     1000, // default in the Go SDK is 1k\n\t\tMaxConcurrentWorkflowTaskExecutionSize: 1000, // default in the Go SDK is 1k\n})\n\nTheres a very remote coincidence that can occur where zero Task slots means you have a perfect balance between the ability for the Workers to complete work and the amount of incoming work. But in this coincidental balance, Tasks are still waiting in the Task Queue to be picked up by Workers. Even if that wait is a minuscule amount of time, no extra Task processing slots are available and so your application is not resilient to even the slightest increase in load.\n\nThis is not an exhaustive list of metrics or configuration values to use for determining when more Workers are needed, only the most common. For more, see the Worker Performance page in the Dev Guide and the full list of SDK and Server metrics.\nWhen to know you have too many Workers\nPerhaps counterintuitively, it is possible to have too many workers. Beyond simply paying for too many compute resources, it could mean your Workers requests to the Server for new Tasks get denied.\nThere are three things you should look at for determining if you have too many Workers:\n\n  Polling success rate\n\nThis rate, defined as\n(poll_success + poll_success_sync) \\ (poll_success + poll_success_sync + poll_timeouts)\nrepresents how often Workers request a Task from the Server, but instead of getting either a Task or a no Tasks in the queue response, the request times out.\nAn example PromQL for this rate is as follows:\n  (\n      sum by (namespace, taskqueue) (rate(poll_success[5m]))\n    +\n      sum by (namespace, taskqueue) (rate(poll_success_sync[5m]))\n  )\n/\n  (\n      sum by (namespace, taskqueue) (rate(poll_success[5m]))\n    +\n      sum by (namespace, taskqueue) (rate(poll_success_sync[5m]))\n    +\n      sum by (namespace, taskqueue) (rate(poll_timeouts[5m]))\n  )\n\nIn a well-functioning system, this rate should be at or very close to 1.0 and consistently greater than 0.95. But in reality, it's expected and normal for some percentage Worker pollers to timeout or, in a high load situation, for an acceptable timeout rate to be as low as 0.8.\n\n  Schedule-To-Start latency\n\nAs mentioned earlier in this guide, the Workflow and Activity Schedule-To-Start latencies should be consistently very low as it represents Workers ability to keep up with the number of incoming Activity and Workflow executions. The exception to this is if you are purposefully rate limiting Activities at a Workfer or Task Queue granularity; in this situation, it's expectedand is not necessarily a sign to optimize your Workersthat Schedule-To-Start latencies will be high.\nWhen low, you likely have plenty of Workers. However, when some of their requests for Tasks are timing out, then not only is a portion of your Worker pool doing nothing, its inefficiently doing nothing. (In many cases this is okay though. For example, over-provisioning to account for load spikes. As in all capacity provisioning, plan according to your specific load characteristics.)\n\n  Host load\n\nMany situations can lead to Task requests timing out, including an overloaded Worker host. And, having an overloaded Worker host is often a sign that you need more hosts.\nBut in the contrary case, where requests for Tasks are timing out while Worker host load is low (or has plenty of headroom), the Workers requests are likely being dropped. (These \"Task requests\" are the API calls the Workers make to the Temporal Server to get more work. Those specific calls are PollWorkflowTaskQueueRequest and PollActivityTaskQueueRequest.)\n\n  \n\nAbove: A set of three graphs exemplifying a situation where there are too many Worker pollers. From left to right: (1) poll success rate is near 1.0 but starts to fall. (2) Workflow and Activity Schedule-To-Start latencies are, eventually, quite low (1-3ms). (3) CPU usage during the same time period is consistently much less than 20%. In this example, Workflow Schedule-To-Start latency started relatively high, and so the operator tried to add many more pollers to their Workers. This resulted in reduced Schedule-To-Start latency and no effect on host load, but also caused >80% of Worker polls to fail. They should reduce the number of pollers and/or Workers.\nWhen all three of these factors are occurring, you likely have too many Workers. Consider reducing the number of pollers, the number of Workers, or the number of Worker hosts.\nSummary: Identifying Poor Worker Performance\nNote that the metrics listed below are only some of the indicators for measuring Worker performance. Depending on your situation and environment(s), you may find other SDK metrics or Cluster metrics useful.\n\n  \n    \n      Metric(s)\n      Metric Type\n      What to look for\n      Meaning\n    \n  \n  \n    \n      workflow_task_schedule_to_start_latency and activity_task_schedule_to_start_latency\n      SDK\n      High and/or increasing. This latency should be consistently near zero.\n      Schedule-to-Start timeout is the time between when a Task is enqueued and when it is picked up by a Worker. This time being long means that your Workers cant keep up  either increase the number of workers (if the host load is already high) or increase the number of pollers per worker.\n    \n    \n      worker_task_slots_available You should filter this metric on the worker_type tag (possible values: \"ActivityWorker\" or \"WorkflowWorker\")\n      SDK\n      Both metric types (WorkflowWorker and ActivityWorker) should be always >0\n      task_slots represents the number of executors (threads or otherwise) a Worker has available to actual run your code. In order to have room for incoming Workflows and Activities, this number should always be greater than 0.\n    \n    \n      poll_success vs poll_timeouts\n      Server\n      Underutilized Worker hosts, plus low Schedule-to-Start latencies, plus low (\u003C90%) poll success rate.\n      You may have too many workers. You might also start to see RPC call failures and rate limiting from the Temporal Server. Either way, consider reducing the number of Workers.\n    \n  \n\nConclusion\nThis guide outlines one of the most fundamental pieces of Temporal: Workers. When you dont have enough Workers, your Workflows can stall, slow down, or possibly never finish. When you have too many Workers, at best youre paying too much for compute resources; at worst, your Workers are rate limited, denying them the ability to poll for new Tasks.\nEither way, striking the balance of having the right amount of Workers can be tricky. Hopefully this guide provides you with pointers for how to find that balance in your application.\nRelated Resources\n\n  Worker Performance Development Guide\n  What is a \"Task\"?\n  What is a \"Task Queue\"?\n  What is a \"Worker Entity\"?\n  What is a \"Worker Process\"?\n  Knowledge Base article on tuning a self-hosted Temporal Server\n\nTitle image courtesy of Pop & Zebra on Unsplash.",featureImage:{title:"pop-zebra-wp81DxKUd1E-unsplash",description:"pop-zebra-wp81DxKUd1E-unsplash",url:"https://images.ctfassets.net/0uuz8ydxyd9p/EPLeWrtzfsG0q404bKGNw/a7f073a60b221cec954b9673b9fefa43/pop-zebra-wp81DxKUd1E-unsplash.jpg"},publishDate:"2023-10-23T00:00-07:00",metaTitle:"An introduction to Worker tuning",socialCard:{title:"pop-zebra-wp81DxKUd1E-unsplash (1) copy",description:"pop-zebra-wp81DxKUd1E-unsplash (1) copy",url:"https://images.ctfassets.net/0uuz8ydxyd9p/26ELbQO5QKXIu1rKTFrDzQ/45fad9757335650e6709cf3f3c75e4f8/pop-zebra-wp81DxKUd1E-unsplash__1__copy.png"},tags:"Temporal Primitives",slug:"an-introduction-to-worker-tuning",contentType:"blogPost",entityId:"1gQYqt9AMCDpkWQ94x2lqE",authors:[{id:"1V2nWXuO9AHzYzI4qmqAJ5",name:"Fitz",slug:"fitz",jobTitle:"Developer Advocate",photograph:{title:"Fitz",description:"Fitz",url:"https://images.ctfassets.net/0uuz8ydxyd9p/5rtdEzcJFPLV5Ce29uPyFb/951227c4a68cb13b1bd03c8856b1f740/fitzface_shadowed_blue-2.jpg"},contentType:"person"}],authorsString:"Fitz",category:"Temporal Concepts",readingTime:13},{title:"Replay replay: Videos live now!",content:"Last month, we held our second annual conference in beautiful Bellevue, Washington and were thankful for 450+ people that helped make it an amazing event! We are also thankful to the impressive array of speakers from both large companies like Netflix, Datadog, and Maersk, and some emerging leaders, like Grab, Logixboard, Autokitteh, and more.\nToday, we published the first set of the talks to our Replay Rewind site, so that you can view and share them with your peers and friends who may have missed out. There are twenty talks currently posted and expect many more in the next few weeks. We'll let you know as we push more live.\nYou can check out the keynote address from our Temporal CEO and co-founder Maxim Fateev, dive deep into our Temporal Cloud custom persistence layer, and hear about some exciting product updates like versioning, schedules, workflow update, multi-region cloud and more. In addition to these announcements, we've also posted the talks from teams at Yum! Brands, Twilio, Hashicorp, Retool, AWS and Microsoft!\nSo, if you are ready to gather some best practices and learn more about durable execution, tune in now.",featureImage:{title:"hero generic",description:"hero generic",url:"https://images.ctfassets.net/0uuz8ydxyd9p/6KqCaPS10y0K8mvLJzCV0U/cd5dcc25054598e3d1c9c39f47fbce5f/hero_generic.jpg"},publishDate:"2023-10-20T00:00-06:00",metaDescription:"Last month, we held our second annual conference in beautiful Bellevue, Washington and were thankful for 450+ people that helped make it an amazing event! ",metaTitle:"Replay replay: Videos live now!",socialCard:{title:"temporal replay 2023 max stage",description:"temporal replay 2023 max stage",url:"https://images.ctfassets.net/0uuz8ydxyd9p/74IMlGs2SalSK8qeqRC5dF/d2bbe37aad257dcc328c439b825b6c10/temporal_replay_2023_max_stage.png"},tags:"Replay",slug:"replay-replay-videos-live-now",contentType:"blogPost",entityId:"4PR5VpNk4qG3MmT1bL7CX",authors:[{id:"1SCcHs5wmwt6kjoR3qMuGZ",name:"Jim Walker",slug:"jim-walker",jobTitle:"VP of Product Marketing",photograph:{title:"headshot-jim-walker",description:"headshot-jim-walker",url:"https://images.ctfassets.net/0uuz8ydxyd9p/3tZdemozlmoJ8a4leDbfGX/ae3233e372bb29e7d3918b9b0d2c4bfc/Screenshot_2023-10-20_at_2.08.33_PM.png"},contentType:"person"}],authorsString:"Jim Walker",category:"Community",readingTime:1},{title:"The distributed machine",content:"The Distributed Machine\n or, Temporal from the perspective of computer architecture\nTemporal is a Game Changer\nWe've written and presented at length about the direct and significant practical impact that Temporal provides to developers writing distributed applications. It simplifies systems that would normally require sprawling microservices and makes strong guarantees around the reliability of business logic through durable execution.\nWe believe that Temporal is the next step in the natural progression of computing machines.\nOur claims may seem bold and outrageous, but when engineers start using Temporal theyconsistentlyrealize that we have something special. Let's ratchet things up a notch and see if we can get really ridiculous and still resonate with developers.\nToday I want to take a brief(1) look at the paradigm shift that came out of virtual machines, how code runs on machines, how operating systems manage programs running on a machine, and how container orchestration has replaced the role of the OS in the cloud. Then, we'll dive into how durable executionand Temporal in particularabstracts distributed processing away from applications and transforms the cloud. From a computer engineering perspective, the result is a new kind of machine beyond the physical or virtual: a distributed machine.\nFrom Physical to Virtual Machines and Containers\nIts definition time! A machine is anything that executes the instructions of a program, a program specifies a set of instructions for a machine to execute, and a process describes an actively running execution of a program on a machine. Today there are two generally accepted types of machines: physical and virtual. Before we make the case for a new type of machine, lets talk about what we have today.\nBefore virtual machines, we just had hardware. Our physical machines had operating systems installed on them and ran whatever software we needed. Multi-user operating systems didnt have very strong isolation and any changes to the operating system installed on the hardware impacted all of the users and software running on the system. As technology advanced toward the level of flexibility in managing machines that exists today, we uncovered the value of decoupling the environmentwhere software runs from the hardware we wanted to run it on.\n\nFor our purposes, were going to touch on complex topics and stop short of deeply illuminating them for the uninitiated. The goal here is to demonstrate patterns and paradigms in order to relate them to Temporal as enabling a distributed machine, not to teach computer architecture or operating system design. There are exceptions to every rule and leaks to every abstraction. Please give me some leeway to be a little general and hand wavy.\nIf these concepts pique your curiosity and you want a deeper dive, I highly recommend Computer Architecture: A Quantitative Approach by Hennessy and Patterson (just Hennessy and Patterson), The Design of the UNIX Operating System by Bach (I dont know if this one has a nickname), and Engineering a Compiler by Cooper and Torczon (theres a third edition that just came out last year I still need to check out). And its really got nothing to do with any of this, but while Im recommending important books in computing I might as well throw in The C Programming Language by Kernighan and Ritchie (just K&R), and The Art of Computer Programming by Knuth (its long - Im still working through it).\nThe virtual machine provided unprecedented flexibility in managing compute workloads on top of physical machines. Rather than reinstalling or rebuilding a physical machine, new virtual machines can be created simply by copying a file. Replacing hardware becomes much easier when you can pause a virtual machine and move it to new hardware. Containers further isolated programs in ways that divorce applications from the physical or virtual machine on which they run. Advancements like container orchestration platforms act as something like a distributed process management system, managing containers not just within a single machine, but across many machines. These technologies make it easier and easier for us to treat processes and machines as cattle rather than pets (as the adage goes), which significantly improves the recoverability and maintainability of systems.\nBut while virtual machines and containers provide incredible flexibility, running coordinated software across many machines has proven quite difficult. To take advantage of a multi-machine environment, software engineers have had to wrestle with advanced techniques in computer science like distributed consensus, resource contention and cache invalidation or make use of heavy weight technologies to hide these problems. The downside of most off the shelf solutions is that they solve only a narrow slice of the distributed systems problem space like shared storage or leader election. Developers still need to fill in all the gaps or glue a bunch of technologies together.\nTo this point, weve abstracted the idea of machines and processes with VMs and containers, but theres something missing. When I run a program, I dont really care which core or CPU or even machine it runs on (or, indeed, whether it all runs on just one machine) as long as it makes progress. If my code is running on a machine that dies, why cant my running program just keep executing on another available machine, picking up from exactly the same line of code where the former machine stopped making progress?\nTemporal provides a revolutionary, world-altering answer to this question: we say you can do exactly that. Temporal provides a solution that lets you just run your program across arbitrarily many machines as if it were a single higher level distributed machine.\nRather than executing code on any one virtual or physical machine, Temporal enables executing code on a distributed execution system thereby obviating the need to build application specific distributed systems.\nLets look a little deeper at machines and processes to talk about how this is possible.\nExecuting Code and Microservices\nWe dont need a deep understanding of how compilers or CPUs work, but to solidify our case for a distributed machine its useful to have some hand wavy idea of a couple things.\nDevelopers don't write in machine code. We rely on high-level languages and use language features like functions, loops, and datastructures to write programs that are translated into a sequence of instructions the machine can understand. To move from a high-level language to machine code, instructions are grouped into basic blocks (sequential instructions without branches) as part of a control flow graph. Breaking programs down in this way enables grouping and optimizing streams of instructions for running on the target machine.\n\n  \n\nIts also important to point out that if we just used this model of process management it would be very difficult to coordinate work across multiple independent machines all running their own OS. One system would need to serialize the state of a running program, including CPU cache and registers, as well as main memory and whatever files and sockets might have been open, and send a copy to another system to take over running the program. Doing this in a fast and efficient way is an ongoing area of research and docker offers experimental support for checkpointing running containers via CRIU.\nUntil Temporal came along, we havent been able to simply write the end-to-end logic for our distributed systems in one program. As a workaround weve learned to break down our larger programs into smaller parts and run them as microservices that communicate with one another. Breaking things apart like this enables us to run small pieces of our program in a replicated fashion to meet performance or reliability goals, but the burden on the programmer is fairly high.\nSoftware That Runs Software\nUnless youre programming performance-sensitive software for microcontrollers, youre probably not running your application directly on hardware. Operating systems do a lot of jobs. The three things we want to focus on here are:\n\n  The abstraction of available hardware\n  Enabling many programs to run at once through scheduling running applications on available resources\n  Enabling communication and coordination between multiple programs\n\nMost of us arent directly accessing hardware by writing to various addresses or setting registers on devices and dealing with sharing access with other programs; the operating system handles all of that for us. Our programs make use of language features or libraries that interact with hardware using drivers provided by the operating system. This significantly simplifies writing software. Language maintainers are able to provide higher-level features to programmers as well. These days we accept that we benefit quite significantly from running our software on software that manages the hardware.\nRunning your software alongside other applications is also something its easy to take for granted, but the operating system has to take an active role in scheduling programs on whatever CPUs and cores are available to the system. Processes get time slices to run based on various priorities, patterns, interrupts, and blocking operations. On a single core system, while applications appear to all be running at the same time, only one process at a time has its instructions actually making progress. On modern multi-core systems, the OS obviates the need to care about which core a process will execute on as well.\nThere are a variety of options that processes have to communicate with each other when they are running on the same OS. Unix-like systems have pipes, files, signals, and sockets to choose from. Some of these options are more readily available to processes that spawn subprocesses as they can easily set up those pipes and propagate signals to any child process they spawn.\nRunning software on software (in this case, an operating system) provides a lot of functionality that reduces the amount of code we need to write to take advantage of the system we are running on, and coordinate with other processes running on the same system.\nDistributed Processes vs Distributed Computing\nSystems like Googles Borg, Kubernetes (which was inspired by Borg), and Apache Mesos allow us to decouple the idea of running processes from the machines on which they run. This has given birth to what the industry has decided to call cloud native computing, ushering in an era where the abstraction layer on which we run software is no longer a single OS on a physical or virtual machine, but a container orchestration system which manages processes across many machines. The execution platform is the cloud itself, if you will.\nWhile cloud native infrastructure has improved operations dramatically, writing cloud native applications still takes a lot of effort. The fundamental operational needs are handled: pulling images, running containers, service discovery, role-based access control (RBAC), networking, and so on, but developers still need to write distributed systems to accomplish business goals on top of container orchestration.\nRather than a CPU that executes a stream of low-level instructions, in a distributed system the processing model is a higher order unit: a loosely coupled collection of machines executes multiple programs that cooperate to achieve a business objective. The smallest unit of work we distribute is a process (think Docker container) or a group of processes (think Kubernetes pod).\nDevelopers typically employ networked microservices with HTTP or RPC APIs, use queues, distributed data stores, replicated state machines, conflict-free replicated data types, leader election, or any number of other approaches to implement algorithms across the cloud to make progress on business logic. Such systems necessarily have a significant amount of complexity that exists only to handle things like consistency and durability in a distributed environment.\nThe key takeaway here is that just having a container orchestrator does not magically give you the ability to run a sequence of business logic across a variety of hardware. Managing distributed processes is necessary but not sufficient. Software currently must be coordinated as a distributed system which makes use of these distributed processes to achieve distributed computing.\nWhat Does Any of this Have to Do with Temporal?\nWeve talked about the organization and execution of programs on hardware, the role of the OS in removing the complexity of running software on hardware, and the complexity of building application-specific distributed systems.\nTemporal takes these single-machine focused concepts and elevates them to the cloud level.\nRather than handling code execution through context switching on hardware running a stream of instructions organized by a compiler, Temporal manages running your program as a series of higher-than-basic-block level tasks. We typically refer to these series of tasks as Workflows, but any program could be a Workflow because its also ultimately just a graph of instructions.\nThere are some key differences between a control flow graph of basic blocks and a Temporal Workflow as a graph of tasks. First, tasks are larger collections of instructions and they include control flow. This is important for performance and recoverability reasons as Temporal durably saves the result of every task (which can get expensive even in the best case scenario). Second, there are two types of tasks: deterministic (Workflow) and non-deterministic (Activity). The advantage of making this distinction is to enable restoration of program state. Deterministic operations can be re-executed in order to recover from failure, but non-deterministic operations need to either be retried or fail the execution of the Workflow.\n\n  \n\nReally, this is just Temporal managing a higher-level graph where the nodes are a subset of the control flow graphs of basic blocks for the whole program. This is essentially the same kind of grouping of code that compilers do to optimize for a target machine but at a higher level. Due to the complexity of balancing performance, determinism, retries, and idempotency concerns, it is up to the programmer to decide how to break down tasks, rather than a compiler. This is probably the toughest part of using Temporal right now, but its way better than building your own distributed system.\nThe process scheduling that operating systems do for a single machine, Temporal does for an arbitrary collection of one or more machines and processes regardless of where and how they run. The only requirement is to be able to communicate over gRPC with a Temporal Cluster. Instead of doing this at the single process or instruction level, Temporal handles executing the next task for a workflow 
<!-- truncated -->
